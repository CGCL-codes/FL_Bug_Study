url	label	title	all_text	comments	created_time	updated_time	closed_time
https://github.com/OpenMined/PySyft/issues/6611	['bug ', '0.2.x']	send doesn't affect Identity layers	"send doesn't affect Identity layers## Description
Identity layers, or models composed only from Identity layers, cannot be sent to a worker. It doesn't happen if there are other types of layers in the model (for example if the model has one Linear layer and one Identity layer), so I suppose this is due to Identity layers not including any tensors.
 
## How to Reproduce
bob = sy.VirtualWorker(hook, id=""bob"")
model = nn.Sequential(nn.Identity(10),nn.Identity(10))
model.send(bob)
print(model.location)
--> None

@JosephChataignon `sy.VirtualWorker` is from 0.2.x which is no longer supported."	1	2022-06-23 15:01:20	2022-06-24 01:24:53	2022-06-24 01:24:48
https://github.com/OpenMined/PySyft/issues/6418	['bug ']	hagrid launch network is not working	"hagrid launch network is not working## Description
I am using pysyft version 0.6.0 and trying to launch network using the below commands and getting errors.
1. hagrid launch network 
      getting below message in loop and network is not launching
      **control: authRoutine: backoff: 13265 msec**

2. hagrid launch United Nations --type network 
      getting below error message
      **Error: No such option: --type** 

3. hagrid launch United Nations --port 8085 --type network
      getting below error message
      **Error: No such option: --port**

I am trying to follow the below notebook from pysyft github notebooks-
    https://github.com/OpenMined/PySyft/blob/dev/notebooks/trade_demo/mock_notebooks/Part%201%20-%20Setup%20Use%20Case.ipynb

## System Information
 - OS: Linux (ubuntu 20.04)
 - Language Version: [e.g. Python 3.8]
Hi @pgupta07 those notebooks are pretty old and are mock notebooks, please see the more up to date docs here: https://openmined.github.io/PySyft/"	1	2022-04-22 08:39:28	2022-04-30 00:12:12	2022-04-30 00:12:12
https://github.com/OpenMined/PySyft/issues/6401	['bug ']	bug	"bug## Description
 No module named 'syft_proto.frameworks.torch.tensors.interpreters.v1.placeholder_pb2'

python3.7
torch1.4.0
syft0.2.3a3Syft 0.2 is no longer supported."	1	2022-04-11 06:47:57	2022-06-08 06:38:05	2022-06-08 06:38:05
https://github.com/OpenMined/PySyft/issues/6389	['bug ', '0.5']	module 'sympc' has no attribute 'merge'	"module 'sympc' has no attribute 'merge'## Description
Hi, Openmined experts,
Per to https://github.com/OpenMined/PySyft/blob/0.6.0/notebooks/trade_demo/Part%204%20-%20Perform%20JOIN%20(backed%20by%20SMPC).ipynb, 

## How to Reproduce
Run the code below,
import sympc
merged_dataset_ptr = sympc.merge(
    left=ca_filtered_dataset_ptr,
    right=it_filtered_dataset_ptr,
    on=""Commodity Code"",
    how=""inner"",
    suffixes=(""_ca"", ""_it""),
)

The following error will occurs,
AttributeError: module 'sympc' has no attribute 'merge'

I check the sourcecode from  https://github.com/OpenMined/SyMPC,  and  no method 'merge' was found. So is there anything missing from ""Part 4 - Perform JOIN (backed by SMPC).ipynb"" ? @iamtrask  Thanks!
@yuanbw 0.6 and 0.7 (dev) do not use SyMPC, instead they use a built in SMPC implementation from the same authors @gmuraru and @rasswanth-s.

@rasswanth-s what is the equivalent of `merge` in 0.7?Hi @yuanbw,
The Old Notebook was one of our Nice to have features, 

It was not fully completed, There are some example smpc examples in https://github.com/OpenMined/PySyft/tree/dev/notebooks/smpc/Training%20Demo
For the initial Training,

To work with the example you would need to launch Domain Nodes through **hagrid**,
Our current syft documentation would help you in the same 
https://openmined.github.io/PySyft/

Creating new examples notebooks for our current architecture is at the top of my `TODO` list, within one or two week , I will create good Starting notebooks for SMPC.

I am closing this issue, as the feature was not implement.
Feel to reach out to me for any questions on OM slack,
Joining link: [OM Slack](https://slack.openmined.org)
My Slack handle: `@Rasswanth`"	2	2022-04-02 09:43:02	2022-06-10 06:37:54	2022-06-10 06:37:53
https://github.com/OpenMined/PySyft/issues/6355	['bug ']	Did Pysyft tensor supports floats and string features?	"Did Pysyft tensor supports floats and string features?## Description
We require the dataset to be created in Syft tensor format to upload to the domian created by Hagrid. I am able to wrap only the integer feature in Syft tensor format but it is not accepting the float features. Screenshot attached.

## Screenshots
![image](https://user-images.githubusercontent.com/73330091/158108147-438c1a0f-fabc-4460-a3a0-950bad0b205c.png)

## System Information
OS: Debian GNU/Linux 10 (buster)
OS Version: 10
Language Version: Python 3.9.7
Package Manager Version: conda 4.10.1

@Crazynovatech we temporarily had an int32 limitation which as been changed now to int64. The underlying implementations of our DP, SMPC and FixedPrecision tensors require different things under the hood. You should be able to load in a normal numpy array in the latest version and it will take care of it. Can you try this with the latests code on `dev`?"	1	2022-03-14 05:07:09	2022-06-08 06:30:59	2022-06-08 06:30:59
https://github.com/OpenMined/PySyft/issues/6291	['bug ']	Error from the tutorials 1	"Error from the tutorials 1In first tutorial, the `sy.launch_duet` is giving a connection TimeoutError. Could you please update with the correct link?

My code- 
```
duet = sy.launch_duet(network_url=""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000/"")
```

notebook link - [here](https://github.com/OpenMined/courses/blob/foundations-of-private-computation/federated-learning/duet_basics/Duet_Basics_Data_Owner.ipynb)

Error Message-
```
ConnectionError: HTTPConnectionPool(host='ec2-18-216-8-163.us-east-2.compute.amazonaws.com', port=5000): Max retries exceeded with url: //metadata (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f04988c9b20>: Failed to establish a new connection: [Errno 110] Connection timed out'))
```


I have made opened an issue here as well - [here](https://github.com/OpenMined/courses/issues/402)Building a local Duet server can help you. #5991 @VIGNESHinZONE it was fixed recently: https://github.com/OpenMined/PySyft/issues/6286"	2	2022-02-11 13:19:58	2022-06-08 06:12:18	2022-06-08 06:12:18
https://github.com/OpenMined/PySyft/issues/6215	['bug ']	hagrid launch gets stuck at some point	"hagrid launch gets stuck at some point## Description
After running `hagrid launch d0 domain` with `hagrid==0.1.8` the console gets filled with all kind of docker and other outputs. After a few minutes it gets stuck at the output below and does not continue for at least one hour, without giving any error.

What confuses me is that setting up a domain already worked and then all of sudden it stops half way through. Is a RabbitMQ and PostgreSQL container missing (see below docker output at Additional Context)?

```
backend_stream_1  | 
backend_stream_1  | INFO:     Started server process [82]
backend_stream_1  | INFO:     Waiting for application startup.
backend_stream_1  | 2021-12-01 08:57:32 | DEBUG    | grid.logger.handler:init_logger:77: Logging to /var/log/pygrid/grid.log
backend_stream_1  | 2021-12-01 08:57:32 | INFO     | uvicorn.lifespan.on:startup:59: Application startup complete.
```

## How to Reproduce
1. Remove all docker containers and images with `docker system prune -a` (optional)
2. Activate Python virtual environment with `syft==0.6.0` and `hagrid==0.1.8`
3. `hagrid launch d0 domain`

## Expected Behavior
Starting a domain node with hagrid on the default port 8081 with default user `info@openmined.org` and password `changethis` to which I then connect via a Jupyter notebook.

## System Information
 - OS: Ubuntu
 - OS Version: 20.04.3 LTS
 - Language Version: Python 3.8.10
 - Package Manager Version: Virtual Environment

## Additional Context
Checking if the port 8081 is used with `sudo netstat -tulpn | grep 8081` does not yield any results.

The command `docker ps -a` yields the following container:
```
CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                                                                                                                                                   NAMES
696482faa828   dc941fe98248   ""waitforit -address=…""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_backend_stream_1
2fecca4e56c6   dc941fe98248   ""/start-reload.sh""       3 minutes ago   Up 3 minutes                                                                                                                                                           d0_backend_1
39271b233da6   dc941fe98248   ""waitforit -address=…""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_celeryworker_1
1c5381d1aa7a   7c399a4425a5   ""/entrypoint.sh --pr…""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_proxy_1
8b3158d72e52   9bcdabb7d998   ""sh -c '/tailscale/t…""   3 minutes ago   Up 3 minutes   0.0.0.0:80->81/tcp, :::80->81/tcp, 0.0.0.0:49172->4000/tcp, :::49172->4000/tcp, 0.0.0.0:49157->41641/udp, :::49157->41641/udp                           d0_tailscale_1
12e3c96d1752   c91dff94df48   ""docker-entrypoint.s…""   3 minutes ago   Up 3 minutes   4369/tcp, 5671/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:49170->5672/tcp, :::49170->5672/tcp, 0.0.0.0:49169->15672/tcp, :::49169->15672/tcp   d0_queue_1
d20260cc79c6   5cdca5bce5c5   ""docker-entrypoint.s…""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_frontend_1
381190bbf1a2   41283533d505   ""docker-entrypoint.s…""   3 minutes ago   Up 3 minutes   0.0.0.0:49171->5432/tcp, :::49171->5432/tcp                                                                                                             d0_db_1
b1bf9ba18e96   1a573a6da0e1   ""/entrypoint.sh""         3 minutes ago   Up 3 minutes                                                                                                                                                           d0_docker-host_1
```

When trying to connect to the domain node over the Jupyter notebook with 
```
domain = sy.login(email=""info@openmined.org"",
                      password=""changethis"",
                      port=8081)
``` 
I get the following error: 
```
Connecting to http://localhost:8081...HTTPConnectionPool(host='localhost', port=8081): Max retries exceeded with url: /api/v1/login (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26283bb8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
````hagrid==0.1.9` seems to have fixed the issue. Even though it is not yet working on ARM architectures."	1	2021-12-01 11:37:34	2021-12-03 16:45:08	2021-12-03 16:45:08
https://github.com/OpenMined/PySyft/issues/6205	[]	Give PySyft and PyGrid version for every tutorial	"Give PySyft and PyGrid version for every tutorialFor me it is hard to follow the pace of changes in PySyft and PyGrid. There are plenty tutorials and blog posts available, however the majority does not work with v0.5.0 and it seems some already use v0.6.0.

Therefore, I propose to make it mandatory for every tutorial, jupyter notebook or blog post to give at least the version of PySyft, PyGrid/Hagrid and PyTorch. Also, every data set used should be directly connected to the tutorial so it is easy to find.

For example, with v0.5.0 the `sy.login(email=""info@openmined.org"", password=""changethis"", port=8081)` returns `TypeError: login() got an unexpected keyword argument 'port'`. So I assume the tutorial [here](https://github.com/OpenMined/PySyft/blob/dev/notebooks/course3/L2_Demo.ipynb) uses v0.6.0, but it is not given anywhere. Also, when starting hagrid and then connecting to it via the web browser briefly shows that v0.6.0alpha is used, but this information is either well hidden or not given at all. 

So please make it easier for others to use your framework without the hustle to dig into the source code to understand what I am doing wrong.
True , the blogposts and tutorials does not point to the exact version for which it was created, some are pretty old.It might be hard to work with them. 

In the future blog posts we would  pin the exact version for which it was created.

Currently at this point, the best starting point to learn more about syft ecosystem , would  be start at our new course.
**Remote Data Science** : https://courses.openmined.org/courses/introduction-to-remote-data-science.
which covers most of the new API,
Feel  free to post any questions.

Closing the issue for now, reopen if necessary."	1	2021-11-29 15:07:13	2022-01-10 06:34:12	2022-01-10 06:33:31
https://github.com/OpenMined/PySyft/issues/5797	['bug ']	PyGrid PyDP example broken	"PyGrid PyDP example broken## Description
PyDP [example](https://github.com/OpenMined/PySyft/blob/dev/packages/syft/examples/pygrid/tutorials/PyDP.ipynb) doesn't work with PyGrid. It crashes every time at .get() with ""Unknown private Exception"".

## Expected Behavior
Approximate value of the float pointer should be displayed as a result of private_mean function.

## Screenshots
![image (2)](https://user-images.githubusercontent.com/52822004/126120503-fbb023fa-d1ac-4540-b1b4-7648db817aa6.png)
![image (3)](https://user-images.githubusercontent.com/52822004/126120529-36f18849-0a41-45a2-b5eb-fe0368c97278.png)

## System Information
 - OS: Windows 10, Ubuntu 20.04, iOS
 - Language Version: Python 3.8@szczepanTopolski I believe this is an issue with PyDP. Check the latest versions here: https://github.com/OpenMined/PyDP/"	1	2021-07-19 07:34:19	2022-06-08 05:51:45	2022-06-08 05:51:45
https://github.com/OpenMined/PySyft/issues/5782	['bug ']	Lint Errors (0.6 alpha branch)	"Lint Errors (0.6 alpha branch)## Description
Tox lint errors (generally styling) need to be resolved.

## How to Reproduce
1. Checkout PySyft branch: `demo_strike_team_branch_4`
2. Run `tox -e lint`

## Expected Behavior
No lint errors!

## Screenshots
`Check python ast.........................................................Failed
- hook id: check-ast
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py: failed parsing with CPython 3.9.5:

    Traceback (most recent call last):
      File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/check_ast.py"", line 20, in main
        ast.parse(f.read(), filename=filename)
      File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
        return compile(source, filename, mode, flags,
      File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py"", line 318
        False=False,
        ^
    SyntaxError: invalid syntax
    
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py: failed parsing with CPython 3.9.5:

    Traceback (most recent call last):
      File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/check_ast.py"", line 20, in main
        ast.parse(f.read(), filename=filename)
      File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
        return compile(source, filename, mode, flags,
      File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py"", line 163
        (s, end),
        ^
    SyntaxError: invalid syntax

Trim Trailing Whitespace.................................................Passed
Check docstring is first.................................................Failed
- hook id: check-docstring-first
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/transport_config.py:33 Module docstring appears after code (code seen on line 30).
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_get_stack.py:33 Module docstring appears after code (code seen on line 30).

Check JSON...............................................................Passed
Check for added large files..............................................Passed
Check Yaml...............................................................Passed
Check for merge conflicts................................................Passed
Check that executables have shebangs.....................................Failed
- hook id: check-executables-have-shebangs
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_free.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_free.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_kubectl.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_kubectl.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/tasks/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/tasks/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/tasks/containers.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/tasks/containers.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/mixins.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/mixins.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/setns.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/setns.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/core.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/core.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/handlers/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/handlers/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/tasks/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/tasks/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/parent.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/parent.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/utils.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/utils.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_local.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_local.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/loaders.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/loaders.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/connection.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/connection.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/jail.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/jail.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/target.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/target.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/services.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/services.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/docker-compose.override.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/docker-compose.override.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_get_stack.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_get_stack.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/unix.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/unix.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible.cfg: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible.cfg`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_machinectl.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_machinectl.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/su.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/su.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/profiler.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/profiler.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/fork.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/fork.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/buildah.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/buildah.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/select.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/select.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/planner.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/planner.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/minify.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/minify.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/strategy_plugins/mitogen_linear.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/strategy_plugins/mitogen_linear.py`
  If it is supposed to be executable, double-check its shebang.
README.md: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x README.md`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/fakessh.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/fakessh.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/tasks/docker.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/tasks/docker.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_sudo.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_sudo.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_fetch.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_fetch.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_ssh.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_ssh.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/module_finder.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/module_finder.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/kubectl.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/kubectl.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/docker-compose.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/docker-compose.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/docker.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/docker.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_buildah.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_buildah.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/group_vars/all/vars.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/group_vars/all/vars.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/logging.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/logging.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/ssh.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/ssh.py`
  If it is supposed to be executable, double-check its shebang.
.gitignore: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x .gitignore`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/debug.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/debug.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/site.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/site.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/master.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/master.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_doas.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_doas.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/os_fork.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/os_fork.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_jail.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_jail.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/Vagrantfile: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/Vagrantfile`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_su.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_su.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/affinity.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/affinity.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/strategy.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/strategy.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxd.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxd.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/compat/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/compat/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_linear.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_linear.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/transport_config.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/transport_config.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/runner.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/runner.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/compat/pkgutil.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/compat/pkgutil.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_setns.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_setns.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/doas.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/doas.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/scanner.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/scanner.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/compat/tokenize.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/compat/tokenize.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/handlers/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/handlers/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/parsing.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/parsing.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/service.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/service.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxc.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxc.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/lxd.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/lxd.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/tasks/system.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/tasks/system.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/process.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/process.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_host_pinned.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_host_pinned.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_docker.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_docker.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/tasks/hagrid.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/tasks/hagrid.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/lxc.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/lxc.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/sudo.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/sudo.py`
  If it is supposed to be executable, double-check its shebang.

Debug Statements (Python)................................................Failed
- hook id: debug-statements
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py - Could not parse ast

        Traceback (most recent call last):
          File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/debug_statement_hook.py"", line 55, in check_file
            ast_obj = ast.parse(f.read(), filename=filename)
          File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
            return compile(source, filename, mode, flags,
          File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py"", line 318
            False=False,
            ^
        SyntaxError: invalid syntax


packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py - Could not parse ast

        Traceback (most recent call last):
          File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/debug_statement_hook.py"", line 55, in check_file
            ast_obj = ast.parse(f.read(), filename=filename)
          File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
            return compile(source, filename, mode, flags,
          File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py"", line 163
            (s, end),
            ^
        SyntaxError: invalid syntax

Tests should end in _test.py.............................................Passed
Fix requirements.txt.....................................................Passed
isort (python)...........................................................Passed
black....................................................................Passed`

## System Information
 - OS: iOS
 - OS Version: 11.4
 - Language Version: Python 3.9.5, Node v14.17.3
 - Package Manager Version: Conda 4.10.1
 - Browser (if applicable): Not Applicable
 - Browser Version (if applicable): Not Applicable

## Additional Context
Thank you sir!"	1	2021-07-14 19:28:30	2021-07-28 01:46:51	2021-07-28 01:46:51
https://github.com/OpenMined/PySyft/issues/5772	['bug ']	AttributeError: 'NoneType' object has no attribute 'serialize'	"AttributeError: 'NoneType' object has no attribute 'serialize'## When I execute part02 in the example, I use Python file to execute it directly, prompting an error


ERROR is :AttributeError: 'NoneType' object has no attribute 'serialize'

![截屏2021-07-13 上午9 06 06](https://user-images.githubusercontent.com/49719634/125374805-5b4b0f00-e3ba-11eb-83fe-50c5ceb2dc72.png)

## System Information
 - OS: Ubuntu 20.04.1 LTS
 - OS Version: 5.4.0-77-generic
 - Language Version:python3.8.5
 -syft Version:2.9.0

## Additional Context
Add any other context about the problem here.
syft 0.2 is deprecated"	1	2021-07-13 01:12:14	2022-06-08 05:48:10	2022-06-08 05:48:09
https://github.com/OpenMined/PySyft/issues/5752	['bug ', 'pygrid']	Error returns 200 code	"Error returns 200 code## Description
[This line ](https://github.com/OpenMined/PySyft/blob/4f276a97fef6b779822437fa7d54e21ff4d8dd1a/packages/grid/apps/worker/src/main/core/services/tensor_service.py#L156) describes an error response, which gives a 200 HTTP code. Should this be `success=False`?.
@IonesioJunior can you help?The same behavior happens for `create` and `update` routes.

I can have a go.

@IonesioJuniorHello @gkaissis, glad to see you! :smiley: 

Initially, the idea of ​​returning rest codes in PyGrid messages was something in our development plan. Over time, due to planning changes and the possibility of the Syft library working with different protocols, this lost some of its semantic meaning. Currently, `status_code=200` is returned by default on all messages (unless an internal error has occurred) just to not break things.

We intend to remove this field in the next versions in order to delegate the responsibility to the frameworks of an external layer (without creating a dependency between the Syft library and the communication protocol used).

In the future, services will be developed following [this pattern](https://github.com/OpenMined/PySyft/blob/785fd8a29e6f8db20ac7b3b159b5842b4c1a8509/packages/syft/src/syft/core/node/common/node_service/dataset_manager/dataset_manager_service.py#L95)

In case of an HTTP request, the code returned will be managed by an external layer, responsible exclusively for handling messages using this protocol.

My apologies for the mistake created."	3	2021-07-02 12:58:27	2022-06-08 05:46:01	2022-06-08 05:46:01
https://github.com/OpenMined/PySyft/issues/5751	['bug ']	AttributeError: 'Tensor' object has no attribute 'locations'	"AttributeError: 'Tensor' object has no attribute 'locations'
I want to use the securenn module in pysyft, but I get an error when I use the relu and maxpool functions.
Refer to Tutorial 12-2 for training and the version of syft is 0.2.9

class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        self.conv1 = nn.Conv2d(1,16,5,1)
        self.conv2 = nn.Conv2d(16,16,5,1)
        self.fc1 = nn.Linear(256,100)
        self.fc2 =nn.Linear(100,10)
    def forward(self, x):
       # print(x.get())
        x = maxpool(relu(self.conv1(x)),2,2)
        x = maxpool(relu(self.conv2(x)),2,2)
        x = x.view(-1,256)
        x = relu(self.fc1(x))
        x = self.fc2(x)

        return nn.Softmax(x)The syft framework uses the protocol in Securenn to implement some functions in AdditivesharingTensor"	1	2021-07-02 08:03:23	2021-07-02 12:45:37	2021-07-02 12:43:54
https://github.com/OpenMined/PySyft/issues/5743	['bug ']	This page cannot be opened 	"This page cannot be opened https://github.com/OpenMined/PySyft/blob/pygrid_demo/examples/pygrid/model_inference/Model%20Inference%20PyGrid%20%2B%20SyMPC.ipynb

![image](https://user-images.githubusercontent.com/10841478/123604199-350b6800-d82d-11eb-8b35-ab52fa3d5e73.png)

These are out of date. Our docs are undergoing an update.These are out of date. Our docs are undergoing an update."	2	2021-06-28 08:24:30	2022-06-08 05:43:32	2022-06-08 05:43:27
https://github.com/OpenMined/PySyft/issues/5627	['bug ']	Large nested SyModules exceed maximum protobuf size	"Large nested SyModules exceed maximum protobuf size## Description
When nesting SyModules with many parameters, protobuf size gets too large (>2gb) and will throw a `ValueError` as a result.

## How to Reproduce

1. Make a very large SyModule (50+ million parameters, BERT sized)
2. Nest it in another SyModule
3. Execute a train plan and call `.get()` on the updated model

Minimal example:

```
import torch
from torch import nn
import syft as sy
from syft import VirtualMachine
from syft.core.plan.plan_builder import make_plan, ROOT_CLIENT
from syft import SySequential, SyModule

class MLP(SyModule):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.layers = SySequential(*[nn.Linear(2048, 2048) for _ in range(20)], input_size=(1, 2048))
        
    def forward(self, x):
        return self.layers(x=x)[0]

model = MLP(input_size=(1, 2048))
print('num_params:', sum(p.numel() for p in model.parameters())) 
# ~84 million parameters

@make_plan
def train(model=model, x=torch.randn(1, 2048)):
    opt = ROOT_CLIENT.torch.optim.SGD(model.parameters(), lr=1e-3)
    out = model(x=x)[0]
    loss = out.mean()
    loss.backward()
    opt.step()
    return [model]

# Send plan, train iteration
alice_client = sy.VirtualMachine(name=""alice"").get_client()
train_ptr = train.send(alice_client)
model_ptr = train_ptr(model=model, x=torch.randn(1, 2048))

# Issue happens here
updated_model = model_ptr.get()
```
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-909fe9935eac> in <module>
     35 
     36 # Issue happens here
---> 37 updated_model = model_ptr.get()

[...]

~/projects/PySyft/packages/syft/src/syft/lib/python/list.py in <listcomp>(.0)
    151         id_ = serialize(obj=self.id)
    152         downcasted = [downcast(value=element) for element in self.data]
--> 153         data = [serialize(obj=element, to_bytes=True) for element in downcasted]
    154         return List_PB(id=id_, data=data)
    155 

~/projects/PySyft/packages/syft/src/syft/core/common/serde/serialize.py in _serialize(obj, to_proto, to_bytes)
     63         # indent=None means no white space or \n in the serialized version
     64         # this is compatible with json.dumps(x, indent=None)
---> 65         serialized_data = is_serializable._object2proto().SerializeToString()
     66         blob: Message = DataMessage(
     67             obj_type=get_fully_qualified_name(obj=is_serializable),

ValueError: Message syft.lib.torch.Module exceeds maximum protobuf size of 2GB: 2685748983
```

Note that using a non-nested SyModule does not have the same issue here. I've not been able to make a model too large to throw a `ValueError` in a non-nested setup, my PC runs out of memory first. To test this, replace line 16 with:

```
model = SySequential(*[nn.Linear(2048, 2048) for _ in range(20)], input_size=(1, 2048))
```

## Expected Behavior
I expect the above model to be serializable.

## Screenshots


## System Information
 - OS: Ubuntu
 - OS Version: 21.04
 - Language Version: Python 3.9.5
 - Package Manager Version: conda 4.10.1
 - Browser (if applicable): -
 - Browser Version (if applicable): -

## Additional Context
Elaborating this issue a bit for #5634. A script that measures what happens to proto size when nesting SyModules:
```
from torch import nn
from syft import  SySequential, SyModule, serialize
import matplotlib.pyplot as plt
from syft import logger
logger.remove()

class Wrapper(SyModule):
    def __init__(self, module, input_size=(1, 10)):
        super().__init__(input_size=input_size)
        self.module = module
        
    def forward(self, x):
        return self.module(x=x)[0]

bytesizes = []
for n in range(10):
    model = SySequential(nn.Linear(10, 10), input_size=(1, 10))
    # Nest model in an empty SyModule n times
    for _ in range(n):
        model = Wrapper(model)
    proto = serialize(model)
    bytesizes.append(proto.ByteSize())
    
plt.plot(bytesizes)
plt.show()
```


Which shows that the protobuf size doubles every time you nest:

![14147894](https://user-images.githubusercontent.com/7243409/120592688-8e56c600-c43e-11eb-8a22-4b3d980636f0.png)"	1	2021-06-01 15:14:16	2022-06-08 05:36:30	2022-06-08 05:36:30
https://github.com/OpenMined/PySyft/issues/5608	['bug ']	AttributeError: module 'torch._C' has no attribute 'native__has_torch_function_unary'	"AttributeError: module 'torch._C' has no attribute 'native__has_torch_function_unary'## Description

When I repeat the experiment following the blog [《ENCRYPTED DEEP LEARNING CLASSIFICATION WITH PYTORCH & PYSYFT》](https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/),  I I encountered the following error:

![Screen Shot 2021-05-27 at 8 58 29 PM](https://user-images.githubusercontent.com/38783332/119829929-56c3b780-bf2e-11eb-93ef-897b8f9c1afe.png)

```
---------------------------------------------------------------------------
PureFrameworkTensorFoundError             Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    286     def send_(self, *location):
--> 287         """"""
    288         Calls send() with inplace option, but only with a single location

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in unwrap_args_from_function(attr, args, kwargs, return_args_type)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(x)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in tuple_one_fold(lambdas, args)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(i)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)

PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-99-5bcf8df4cadf> in <module>
      2 optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment
      3 for epoch in range(1, args.epochs + 1):
----> 4     train(args, model, device, federated_train_loader, optimizer, epoch)
      5     test(args, model, device, test_loader)

<ipython-input-97-9b8111af22ce> in train(args, model, device, train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
    887         """"""
    888         for name, module in self.named_children():
--> 889             yield module
    890 
    891     def named_children(self):

<ipython-input-96-ceb0955942ca> in forward(self, x)
      8 
      9     def forward(self, x):
---> 10         x = F.relu(self.conv1(x))
     11         x = F.max_pool2d(x, 2, 2)
     12         x = F.relu(self.conv2(x))

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    295         return self.send(*location, inplace=True)
    296 
--> 297     def create_pointer(
    298         self,
    299         location: BaseWorker = None,

/usr/local/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py in handle_func_command(cls, command)

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    485 
    486         Example:
--> 487             >>> import syft as sy
    488             >>> hook = sy.TorchHook(verbose=False)
    489             >>> me = hook.local_worker

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    256         :return: a pointer to the result
    257         """"""
--> 258 
    259         command, _self, args = message
    260 

/usr/local/lib/python3.7/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      5     def _send_msg(self, message, location):
      6         return location._recv_msg(message)
----> 7 
      8     def _recv_msg(self, message):
      9         return self.recv_msg(message)

/usr/local/lib/python3.7/site-packages/syft/workers/virtual.py in _recv_msg(self, message)
      8     def _recv_msg(self, message):
      9         return self.recv_msg(message)

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in recv_msg(self, bin_message)
    290             # TODO: Handle when the response is not simply a tensor
    291             # don't re-register tensors if the operation was inline
--> 292             # not only would this be inefficient, but it can cause
    293             # serious issues later on
    294             # if(_self is not None):

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in execute_command(self, message)
    430 
    431     # SECTION: convenience methods for constructing frequently used messages
--> 432 
    433     def send_obj(self, obj, location):
    434         """"""Send a torch object to a worker.

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    319                 to another worker so you can pre-initialize the location
    320                 attribute of the pointer to some other worker, but this is a
--> 321                 rare exception.
    322             id_at_location: A string or integer id of the tensor being pointed
    323                 to. Similar to location, this parameter is almost always

/usr/local/lib/python3.7/site-packages/torch/nn/functional.py in relu(input, inplace)
   1199     Sample from Gumbel(0, 1)
   1200 
-> 1201     based on
   1202     https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,
   1203     (MIT license)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    319                 to another worker so you can pre-initialize the location
    320                 attribute of the pointer to some other worker, but this is a
--> 321                 rare exception.
    322             id_at_location: A string or integer id of the tensor being pointed
    323                 to. Similar to location, this parameter is almost always

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in <module>

AttributeError: module 'torch._C' has no attribute 'native__has_torch_function_unary'
```


## System Information
 - OS:  macos 
 - Language Version:  Python 3.7
 - syft: 0.1.29a1 
 - pytorch: 1.1.0

Hi @napoay !

Thank you for your interest in Syft! Sadly, everything that is lower than `0.3.0` hit EOL and it's no longer supported. Checkout the latest releases, maybe it will suit your needs!"	1	2021-05-27 12:59:37	2021-05-28 09:32:25	2021-05-28 09:32:25
https://github.com/OpenMined/PySyft/issues/5559	['bug ']	Range test broken in Nightlies	"Range test broken in Nightlies## Description
Nightlies are broken: https://github.com/OpenMined/PySyft/runs/2570729351?check_suite_focus=true
Possibly due to this Range PR: https://github.com/OpenMined/PySyft/pull/5452 

My guess is that the tests were copied from python 3.9 CPython repo. Two things:
1) These always break across different versions because they are designed to fix regressions in older python where as we support all those versions
2) we need to add a reference to these in our LICENSE file.

See: LICENSE:
```

The following files are copied from CPython and are under the PSF license.
See here for more: https://github.com/python/cpython/blob/master/LICENSE

tests/syft/lib/python/collections/ordered_dict/ordered_dict_sanity_test.py
tests/syft/lib/python/complex/complex_test.py
tests/syft/lib/python/dict/dict_test.py
tests/syft/lib/python/float/float_test.py
tests/syft/lib/python/list/list_test.py
tests/syft/lib/python/string/string_utils_test.py
```

```
2021-05-12T22:09:09.0419344Z __________ ERROR collecting tests/syft/lib/python/range/range_test.py __________
2021-05-12T22:09:09.0421077Z ImportError while importing test module '/home/runner/work/PySyft/PySyft/tests/syft/lib/python/range/range_test.py'.
2021-05-12T22:09:09.0422155Z Hint: make sure your test modules/packages have valid Python names.
2021-05-12T22:09:09.0422873Z Traceback:
2021-05-12T22:09:09.0423672Z /opt/hostedtoolcache/Python/3.6.13/x64/lib/python3.6/importlib/__init__.py:126: in import_module
2021-05-12T22:09:09.0424842Z     return _bootstrap._gcd_import(name[level:], package, level)
2021-05-12T22:09:09.0425699Z tests/syft/lib/python/range/range_test.py:7: in <module>
2021-05-12T22:09:09.0426436Z     from test.support import ALWAYS_EQ
2021-05-12T22:09:09.0427366Z E   ImportError: cannot import name 'ALWAYS_EQ'
```

Working on fixing it, will create a PR.This is fixed."	2	2021-05-13 03:28:40	2021-06-01 07:07:43	2021-06-01 07:07:43
https://github.com/OpenMined/PySyft/issues/5530	['bug ', '0.2.x']	AttributeError: module 'syft' has no attribute 'FederatedDataset' and AttributeError: module 'syft' has no attribute 'FederatedDataLoader'	"AttributeError: module 'syft' has no attribute 'FederatedDataset' and AttributeError: module 'syft' has no attribute 'FederatedDataLoader'```

federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])
federated_test_dataset = sy.FederatedDataset([bob_test_dataset, anne_test_dataset])

federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, 
                                                shuffle=True, batch_size=BATCH_SIZE)
federated_test_loader = sy.FederatedDataLoader(federated_test_dataset, 
                                               shuffle=False, batch_size=BATCH_SIZE)

```

I trying to implement this but a have error :  
AttributeError: module 'syft' has no attribute 'FederatedDataset'

AttributeError: module 'syft' has no attribute 'FederatedDataLoader'Hi! `0.2.x` hit EOL 2 months ago, we are no longer support it.

Thank you and take a look maybe syft `0.5.0` suits your needs already!"	1	2021-05-02 13:14:48	2021-06-01 11:01:44	2021-06-01 11:01:43
https://github.com/OpenMined/PySyft/issues/5509	['bug ']	MNIST GPU training is failed	"MNIST GPU training is failed## Description
Try to run MNIST GPU training example from https://github.com/OpenMined/PySyft/tree/dev/examples/duet/mnist but failed. However, CPU training works fine.

## How to Reproduce
1. Open Data owner and Data Scientist notebook based on https://github.com/OpenMined/PySyft/tree/dev/examples/duet/mnist
2. Run Data Owner Code Part 1 to launch duet
3. Run Data Scientist Code Part 1 to join duet
4. Run Data Owner Code Part 2 to add handler
5. Run Data Scientist Code Part 2 to do training
6. Error log show both on Data Scientist training cell and Data Owner handler cell. 

## Expected Behavior
No error happened

## Screenshots
- Data Scientist
> Code
```
import time

args[""dry_run""] = True  # comment to do a full train
print(""Starting Training"")
for epoch in range(1, args[""epochs""] + 1):
    epoch_start = time.time()
    print(f""Epoch: {epoch}"")
    # remote training on model with remote_torch
    train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)
    # local testing on model with local torch
    test_local(model, torch, test_loader, test_data_length)
    scheduler.step()
    epoch_end = time.time()
    print(f""Epoch time: {int(epoch_end - epoch_start)} seconds"")
    if args[""dry_run""]:
        break
print(""Finished Training"")
```
> Error
![image](https://user-images.githubusercontent.com/3213161/115989749-72b40080-a5f2-11eb-9df7-bbcb14e43b14.png)

- Data Owner
![image](https://user-images.githubusercontent.com/3213161/115989784-9e36eb00-a5f2-11eb-9620-021fbe7431b3.png)

## System Information
 - OS: ubuntu Server
 - OS Version: LTS 18.04
 - Language Version: Python 3.6.9
 - Package Manager Version: syft = 0.5.0rc1, torch=1.8.0, torchcsprng=0.2, torchvision=0.9.0
 - Browser (if applicable): Google Chrome
 - Browser Version (if applicable):  90.0.4430.85
 
## Additional Context
Found some explanation on https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte, but failed to send data to cuda  for data_ptr and and target_ptr for the following pySyft training def.
```

def train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length):
    # + 0.5 lets us math.ceil without the import
    train_batches = round((train_data_length / args[""batch_size""]) + 0.5)
    print(f""> Running train in {train_batches} batches"")
    if model.is_local:
        print(""Training requires remote model"")
        return

    model.train()

    for batch_idx, data in enumerate(train_loader):
        data_ptr, target_ptr = data[0], data[1]
        optimizer.zero_grad()
        output = model(data_ptr)
        loss = torch_ref.nn.functional.nll_loss(output, target_ptr)
        loss.backward()
        optimizer.step()
        loss_item = loss.item()
        train_loss = loss_item.resolve_pointer_type()
        if batch_idx % args[""log_interval""] == 0:
            local_loss = None
            local_loss = train_loss.get(
                reason=""To evaluate training progress"",
                request_block=True,
                timeout_secs=5
            )
            if local_loss is not None:
                print(""Train Epoch: {} {} {:.4}"".format(epoch, batch_idx, local_loss))
            else:
                print(""Train Epoch: {} {} ?"".format(epoch, batch_idx))
        if batch_idx >= train_batches - 1:
            print(""batch_idx >= train_batches, breaking"")
            break
        if args[""dry_run""]:
            break
```
Has the problem been solved?I didn't test it for the moment so I close it."	2	2021-04-25 10:23:36	2021-07-25 23:28:57	2021-07-25 23:28:57
https://github.com/OpenMined/PySyft/issues/5507	['bug ']	AttributeError: module 'syft' has no attribute 'TensorFlowHook'	"AttributeError: module 'syft' has no attribute 'TensorFlowHook'https://stackoverflow.com/questions/67248373/attributeerror-module-syft-has-no-attribute-tensorflowhook

Which version of Syft are you using? If it is 0.2.x, switch to 0.5. PySyft has been completed revamped after 0.2 and there is no use of hooks anymore. Also, support for tensorflow was discontinued.here is my syft version from pip list
syft 0.3.0.post0.dev1298+g30278611f
syft-proto 0.5.3
syft-tensorflow 0.1.0@JozefKondas seems like you are running the wrong code for this version. Support for hooks is deprecated in `0.3.0` .  Try running the below code to create a vm and have a root user. 
```python
import syft as sy
bob_vm = sy.VirtualMachine(name=""bob"")
bob_root = bob_vm.get_root_client()
ptr = bob_root.torch.Tensor([1,2,3])
ptr = ptr.get()
print(ptr)
```
Also, syft no longer supports Tensorflow.I will use torch, thanks for help@avinsit123  could you please share me the link for syft updated documentation?"	5	2021-04-24 23:38:20	2021-09-06 20:34:57	2021-05-02 13:19:00
https://github.com/OpenMined/PySyft/issues/5470	[]	Integrate NumPy into PySyft	"Integrate NumPy into PySyft## Feature Description
This issue will eventually integrate NumPy into PySyft.

## Is your feature request related to a problem?
No, it is due to a lack of current support. 

## What alternatives have you considered?
There are presently no alternatives.

## Are you interested in working on this yourself?
Yes.

## Additional Context
The checklist will be added soon.

Is this available to work on?
This is being worked on."	2	2021-04-13 17:34:34	2021-04-21 08:49:34	2021-04-21 08:49:33
https://github.com/OpenMined/PySyft/issues/5460	['bug ']	ValueError: bytes is not a 16-char string	"ValueError: bytes is not a 16-char string## Description

The return statement `return deserialize(pb)` in function `get_model(grid_address, worker_id, request_key, model_id)` utilise in the Federated Learning model-centric example `PySyft/examples/federated-learning/model-centric/mcfl_create_plan.ipynb` gives an error `ValueError: bytes is not a 16-char string`

## Software Versions
Pygrid (latest dev branch)
Syft (0.5.0rc1)
Torch (1.8.0)
Torchvision (0.8.2)
Python - (3.7.6)

## How to Reproduce
1. Start Pygrid domain server using command `./run.sh --host localhost  --port 7000 --start_local_db`
2. Execute the NoteBook `PySyft/examples/federated-learning/model-centric/mcfl_create_plan.ipynb`
3. The following error occurs
```
 # Model 
model_params_downloaded = get_model(grid_address, worker_id, request_key, model_id) 
print(""Params shapes:"", [p.shape for p in model_params_downloaded])                                                                                            
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-22-14a183e0aa75> in <module>
      1 # Model
----> 2 model_params_downloaded = get_model(grid_address, worker_id, request_key, model_id)
      3 print(""Params shapes:"", [p.shape for p in model_params_downloaded])

<ipython-input-21-43c3f622395f> in get_model(grid_address, worker_id, request_key, model_id)
      6     pb = ListPB()
      7     pb.ParseFromString(req.content)
----> 8     return deserialize(pb)
      9 

~/anaconda3/lib/python3.7/site-packages/syft/core/common/serde/deserialize.py in _deserialize(blob, from_proto, from_bytes)
     87         traceback_and_raise(deserialization_error)
     88 
---> 89     res = _proto2object(proto=blob)
     90     return res

~/anaconda3/lib/python3.7/site-packages/syft/lib/python/list.py in _proto2object(proto)
    156     @staticmethod
    157     def _proto2object(proto: List_PB) -> ""List"":
--> 158         id_: UID = deserialize(blob=proto.id)
    159         value = []
    160         # list comprehension doesn't work since it results in a

~/anaconda3/lib/python3.7/site-packages/syft/core/common/serde/deserialize.py in _deserialize(blob, from_proto, from_bytes)
     87         traceback_and_raise(deserialization_error)
     88 
---> 89     res = _proto2object(proto=blob)
     90     return res

~/anaconda3/lib/python3.7/site-packages/syft/core/common/uid.py in _proto2object(proto)
    189             if you wish to deserialize an object.
    190         """"""
--> 191         return UID(value=uuid.UUID(bytes=proto.value))
    192 
    193     @staticmethod

~/anaconda3/lib/python3.7/uuid.py in __init__(self, hex, bytes, bytes_le, fields, int, version, is_safe)
    167         if bytes is not None:
    168             if len(bytes) != 16:
--> 169                 raise ValueError('bytes is not a 16-char string')
    170             assert isinstance(bytes, bytes_), repr(bytes)
    171             int = int_.from_bytes(bytes, byteorder='big')

ValueError: bytes is not a 16-char string
```

## Expected Behavior
Show the expected model information.

## Screenshots
If applicable, add screenshots to help explain your problem.

<img width=""933"" alt=""11"" src=""https://user-images.githubusercontent.com/12051191/114309870-0365e900-9ae9-11eb-95a7-43794d75335d.png"">

## System Information
 - OS: [ubuntu]
 - OS Version: [18.04]
 - Language Version: [Python 3.7.6]
Having a similar issue at the same point in the notebook

Any solutions yet ? @YasirArfat32@mnshmnu not yetHave you tried the same with an alternate version of PySyft?

like 0.3.0dev etc..?

@YasirArfat32Fixed in https://github.com/OpenMined/PySyft/pull/5520
Note: this error doesn't affect FL model from being hosted or later execution of training plan (in execute plan notenook).
It's just the part of notebook that demonstrates low-level interaction with pygrid and it had outdated code of how model is serialized.Please reopen as this is not yet fixed in 0.5.0 (latest release) or dev branch. The changes in #5520 still work if applied manually but currently that branch can't be merged to dev due to conflicts."	5	2021-04-11 15:21:57	2021-07-15 14:43:41	2021-05-04 06:12:06
https://github.com/OpenMined/PySyft/issues/5341	['bug ']	DictPointer.items() can't be iterated	"DictPointer.items() can't be iterated## Description
I got error when trying to iterate on `DictPointer.items()`, (while I can iterate on `ListPointer`).
## How to Reproduce
```python
# on DO side
duet.requests.add_handler(action=""accept"")

# on DS side
d = sy.lib.python.Dict({""1"":1,""2"":2})
dptr = d.send(duet)
itemsptr = dptr.items() # you get a ListPointer
itemsptr.__len__() # got error
for e in itemsptr: # got error too
    print(e)
```


## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
@tudorcebere Did we end up supporting Dicts in the `Iterator`? Seems like you can get `.len()` on the `dptr` but not on the `itemsptr` interestingly.@madhavajay Awkward, I remember solving this at some point. @xutongye fixed and added tests to be sure to not have a regression again."	2	2021-03-23 02:39:19	2021-03-23 20:07:18	2021-03-23 20:07:18
https://github.com/OpenMined/PySyft/issues/5234	['bug ']	conftest.py file is erroneous	"conftest.py file is erroneous## Description
I use ``pipenv shell`` for all the PySyft work. I was testing my ``slice`` branch from ``dev`` branch and ran ``pytest -m fast`` and got an exception.

## How to Reproduce
1. Go to PySyft repo
2. Type in ``pytest -m fast`` or ``pytest -m slow`` or ``pytest -m all`` or ``pytest -m vendor``
3. See error

## Expected Behavior
Run all the tests

## System Information
 - OS: Ubuntu 20.04 LTS
 - Language Version: Python 3.8
 - Package Manager Version: Conda latest
 
## Additional Context
The error is as follows : 
```
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest -m fast -n auto
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ cd src/syft/lib/python
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib/python$ nano bool.py
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib/python$ nano slice.py
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib/python$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest -m fast
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest -m fast -n auto
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ cd tests
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/tests$ nano conftest.py
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/tests$ pytest -m all
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
```
@dnabanita7 we use those commands in CI, so it's possible this is related to your current branch.
Are you in a particular branch you can share to test this?
Do you have a circular import or other issue in your branch?My bad! it works fine now.
What is a circular import?"	2	2021-03-02 06:14:31	2021-03-02 13:32:01	2021-03-02 13:32:00
https://github.com/OpenMined/PySyft/issues/5132	['bug ', '0.2.x']	RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()	"RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()windows 10
python 3.7.3
pytorch=1.1.0
pysyft=0.1.15a1


```
def plot_federated_graphs(diagnosis_title, losses, accuracies):
    for i in range(n_hospitals):
        plt.plot(losses[i], label=f'Hospital {i}')
    legend = plt.legend(loc='upper right', shadow=True)
    plt.title(f""{diagnosis_title} - Training Loss"")
    plt.xlabel(""Iterations"")
    plt.ylabel(""Training Loss"")
    plt.show()
    for i in range(n_hospitals):
        plt.plot(accuracies[i], label=f'Hospital {i}')
    legend = plt.legend(loc='lower right', shadow=True)
    plt.title(f""{diagnosis_title} - Training Accuracy"")
    plt.xlabel(""Iterations"")
    plt.ylabel(""Training Accuracy (Percent %)"")
    plt.show()
    
def compute_federated_accuracy(model, input, output):
    prediction = model(input)
    n_samples = prediction.shape[0]
    s = 0.
    for i in range(n_samples):
        p = 1. if prediction[i] >= 0.5 else 0.
        e = 1. if p == output[i] else 0.
        s += e
    return 100. * s / n_samples

iterations = 1000 #2000
worker_iterations = 5

def federated_learning(diagnosis_title, hospital_features, hospital_targets, test_input, test_output):
    model = LogisticRegression()
    criterion = torch.nn.BCELoss(size_average=True)
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  
    losses = [[] for i in range(n_hospitals)]
    accuracies = [[] for i in range(n_hospitals)]
    for iteration in range(iterations):
        models = [model.copy().send(hospitals[i]) for i in range(n_hospitals)]
        optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_hospitals)]
        for worker_iteration in range(worker_iterations):
            last_losses = []
            for i in range(n_hospitals):
                optimizers[i].zero_grad()
                prediction = models[i](hospital_features[i])
                loss = criterion(prediction, hospital_targets[i])
                loss.backward()
                optimizers[i].step()
                loss = loss.get().data.item()
                last_losses.append(loss)
        for i in range(n_hospitals):
            losses[i].append(last_losses[i])
            train_acc = compute_federated_accuracy(models[i], hospital_features[i], hospital_targets[i])
            accuracies[i].append(train_acc)
            models[i].move(secure_worker)
        with th.no_grad():
            avg_weight = sum([models[i].linear.weight.data for i in range(n_hospitals)]) / n_hospitals
            model.linear.weight.set_(avg_weight.get())
            avg_bias = sum([models[i].linear.bias.data for i in range(n_hospitals)]) / n_hospitals
            model.linear.bias.set_(avg_bias.get())
        if iteration % 100 == 0:
            losses_str = ['{:.4f}'.format(losses[i][-1]) for i in range(n_hospitals)]
            accuracies_str = [to_percent(accuracies[i][-1]) for i in range(n_hospitals)]
            print('Iteration={}, losses={}, accuracies={}'.format(iteration, losses_str, accuracies_str))
    plot_federated_graphs(diagnosis_title, losses, accuracies)
    test_acc = compute_accuracy(model, test_input, test_output)
    print('\nTesting Accuracy = {}'.format(to_percent(test_acc)))
    return model
model = federated_learning(diagnosis_title1, hospital_features, hospital_targets1, test_input, test_output1)
```


```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-20-f697b3c5e29b> in <module>
----> 1 model = federated_learning(diagnosis_title1, hospital_features, hospital_targets1, test_input, test_output1)

<ipython-input-19-4e11088f598e> in federated_learning(diagnosis_title, hospital_features, hospital_targets, test_input, test_output)
     35     accuracies = [[] for i in range(n_hospitals)]
     36     for iteration in range(iterations):
---> 37         models = [model.copy().send(hospitals[i]) for i in range(n_hospitals)]
     38         optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_hospitals)]
     39         for worker_iteration in range(worker_iterations):

<ipython-input-19-4e11088f598e> in <listcomp>(.0)
     35     accuracies = [[] for i in range(n_hospitals)]
     36     for iteration in range(iterations):
---> 37         models = [model.copy().send(hospitals[i]) for i in range(n_hospitals)]
     38         optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_hospitals)]
     39         for worker_iteration in range(worker_iterations):

/opt/conda/lib/python3.7/site-packages/syft/frameworks/torch/hook.py in module_send_(nn_self, dest)

/opt/conda/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in send_(self, *location)
    329             for loc in location:
    330                 children.append(self.clone().send(loc))
--> 331 
    332             output = syft.frameworks.torch.tensors.interpreters.MultiPointerTensor(
    333                 children=children

/opt/conda/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in send(self, inplace, *location)
    278                     ptr_ = self.ptr()
    279                     if ptr_ is not None:
--> 280                         ptr_.garbage_collect_data = False
    281 
    282             # we need to cache this weak reference to the pointer so that

RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()
```Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x."	1	2021-02-09 15:47:25	2021-04-21 09:21:39	2021-04-21 09:21:39
https://github.com/OpenMined/PySyft/issues/5080	['bug ', '0.5']	Duet: send a model in the store for debugging purposes.	"Duet: send a model in the store for debugging purposes.## Description
For the TenSEAL training/inference scenarios, I want to compare the encrypted results with the plain results.
More specifically, I want to evaluate N ciphertexts with a model and get their accuracy.
Then, I want to test the N underlining plaintexts with the same model and get the plain accuracy.

Then, I want to show a comparison between the plain accuracy and the encrypted accuracy. 
But for the second step, I have to share the model with the DO instance.

The model inherits sy.Module, but I cannot add tags on Duet send.

model.send(duet, tags=[""model""])
results in the error
```
TypeError: send() got an unexpected keyword argument 'tags'
```
I cannot retrieve the model_ptr otherwise

## System Information
 - Language Version: Python 3.8
@bcebere We also need something similar for Opacus so we can remotely attach the PrivacyEngine to the model. The way the SyModule currently works is its a thin veneer over the submodule layers. Perhaps we can simply create a real torch module on either side inside the SyModule to help attach all of the layers to thus providing a very real normal model to get a pointer to. The main issue is that `send` requires serialization so if we want to send the whole model we need to support sending everything the model supports where as currently we just invoke the creation of the same modules remotely. I would love some input on the best way to tackle this one.@bcebere this is resolved now that torch.nn.module is serializable properly."	2	2021-02-01 07:03:54	2021-04-21 07:51:47	2021-04-21 07:51:47
https://github.com/OpenMined/PySyft/issues/5069	['bug ', 'help wanted :wave:', '0.5', 'rescope']	Accepting requests on objects from an iterable	"Accepting requests on objects from an iterable## Description
We would like to be able to do on the DS side:
```
torch_ptr = duet.torch.Tensor([1, 2, 3])
torch_ptr[0].request(reason=""some reason"")
```
And on the DO side:
```
duet.requests[0].accept()
```
Currently, the execution fails due to unknown UID of torch_ptr[0] in the store.

## Expected Behavior
We would like to be able to get the described object.

## Additional Context
The issue will be assigned after a PR will be opened. The PR has to have the base branch the `0.4` one.Hi, I think there is a bigger bug in the functionality provided here,

When we execute the following statement from the DS side:

```
torch_ptr = duet.torch.Tensor([1, 2, 3])
```

It adds the data in the store of the Data Owner beforehand (even before administering the request itself). The Data Scientist can flood the data store of the data owner via this, an example

```
>>> duet.store.pandas
                                        ID Tags Description             object_type
0  <UID: cd63b75dfa55405eaabe28546e7b9717>  [x]      xasdad  <class 'torch.Tensor'>
1  <UID: e50520210b4244ca87eb274c4659f997>   []              <class 'torch.Tensor'>
2  <UID: 4ca9b63f45534f7a8e53bee1bec5bb96>   []              <class 'torch.Tensor'>
3  <UID: 01a56e5218884d90b0b396869959001b>   []              <class 'torch.Tensor'>
4  <UID: 38560424aacf44af834daf73b6236927>   []              <class 'torch.Tensor'>

>>> duet.store[1].get()
tensor([1., 2., 3.])
```"	1	2021-01-28 10:26:52	2022-06-08 05:13:44	2022-06-08 05:13:44
https://github.com/OpenMined/PySyft/issues/5043	['bug ', '0.5', 'rescope']	Duet: sending an object twice with the same tag results in duplicate objects	"Duet: sending an object twice with the same tag results in duplicate objects## Description
Duet: sending an object twice with the same tag results in duplicate objects, and the DS cannot retrieve it anymore.

Reproduced with the TenSEAL  notebook.

Sending the context once is fine and the DS can retrieve it
```
ctx_ptr = context.send(duet, searchable=True, tags=[""context""])
duet.store.pandas

	ID	Tags	Description
0	<UID: 5061f0db8a824e4f90c8295cc745cd0d>	[context]	
```

Running the cell again and sending the context results in a duplicate tag in the store
```
ctx_ptr = context.send(duet, searchable=True, tags=[""context""])
duet.store.pandas

	ID	Tags	Description
0	<UID: 5061f0db8a824e4f90c8295cc745cd0d>	[context]	
1	<UID: 16557f39c8cc413aacd640d50e5995af>	[context]	
```
Now the DS instance fails to get the context with
```
[2021-01-20T18:32:20.696733+0200][CRITICAL][logger] 'More than one item with tag:context'
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-10-cad91c8e2dae> in <module>
      1 # STEP 1 Get pointers to the two encrypted vectors
----> 2 ctx_ptr = duet.store[""context""]
      3 enc_v1_ptr = duet.store[""enc_v1""]
      4 enc_v2_ptr = duet.store[""enc_v2""]

~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/core/node/common/client.py in __getitem__(self, key)
    430                 return match_obj
    431             elif matches > 1:
--> 432                 traceback_and_raise(KeyError(""More than one item with tag:"" + str(key)))
    433 
    434             traceback_and_raise(KeyError(""No such request found for id:"" + str(key)))

~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
     57     except BaseException as ex:
     58         logger.debug(""failed to print exception"", ex)
---> 59     raise e
     60 
     61 

KeyError: 'More than one item with tag:context'
```


## System Information
 - OS: Ubuntu 20.04
 -  Python 3.8.5
I have some thoughts about this issue.
1. The problem is not that ""duet.store has multiple elements with same tags"". I think it's okay and reasonable.
2. And ""we can't call `duet.store['context']` when there are multiple elements with tags=['context']"" is also not the real problem. Because it's natural that syft can't figure out  which one to return when there are mutiple ones match. The right way in this case is to use `duet.store[""5061f0db8a824e4f90c8295cc745cd0d""]# use id` or `duet.store[0] # use index`.
3. But it is truly a problem that ""multiple ptrs in duet.store pointing to the same object, if we send a same object multiple times."" This is a bug we want to fix. And I have one optional solution in mind:
    1. The method `SaveObjectAction.execute_action` is where we put an object into `node.store`.
    2. In this method, before we do anything, we should first check if there already exists an object with the same id.
    3. If so, we just do nothing. Becuase the object we want to put into store is already there.
    4. Else, we do what should be done normally.@xutongye also perhaps rather than rely on ID we could look at a hash since we use that already for signing.I think we should be able to fix this with a client side registry which tracks duplicates and introduce the unique shared network `var_name`. See notion: https://www.notion.so/openmined/2021-02-10-0-5-API-Refactor-f636ae0ff25f4921a84505ac7bd97ac7"	3	2021-01-20 16:33:41	2022-06-08 05:13:32	2022-06-08 05:13:32
https://github.com/OpenMined/PySyft/issues/5041	['bug ', '0.5', 'rescope']	Transforming a StorableObject to proto and back doesn't work 	"Transforming a StorableObject to proto and back doesn't work ## Description
Using `_object2proto` on a StorableObject to create a proto, and then using `_proto2object` on the result to create a StorableObject does not work

## How to Reproduce
1. Create a StorableObject
2. Execute `StorableObject._object2proto` on it to create a proto object
3. Execute `StorableObject._proto2object` on the proto object 
4. See error

## Expected Behavior
At the end we should see a valid StorableObject

## Screenshots
```python
storable
<Storable: <UID: 7ceb6fe14a094ed7b85addfcf9de4068>>
(Pdb) proto_storable = StorableObject._object2proto(storable)
(Pdb) proto_storable
id {
  value: ""\265\264\007\253\337>D\276\260]+`G\271\025~""
}
obj_type: ""syft.core.store.storeable_object.StorableObject""
data {
  type_url: ""type.googleapis.com/syft.core.common.UID""
  value: ""\n\020|\353o\341J\tN\327\270Z\335\374\371\336@h""
}
description: ""This is a dummy id""
tags: ""dummy""
tags: ""test""
type(proto_storable)
<class 'proto.core.store.store_object_pb2.StorableObject'>
StorableObject._proto2object(proto=proto_storable)
*** ValueError: bytes is not a 16-char string
```

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.8.5
 - Package Manager Version: pip 20.0.2
 @Benardi how does this look with the new https://github.com/OpenMined/PySyft/pull/5104 changes?Since we have completely overhauled the `StorableObject` code im going to assume this isn't an issue anymore.
There"	2	2021-01-20 11:44:37	2021-02-22 06:41:27	2021-02-22 06:41:27
https://github.com/OpenMined/PySyft/issues/5024	['bug ', 'help wanted :wave:']	Flaky Duet Test	"Flaky Duet Test## Description
The test in tests/syft/grid/duet/duet_test.py can fail due to a race conditional/already used port, etc.

## How to Reproduce
Remove the `@pytest.mark.skip` decorator from the test and run it multiple times.

## Expected Behavior
The test must pass.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
I can work on this one."	1	2021-01-19 21:09:23	2021-02-08 11:56:48	2021-02-08 11:56:48
https://github.com/OpenMined/PySyft/issues/5015	['bug ', 'help wanted :wave:', 'good first issue :mortar_board:', '0.5']	Autoapprove requests made by root clients	"Autoapprove requests made by root clients## Description
Requests made by root clients in the `VirtualMachine` context should be automatically accepted.

## How to Reproduce
```
import syft as sy
alice = sy.VirtualMachine(name=""alice"")
alice_client = alice.get_root_client()

alice_client.torch.Tensor([1, 2, 3]).get(
    request_block=True,
    name=""Test""
)
```

## Expected Behavior
To receive the requested object.Hey, I want to work on this issue, can you help from where to get started?Can I work on this?@tudorcebere I am getting the following error(in screenshot) when I run your code snippet. I am not able to understand the purpose of `request_block = True` as when I use a normal `Tensor([1,2,3]).get()` I am able to retrieve the tensor from alice_client . Do you want the .get() function to still return if the `request_block` is set to `True` .
![Screenshot 2021-01-19 at 12 22 20 PM](https://user-images.githubusercontent.com/33565881/104998712-af031e00-5a51-11eb-8809-c2123344fc62.png)
Hi all!

An issue will be assigned after a PR is opened to tackle the progress/give feedback.

Open a PR and ping me where you get stuck, thank you for your interest in syft!"	4	2021-01-14 14:25:49	2021-03-10 08:15:18	2021-03-10 08:15:18
https://github.com/OpenMined/PySyft/issues/5002	['bug ', 'help wanted :wave:', 'priority: 2 - high :cold_sweat:']	Model parameters not preserving .grad property	"Model parameters not preserving .grad property## Description
`.grad` property is not preserved on a model parameters when it's downloaded locally.

## How to Reproduce

```
import syft as sy
import torch

alice = sy.VirtualMachine(name=""alice"")
alice_client = alice.get_root_client()
remote_torch = alice_client.torch

class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.fc1 = self.torch_ref.nn.Linear(100, 10)

    def forward(self, x):
        return self.fc1(x)

model = SyNet(torch)
data = torch.randn(size=(1, 100))
result = model(data)
labels = torch.randn(size=(1, 10))
loss_func = torch.nn.L1Loss()
loss = loss_func(result, labels)
loss.backward()

print(model.parameters()[-1].grad) # exists


model_ptr = model.send(alice_client)
data_ptr = data.send(alice_client)
labels_ptr = labels.send(alice_client)
results_ptr = model_ptr(data_ptr)
remote_loss_func = alice_client.torch.nn.L1Loss()
remote_loss = remote_loss_func(results_ptr, labels_ptr)
remote_loss.backward()

print(model_ptr.parameters().get()[-1].grad) # exists
print(model_ptr.get().parameters()[-1].grad) # does not exist anymore
```

## Expected Behavior
The `.grad` attribute should be present when we download the remote model.I can work on this one. Please assign it to me.PyTorch's load_state_dict breaks the computational graph, so on get(), there won't be any gradients to retrieve.

The gradients will have to be retrieved via the model_ptr.parameters().get() call."	2	2021-01-10 18:19:39	2021-01-18 10:13:55	2021-01-18 10:13:55
https://github.com/OpenMined/PySyft/issues/4961	['bug ']	Upcast for List is not recursive	"Upcast for List is not recursivehttps://github.com/OpenMined/PySyft/blob/65ba3ebe83eecc26528f1b451746ede7f6a43fc0/src/syft/lib/python/list.py#L59

```
obj = lib.python.util.downcast({1 : [None, 1, 2, 3]})
obj
```
`{1: [<syft.lib.python._SyNone object at 0x7f073b9de438>, 1, 2, 3]}`


```
lib.python.util.upcast(obj)
```
`{1: [<syft.lib.python._SyNone object at 0x7f073b9de438>, 1, 2, 3]}
`
This will be a problem if we use `{1 : [None, 1, 2, 3]} ` as function argument@NProkoptsev There is some asymmetry in upcasting and downcasting at the moment because `generate_primitive` doesn't pass through anything non primitives but instead terminates in a SyNone. Do you have an example of this actually causing an issue yet?The main problem is that
`lib.python.util.downcast(None) is None` returns `False`, so some functions may not work correctly@NProkoptsev totally understand, we battled with that for a while but since the `is` comparison relates to the actual memory address and `None` is a singleton it's impossible to provide `SyNone is None`. The recursive `upcasting` and `downcasting` on both sides can be done but we will need to go through the code and just double check we aren't relying on the current functionality. If you have already had this issue with a particular bit of code, I would be interested in seeing an example.@NProkoptsev we have a related issue which might make more sense: https://github.com/OpenMined/PySyft/issues/4854@madhavajay I don't think that this issue is relevant
Let me provide a more clear example
`type(upcast(downcast([1,2,3]))[0])` gives `syft.lib.python.Int` while it should be just `int`
I got the idea that `upcast` should be inverse of `downcast`

Here is the example with pytorch optimizer, that can use the list param_groups as an argument

This code runs successfully
```
class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.lin = nn.Linear(1,1)

    def forward(self, x):
        return self.lin(x)
    
model = SyNet(torch)

parameters = [{'params': model.parameters()[0], 'lr':0.1},
        {'params': model.parameters()[1], 'lr' : 0.01 }]

optimizer = torch.optim.Adadelta(parameters)
```

This one returns error 
```
class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.lin = nn.Linear(1,1)

    def forward(self, x):
        return self.lin(x)
    
model = SyNet(torch)
model.send(client)

parameters = [{'params': model.parameters()[0], 'lr':0.1},
        {'params': model.parameters()[1], 'lr' : 0.01 }]

optimizer = client.torch.optim.Adadelta(parameters)
```
Stacktrace:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-187-6514aa276e26> in <module>
     13         {'params': model.parameters()[1], 'lr' : 0.01 }]
     14 
---> 15 optimizer = client.torch.optim.Adadelta(parameters)
     16 
     17 

/opt/conda/lib/python3.8/site-packages/syft/ast/callable.py in __call__(self, *args, **kwargs)
     96                 )
     97 
---> 98                 self.client.send_immediate_msg_without_reply(msg=msg)
     99 
    100                 inherit_tags(

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/client.py in send_immediate_msg_without_reply(self, msg, route_index)
    256             msg = msg.sign(signing_key=self.signing_key)
    257         debug(f""> Sending {msg.pprint} {self.pprint} ➡️  {msg.address.pprint}"")
--> 258         self.routes[route_index].send_immediate_msg_without_reply(msg=msg)
    259 
    260     def send_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/route.py in send_immediate_msg_without_reply(self, msg)
    165     ) -> None:
    166         debug(f""> Routing {msg.pprint} via {self.pprint}"")
--> 167         self.connection.send_immediate_msg_without_reply(msg=msg)
    168 
    169     def send_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/virtual.py in send_immediate_msg_without_reply(self, msg)
     68         self, msg: SignedImmediateSyftMessageWithoutReply
     69     ) -> None:
---> 70         self.server.recv_immediate_msg_without_reply(msg=msg)
     71 
     72     def send_immediate_msg_with_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/virtual.py in recv_immediate_msg_without_reply(self, msg)
     38         self, msg: SignedImmediateSyftMessageWithoutReply
     39     ) -> None:
---> 40         self.node.recv_immediate_msg_without_reply(msg=msg)
     41 
     42     def recv_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/node.py in recv_immediate_msg_without_reply(self, msg)
    395         )
    396 
--> 397         self.process_message(msg=msg, router=self.immediate_msg_without_reply_router)
    398         try:
    399             pass

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/node.py in process_message(self, msg, router)
    477                 traceback_and_raise(KeyError(log))
    478 
--> 479             result = service.process(
    480                 node=self,
    481                 msg=msg.message,

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/service/obj_action_service.py in process(node, msg, verify_key)
     25         verify_key: Optional[VerifyKey] = None,
     26     ) -> None:
---> 27         msg.execute_action(node=node, verify_key=verify_key)
     28 
     29     @staticmethod

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/action/function_or_constructor_action.py in execute_action(self, node, verify_key)
    124 
    125         # execute the method with the newly upcasted args and kwargs
--> 126         result = method(*upcasted_args, **upcasted_kwargs)
    127 
    128         # to avoid circular imports

/opt/conda/lib/python3.8/site-packages/torch/optim/adadelta.py in __init__(self, params, lr, rho, eps, weight_decay)
     34 
     35         defaults = dict(lr=lr, rho=rho, eps=eps, weight_decay=weight_decay)
---> 36         super(Adadelta, self).__init__(params, defaults)
     37 
     38     @torch.no_grad()

/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py in __init__(self, params, defaults)
     50 
     51         for param_group in param_groups:
---> 52             self.add_param_group(param_group)
     53 
     54     def __getstate__(self):

/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py in add_param_group(self, param_group)
    228         for param in param_group['params']:
    229             if not isinstance(param, torch.Tensor):
--> 230                 raise TypeError(""optimizer can only optimize Tensors, ""
    231                                 ""but one of the params is "" + torch.typename(param))
    232             if not param.is_leaf:

TypeError: optimizer can only optimize Tensors, but one of the params is syft.lib.python.Dict
```

This happens because in
https://github.com/pytorch/pytorch/blob/95d2318510371523b3406ae1d4818f8f0607bbc6/torch/optim/optimizer.py#L50
param_groups[0] is `syft.lib.python.Dict` instead of `dict`

`param_groups = [{'params': param_groups}]` makes optimizer crash later with given stacktraceIt seems that it is fixed in https://github.com/OpenMined/PySyft/commit/04bd42c7ae71576f5896a9808346aa5fb533346d"	6	2020-12-29 19:42:59	2021-04-07 18:40:30	2021-04-07 18:40:29
https://github.com/OpenMined/PySyft/issues/4917	['bug ', '0.2.x']	Opacus won't work with Syft 0.2.9	"Opacus won't work with Syft 0.2.9## Description
Existing Ticket on PriMIA: https://github.com/gkaissis/PriMIA/issues/47
This still does not work, when i try to run https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/
How were they able to run both together at that time? i tried pysyft 0.2.8 + opacus 0.9.x also can not.
Any ideas on what versions of both library can work together?
@madhavajay 
Same issue here. Any tutorial for 0.2.x or 0.3.x to work with privacy engine in Opacus is really helpful. I have been waiting for 2 months so far.I have the same problem. I tried pysyft 0.2.8 + opacus 0.9.x and  pysyft 0.2.9 + opacus 0.9.x , but it still doesn't work.@bigmoumou and @cherrytora 
The current example is here:
https://github.com/OpenMined/PySyft/tree/dev/examples/differential-privacy/opacus

Its still a work in progress but you can remotely train MNIST with opacus.Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x."	5	2020-12-16 04:11:59	2021-04-21 09:21:09	2021-04-21 09:21:09
https://github.com/OpenMined/PySyft/issues/4916	['bug ', '0.2.x']	Bug in torch.square for additive shared tensor	"Bug in torch.square for additive shared tensor## Description
torch.square(t) currently fails  with encrypted-shared tensors

## How to Reproduce


`import syft as sy`
`import torch`

`hook = sy.TorchHook(torch)`

`alice = sy.VirtualWorker(hook, id=""alice"")`
`bob = sy.VirtualWorker(hook, id=""bob"")`
`crypto_provider = sy.VirtualWorker(hook, id=""crypto_provider"")`
`t = torch.tensor([1.5, 2.5])`
`t_encrypt = t.fix_precision().share(alice, bob, crypto_provider=crypto_provider, protocol=""fss"")`
`print(t_encrypt)`

Computing the mean and centering the tensor works just fine:

`t_mean = torch.mean(t_encrypt)`
`new_t = t_encrypt - t_mean `
`new_t.get().float_precision()`     # returns the correct output tensor = [-0.5, 0.5]

What if we want to square the tensor after centering:

`t_mean = torch.mean(t_encrypt) `
`new_t = t_encrypt - t_mean`
`new_t_square = torch.square(new_t)`
`new_t_square.get().float_precision()`   # returns the wrong output tensor = [-7.3e+15, -7e+15]*. 

*Tensor values vary with relative magnitude on the order of ~ e+15

The desired output tensor can be calculated as:

`new_t_square = torch.square(t - torch.mean(t))`    # returns the desired output tensor = [0.25, 0.25]

## System Information
 - OS: macOS 
 - OS Version: 10.15.6
 - Language Version: Python 3.7.9
 - Package Manager Version: Conda 4.8.4
 - Syft version: 0.2.9
 Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x."	1	2020-12-15 21:01:46	2021-04-21 09:21:06	2021-04-21 09:21:06
https://github.com/OpenMined/PySyft/issues/4904	['bug ', 'rescope']	Syft logger generates error stack due to Unicode Emojis	"Syft logger generates error stack due to Unicode Emojis## Description
While testing the Duet MNIST tutorials with latest version of syft (dev branch) I ran into the following error:

```
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=207266), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating ✉️  (RunFunctionOrConstructorAction) <UID:🚁🚃>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 68042, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=208269), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 256, 'message': '> 📡 [🏰] Launcher Client (Duet)@<UID:🚉🚈> Signing ✉️  (RunFunctionOrConstructorAction) with 🝔', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 69045, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4e1' in position 107: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=209268), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'sign', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 87, 'message': '> Signing with 🝔', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 70044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f754' in position 87: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=212265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚁🚃>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 73041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 95-96: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=213268), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 258, 'message': '> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🏰] Launcher Client (Duet)@<UID:🚉🚈> ➡️  💠 [🏰] Launcher Client (Address)', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 74044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 115-116: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=213268), 'exception': None, 'extra': {}, 'file': (name='route.py', path='e:\\repos\\pysyft\\src\\syft\\core\\io\\route.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 166, 'message': '> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)', 'module': 'route', 'name': 'syft.core.io.route', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 74044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 105-106: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=215267), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating ✉️  (RequestMessage) <UID:🙾🜏>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 76043, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=216267), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 256, 'message': '> 📡 [🏰] Launcher Client (Duet)@<UID:🚉🚈> Signing ✉️  (RequestMessage) with 🝔', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 77043, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4e1' in position 107: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=217267), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'sign', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 87, 'message': '> Signing with 🝔', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 78043, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f754' in position 87: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=225268), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🙾🜏>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 86044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 95-96: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=228265), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 258, 'message': '> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🏰] Launcher Client (Duet)@<UID:🚉🚈> ➡️  💠 [🏰] Launcher Client (Address)', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 89041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 115-116: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=228265), 'exception': None, 'extra': {}, 'file': (name='route.py', path='e:\\repos\\pysyft\\src\\syft\\core\\io\\route.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 166, 'message': '> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)', 'module': 'route', 'name': 'syft.core.io.route', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 89041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 105-106: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=344265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating ✉️  (RequestAnswerMessage) <UID:🚱🙔>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 205041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=345265), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_with_reply', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 221, 'message': '> 📡 [🏰] Launcher Client (Duet)@<UID:🚉🚈> Signing ✉️  (RequestAnswerMessage) with 🝔', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 206041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4e1' in position 104: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=345265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'sign', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 87, 'message': '> Signing with 🝔', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 206041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f754' in position 87: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=349264), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithReply) <UID:🚱🙔>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 210040, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 95-96: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=354262), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 53, 'message': '> Creating ✉️  (RequestAnswerMessage) <UID:🚲🙖>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 215038, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=357264), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': '_object2proto', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 158, 'message': '> ✉️ 🔏 -> Proto 🔢 <UID: af8d7977a5014f1c80c2cfdfd18460e4>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 218040, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 84-85: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=361265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': '_object2proto', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 158, 'message': '> ✉️ 🔏 -> Proto 🔢 <UID: fbefe4e6d0904fd881c439e3afbd02e5>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 222041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 84-85: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=364265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': '_object2proto', 'level': (name='DEBUG', no=10, icon='🐞'), 'line': 158, 'message': '> ✉️ 🔏 -> Proto 🔢 <UID: 03f3d92ec8754f9896940b581539c15f>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 225041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 84-85: character maps to <undefined>
--- End of logging error ---
```

### ⚠️ Note - The error (obviously) goes away if `sy.logging(file_path=""./syft_do.log"")` is commented out. 

I am taking a wild guess here but it seems the logger cannot handle some emojis.

## How to Reproduce
1. Run the MNIST example notebooks


## System Information
 - OS: Windows 10
 - Language Version: Python 3.8.5,
 - Syft Version - Syft Dev 0.3.0.post0.dev34+ga9a7874a

@jaintj95, this looks like its converting UTF-8 into cp1252 on windows and failing. Are you able to find the exact char sequence which fails and dump it do we can turn this into a test for all platforms and fix the issue?This should be fixed."	2	2020-12-11 10:54:01	2021-04-20 07:28:02	2021-04-20 07:28:02
https://github.com/OpenMined/PySyft/issues/4903	['bug ', '0.5']	ptr.__len__() returns None in syft 0.3.0 dev	"ptr.__len__() returns None in syft 0.3.0 dev## Description
While testing the Duet MNIST tutorials with latest version of syft (dev branch) I ran into the following error
![len](https://user-images.githubusercontent.com/36858630/101894253-e74e4b80-3bcb-11eb-98d1-fef7594c0cb2.png)


## How to Reproduce
1. Run the MNIST example notebooks
2. The error occurs on `def get_train_length(train_data_ptr)` cell in Data Scientist notebook

Also the `try-except` block seems redundant here. 

## System Information
 - OS: Windows 10
 - Language Version: Python 3.8.5, 
 - Syft Version - Syft Dev 0.3.0.post0.dev34+ga9a7874a@jaintj95. Good spot, this is most likely in the dev branch which is not 100% stable. We recently added a new __len__ getter mechanism for iterators, so this code will need to change but the API hasn't been fully worked out yet.

You can see in these cells that there is an automatically generated request in the background.
<img width=""1083"" alt=""Screen Shot 2020-12-14 at 10 25 41 am"" src=""https://user-images.githubusercontent.com/2882739/102028621-e4836e80-3df6-11eb-98c1-210e33f1d46d.png"">


<img width=""793"" alt=""Screen Shot 2020-12-14 at 10 26 00 am"" src=""https://user-images.githubusercontent.com/2882739/102028619-e0efe780-3df6-11eb-81b2-bd2397f9f2b2.png"">

I will make sure we get this example updated once we get the Iterators / Len stuff sorted.
I believe this is related to the scenario in which the request is made:
https://github.com/OpenMined/PySyft/issues/5170

This does need to be fixed.This has been solved by #5275."	3	2020-12-11 10:48:27	2021-03-10 08:05:07	2021-03-10 08:05:07
https://github.com/OpenMined/PySyft/issues/4887	['bug ', '0.2.x']	Error in PySyft Autograd for Convolution	"Error in PySyft Autograd for Convolution## Description
It looks like convolution are not handle by the PySyft 0.2.9 Custom Autograd system, resulting in poor performance for training CNN in fixed precision or in a fully private way

## How to Reproduce
Take any small CNN and train it in fixed precision over MNIST. If you observe the convolution parameters during training, they don't change.

## System Information
 - PySyft 0.2.9
Hey!
I notice the same issue on my end, and was wondering if you found any solution to this? 
I am currently using PySyft 0.2.9 (the same as you mentioned in the post). Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x."	2	2020-12-03 09:29:08	2021-04-21 09:20:58	2021-04-21 09:20:57
https://github.com/OpenMined/PySyft/issues/4802	['bug ', '0.2.x']	[WinError 10061] No connection could be made because the target machine actively refused it	"[WinError 10061] No connection could be made because the target machine actively refused it## Description
The WebsocketClientWorker refuses to connect to the mentioned port.

## How to Reproduce
1. Convert both the notebooks WebsocketServerWorker.ipynb and WebsocketClientWorker.ipynb as python files
1. Run file WebsocketServerWorker.py
2. Run file WebsocketClientWorker.py
4. See error: [WinError 10061] No connection could be made because the target machine actively refused it

## Expected Behavior
A successful connection of client to the server and exchange of data

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.7
 - Package Manager Version: pip 20.2.4
Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I’ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I’ll reopen the issue."	1	2020-11-10 12:42:26	2020-11-19 13:40:33	2020-11-19 13:40:33
https://github.com/OpenMined/PySyft/issues/4786	['bug ', '0.2.x']	comparison between FPT and AST is broken for SNN protocol	"comparison between FPT and AST is broken for SNN protocol## Description
Comparison operations mainly <, >, ==, <=, >= are broken for SNN protocol when we use it for FPT and AST.

## How to Reproduce
![Screenshot 2020-11-06 at 1 01 54 PM](https://user-images.githubusercontent.com/28955148/98338478-41d61400-2030-11eb-81be-6cac8899dfb7.png)

## Expected Behavior
it should be working as same as its working for FSS protocol
![Screenshot 2020-11-06 at 1 02 59 PM](https://user-images.githubusercontent.com/28955148/98338590-68944a80-2030-11eb-9615-7533da639108.png)
I am new to this project and wish to contribute to it I have gone through all the tutorials. Can give a try to this issueYes @ayush12gupta go ahead!@ayush12gupta updates?I read the about the implementation of snn through its paper and not trying to understand the code structureHello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I’ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I’ll reopen the issue."	5	2020-11-06 07:35:00	2020-11-19 13:40:10	2020-11-19 13:40:10
https://github.com/OpenMined/PySyft/issues/4784	['bug ', '0.2.x']	TenSEAL framework missing for CKKS encryption	"TenSEAL framework missing for CKKS encryption## Description
Trying to run the homomorphic encryption via CKKS in the OpenMined tutorial. The syft.frameworks.tenseal is missing.

## How to Reproduce
1. Go to https://blog.openmined.org/what-is-homomorphic-encryption/
2. Run the CKKS tutorial
4. See error

## Expected Behavior
Tutorial should run

## Screenshots
![Screenshot 2020-11-05 at 14 11 20](https://user-images.githubusercontent.com/51291404/98251580-c8c3b780-1f70-11eb-8b65-52c8858f9de7.png)

## System Information
 - OS: macOS Catalina
 - OS Version: 10.15.5
 - Language Version: Python 3.7
 - Package Manager Version: Venv

## Additional Context
Looking at https://github.com/OpenMined/TenSEAL/issues/19 it seems like if you want to use syft.frameworks.tenseal you have to use the [tenseal/ckksvector](https://github.com/OpenMined/PySyft/tree/tenseal/ckksvector) branch. But it seems like adding CKKSTensor won't be merged into master anytime soon due to the technical challenges faced.

I also tried running the tutorial but after using [tenseal/ckksvector](https://github.com/OpenMined/PySyft/tree/tenseal/ckksvector)  I got the following error even though the import succeeded:

![image](https://user-images.githubusercontent.com/12242041/98362780-ba83a300-2025-11eb-8635-1c515eb774a8.png)
As @boris-vasilev explained, the use of ckks isn't yet fully supported in PySyft. We are working hard on TenSEAL to make the integration as soon as possible.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I’ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I’ll reopen the issue."	3	2020-11-05 14:13:25	2020-11-19 13:39:53	2020-11-19 13:39:53
https://github.com/OpenMined/PySyft/issues/4745	['bug ', 'syft 0.3']	KeyError / Fix the FQN issue on print(duet.store)	"KeyError / Fix the FQN issue on print(duet.store)## Description

Sending a searchable SyPrimitive type seems to cause an exception when printing the store.
```
l = sy.lib.python.List()
l.send(duet, searchable=True)
print(duet.store)
```

## Definition of Done
Fixed.
This is happening with any and all classes where the fqn changes depending on import context, so we need something more permanently corrective.Still happens on classes like:
```
>>> torch.nn.modules.Sequential
<class 'torch.nn.modules.container.Sequential'>
>>> torch.nn.Sequential
<class 'torch.nn.modules.container.Sequential'>
```This also happens inside the new sy.module:
```
# module.py
def __setattr__(self, name: str, value: Union[Any, ""Module""]) -> None:
        # bug where torch.nn.modules isnt the full name on some imports
        # TODO: fix this properly
        if ""torch.nn"" in full_name_with_qualname(klass=type(value)):
            modules = self.__dict__.get(""_modules"")
            if modules is not None:
                modules[name] = value
        else:
            object.__setattr__(self, name, value)

```"	3	2020-10-28 20:59:09	2021-01-22 05:39:45	2021-01-22 05:39:45
https://github.com/OpenMined/PySyft/issues/4742	['bug ', '0.5']	Duet Network Exception	"Duet Network Exception## Description
This sometimes happens when using the MNIST notebooks, but doesn't seem to cause any issue. I guess there is a problem with the internal state sometimes and this exception isn't being caught.
```
Exception in callback Transaction.__retry()
handle: <TimerHandle when=156.343500133 Transaction.__retry()>
Traceback (most recent call last):
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/nest_asyncio.py"", line 198, in run
    ctx.run(self._callback, *self._args)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aioice/stun.py"", line 299, in __retry
    self.__future.set_exception(TransactionTimeout())
  File ""/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/futures.py"", line 246, in set_exception
    raise exceptions.InvalidStateError(f'{self._state}: {self!r}')
asyncio.exceptions.InvalidStateError: FINISHED: <Future finished result=(Message(messa...\x8c\xe8\xd1'), ('192.168.176.153', 64677))>
```

## Definition of Done
Figure out how to repeat and setup exception handling to prevent this from displaying in the notebook.
Another similar one:
```
Task exception was never retrieved
future: <Task finished name='Task-47763' coro=<RTCSctpTransport._transmit() done, defined at /Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py:1505> exception=ConnectionError('Cannot send encrypted data, not connected')>
Traceback (most recent call last):
  File ""/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/tasks.py"", line 280, in __step
    result = coro.send(None)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py"", line 1539, in _transmit
    await self._send_chunk(chunk)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py"", line 1339, in _send_chunk
    await self.__transport._send_data(
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py"", line 655, in _send_data
    raise ConnectionError(""Cannot send encrypted data, not connected"")
ConnectionError: Cannot send encrypted data, not connected
```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-10-28 09:33:18	2022-06-08 05:02:26	2022-06-08 05:02:26
https://github.com/OpenMined/PySyft/issues/4735	['bug ', 'syft 0.3']	Replicate and Document Issue on Ubuntu with GPU during Training	"Replicate and Document Issue on Ubuntu with GPU during Training## Description
There seems to be some bug / exception happening, but I need to detail and replicate it better.
It occurs on my VM on GCE with Ubuntu and a GPU during the MNIST duet notebooks, but not on CPU on my Macbook.

## Definition of Done
Figure out what this bug is and document how to re-produce / solve it.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Last check worked, so we can close this until the GPU CI tests."	2	2020-10-28 00:38:44	2021-02-18 08:20:31	2021-02-18 08:20:31
https://github.com/OpenMined/PySyft/issues/4734	['bug ', 'good first issue :mortar_board:']	Duplicate Request after .get() is successful causes Issue	"Duplicate Request after .get() is successful causes Issue## Description
When you keep a local reference to a pointer, then fetch the item and then make a request again you can get into a bad state.

DO:

```
x = sy.lib.python.Int(1)
x.send(duet, searchable=True)
duet.requests.add_handler(
    action=""accept""
)
```

DS:

```
x = duet.store[0]
x.request()
y = x.get()
...
x.request() <---- this ID doesnt exist so this request causes a looping exception on the DO
```

Prevent `.request()` working on a deleted obj, just like garbage collection when disabled.

## Definition of Done
This should not cause any major issues to the state of the notebook and a test should be written to ensure the correct behaviour occurs.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This should be handled by the client registry.Hi @madhavajay, I'm new to the community and I'd like to be assigned to this issue if possible :)Hey @madhavajay! Just wanted to confirm, is it the case that this issue is no longer open to new contributors?"	5	2020-10-28 00:36:43	2022-06-08 05:02:18	2022-06-08 05:02:18
https://github.com/OpenMined/PySyft/issues/4676	['bug ', 'priority: 2 - high :cold_sweat:', 'severity: 1 - critical :fire:']	torch ops not working with smpc	"torch ops not working with smpc## Description
torch ops like relu and argmax etc are not working during encrypted training on encrypted data (using smpc)

these are working if we pass protocol = `fss` during encryption but earlier it used to work with default protocols
## How to Reproduce
used below model with oygrid nodes

```
class Classifier(sy.Plan):
    def __init__(self, in_features, out_features):
        super(Classifier, self).__init__()
        self.fc = torch.nn.Linear(in_features, out_features)
    def forward(self, x):
        logits = self.fc(x)
        probs =F.relu(logits)
        return probs, logits                                                                    
# Create the classifer 
classifier = Classifier(in_features = 300, out_features = 2)
# Apply SMPC encryption
classifier = classifier.fix_precision()\
                       .share(bob, alice, 
                              crypto_provider = james,
                              requires_grad = True,
                             )

```


## Screenshots
```
KeyError                                  Traceback (most recent call last)
<ipython-input-55-c062504472ad> in <module>
     10 
     11         # Predict sentiment probabilities
---> 12         probs, logits = classifier(vectors)
     13 
     14         # Compute loss and accuracy
~/Anton/OpenMined/PySyft/syft/execution/plan.py in __call__(self, *args)
    376             if self.include_state:
    377                 args = (*args, self.state)
--> 378             return self.forward(*args)
    379         else:
    380             if self.validate_input_types:
<ipython-input-52-1607ff94b4a2> in forward(self, x)
     17         logits = self.fc(x)
     18 
---> 19         probs =F.relu(logits)
     20 
     21         return probs, logits
~/Anton/OpenMined/PySyft/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)
    344                 handle_func_command = syft.framework.Tensor.handle_func_command
    345 
--> 346             response = handle_func_command(command)
    347 
    348             return response
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    439             # Send it to the appropriate class and get the response
    440             try:
--> 441                 response = new_type.handle_func_command(new_command)
    442             except RuntimeError:
    443                 # Change the library path to avoid errors on layers like AvgPooling
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py in handle_func_command(cls, command)
    292 
    293         if cmd is not None:
--> 294             return cmd(*args_, **kwargs_)
    295 
    296         # Replace all AutogradTensor with their child attribute
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py in relu(tensor, **kwargs)
    257 
    258                 def relu(tensor, **kwargs):
--> 259                     return tensor.relu()
    260 
    261                 module.relu = relu
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py in method_with_grad(*args, **kwargs)
    161                 )
    162 
--> 163                 result = getattr(new_self, name)(*new_args, **new_kwargs)
    164 
    165                 # Put back SyftTensor on the tensors found in the response
~/Anton/OpenMined/PySyft/syft/generic/frameworks/hook/hook.py in overloaded_syft_method(self, *args, **kwargs)
    110 
    111             # Send it to the appropriate class and get the response
--> 112             response = getattr(new_self, attr)(*new_args, **new_kwargs)
    113 
    114             # For inplace methods, just directly return self
~/Anton/OpenMined/PySyft/syft/frameworks/torch/mpc/__init__.py in method(self, *args, **kwargs)
     32 
     33         def method(self, *args, **kwargs):
---> 34             f = protocol_store[(name, self.protocol)]
     35             return f(self, *args, **kwargs)
     36 
KeyError: ('AdditiveSharingTensor.relu', None)

```

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: latest master branch of Pysyft (0.2.9_
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
Hi @Nilanshrajput I just tried this on my machine and its working and as discussed with you we can close this issue :) Yup closing it, thanks."	2	2020-10-19 13:04:40	2020-11-06 08:40:15	2020-11-06 08:40:15
https://github.com/OpenMined/PySyft/issues/4673	['bug ']	Tutorial Part 11 - Secure Deep Learning Classification runs into a EmptyCryptoPrimitiveStoreError	"Tutorial Part 11 - Secure Deep Learning Classification runs into a EmptyCryptoPrimitiveStoreError ## Description
Tutorial [Part 11 - Secure Deep Learning Classification](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2011%20-%20Secure%20Deep%20Learning%20Classification.ipynb) runs into an EmptyCryptoPrimitiveStoreError.

## How to Reproduce
Just running the tutorial as it is produces this error.


## Screenshots
If applicable, add screenshots to help explain your problem.
![image](https://user-images.githubusercontent.com/51778760/96413765-bd9b2880-1209-11eb-9677-b89f99f0ac59.png)


## System Information
syft version 0.2.5
torch version 1.4.0




Thank you for opening this!Hi @Bhuvan-21 just checked this notebook, runs perfectly on my machine. Please upgrade to the latest syft master, I am sure it will no longer throw this error. @Bhuvan-21 is this problem still showing up?Closing! Unable to get output from the author."	4	2020-10-19 07:23:01	2020-11-12 18:32:50	2020-11-12 18:32:50
https://github.com/OpenMined/PySyft/issues/4671	['bug ', 'good first issue :mortar_board:', 'severity: 1 - critical :fire:', 'syft 0.3']	Fix broken float tests	"Fix broken float tests## Description
There are two tests marked `@pytest.mark.xfail` in id_test.py which need to be fixed.

## How to Reproduce
Remove the annotations marked `@pytest.mark.xfail` then run the fast tests:
```
$ pytest -m fast
```

## Expected Behavior
Tests should pass

## Definition of Done
PR should be posted with passing test suite and `@pytest.mark.xfail` annotations removed.
If there is a good reason these tests cannot pass that should be documented and then explained here.
Can I work on this? @madhavajay Sure @rajathpatel23. Assigned it to you :+1: It is the ```syft_0.3.0``` branchThank you @gmuraru @rajathpatel23 Yes, this is for 0.3 but contributions are welcome. If you checkout syft_0.3.0 and then branch from there and make this change that would be amazing. Just a note, the ""slow"" tests are currently failing on the 0.3.0 branch which i am fixing now in another PR, so don't be surprised if that happens. This task only applies to the fast tests.

Also this might not be the easiest task for starting on the 0.3 code base, so sorry if I labelled it that way, its hard to know if the work has been done yet or it's just still left off. Feel free to try or if you don't want to thats also okay. 😊

If you have any questions just write them here or ping me on slack and I can try to help.@madhavajay , cool I would like to give it a try for next couple of days, if I do not make progress we can handover it to someone, does that work ?@madhavajay I was not able to make progress on this, we can assign it somone."	7	2020-10-18 23:15:06	2020-11-02 06:03:02	2020-11-02 06:03:02
https://github.com/OpenMined/PySyft/issues/4657	['bug ']	Unable to host model for Model Centric FL when using manually started grid network	"Unable to host model for Model Centric FL when using manually started grid network## Description
I have manually started PyGrid network using:
`./run.sh --port 7000 --start_local_db`

I am also using Part 01 - Create Plan.ipynb notebook and I am unable to send model to the network for hosting when I execute the following:
```
response = grid.host_federated_training(
    model=model_params_state,
    client_plans={'training_plan': training_plan},
    client_protocols={},
    server_averaging_plan=avg_plan,
    client_config=client_config,
    server_config=server_config
)
print(""Host response:"", response) 
```

The error that I get in the notebook states:
`Host response: {'status': 'error', 'message': 'Invalid request format!'}
`
However, on the server running grid network, I get 
`Message:  {'type': 'model-centric/host-training', 'data': {'model': 'XXXX`, 'plans': {'training_plan': 'XXXX'},  'protocols': {}, 'averaging_plan': 'XXXX', 'client_config': {'name': 'mnist', 'version': '1.0.0', 'batch_size': 64, 'lr': 0.005, 'max_updates': 100}, 'server_config': {'min_workers': 5, 'max_workers': 5, 'pool_selection': 'random', 'do_not_reuse_workers_until_cycle': 6, 'cycle_length': 28800, 'num_cycles': 5, 'max_diffs': 1, 'minimum_upload_speed': 0, 'minimum_download_speed': 0, 'iterative_plan': True}}}

##### I have replaced the long strings for model, plans and averaging_plan with 'XXXX'

## How to Reproduce
1. Start the Grid network manually using `./run.sh --port 7000 --start_local_db`
2. Run 'Part - 01 - Create Plan.ipynb' inside model centric tutorials
3. Error will occur in code cell 17 containing:
```
response = grid.host_federated_training(
    model=model_params_state,
    client_plans={'training_plan': training_plan},
    client_protocols={},
    server_averaging_plan=avg_plan,
    client_config=client_config,
    server_config=server_config
)
print(""Host response:"", response) 
```
4. See error - Host response: {'status': 'error', 'message': 'Invalid request format!'}

## Expected Behavior
Status : success  

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.7
 - Package Manager Version: Conda 4.8.3, Poetry 1.1.3
 - Browser (if applicable): Firefox
 - Browser Version (if applicable): 81.0.2

## Additional Context
It does not matter if the grid network is running on a different system or on the same system running Jupyter notebook, same thing happens.@IonesioJunior ^^ if you have any ideaGot it to work, I was using Network instead of Node app from PyGrid. Thanks @gmuraru anyway! Great!"	3	2020-10-18 02:29:57	2020-10-19 07:47:02	2020-10-18 20:42:28
https://github.com/OpenMined/PySyft/issues/4624	['bug ', '0.2.x']	'IndexError: list index out of range' occurs whenever I try to do websocket connection.	"'IndexError: list index out of range' occurs whenever I try to do websocket connection.## Description
Hi, I'm attempting to do federated learing tutorial using websocket communication. I used 2 Raspberry Pi 4 to do this. 

I followed the instructions written in here; https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis,
but It threw an error. 

## How to Reproduce
I was using Docker env(arm32v7/python:3.7-slim) on Raspberry Pi 4s running **run_websocket_server.py** and central coordinator runs this notebook : https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/Federated%20Recurrent%20Neural%20Network.ipynb

First time, I used 
**python 3.7**
**run_websocket_server.py from branch 0.2.3a**(https://github.com/OpenMined/PySyft/blob/0.1.23a/examples/tutorials/advanced/websockets-example-MNIST/run_websocket_server.py)
**syft 0.1.13a**
**torch 1.0.0**
**torchvision 0.2.2.post3**

and this kind of error happened.

```2020-10-01 09:56:21,437 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
2020-10-01 09:56:21,674 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
2020-10-01 10:15:40,288 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
2020-10-01 10:15:40,513 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
```

Then second time, I used
**python 3.7**
**run_websocket_server.py from master branch**
**syft 0.2.3**
**torch 1.4.0**
**torchvision 0.5.0**

and similar error happened.
```
2020-10-05 04:29:26,743 ERROR base_events.py(l:1619, p:12) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=KeyError(53)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 309, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 69, in deserialize
    return strategy(binary, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 369, in deserialize
    return _deserialize_msgpack_simple(simple_objects, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 360, in _deserialize_msgpack_simple
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 460, in _detail
    return detailers[obj[0]](worker, obj[1], **kwargs)
KeyError: 53
2020-10-05 04:29:26,972 ERROR base_events.py(l:1619, p:12) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=KeyError(53)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 309, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 69, in deserialize
    return strategy(binary, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 369, in deserialize
    return _deserialize_msgpack_simple(simple_objects, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 360, in _deserialize_msgpack_simple
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 460, in _detail
    return detailers[obj[0]](worker, obj[1], **kwargs)
KeyError: 53
```

Error occurs right after the worker devices(RPi) receive a message from central device. Can you give me some advice about this situation?

+)
Error at the centeral deveice is like below
```
2020-10-05 16:01:10,413 WARNING websocket_client.py(l:107) - Websocket connection closed (worker: alice)
2020-10-05 16:01:10,537 WARNING websocket_client.py(l:112) - Created new websocket connection
Traceback (most recent call last):
  File ""<file path...>/run_websocket_client(0.2.3).py"", line 280, in <module>
    main()
  File ""<file path...>/run_websocket_client(0.2.3).py"", line 218, in main
    alice = WebsocketClientWorker(id=""alice"", port=10002, **a_kwargs_websocket)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 66, in __init__
    self.connect()
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 79, in connect
    self._log_msgs_remote(self.log_msgs)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 145, in _log_msgs_remote
    return self._send_msg_and_deserialize(""_log_msgs"", value=value)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 126, in _send_msg_and_deserialize
    response = self._send_msg(serialized_message)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 93, in _send_msg
    return self._recv_msg(message)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 117, in _recv_msg
    ""Websocket connection closed and creation of new connection failed.""
RuntimeError: Websocket connection closed and creation of new connection failed.

Process finished with exit code 1
```

## Expected Behavior
When I tested it in local environment(without using RPis) It worked perfectly. 

## System Information
 - OS: Devian (Docker : https://hub.docker.com/r/arm32v7/python/)
 - Language Version:  Python 3.7
 - Package Manager Version: Written above

## Additional Context

I was filled with hope that it would be succesful, but after got this thing my heart's broken.... plz help me....

@IonesioJunior do you have any idea?Is it open to fix then I want to give a trySure! Assigned it to you @sparkingdark Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I’ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I’ll reopen the issue.Okay I will inform you soon... @cereallarceny and btw I am not on slack,can you send me a invite"	5	2020-10-01 14:26:23	2020-12-01 14:00:56	2020-11-19 13:36:23
https://github.com/OpenMined/PySyft/issues/4623	['bug ', 'good first issue :mortar_board:', 'hacktoberfest']	"Sending private tensors throws and error when only one user is listed in ""allowed_users"" "	"Sending private tensors throws and error when only one user is listed in ""allowed_users"" ## Description
After creating a private tensor, I get a `SendNotPermittedError` when trying to send the data to the node if only one user is listed in allowed_users.

## How to Reproduce
`private_dataset = th.tensor([1, 3.5, 47.3]).private_tensor(allowed_users = (""Alice""))
private_dataset = private_dataset.tag('#my_data')
data_pointer = private_dataset.send(site, user='Alice')`

## Expected Behavior
Possibility to define only one allowed user.

## Additional Context
To overcome this issue I am currently listing the same user twice. For instance, `allowed_users = (""Alice"", ""Alice"")`
Thank you for reporting this :+1: I will take this one.:raised_hands: actually this not a bug, private tensor expects a list of users, `private_tensor(allowed_users = (""Alice"")) ` and here you are passing a string basically which converts to 5 users ['A', 'l' ....], 

either pass a list or tuple. for tuple with single element you need to use this format `(""Alice"",)` ,   `(""Alice"")` this is just a string
`private_tensor(allowed_users = (""Alice"",)) ` this will work
or better `private_tensor(allowed_users = [""Alice""]) `Thank you for looking into this. I think we can close it!@gmuraru  should i add a method to convert string to list explicitly?
so you can pass a string also, and passing string for single user looks betterNope, I think it is fine because the parameter name ```allowed_users``` allude to a list/tuple of user namescool np"	8	2020-10-01 08:15:58	2020-10-01 14:27:49	2020-10-01 14:24:56
https://github.com/OpenMined/PySyft/issues/4616	['bug ', 'status: available :wave:', 'hacktoberfest', '0.2.x']	SVD is returning 4 pointers instead of 3	"SVD is returning 4 pointers instead of 3## Description
When sending a tensor to a worker and performing SVD, returns four pointers instead of three. Also, the third one is not gettable. By experimentation, I have had to solve the issue using `U, s, _, V = x.svd()`.

## How to Reproduce
```python
import torch
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id='bob')

x = torch.rand(250, 84).send(bob)  # Synthetic tensor
x.svd()

# Output:
# ((Wrapper)>[PointerTensor | me:88822589827 -> bob:10423896311],
#  (Wrapper)>[PointerTensor | me:22528885369 -> bob:34285527022],
#  (Wrapper)>[PointerTensor | me:46709676193 -> bob:67244907535],
#  (Wrapper)>[PointerTensor | me:235847656 -> bob:15738446586])
```

## Expected Behavior
Should return **three** pointers: `U, s, V = x.svd()`

## System Information
 - Official released Docker container
 - Same for pip package:
   - Ubuntu 18.04.5 LTS (Bionic Beaver)
   - Python 3.6.9this is pretty weird I run this code in debug mode, stepped into every function, the things seemed correct while computing the response (3 tensors were returned),  and in the end got this error : (which shows things were correct 3 tensor returned as expected)
```
Exception has occurred: ValueError
not enough values to unpack (expected 4, got 3)
  File ""/home/nilansh/Anton/OpenMined/PySyft/debug.py"", line 8, in <module>
    U, s, _, V = x.svd()

```

but returns 4 values when run as normal python code.

@LaRiffle  want to work on it.@sssilvar could you test this? It should be solved on on the 0.2.x branchHello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I’ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I’ll reopen the issue."	4	2020-09-28 14:38:42	2020-11-19 13:36:07	2020-11-19 13:36:07
https://github.com/OpenMined/PySyft/issues/4585	['bug ', 'priority: 4 - low :sunglasses:', '0.2.x']	Protobuf serialization mode seems broken	"Protobuf serialization mode seems broken## Description
Have any of you used the protobuf serialization mode instead of the msgpack one?
I know we have one, but I switch to this mode by doing in `syft/serde/serde.py`
```
from syft.serde.msgpack import serialize as msgpack_serialize
from syft.serde.msgpack import deserialize as msgpack_deserialize
```
-> 
```
from syft.serde.protobuf import serialize as msgpack_serialize
from syft.serde.protobuf import deserialize as msgpack_deserialize
```

## How to Reproduce
I have tons of weird errors on the simple example:
```
message = th.tensor([[1., 2], [3, 4]])
message.send(alice).get()
```

This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue."	2	2020-09-22 14:53:25	2020-11-19 13:31:08	2020-11-19 13:31:08
https://github.com/OpenMined/PySyft/issues/4579	['bug ']	"I got problems while I'm executing ""examples/tutorials/advanced/websockets_mnist/"""	"I got problems while I'm executing ""examples/tutorials/advanced/websockets_mnist/""Hi, there.

While I was following the tutorial ""examples/tutorials/advanced/websockets_mnist/"", I got some problems and I'm here to ask one of those.

_Question is_ 
whenever I execute ""start_websocket_servers.py"" I get **""TypeError: argument of type 'WindowsPath' is not iterable""**
Is this related with FILE_PATH object?

For your convinience, I attached the codes and error messages below

```
import subprocess
import sys
from pathlib import Path

python = Path(sys.executable).name

FILE_PATH = Path(__file__).resolve().parent.joinpath(""run_websocket_server.py"")

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]

call_bob = [python, FILE_PATH, ""--port"", ""8778"", ""--id"", ""bob""]

call_charlie = [python, FILE_PATH, ""--port"", ""8779"", ""--id"", ""charlie""]


print(""Starting server for Alice"")
subprocess.Popen(call_alice)

print(""Starting server for Bob"")
subprocess.Popen(call_bob)

print(""Starting server for Charlie"")
subprocess.Popen(call_charlie)

```

```
Traceback (most recent call last):
  File ""C:/Users/Lee/Documents/GitHub/FED/websockets_mnist/start_websocket_servers.py"", line 18, in <module>
    subprocess.Popen(call_alice)
  File ""C:\Users\Lee\anaconda3\envs\websockets_mnist\lib\subprocess.py"", line 800, in __init__
    restore_signals, start_new_session)
  File ""C:\Users\Lee\anaconda3\envs\websockets_mnist\lib\subprocess.py"", line 1148, in _execute_child
    args = list2cmdline(args)
  File ""C:\Users\Lee\anaconda3\envs\websockets_mnist\lib\subprocess.py"", line 555, in list2cmdline
    needquote = ("" "" in arg) or (""\t"" in arg) or not arg
TypeError: argument of type 'WindowsPath' is not iterable
```

and honestly... I don't know where the ""run_websocket_server.py"" at ""FILE_PATH"" came from. I couldn't find it anywhere in this tutorial. Do I have to make this file on my own?


There are many other questions but that's the main one anyway. I guess I can do the rest myself after solving this one.

Thank you in advance!
I solved this problem by wrapping FILE_PATH with str() like below.
`FILE_PATH = str(Path(__file__).resolve().parent.joinpath(""run_websocket_server.py""))`

I think it's not that elaborate way, but anyway it works for my case."	1	2020-09-21 11:18:12	2020-09-22 06:50:48	2020-09-22 06:50:48
https://github.com/OpenMined/PySyft/issues/4568	['bug ', 'hacktoberfest', '0.2.x']	 model.get() causes RuntimeError if the code is running on GPU with resnet model	"model.get() causes RuntimeError if the code is running on GPU with resnet model## Description
After I train the model locally by a worker, I do model.get() to retrieve it and I have the following runtime error: ""Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_"".
I am training on GPU (same code runs perfectly if I use CPU) and I am using resnet50 model.

## How to Reproduce
```
optimizer = optim.Adam(model.parameters(), lr=lr) 
criterion = nn.CrossEntropyLoss()

model.train()
model.send(worker)
for batch_idx, (data, target) in enumerate(batches):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        loss = loss.get()
        model.get()  # <-- This get causes the error
```

## System Information
 - syft: 0.2.9Hey, thanks for reporting!
can you alors provide your stack trace please? :) Hi @Hjeljeli @LaRiffle, I encountered the same problem a few months ago, please refer to the comments in #3848 for further explanation.@LaRiffle 
Hi Theo, please find my stack trace. Merci pour ton aide!

```
<ipython-input-16-1a450dc3c5d4> in <module>
      3 logging.basicConfig(format=FORMAT, level=LOG_LEVEL)
      4 
----> 5 main()

<ipython-input-15-443eb06bbc7c> in main()
    208     for epoch in range(1, epochs + 1):
    209         logger.warning(""Starting epoch %s/%s"", epoch, epochs)
--> 210         model = train(model, device, federated_train_loader, test_loader, lr, federate_after_n_batches)
    211         test(model, device, test_loader)

<ipython-input-15-443eb06bbc7c> in train(model, device, federated_train_loader, test_loader, lr, federate_after_n_batches, abort_after_one)
    112             curr_batches = batches[worker]
    113             if curr_batches:
--> 114                 local_models[worker] = train_on_batches(worker, curr_batches, model, device, test_loader, lr)
    115 
    116             else:

<ipython-input-15-443eb06bbc7c> in train_on_batches(worker, batches, model_in, device, test_loader, lr)
     42             t1 = time.time()
     43             # We measure accurancy of worker's model
---> 44             model.get()
     45             accuracy = test(model, device, test_loader)
     46             accuracies[worker].append(accuracy)

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
    673             if isinstance(nn_self.forward, Plan):

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in get_(self, *args, **kwargs)
    685         Calls get() with inplace option set to True
    686         """"""
--> 687         return self.get(*args, inplace=True, **kwargs)
    688 
    689     def allow(self, user=None) -> bool:

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    672 
    673         if inplace:
--> 674             self.set_(tensor)
    675             if hasattr(tensor, ""child""):
    676                 self.child = tensor.child

RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_
```+1, I also run into this issue with very similar code to the above, except using mobilenet instead of resnet. RuntimeError message is the same. The issue disappears when I use a neural net I specify for myself, so I think it could be interop with the torch model zoo models?

(for reference I had this same issue back in ~May on syft ~0.2.4 but didn't report- unfortunately some other projects pulled me away from this one)Thank you for reporting it! It might be a problem that the tensors should be sent to the ```device``` (in this case GPU) before using ```set_```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.> This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.

Updating so this issue is active.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.is this issue fixed in 0.3.x? @Hjeljeli. Currently stuck with this bug in 0.2.9 :(.@naveenggmu Hi Naveen, I could not test on 0.3.x as you know the releases 0.3.x do not support all the privacy-preserving techniques that 0.2.x used to support, for me I am using PySyft for Federated Learning."	10	2020-09-18 09:40:30	2020-12-28 00:54:47	2020-11-19 13:30:59
https://github.com/OpenMined/PySyft/issues/4555	['bug ']	utils.federated_avg() gives ar error with resnet models on pysyft-0.2.9	"utils.federated_avg() gives ar error with resnet models on pysyft-0.2.9## Description
When I call utils.federated_avg() on resnet models, I have the following error: init() missing 2 required positional arguments: 'block' and 'layers'. Any idea how to fix this?

## System Information
Pysyft Version: 0.2.9

## Code Snippet 
import torch
from torchvision import datasets, transforms, models

import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.frameworks.torch.fl import utils
hook = sy.TorchHook(torch)

alice = VirtualWorker(id=""alice"", hook=hook)
bob = VirtualWorker(id=""bob"", hook=hook)
carol = VirtualWorker(id=""carol"", hook=hook)
workers = [alice, bob, carol]

model_in = models.resnet50(pretrained=True)

local_models = {}
for worker in workers:
local_models[worker]= model_in.copy()

model_out = utils.federated_avg(local_models)

## Error
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/hamza/PySyft-0.2.9/syft/frameworks/torch/fl/utils.py"", line 85, in federated_avg
    model = type(model_list[0])()
TypeError: __init__() missing 2 required positional arguments: 'block' and 'layers'Closing this issue as it is a duplicate of #4481"	1	2020-09-15 02:08:16	2020-09-15 15:00:05	2020-09-15 15:00:04
https://github.com/OpenMined/PySyft/issues/4530	['bug ']	## Under contributors guidelines to pysft, deploying workers guide returns a 404 page	"## Under contributors guidelines to pysft, deploying workers guide returns a 404 page## Description
A clear and concise description of the bug.

## How to Reproduce
1. Go to '...'
2. Click on '...'
3. Scroll down to '...'
4. See error

## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
Hey can you please precise what the bug is? Thanks 😄 
Hey there @LaRiffle i was reading through the contribution.md page and under the deploying workers section, the example link on how to deploy workers returns a 404 page. Here's the link https://github.com/OpenMined/PySyft/blob/master/examples/deploy_workers/deploy-and-connect.ipynbI guess it has been moved here: https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/tutorial-websocket/deploy_workers/deploy-and-connect.ipynb
Will fix this, thanks!"	3	2020-09-03 23:08:13	2020-09-15 16:31:46	2020-09-15 16:31:46
https://github.com/OpenMined/PySyft/issues/4514	['bug ', '0.2.x']	Sending requests to the pygrid using os.path.join	"Sending requests to the pygrid using os.path.join## Description
I have just noticed a limitation of PySyft/PyGrid when relying on `os.path.join` to interface with the network. More specifically, nothing happens when I try to add a node to the network using `.\apps\node\run.sh --id Alice --port 5001 --host localhost --network http://localhost:7000 --start_local_db`. I manually checked this behavior as shown below. This is due to the fact that `os.path.join` uses back slashes instead of forward slashes. I temporally solved this using `.replace(""\\"",""/"")` after `os.path.join`.

## How to Reproduce
1. Create a grid via `.\apps\network>run.sh --port 7000 --start_local_db`
2. In a Jupyter notebook run


> import requests
> import os
> import json
> 
> node_id = 'Alice'
> port = '5001'
> GRID_NETWORK_PORT = '7000'
> 
> res = requests.post(
>      #  Expected path ""http://localhost:7000//join""
>      # Actual path ""http://localhost:7000\\join""
>      os.path.join(""http://localhost:"" + GRID_NETWORK_PORT, ""join""),
>      data=json.dumps(
>          {""node-id"": node_id, ""node-address"": ""http://localhost:"" + port}
>      ),
> )

3. Check response via `res.text`
4. Response: `'<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 3.2 Final//EN"">\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n'`

## Expected Behavior
The path should be ""http://localhost:7000//join"" (now ""http://localhost:7000\\join"").

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.7.3 (running on virtualenv)
 - Browser (if applicable): Google Chrome
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue."	2	2020-09-01 07:40:48	2020-11-19 13:30:22	2020-11-19 13:30:22
https://github.com/OpenMined/PySyft/issues/4507	['bug ']	"Error when saving model with torch.save() trained with SMPC - ""Can't pickle module objects"""	"Error when saving model with torch.save() trained with SMPC - ""Can't pickle module objects""## Description
Trained a model using the tutorial example for encrypted training on MNIST. The training works fine. When doing torch.save(model.state_dict(), PATH), it gives the following error - 
 _""... pickler.dump(obj)
TypeError: can't pickle module objects""_

## How to Reproduce
1. Run tutorial example - Encrypted training on MNIST.ipynb
2. Execute - torch.save(model.state_dict(), ""private_MNIST.pt"")

## System Information
 - OS: Ubuntu 18.04.5
 - Language Version:  Python 3.7.7
-  syft 0.2.8
-  syft-proto 0.5.2
 - Package Manager Version:  Conda 4.8.4

Resolved. The solution turned out to be simple. Just reconstruct the model and convert it back to floating point using model.get().float_precision(). Then use torch.save(model, PATH)."	1	2020-08-31 15:12:48	2020-08-31 18:23:13	2020-08-31 18:23:12
https://github.com/OpenMined/PySyft/issues/4502	['bug ']	Unable to execute PySyft/examples/tutorials/model-centric-fl/Part 01 - Create Plan.ipynb	"Unable to execute PySyft/examples/tutorials/model-centric-fl/Part 01 - Create Plan.ipynb## Description

Hi PySyft team,

I encountered these errors when running the mentioned notebook. 
 
The error below happens with syft==0.2.7.
```
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-3-22da4773ebd0> in <module>
      6 from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB
      7 from syft_proto.execution.v1.state_pb2 import State as StatePB
----> 8 from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient
      9 from syft.execution.state import State
     10 from syft.execution.placeholder import PlaceHolder

ModuleNotFoundError: No module named 'syft.grid.clients.model_centric_fl_client'
```

While another error below happens with syft==0.2.8.

```
KeyError                                  Traceback (most recent call last)
<ipython-input-17-8a945e035458> in <module>
     12     server_averaging_plan=avg_plan,
     13     client_config=client_config,
---> 14     server_config=server_config
     15 )
     16 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/clients/model_centric_fl_client.py in host_federated_training(self, model, client_plans, client_protocols, client_config, server_averaging_plan, server_config)
    119         }
    120 
--> 121         return self._send_msg(message)
    122 
    123     def get_model(self, name, version, checkpoint=""latest""):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/clients/model_centric_fl_client.py in _send_msg(self, message)
     49         json_response = json.loads(self.ws.recv())
     50 
---> 51         error = json_response[""data""].get(""error"", None)
     52         if error is not None:
     53             raise GridError(error, None)

KeyError: 'data'
```
Please share the list of dependencies that work with the examples. Thanks
@chihan461 How did you fix this? I am having the same error for syft==0.2.8"	1	2020-08-29 18:12:02	2020-09-10 14:28:11	2020-08-30 07:30:20
https://github.com/OpenMined/PySyft/issues/4495	['bug ', '0.2.x']	RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.	"RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.Hi PySyft-Team,

I have updated the PySyft version from v0.2.1.a1 to 0.2.4.

Now I get the following error message when I run my program on the client (here a WebsocketServerWorker is running):

```
Serving. Press CTRL-C to stop.
Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/jetson/PySyft/syft/workers/websocket_server.py:95> exception=RuntimeError('a leaf Variable that requires grad is being used in an in-place operation.',)>
Traceback (most recent call last):
  File ""/home/jetson/PySyft/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/jetson/PySyft/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/home/jetson/PySyft/syft/workers/base.py"", line 320, in recv_msg
    response = self._message_router[type(msg)](msg)
  File ""/home/jetson/PySyft/syft/workers/base.py"", line 434, in execute_tensor_command
    return self.execute_computation_action(cmd.action)
  File ""/home/jetson/PySyft/syft/workers/base.py"", line 464, in execute_computation_action
    getattr(_self, op_name)(*args, **kwargs)
  File ""/home/jetson/PySyft/syft/generic/frameworks/hook/trace.py"", line 83, in trace_wrapper
    response = func(*args, **kwargs)
  File ""/home/jetson/PySyft/syft/generic/frameworks/hook/hook.py"", line 419, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""/home/jetson/PySyft/syft/generic/frameworks/hook/hook.py"", line 415, in overloaded_native_method
    response = method(*args, **kwargs)
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
```

This is done by executing the following command on the server (has the client mounted as WebsocketClientWorker):

`optimizer.step()`

The data is loaded to the client (on the client before the websocket server is started) as follows:

```
remote_worker = WebsocketServerWorker(...)
...
data = data.to(DEVICE) 
target = target.to(DEVICE)

data_ptr = th.tensor(data, requires_grad=True).tag(TRAIN_DATA_TAG).send(remote_worker)  
target_ptr = th.tensor(target, requires_grad=False).tag(TRAIN_TARGET_TAG).send(remote_worker)

remote_worker.start()
```

Does anyone have an idea?
Many thanks in advance
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue."	2	2020-08-28 08:57:33	2020-11-19 13:30:13	2020-11-19 13:30:13
https://github.com/OpenMined/PySyft/issues/4491	['bug ', '0.2.x']	PureFrameworkTensorFoundError AttributeError: 'Tensor' object has no attribute 'child'	"PureFrameworkTensorFoundError AttributeError: 'Tensor' object has no attribute 'child'After using the .get() function on each tensor in the list of features produced by an UXception encoder model which resides at the client worker(virtual worker on same machine), I pass this list of features through a decoder model. This is when I get the error as stated below.

---------------------------------------------------------------------------
PureFrameworkTensorFoundError             Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    340             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
--> 341                 cmd, args_, kwargs_, return_args_type=True
    342             )

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in unwrap_args_from_function(attr, args_, kwargs_, return_args_type)
    156         # Try running it
--> 157         new_args = hook_args(args_)
    158 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(x)
    355 
--> 356     return lambda x: f(lambdas, x)
    357 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in tuple_one_fold(lambdas, args_)
    522     def tuple_one_fold(lambdas, args_):
--> 523         return (lambdas[0](args_[0], **kwargs),)
    524 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(i)
    330         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 331         else lambda i: forward_func[type(i)](i)
    332         for a, r in zip(args_, rules)  # And do this for all the args / rules provided

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     23     if hasattr(i, ""child"")
---> 24     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     25     torch.nn.Parameter: lambda i: i.child

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     23     if hasattr(i, ""child"")
---> 24     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     25     torch.nn.Parameter: lambda i: i.child

PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    383             try:
--> 384                 response = cls._get_response(cmd, args_, kwargs_)
    385             except AttributeError:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in _get_response(cmd, args_, kwargs_)
    417         if isinstance(args_, tuple):
--> 418             response = command_method(*args_, **kwargs_)
    419         else:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/functional.py in interpolate(input, size, scale_factor, mode, align_corners)
   2508 
-> 2509     if input.dim() == 3 and mode == 'nearest':
   2510         return torch._C._nn.upsample_nearest1d(input, _output_size(1))

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    173                     # we can make some errors more descriptive with this method
--> 174                     raise route_method_exception(e, self, args, kwargs)
    175 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    169                 try:
--> 170                     response = method(*args, **kwargs)
    171 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py in dim(self)
    106         def dim(self):
--> 107             return len(self.shape)
    108 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in shape(self)
    136         if self.is_wrapper:
--> 137             return self.child.shape
    138         else:

AttributeError: 'Tensor' object has no attribute 'child'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-29-2ce8f7bfa4e9> in <module>
     56 
     57     #4) make prediction on next model using recieved signal
---> 58     output = server_model(server_a)
     59     break
     60 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-12-df1dc6dd3ba5> in forward(self, features)
     47         """"""Sequentially pass `x` trough model`s encoder, decoder and heads""""""
     48         #features = self.encoder(x)
---> 49         decoder_output = self.decoder(*features)
     50 
     51         masks = self.segmentation_head(decoder_output)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-6-821c73a4e911> in forward(self, *features)
    110         for i, decoder_block in enumerate(self.blocks):
    111             skip = skips[i] if i < len(skips) else None
--> 112             x = decoder_block(x, skip)
    113 
    114         return x

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-6-821c73a4e911> in forward(self, x, skip)
     27 
     28     def forward(self, x, skip=None):
---> 29         x = F.interpolate(x, scale_factor=2, mode=""nearest"")
     30         if skip is not None:
     31             x = torch.cat([x, skip], dim=1)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)
    338                 handle_func_command = syft.framework.Tensor.handle_func_command
    339 
--> 340             response = handle_func_command(command)
    341 
    342             return response

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    386                 # Change the library path to avoid errors on layers like AvgPooling
    387                 cmd = cls._fix_torch_library(cmd)
--> 388                 response = cls._get_response(cmd, args_, kwargs_)
    389 
    390         return response

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in _get_response(cmd, args_, kwargs_)
    416 
    417         if isinstance(args_, tuple):
--> 418             response = command_method(*args_, **kwargs_)
    419         else:
    420             response = command_method(args_, **kwargs_)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/functional.py in interpolate(input, size, scale_factor, mode, align_corners)
   2507             align_corners = False
   2508 
-> 2509     if input.dim() == 3 and mode == 'nearest':
   2510         return torch._C._nn.upsample_nearest1d(input, _output_size(1))
   2511     elif input.dim() == 4 and mode == 'nearest':

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    172                 except BaseException as e:
    173                     # we can make some errors more descriptive with this method
--> 174                     raise route_method_exception(e, self, args, kwargs)
    175 
    176             else:  # means that there is a wrapper to remove

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    168 
    169                 try:
--> 170                     response = method(*args, **kwargs)
    171 
    172                 except BaseException as e:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py in dim(self)
    105 
    106         def dim(self):
--> 107             return len(self.shape)
    108 
    109         tensor_type.dim = dim

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in shape(self)
    135     def shape(self):
    136         if self.is_wrapper:
--> 137             return self.child.shape
    138         else:
    139             return self.native_shape

AttributeError: 'Tensor' object has no attribute 'child'
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.but the problem is that version 0.3.x does not support torchhook. If it's supported please share an example."	3	2020-08-26 17:54:50	2022-02-07 15:36:33	2020-11-19 13:29:57
https://github.com/OpenMined/PySyft/issues/4481	['bug ', '0.2.x']	utils.federated_avg() gives ar error with resnet models	"utils.federated_avg() gives ar error with resnet models## Description
When I call **utils.federated_avg()** on **resnet** models, I have the following error: __init__() missing 2 required positional arguments: 'block' and 'layers'. Any idea how to fix this?

## System Information
 - Pysyft Version: 0.2.9

## Code snippet
```
import torch
from torchvision import datasets, transforms, models

import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.frameworks.torch.fl import utils
hook = sy.TorchHook(torch)

alice = VirtualWorker(id=""alice"", hook=hook)
bob = VirtualWorker(id=""bob"", hook=hook)
carol = VirtualWorker(id=""carol"", hook=hook)
workers = [alice, bob, carol]

model_in = models.resnet50(pretrained=True)

local_models = {}
for worker in workers:
    local_models[worker]= model_in.copy()
    
# Average the models
model_out = utils.federated_avg(local_models)
```@Hjeljeli  Could you also provide a code snippet to reproduce the error. Thanks
@steph-en-m Sure. I added a code snippet to the description. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.> This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.

Updating so this issue is active.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue."	5	2020-08-26 00:53:41	2020-11-19 13:29:44	2020-11-19 13:29:43
https://github.com/OpenMined/PySyft/issues/4477	['bug ', '0.2.x']	Duplicated method name in base.py	"Duplicated method name in base.py`syft/workers/base.py` contains two identically named `register_obj` methods:

https://github.com/OpenMined/PySyft/blob/99190dfa85d86b1d6542a7ee0454b2758c289605/syft/workers/base.py#L189

and 

https://github.com/OpenMined/PySyft/blob/99190dfa85d86b1d6542a7ee0454b2758c289605/syft/workers/base.py#L553


In best python tradition, only the latter one actually gets called, but we should fix that. 

@gkaissis ..I would like to give this a shot..how would you like me to approach this bug?Could you please see to the failing tests and perhaps @cereallarceny or @gmuraru have a look? This was a subject of discussion recently owing to the issues we had with websocket trainingThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue."	4	2020-08-25 14:56:27	2020-11-19 13:27:31	2020-11-19 13:27:31
https://github.com/OpenMined/PySyft/issues/4048	['bug ', 'good first issue :mortar_board:']	Reciprocal test enchantment negative numbers	"Reciprocal test enchantment negative numbers## Description
Test the ```reciprocal``` method from precision using negative numbers

## Expected Behavior
All tests are passing

## Screenshots
If applicable, add screenshots to help explain your problem.

## Additional Context
It might require changes to the reciprocal methodI guess the Log and NR method are a problem. Division works fine.. Will look into the issueAdding you :)> I guess the Log and NR method are a problem. Division works fine.. Will look into the issue

Also, there might be worth checking out how [CrypTen](https://github.com/facebookresearch/CrypTen) is doing - if they take into consideration negative values.

If not, one idea (it might not be the greatest) is to use symmetry.hey could you review my PR?
https://github.com/OpenMined/PySyft/pull/4065"	4	2020-08-20 06:13:18	2020-08-23 10:50:12	2020-08-23 10:50:12
https://github.com/OpenMined/PySyft/issues/4036	['bug ', 'good first issue :mortar_board:', '0.2.x']	Flaky exp test	"Flaky exp test## Description
The tolerance for the ```exp``` needs to be increased since it is failing randomly (because of the random order in which we run the tests).

## How to Reproduce
```
____________________ test_torch_sigmoid_approx[exp-3-0.065] ____________________

method = 'exp', prec_frac = 3, tolerance = 0.065
workers = {'alice': <VirtualWorker id:alice #objects:1>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:0>, ...}

    @pytest.mark.parametrize(
        ""method, prec_frac, tolerance"",
        [
            (""chebyshev"", 3, 6 / 100),
            (""chebyshev"", 4, 1 / 1000),
            (""exp"", 3, 6.5 / 100),
            (""exp"", 4, 1 / 100),
            (""maclaurin"", 3, 7 / 100),
            (""maclaurin"", 4, 15 / 100),
        ],
    )
    def test_torch_sigmoid_approx(method, prec_frac, tolerance, workers):
        """"""
        Test the approximate sigmoid with different tolerance depending on
        the precision_fractional considered
        """"""
        alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
        t = torch.tensor(range(-10, 10)) * 0.5
        t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
        r_sh = t_sh.sigmoid(method=method)
        r = r_sh.get().float_prec()
        t = t.sigmoid()
        diff = (r - t).abs().max()
        norm = (r + t).abs().max() / 2
    
>       assert (diff / (tolerance * norm)) < 1
E       assert (tensor(1.2798e+13) / (0.065 * tensor(6.3991e+12))) < 1
```

## Expected Behavior
The test should be passing

## Screenshots
If applicable, add screenshots to help explain your problem.
Hey @gmuraru would want to work on this!Assigned it to you! But I think this will require more research since it seems that the value is pretty high and probably we do something behind the scenes which brokes the ```exp```. A simple increase in the tolerance would not do the job.The issue is related to the method we use for ```sigmoid``` when computing ```reciprocal```.
Could you make a PR where you can simply add ```method=""division""``` to the reciprocal.So multiple things. Firstly, should'nt we get a value >1 and not <1 as the assert suggests! Also the reciprocal method is tested.Passing method=""division  is just a default parameter and anyway tests with all methods(divison,log,nr) are getting passed. Tell me if I am missing somethingI merged yesterday a PR for [this](https://github.com/OpenMined/PySyft/pull/4044).
Yep - you are correct. The tests are passing, but there is a scenario that we do not take care of. Opened a new issue for this - [here](https://github.com/OpenMined/PySyft/issues/4048)This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hey, I want to work on this issue, Can you assign me on this issue?Sure :D@gmuraru is this issue still valid?It can be closed - we would deal with it in SyMPC when the time would come"	10	2020-08-18 13:04:10	2021-02-18 13:31:12	2021-02-18 13:31:12
https://github.com/OpenMined/PySyft/issues/3986	['bug ', '0.2.x']	'sy.TorchHook(torch)' cause error	"'sy.TorchHook(torch)' cause errorI use Pysyft to train the network, which involves the following operations:

```python
import torch
import numpy as np
import syft as sy

hook = sy.TorchHook(torch)
data = torch.rand(3, 2).to(""cuda"")
index1 = np.array([2,1,0,0,1,1,0,2,2,1,0,0,1,1,0,2,2,1,0,0,1,1,0,2,2,1,0,0,1,1,0,2])
index1 = torch.from_numpy(index1).long().to(""cuda"")
index2 = np.array([2,1,0,0,1,1,0,2])
index2 = torch.from_numpy(index2).long().to(""cuda"")
print(data[index1])
print(data[index2])
```

When `print(data[index2])` is executed, it causes the error “too many indices for tensor of dimension 2”. But when `hook = sy.TorchHook(torch)
` was commented out, the code runs successfully. Why is this happening? 

My environment:
pytorch: 1.4.0
syft: 0.25Hmmm..if you remove the ```to(""cuda"")``` it works?I removed the `to(""cuda"")`,  and it still doesn't work.Yep - there is an issue. If you try to directly use ```index2``` without converting it to a tensor it works.
Thank you for signaling it :DYes. If `index2` is a numpy array, it works. Will the issue be resolved?We will start looking into this.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue should be reopened, I had the exact same problem because of the hook:
![image](https://user-images.githubusercontent.com/26694607/106267656-a28d7b00-6232-11eb-8e28-64bdc4ae7063.png)
If I comment out the hook part (hook = sy.TorchHook(torch)) it works
Also worked when I moved into numpy to do the operations and back to torch. As of `Jan 2022`, this error still remains , 
![image](https://user-images.githubusercontent.com/52364337/151281193-3eda6fad-de71-451b-a965-382fd9b236ef.png)"	9	2020-08-11 11:03:21	2022-01-27 02:31:15	2020-12-21 00:15:48
https://github.com/OpenMined/PySyft/issues/3982	['bug ', 'good first issue :mortar_board:']	Return invalid dtype when MPC is applied to Other Dtype Tensor	"Return invalid dtype when MPC is applied to Other Dtype Tensor## Description

When MPC is applied to the int tensor, it must be int but float return.

## How to Reproduce

```python
x = torch.tensor([1, 2, 3])
print(x.dtype) # torch.int64

x = share(bob, alice, crypto_provider=theo)
print(x.dtype) # torch.float32 # should be torch.int64

print(x.get().dtype) # torch.int64
```

## Expected Behavior

should be `torch.int64`

## Screenshots

![image](https://user-images.githubusercontent.com/39186433/89849067-a9f89380-dbc2-11ea-84aa-6bf791a46b78.png)


## System Information
 - OS: MAC
 - OS Version: Catalina
 - Language Version: Python3.7
 - Package Manager Version: Conda 4.8.3
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context


Hi @gmuraru can I take this?Sure :D"	2	2020-08-11 02:07:13	2020-08-22 05:34:34	2020-08-22 05:34:34
https://github.com/OpenMined/PySyft/issues/3980	['bug ', 'status: stale :bread:']	AutogradTensor.backward() in sy.Plan does not propagate to the entire NN model	"AutogradTensor.backward() in sy.Plan does not propagate to the entire NN model## Description

I'm trying to use the example code from [Part 01 - Create Plan.ipynb](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/model-centric-fl/Part%2001%20-%20Create%20Plan.ipynb) to create a Plan for an LSTM model that I built using a modular approach. However, when executing the `loss.backward()` the gradient error does not propagate back to all layers (& model parameters) in the model besides the ones defined in the last subclass/module

## How to Reproduce
1. Here's my LSTM implementation https://gist.github.com/santteegt/55ec836b00493ded4479c1cefa9f5c8a
2. Execute using a dev PySyft environment
3. You'll get an error `TypeError: mul(): argument 'other' (position 1) must be Tensor, not NoneType` in the `naive_sgd` function due to a `param.grad` is None

## Expected Behavior
All model parameters should have a grad != None
I have the same problem but with a convolutional network, mainly with a Conv2d layer. I think that the problem is related to issue #3509 and this one  #3550. I want to contribute for solve the problem and make .grad of this layer different from None. I tried to use the Conv2d from syft/frameworks/torch/nn/conv, but I'm still without success. The same occurs when a modified the autograd.py to support conv2d on backward pass. Based on the related issues I think, if available, that @iamtrask @karlhigley  and @vvmnnnkv can give us a start guide or tips to make these layers work in this example. I really want to contribute guys :+1: .This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.the same question"	3	2020-08-10 23:08:49	2021-02-13 16:40:52	2020-11-29 00:11:25
https://github.com/OpenMined/PySyft/issues/3950	['bug ', 'good first issue :mortar_board:', 'status: stale :bread:', '0.2.x']	Fixed precision tensor: linear operations with torch tensor are broken	"Fixed precision tensor: linear operations with torch tensor are brokenfixed precision tensor is supposed to work correctly given an int or float to be subtracted from or added to, just like a torch tensor.
for example:
torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
this should be the correct behavior of FPT:
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
but instead we get:
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)

multiplication also is broken. 
any fix should be tested against all arithmetic operations (add, sub, mul, div, ..etc)I'd like to take this on :) 

---

Formatting the exit condition and setup for easier checking

```
torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
```

this should be the correct behavior of FPT:

```
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
```

but instead we get:

```
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)
```@IanQS how it goes with this issue. Did you start work on it?Heya @gmuraru ! 

I've started working on it but I'm running into roadblocks. I've solved the 

`torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)` but admittedly my solution isn't pretty and I've not run tests to make sure that my changes don't break anything. 

I'm not too sure about how to solve the first issue (`PureFrameworkTensorFoundError`) I'd love some guidance if you've got any insight into it@gmuraru 

I've linked my PR to this. Let me know if you think I'm going down the wrong path. I'd love to get feedback as I go along. I'm still trying to figure out how to address the `PureFrameworkTensorFoundError`@IanQS you'd wanna look at the operations of the native tensor, since torch.Tensor+FPT calls the __add__ method of the native tensor (torch.Tensor)Got it! I'll look into `syft.frameworks.torch.tensor.interpreters.Tensor` specifically the `add`! I'll get to it this weekend and will try my best to have something up by Monday. @IanQS let's review and merge the first fix and make the second one in a separate PRHey @abogaziah  @gmuraru 

I think it might be better for me to unassign myself. I'm really not sure how to fix the issue or where to put the fixes so it might be better for someone else to try and take it on. I'll close out the PR but leave a reference to itHi @abogaziah I would like to attempt this if still available@duggalsu sure, go-ahead  I would like to fix this if still availableHi @xutongye , I've started to work on this now. Will need a few days. I'll let you know if I cannot finish it.@LaRiffle I know we discussed yesterday about this behavior.

We throw an exception if:
- float_tensor (+|-|*|/) fix_prec_tensor
- fix_prec_tensor (+|-|*|/) float_tensor

This was the conclusion, right?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	14	2020-08-05 20:13:02	2020-12-08 00:12:01	2020-12-08 00:12:01
https://github.com/OpenMined/PySyft/issues/3937	['bug ', 'priority: 2 - high :cold_sweat:', 'status: stale :bread:']	SMPC for more than 2 parties	"SMPC for more than 2 parties## Description
Currently, we support only SMPC for <= 2 parties. We would like to support ```n``` parties.
See [this](https://github.com/OpenMined/PySyft/pull/3909) for more details.


## Acceptance Criteria
* Add tests where we have multiple workersThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-08-04 08:37:41	2020-11-29 00:11:33	2020-11-29 00:11:33
https://github.com/OpenMined/PySyft/issues/3912	['bug ', 'status: stale :bread:']	Memory leak problem and worker is not training problem.	"Memory leak problem and worker is not training problem.## Description
### Memory leak problem 
I deployed 10 workers on a server for federated learning, controlled by train_config.  After one training is completed and the average of ten models is collected, the model is assigned to TrainConfig.model and the entire TrainConfig is sent. There is a serious memory leak on the worker side. I inserted objgraph.show_growth into the fit functionin the worker, as shown in Figure 1. It is found that the memory growth is shown in Figure 2.
![微信图片_20200731105702](https://user-images.githubusercontent.com/18498934/88995295-d8ea4c00-d31c-11ea-8c8c-e7b7adfd98f1.png)





![微信图片_20200731105654](https://user-images.githubusercontent.com/18498934/88995299-dd166980-d31c-11ea-9f21-784e2499cdbb.png)


Worker is not training problem
Since the sending of train_config will cause memory leaks, I tried to solve the problem by passing only the model, but after sending the model through self.model_ptr, self._model_id = self._wrap_and_send_obj(self.model, location), the training cannot be obtained After the model.


## System Information
 - OS: [ubuntu18.04]
 - OS Version: [ubuntu18.04]
 - Language Version: [Python 3.6]
 - Package Manager Version: [pip]
-sypysyft 0.2.3
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-07-31 03:13:13	2020-12-21 00:15:50	2020-12-21 00:15:50
https://github.com/OpenMined/PySyft/issues/3905	['bug ', 'priority: 3 - medium :unamused:']	Cannot find dataset pointers	"Cannot find dataset pointers## Description
A clear and concise description of the bug.  I tried the tutorial for the federated learning for Mnist, the link is: https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/grid/federated_learning/mnist
but I cannot find the dataset pointer

## How to Reproduce
1. Go to '...'
2. Click on '...'
3. Scroll down to '...'
4. See error

## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS] windows 10
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1] python 3.7
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
Here is my code.
import syft as sy
from syft.grid.clients.dynamic_fl_client import DynamicFLClient
import torch
import pickle
import time
import torchvision
from torchvision import datasets, transforms
import tqdm
from syft.grid.public_grid import PublicGridNetwork
from syft.grid.private_grid import PrivateGridNetwork
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def epoch_total_size(data):
    total = 0
    for i in range(len(data)):
        for j in range(len(data[i])):
            total += data[i][j].shape[0]

    return total


def train(epoch, data):
    model.train()
    epoch_total = epoch_total_size(data)
    current_epoch_size = 0
    for i in range(len(data)):
        for j in range(len(data[i])):
            current_epoch_size += len(data[i][j])
            worker = data[i][j].location
            model.send(worker)
            optimizer.zero_grad()
            pred = model(data[i][j])
            loss = criterion(pred, target[i][j])
            loss.backward()
            optimizer.step()
            model.get()
            loss = loss.get()
            print('Train Epoch: {} | With {} data |: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                      epoch, worker.id, current_epoch_size, epoch_total,
                            100. *  current_epoch_size / epoch_total, loss.item()))


hook = sy.TorchHook(torch)

nodes = [""ws://localhost:3001/"", ""ws://localhost:3000/""]

compute_nodes = []
for node in nodes:
    compute_nodes.append(DynamicFLClient(hook, node))

N_SAMPLES = 10000
MNIST_PATH = './dataset'

transform = transforms.Compose([
                              transforms.ToTensor(),
                              transforms.Normalize((0.1307,), (0.3081,)),
                              ])

trainset = datasets.MNIST(MNIST_PATH, download=True, train=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=N_SAMPLES, shuffle=False)

dataiter = iter(trainloader)

images_train_mnist, labels_train_mnist = dataiter.next()

datasets_mnist = torch.split(images_train_mnist, int(len(images_train_mnist) / len(compute_nodes)), dim=0 ) #tuple of chunks (dataset / number of nodes)
labels_mnist = torch.split(labels_train_mnist, int(len(labels_train_mnist) / len(compute_nodes)), dim=0 )  #tuple of chunks (labels / number of nodes)

tag_img = []
tag_label = []


for i in range(len(compute_nodes)):
    tag_img.append(datasets_mnist[i].tag(""#X"", ""#mnist"", ""#dataset"").describe(""The input datapoints to the MNIST dataset.""))
    tag_label.append(labels_mnist[i].tag(""#Y"", ""#mnist"", ""#dataset"").describe(""The input labels to the MNIST dataset.""))


shared_x1 = tag_img[0].send(compute_nodes[0], garbage_collect_data=False) # First chunk of dataset to Bob
shared_x2 = tag_img[1].send(compute_nodes[1], garbage_collect_data=False) # Second chunk of dataset to Alice

shared_y1 = tag_label[0].send(compute_nodes[0], garbage_collect_data=False) # First chunk of labels to Bob
shared_y2 = tag_label[1].send(compute_nodes[1], garbage_collect_data=False) # Second chunk of labels to Alice

# print(""X tensor pointers: "", shared_x1, shared_x2)
# print(""Y tensor pointers: "", shared_y1, shared_y2)

device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")

if (torch.cuda.is_available()):
    torch.set_default_tensor_type(torch.cuda.FloatTensor)

model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

GRID_ADDRESS = 'localhost'
GRID_PORT = '5000'

my_grid = PublicGridNetwork(hook, ""http://"" + GRID_ADDRESS + "":"" + GRID_PORT)

data = my_grid.search(""#X"", ""#mnist"", ""#dataset"")
target = my_grid.search(""#Y"", ""#mnist"", ""#dataset"")

data = data.values()
print(data)

N_EPOCS = 3
SAVE_MODEL = True
SAVE_MODEL_PATH = './models'


for epoch in range(N_EPOCS):
    train(epoch, data)
@IonesioJunior  @junrong1  I have the same problem of not finding the pointer via the grid search. 
Is there a workaround or a solution meanwhile?

Thx in advance!Okay, I've found an docker image with a working pygrid! (development tag)> @IonesioJunior @junrong1 I have the same problem of not finding the pointer via the grid search.
> Is there a workaround or a solution meanwhile?
> 
> Thx in advance!

Ohhhhhh, sorry for late respond, I haven't found the solution, could u tell me ur solution to fix this?@junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.

So, consider the following:

```
docker pull openmined/grid-network:development
docker pull openmined/grid-node:development
```

and then run the mnist federated learning example again.> @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> 
> So, consider the following:
> 
> ```
> docker pull openmined/grid-network:development
> docker pull openmined/grid-node:development
> ```
> 
> and then run the mnist federated learning example again.

I tried to use
`docker pull openmined/pysyft-notebook`
but I cannaot find the link they give me.> > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > So, consider the following:
> > ```
> > docker pull openmined/grid-network:development
> > docker pull openmined/grid-node:development
> > ```
> > 
> > 
> > and then run the mnist federated learning example again.
> 
> I tried to use
> `docker pull openmined/pysyft-notebook`
> but I cannaot find the link they give me.

Is there any tutorials for using network and node on docker?> > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > So, consider the following:
> > > ```
> > > docker pull openmined/grid-network:development
> > > docker pull openmined/grid-node:development
> > > ```
> > > 
> > > 
> > > and then run the mnist federated learning example again.
> > 
> > 
> > I tried to use
> > `docker pull openmined/pysyft-notebook`
> > but I cannaot find the link they give me.
> 
> Is there any tutorials for using network and node on docker?

Hi @junrong1 and @thiessl . The docker images were updated recently (a couple of day ago), actually the images are automatically udpated when a commit to develop or master is pushed.

@junrong1 , is https://hub.docker.com/r/openmined/grid-node the image you are looking for?

Please confirm this is solved in order to close the issue.
For trazability reasons, we reccomend to open this issues directly on PyGrid repo> > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > So, consider the following:
> > > ```
> > > docker pull openmined/grid-network:development
> > > docker pull openmined/grid-node:development
> > > ```
> > > 
> > > 
> > > and then run the mnist federated learning example again.
> > 
> > 
> > I tried to use
> > `docker pull openmined/pysyft-notebook`
> > but I cannaot find the link they give me.
> 
> Is there any tutorials for using network and node on docker?

Create a docker-compose.yml file with the following content:

```
version: '3'
services:
  network:
    image: openmined/grid-network:development
    environment:
      - PORT=5000
      - SECRET_KEY=ineedtoputasecrethere
      - DATABASE_URL=sqlite:///databasenetwork.db
    ports:
      - 5000:5000
  bob:
    image: openmined/grid-node:development
    environment:
      - NODE_ID=Bob
      - ADDRESS=http://bob:3000/
      - PORT=3000
      - NETWORK=http://network:5000
      - DATABASE_URL=sqlite:///databasenode.db

    depends_on:
      - 'network'
    ports:
      - 3000:3000
  alice:
    image: openmined/grid-node:development
    environment:
      - NODE_ID=Alice
      - ADDRESS=http://alice:3001/
      - PORT=3001
      - NETWORK=http://network:5000
      - DATABASE_URL=sqlite:///databasenode.db
    depends_on:
      - 'network'
    ports:
      - 3001:3001
```

and execute

`docker-compose up`

this ensures that alice and bob (grid-nodes) and the grid-network run based on the respective docker image (development tag, as this works with the current commit).

After that you can execute your notebook and connect to your grid-nodes properly.> > > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > > So, consider the following:
> > > > ```
> > > > docker pull openmined/grid-network:development
> > > > docker pull openmined/grid-node:development
> > > > ```
> > > > 
> > > > 
> > > > and then run the mnist federated learning example again.
> > > 
> > > 
> > > I tried to use
> > > `docker pull openmined/pysyft-notebook`
> > > but I cannaot find the link they give me.
> > 
> > 
> > Is there any tutorials for using network and node on docker?
> 
> Create a docker-compose.yml file with the following content:
> 
> ```
> version: '3'
> services:
>   network:
>     image: openmined/grid-network:development
>     environment:
>       - PORT=5000
>       - SECRET_KEY=ineedtoputasecrethere
>       - DATABASE_URL=sqlite:///databasenetwork.db
>     ports:
>       - 5000:5000
>   bob:
>     image: openmined/grid-node:development
>     environment:
>       - NODE_ID=Bob
>       - ADDRESS=http://bob:3000/
>       - PORT=3000
>       - NETWORK=http://network:5000
>       - DATABASE_URL=sqlite:///databasenode.db
> 
>     depends_on:
>       - 'network'
>     ports:
>       - 3000:3000
>   alice:
>     image: openmined/grid-node:development
>     environment:
>       - NODE_ID=Alice
>       - ADDRESS=http://alice:3001/
>       - PORT=3001
>       - NETWORK=http://network:5000
>       - DATABASE_URL=sqlite:///databasenode.db
>     depends_on:
>       - 'network'
>     ports:
>       - 3001:3001
> ```
> 
> and execute
> 
> `docker-compose up`
> 
> this ensures that alice and bob (grid-nodes) and the grid-network run based on the respective docker image (development tag, as this works with the current commit).
> 
> After that you can execute your notebook and connect to your grid-nodes properly.

I have an error with worker failed to boot. Do you know how can I fix this?No. I run this yesterday from the docker compose from the repo without erros> > > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > > So, consider the following:
> > > > ```
> > > > docker pull openmined/grid-network:development
> > > > docker pull openmined/grid-node:development
> > > > ```
> > > > 
> > > > 
> > > > and then run the mnist federated learning example again.
> > > 
> > > 
> > > I tried to use
> > > `docker pull openmined/pysyft-notebook`
> > > but I cannaot find the link they give me.
> > 
> > 
> > Is there any tutorials for using network and node on docker?
> 
> Hi @junrong1 and @thiessl . The docker images were updated recently (a couple of day ago), actually the images are automatically udpated when a commit to develop or master is pushed.
> 
> @junrong1 , is https://hub.docker.com/r/openmined/grid-node the image you are looking for?
> 
> Please confirm this is solved in order to close the issue.
> For trazability reasons, we reccomend to open this issues directly on PyGr

> No. I run this yesterday from the docker compose from the repo without erros"	11	2020-07-28 09:33:57	2020-08-13 09:39:11	2020-08-13 09:39:11
https://github.com/OpenMined/PySyft/issues/3902	['bug ', 'status: stale :bread:']	RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_	"RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_RuntimeError when adding Batchnorm in the tutorial

differ from 
#[2498](https://github.com/OpenMined/PySyft/issues/2498) 
#[2132](https://github.com/OpenMined/PySyft/issues/2132)
I got a new problem:
Traceback (most recent call last):
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/mytest.py"", line 117, in <module>
    train(args, model, device, federated_train_loader, optimizer, epoch)
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/mytest.py"", line 84, in train
    model.get() # <-- NEW: get the model back
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/syft/frameworks/torch/hook/hook.py"", line 671, in module_get_
    p.get_()
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/syft/frameworks/torch/tensors/interpreters/native.py"", line 687, in get_
    return self.get(*args, inplace=True, **kwargs)
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/syft/frameworks/torch/tensors/interpreters/native.py"", line 674, in get
    self.set_(tensor)
RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_

Process finished with exit code 1

Something wrong when model.get(), if I delete ""to(device)"", it works when I use cpu for data and model. It seems that type doesn't change in BN.
Here is my code:

```
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms

import syft as sy  # <-- NEW: import the Pysyft library
epochs = 10

hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob
alice = sy.VirtualWorker(hook, id=""alice"")

class Arguments():
    def __init__(self):
        self.batch_size = 64
        self.test_batch_size = 1000
        self.epochs = epochs
        self.lr = 0.01
        self.momentum = 0.5
        self.no_cuda = False
        self.seed = 1
        self.log_interval = 30
        self.save_model = False

args = Arguments()

use_cuda = not args.no_cuda and torch.cuda.is_available()

torch.manual_seed(args.seed)

device = torch.device(""cuda"" if use_cuda else ""cpu"")

kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)
        self.bn1 = nn.BatchNorm2d(20)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.bn1(x)
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def train(args, model, device, federated_train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
        model.send(data.location) # <-- NEW: send the model to the right location
        data, target = data.to(device), target.to(device)
        # data, target = data.cuda(), target.cuda()
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        model.get() # <-- NEW: get the model back
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # <-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
                100. * batch_idx / len(federated_train_loader), loss.item()))


def test(args, model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss
            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))

model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment

for epoch in range(1, args.epochs + 1):
    train(args, model, device, federated_train_loader, optimizer, epoch)
    test(args, model, device, test_loader)

if (args.save_model):
    torch.save(model.state_dict(), ""mnist_cnn.pt"")
```


python 3.7.7
torch 1.4.0

This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hi, have you find a solution?> Hi, have you find a solution?

Not yet, I have given up PySyftThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.I got the same issue, is there any solution to this?"	5	2020-07-27 15:08:33	2021-11-19 14:33:30	2020-12-21 00:15:52
https://github.com/OpenMined/PySyft/issues/3897	['bug ', 'status: stale :bread:']	split_neural_network tutorial fails at move() method when work with Websocket Workers	"split_neural_network tutorial fails at move() method when work with Websocket Workers## Description
After I changed VirtualWorkers to pairs of WebSocketServerWorker and WebSocketClientWorker. The move method stop working. 
The notebook prints ""RuntimeError: Websocket connection closed and creation of new connection failed.""
The WebSocketServerWorker prints ""Worker alice1 couldn't recognize worker alice2"" and raise an error saying ""AttributeError: 'str' object has no attribute '_recv_msg'""

## How to Reproduce
1. Go to [Tutorial 1 - SplitNN Introduction.ipynb](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb)
2. Modify the VirtualWorkers to WebSocket Workers and those related variables (Bob, Alice => Alice1, Alice2 in screenshot)
3. Make sure the WebSocketServerWorkers are running.
4. Click ""Kernel"" => ""Restart & Run All""
5. See error

## Expected Behavior
Move() method can move objects from one WebSocketServerWorker to another.

## Screenshots
![Screen Shot 2020-07-25 at 5 31 30 PM](https://user-images.githubusercontent.com/34226180/88466687-e62ab500-ce9c-11ea-883c-37b4b9567c2e.png)
![Screen Shot 2020-07-25 at 5 32 14 PM](https://user-images.githubusercontent.com/34226180/88466688-ea56d280-ce9c-11ea-8718-d37d06564167.png)
![Screen Shot 2020-07-25 at 5 31 59 PM](https://user-images.githubusercontent.com/34226180/88466689-ecb92c80-ce9c-11ea-9ed9-72c57c6f3d9a.png)
![Screen Shot 2020-07-25 at 5 12 12 PM](https://user-images.githubusercontent.com/34226180/88466411-fd1bd800-ce99-11ea-8091-17af4ef577d3.png)

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.6.9; Syft 0.2.6
 - Package Manager Version: pip 20.1.1
 - Browser (if applicable): Safari
 - Browser Version (if applicable): Version 13.1.1 (15609.2.9.1.2)


Thank you for your help!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This bug is still present unfortunately.Is there any other way to bypass the problem by using some alternative method than **move()**This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hi,
    Just in case for anyone in the same situation, this is fixed with PyGrid workers.(not supporting PySyft-0.3.0 for now)
    You can check [this slack posting](https://openmined.slack.com/archives/C6EEFN3A8/p1596720041221900?thread_ts=1596661549.217900&cid=C6EEFN3A8) for an example to setup PyGrid workers and then move() should work.

Thanks,"	5	2020-07-25 21:36:41	2020-12-14 16:29:52	2020-12-14 16:29:52
https://github.com/OpenMined/PySyft/issues/3887	['bug ', '0.2.x']	Cannot move traced model to cuda	"Cannot move traced model to cuda## Description
After initializing TorchHook and tracing model you can't move this model to another device (cuda or cpu). This happens because  method `parameters()` of a traced model returns list of torch.Tensor instead of list of nn.Parameter, so we can't move tensors to another device because they don't have setter for .data property
https://github.com/OpenMined/PySyft/blob/5c8e7b78eba693ea29e07eac7476aa7517e5dfef/syft/frameworks/torch/tensors/interpreters/native.py#L141


```
import torch
import syft as sy
hook = sy.TorchHook(torch)
model = torch.nn.Linear(1,1)
model = torch.jit.trace(model,torch.rand(1,1))
model.cpu()
```
This code produces error `AttributeError: can't set attribute`
The traceback:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-54d42a2d39a0> in <module>
----> 1 model.cpu()

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in cpu(self)
    310             Module: self
    311         """"""
--> 312         return self._apply(lambda t: t.cpu())
    313 
    314     def type(self, dst_type):

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in _apply(self, fn)
    224                 should_use_set_data = compute_should_use_set_data(param, param_applied)
    225                 if should_use_set_data:
--> 226                     param.data = param_applied
    227                 else:
    228                     assert isinstance(param, Parameter)

AttributeError: can't set attribute
```

## System Information
 - PySyft 0.2.7
 - Torch 1.4.0
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.@NProkoptsev is there any workaround for this problem? Save model to disk, then
torch.jit.load(f, map_location='cuda') @NProkoptsev thanks, I do so. But it seems saving and loading would break the object pointer so once you use the `get` command to retrieve your model from one of the workers it retrieves the old one (the same model before saving and not the updated one).
```Python
torch.jit.save(model,'model.pt')
model = torch.jit.load('model.pt',map_location='cpu')
```Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue."	5	2020-07-21 22:38:35	2020-11-19 13:26:11	2020-11-19 13:26:09
https://github.com/OpenMined/PySyft/issues/3879	['bug ', 'status: stale :bread:']	'Dense' object has no attribute '_constructor_parameters_store'	"'Dense' object has no attribute '_constructor_parameters_store'## Description
I am trying to recreate  to recreate [this Keras example](https://keras.io/examples/structured_data/imbalanced_classification/) using PySyft. I am facing the following error : `AttributeError: 'Dense' object has no attribute '_constructor_parameters_store'`
when I run `model.share(cluster)`.

## How to Reproduce
1. `git clone https://github.com/madisonestabrook/imbalanced_classification.git`
2. `cd imbalanced_classification`
3. `conda env create -f pysyft.yml`
4. Download the data from [https://www.kaggle.com/mlg-ulb/creditcardfraud/](https://www.kaggle.com/mlg-ulb/creditcardfraud/) and place in your `imbalanced_classification` folder
5. Open `imbalanced_classification.ipynb` your preferred `.ipynb` editor 
6. Run up to cell 7
7. Notice the error

## Expected Behavior
The code should run without errors.

## Screenshots
![image](https://user-images.githubusercontent.com/29613918/87881340-96447d80-c9c6-11ea-82ae-164277fadd00.png)

## System Information
 - OS: Windows
 - OS Version: 10 Pro (64-bit)
 - Language Version: Python 3.7.7 (64-bit) 
 - Package Manager Version: Anaconda 2020.02
-  `.ipynb` Editor: Visual Studio Code

## Additional Context
I am trying to apply the [tutorials](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials) to non-toy and non-text data. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-07-19 17:58:58	2020-12-21 00:15:55	2020-12-21 00:15:54
https://github.com/OpenMined/PySyft/issues/3871	['bug ', 'status: stale :bread:']	socket timeout error in deploy_workers example	"socket timeout error in deploy_workers example## Description
When I try out the [deploy_workers example](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/websocket/deploy_workers/deploy-and-connect.ipynb) code after creating workers with the given docker-compose file it is giving me a socket timeout error.

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 66, in __init__
    self.connect()
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 78, in connect
    self.ws = websocket.create_connection(**args_)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_http.py"", line 193, in _open_socket
    raise error
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_http.py"", line 176, in _open_socket
    sock.connect(address)
socket.timeout: timed out
``` 

In the example code the host is  127.0.0.1. That code on execution gave me this error,
```
Websocket connection closed (worker: alice)
Created new websocket connection
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 66, in __init__
    self.connect()
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 79, in connect
    self._log_msgs_remote(self.log_msgs)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 145, in _log_msgs_remote
    return self._send_msg_and_deserialize(""_log_msgs"", value=value)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 126, in _send_msg_and_deserialize
    response = self._send_msg(serialized_message)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 93, in _send_msg
    return self._recv_msg(message)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 117, in _recv_msg
    ""Websocket connection closed and creation of new connection failed.""
RuntimeError: Websocket connection closed and creation of new connection failed.
```

So I inspected the container ids and found out docker created those workers in different IPs.
Like ""127.21.0.1"". I tried those IPs and received the first error.

## How to Reproduce
1. docker-compose up this [docker-compose file](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/websocket/deploy_workers/docker-compose.yaml)
2. Try the following code
```python
import torch
import syft
from syft import WebsocketClientWorker
hook = syft.TorchHook(torch)
alice = WebsocketClientWorker(hook=hook, id=""alice"", host=""172.0.0.1"", port=8777)
```

I tried the localhost and the IP address docker compose inspect container provided. Both resulted in corresponding errors I mentioned above

## System Information
 - OS: MacOS Catelina
 - OS Version: 10.15.5
 - Language Version: Python 3.7
 - Package Manager Version: Conda 4.8.3
 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-07-17 21:40:39	2020-08-24 00:10:59	2020-08-24 00:10:59
https://github.com/OpenMined/PySyft/issues/3863	['bug ', 'status: stale :bread:']	Averaging method utils.federated_avg(models) returns wrong results and further bug	"Averaging method utils.federated_avg(models) returns wrong results and further bug## Description
The result of the function utils.federated_avg() is not the average of the input models.

## How to Reproduce
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x,dim=1)

net1 = Net()
net2 = Net()
avg_net = utils.federated_avg(dict(enumerate([net1, net2])))
print(""Net 1  "", list(net1.parameters())[0][0][0][0])
print(""Net 2  "", list(net2.parameters())[0][0][0][0])
print(""----------------------------"")
print(""fed_avg"", list(avg_net.parameters())[0][0][0][0])
print(""----------------------------"")
print(""avg 1+2"", 1/2*(list(net1.parameters())[0][0][0][0]+list(net2.parameters())[0][0][0][0]))
print(""----------------------------"")
print(""Net 1  "", list(net1.parameters())[0][0][0][0])
print(""Net 2  "", list(net2.parameters())[0][0][0][0])

## Expected Behavior
The result should be the average.
## Screenshots
![FA Not Correct 3](https://user-images.githubusercontent.com/68423474/87773999-3f06a780-c824-11ea-8284-330806811356.png)

## What is the Problem and how to fix?

In the method utils.federated_avg(models) you initially use
**model = type(model_list[0])()**
to sum over the input models. Unfortunatelly, model has **non zero parameters**, which causes the wrong result.
A fix could be 
![Hot Fix FA Error in Initialize](https://user-images.githubusercontent.com/68423474/87774354-b50b0e80-c824-11ea-8dd5-a9eb38c4dc10.png)
There is a further bug in the averaging method: If two nets living on the GPU are averaged, one gets an exception because the new model for the sum is initiated on the CPU.

![average cuda bug](https://user-images.githubusercontent.com/68423474/89156140-7b4b3f00-d56a-11ea-9519-3a3ea362f0ad.png)
What is the current state of this issue?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	3	2020-07-17 09:58:43	2020-11-29 00:11:35	2020-11-29 00:11:35
https://github.com/OpenMined/PySyft/issues/3848	['bug ', 'status: stale :bread:']	Cannot move PointerTensors to GPU	"Cannot move PointerTensors to GPUSo, while trying to retrieve a model on GPU using .get(), I came across the following error:

`RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_`

Here is the traceback:

```
~/splitnn/src/utils/trainer.py in split_train(client_ids, data_paths, server_model, client_model, hook, optim, optim_params, criterion, dataloader_fn, dataloader_params, save_path, num_epochs, verbose, cuda)
    262                            dataloaders=dataloaders, criterion=criterion, num_epochs=num_epochs,
    263                            save_path=save_path, verbose=verbose, device=device)
--> 264     stats = trainer.train()
    265 
    266     return stats

~/splitnn/src/utils/trainer.py in train(self, train_clts, val_clts)
     68                 print('\nTraining client {}, epoch {}\n'.format(client_id, epoch + 1))
     69 
---> 70                 train_metrics = self._run_epoch('train', client_id)
     71                 self._log('train', 'loss', client_id, epoch + 1, train_metrics['loss'])
     72                 if self.verbose > 0:

~/splitnn/src/utils/trainer.py in _run_epoch(self, mode, client_id)
    113             else:
    114                 pred, loss = self._validate_iter(image, label, client_id)
--> 115             client = self.network.clients[client_id].get()
    116             print(""PASSED!!!!!!!!!!!!!!"")
    117             running_loss += loss

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
    673             if isinstance(nn_self.forward, Plan):

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in get_(self, *args, **kwargs)
    670         Calls get() with inplace option set to True
    671         """"""
--> 672         return self.get(*args, inplace=True, **kwargs)
    673 
    674     def allow(self, user=None) -> bool:

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    657 
    658         if inplace:
--> 659             self.set_(tensor)
    660             if hasattr(tensor, ""child""):
    661                 self.child = tensor.child

RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_
```

I manually checked that all the parameters of the model and the input images are in fact located on GPU.  After investigating the `~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py` line 671 with a lot of print statements, I found that when the model goes into the for loop:
```
~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
```

one of the `p`  values is a PointerTensor located on the CPU with `tensor.Size([ ])` whereas the previous (non-erroring) `p`s are located on GPU with regular tensor sizes (e.g. `tensor.Size([64, 3, 3, 3])`). I tried to move the PointerTensors to GPU, using `.to()` and `.cuda()` methods, but those failed to change the pointer's device. The issue got finally resolved when I wrote:

`torch.set_default_tensor_type(torch.cuda.FloatTensor)`

I don't fully understand why this is happening, but I feel it may be related to [this issue](https://github.com/OpenMined/PySyft/issues/2518). It would also be greatly useful for debugging purposes if it were possible to move PointerTensors from one device to another.
Recently I ran into the same issue while training a ResNet18 model with PySyft on GPU.

In my case, I found the error was caused by `torch.nn.BatchNorm2d`, which would generate `num_batches_tracked` tensors in Buffers and push them to CPU while `forward()`.

A quick solution is to set `track_running_stats=False` when using `torch.nn.BatchNorm2d`. However, this results in `torch.nn.BatchNorm2d` using batch statistics instead of running estimates while training ([[1](https://pytorch.org/docs/master/generated/torch.nn.BatchNorm2d.html)], [[2](https://discuss.pytorch.org/t/what-num-batches-tracked-in-the-new-bn-is-for/27097)]).This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-07-10 12:42:59	2020-08-20 00:10:33	2020-08-20 00:10:33
https://github.com/OpenMined/PySyft/issues/3845	['bug ', 'status: stale :bread:']	clone on a remote nn.Module fails	"clone on a remote nn.Module fails## Description
Take a model, .send() it and call clone on it, it will fail.


## How to Reproduce
```
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in clone(self, *args, **kwargs)
    758 
    759         if self.has_child():
--> 760             cloned_tensor.child = self.child.clone(*args, **kwargs)
    761 
    762         return cloned_tensor

TypeError: clone() got an unexpected keyword argument 'memory_format'
```

## How to solve
Add the memory_format kwarg to the clone method of pointer tensorSame with `copy()` method as it invokes `clone`. Hi @LaRiffle, I'm trying to reproduce, but I don't quite understand how.

```
import torch
import torch.nn as nn
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")
```

I've tested 3 cases.

#### Case 1

```
model = nn.Linear(2, 1)
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

#### Case 2
```
model = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 1))
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

#### Case 3
```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc = nn.Linear(2, 1)
    def forward(self, x):
        return nn.functional.relu(self.fc(x))

model = Net()
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

All the cases fail but with a different error like:
```
...
AttributeError: 'Linear' object has no attribute 'clone'
```

How is this clone supposed to be made?

I also ended up noticing that I can do things like these ones, 

```
model_weights_copy = model_ptr.weight.clone()
model_bias_copy = model_ptr.bias.clone()
```
which works!
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	3	2020-07-10 09:12:22	2020-08-20 00:10:35	2020-08-20 00:10:35
https://github.com/OpenMined/PySyft/issues/3844	['bug ', 'status: stale :bread:']	CUDA out of memory in middle of training due to .move() command	"CUDA out of memory in middle of training due to .move() command## Description
So, I came across a CUDA OOM issue in the middle of training when training a network with PySyft. I clearly had enough GPU memory since the first ~50 iterations did not raise any memory errors, and therefore, the OOM was due to some memory leak. Investigating the source of leak with garbage collector, I realized that it was sourced in the `move()` method of pysyft:

```
        out_client = client.forward(x)
        x_server = out_client.move(server.location, requires_grad=True)
        out_server = server.forward(x_server)
        
        return out_server
```
I modeled the above piece of code after [this](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb) Split Learning notebook, and so expected it to be bug-free. Yet, the number of items in the garbage collector increased immediately after using the move function. My understanding is that `move()` does not release the 
client activations from memory. Replacing `move()` with `send()` and `remote_get` resolved the issue:

```
        out_client = client.forward(x)
        x_server = out_client.send(server.location, requires_grad=True)
        x_server = x_server.remote_get()
        out_server = server.forward(x_server)
        
        return out_server
```
Yet, by [this](https://blog.openmined.org/federated-learning-additive-secret-sharing-pysyft/) OpenMined blog post, `move()` method should be equivalent to calling `send()` and `remote_get()` together.  

Given this, it would be great if OpenMined team could:

1.  Clarify the differences between `move()` and `send () + remote_get()`
2. Update [the blog post](https://blog.openmined.org/federated-learning-additive-secret-sharing-pysyft/) if the current description of `move()` is mislearding, or fix the memory management bug
3. Update [the split learning notebook]((https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb) ) since using `move()` causes the same memory issue as can be seen from printing the number of garbage collector objects in the data iteration loop. The code doesn't currently error out since the cifar10 dataset is so small but will if you change the dataset, increase the model complexity, or use a larger dataset. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-07-10 04:40:33	2020-08-17 00:10:47	2020-08-17 00:10:47
https://github.com/OpenMined/PySyft/issues/3834	['bug ', 'status: stale :bread:']	"""clone() got an unexpected keyword argument 'memory_format'"" at model.copy().get() "	"""clone() got an unexpected keyword argument 'memory_format'"" at model.copy().get() ## Description
This bug has been recently reported before at [this issue](https://github.com/OpenMined/PySyft/issues/3514) but was closed with no follow-up.  Since problem seems quite fundamental, I decided to bring this up again.  

As the title says, trying to copy a model in a remote server raises ""clone() got an unexpected keyword argument 'memory_format'""  error.  

Here is the traceback:

```
/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    278     if state is not None:
    279         if deep:
--> 280             state = deepcopy(state, memo)
    281         if hasattr(y, '__setstate__'):
    282             y.__setstate__(state)

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    148     copier = _deepcopy_dispatch.get(cls)
    149     if copier:
--> 150         y = copier(x, memo)
    151     else:
    152         try:

~/splitnn/venv/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)
    238     memo[id(x)] = y
    239     for key, value in x.items():
--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)
    241     return y
    242 d[dict] = _deepcopy_dict

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    304             for key, value in dictiter:
    305                 key = deepcopy(key, memo)
--> 306                 value = deepcopy(value, memo)
    307                 y[key] = value
    308         else:

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    278     if state is not None:
    279         if deep:
--> 280             state = deepcopy(state, memo)
    281         if hasattr(y, '__setstate__'):
    282             y.__setstate__(state)

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    148     copier = _deepcopy_dispatch.get(cls)
    149     if copier:
--> 150         y = copier(x, memo)
    151     else:
    152         try:

~/splitnn/venv/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)
    238     memo[id(x)] = y
    239     for key, value in x.items():
--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)
    241     return y
    242 d[dict] = _deepcopy_dict

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    304             for key, value in dictiter:
    305                 key = deepcopy(key, memo)
--> 306                 value = deepcopy(value, memo)
    307                 y[key] = value
    308         else:

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    159             copier = getattr(x, ""__deepcopy__"", None)
    160             if copier:
--> 161                 y = copier(memo)
    162             else:
    163                 reductor = dispatch_table.get(cls)

~/splitnn/venv/lib/python3.6/site-packages/torch/nn/parameter.py in __deepcopy__(self, memo)
     30             return memo[id(self)]
     31         else:
---> 32             result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)
     33             memo[id(self)] = result
     34             return result

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in clone(self, *args, **kwargs)
    758 
    759         if self.has_child():
--> 760             cloned_tensor.child = self.child.clone(*args, **kwargs)
    761 
    762         return cloned_tensor

TypeError: clone() got an unexpected keyword argument 'memory_format'
```

It seems like the problem is inherent to the PySyft package since the kwarg `memory_format` is supplied by the native `__deepcopy__` method of torch which `TorchTensor` [seems to be calling](https://github.com/OpenMined/PySyft/blob/8a65122db3c09a1bcc213c803be38a86a8e909ef/syft/frameworks/torch/tensors/interpreters/native.py#L765) for its children. 
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-07-08 12:37:54	2020-08-16 00:10:38	2020-08-16 00:10:38
https://github.com/OpenMined/PySyft/issues/3833	['bug ']	TypeError: add_() takes 1 positional argument but 2 were given with Adam optimizer	"TypeError: add_() takes 1 positional argument but 2 were given with Adam optimizer## Description
Running federated learning with Adam optimizer gives the error
```python
Websocket connection closed (worker: wlg)
Created new websocket connection
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-12-d30adddcefbb> in <module>
     28             loss = criterion(pred, target_batches[i][j])
     29             loss.backward()
---> 30             optimizer.step()
     31         model = model.get()
     32         loss = loss.get()

~/anaconda3/envs/Syft/lib/python3.8/site-packages/torch/optim/adam.py in step(self, closure)
     93 
     94                 # Decay the first and second moment running average coefficient
---> 95                 exp_avg.mul_(beta1).add_(1 - beta1, grad)
     96                 exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
     97                 if amsgrad:

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    208                 # Send the new command to the appropriate class and get the response
    209                 method = getattr(new_self, method_name)
--> 210                 response = method(*new_args, **new_kwargs)
    211 
    212                 # For inplace methods, just directly return self

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/generic/frameworks/hook/pointers.py in overloaded_pointer_method(self, *args, **kwargs)
     82 
     83             # Send the command
---> 84             response = owner.send_command(location, attr, self, args, kwargs)
     85 
     86             # For inplace methods, just directly return self

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    624                 cmd_name, target, args_, kwargs_, return_ids, return_value
    625             )
--> 626             ret_val = self.send_msg(message, location=recipient)
    627         except ResponseSignatureError as e:
    628             ret_val = None

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/base.py in send_msg(self, message, location)
    272 
    273         # Step 2: send the message and wait for a response
--> 274         bin_response = self._send_msg(bin_message, location)
    275 
    276         # Step 3: deserialize the response

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
     14             sleep(self.message_pending_time)
     15 
---> 16         return location._recv_msg(message)
     17 
     18     def _recv_msg(self, message: bin) -> bin:

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/websocket_client.py in _recv_msg(self, message)
    112             response = self._forward_to_websocket_server_worker(message)
    113             if not self.ws.connected:
--> 114                 raise RuntimeError(
    115                     ""Websocket connection closed and creation of new connection failed.""
    116                 )

RuntimeError: Websocket connection closed and creation of new connection failed.
```
## How to Reproduce
1. Run FL on two clients then train using the code below:
```python
for epoch in range(N_EPOCS):
    epoch_total = epoch_total_size(data_batches[0])
    current_epoch_size = 0
    for i in range(len(compute_nodes)):
        worker = data_batches[i][0].location
        print(worker)
        model.send(worker)
        for j in range(len(data_batches[i])):
            current_epoch_size += len(data_batches[i][j])
            optimizer.zero_grad()
            pred = model(data_batches[i][j])
            print(target_batches[i][j].shape, pred.shape)
            loss = criterion(pred, target_batches[i][j])
            loss.backward()
            optimizer.step()
        model = model.get()
        loss = loss.get()
```


## System Information
- PyTorch 1.4.0
- Syft 0.2.6

## Additional Context
The error raises when I finish one epoch on the first client, get the model, send it to the second client then it raises at line optimizer.step()
Hey @wmlba, could you share a notebook/script with all the code (that throws this error)? This is also happening for virtual workers, right?@gmuraru Thanks for chiming in. After some research, i figured that this issue is related to this: https://github.com/OpenMined/PySyft/issues/3349

The default Adam optimizer work but the wrapped version will. This is due to having multiple different workers. Closing now."	2	2020-07-08 11:50:22	2020-07-11 01:09:33	2020-07-11 01:09:33
https://github.com/OpenMined/PySyft/issues/3825	['bug ', 'status: stale :bread:']	[torch] Cannot set values at indices in a tensor	"[torch] Cannot set values at indices in a tensor## Description
Code like:
```Python
t = torch.zeros((2, 3), dtype=torch.float)
indices = torch.rand_like(t) > 0.5
t[indices] = 1
```
is fine when not hooked but fails when Torch is hooked.

## How to Reproduce
```Python
import syft as sy
import torch


def set_indices():
	t = torch.zeros((2, 3), dtype=torch.float)
	indices = torch.rand_like(t) > 0.5
	t[indices] = 1
	print(""Set indices"")


# The first call works fine.
set_indices()
hook = sy.TorchHook(torch)
# This call fails.
set_indices()
```

```
Set indices
Traceback (most recent call last):
  File ""code.py"", line 16, in <module>
    set_indices()
  File ""code.py"", line 8, in set_indices
    t[indices] = 1
  File ""[REDACTED]\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 170, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""[REDACTED]\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 166, in overloaded_native_method
    response = method(*args, **kwargs)
IndexError: The shape of the mask [3] at index 0 does not match the shape of the indexed tensor [2, 3] at index 0
```



## Expected Behavior
Should be able to assign a value.

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.7.7
 - Package Manager Version: Anaconda
- syft==0.2.6 (Installed via Pip)
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Can anyone advise on where to make the change the correct this?I encountered the same issue when using facenet-pytorch (https://github.com/timesler/facenet-pytorch), using Python version 3.7.9, PySyft version 0.2.9 and PyTorch version 1.4. My code:
```python
from facenet_pytorch import MTCNN
from PIL import Image
import torch
import syft as sy

im = Image.open(""example.jpg"")
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

mtcnn = MTCNN(
    image_size=160, margin=0, min_face_size=20,
    thresholds=[0.6,0.7,0.7], factor=0.709, post_process=True,
    device=device, keep_all=True
)

# Calling this works fine
x_aligned = mtcnn(im)
hook = sy.TorchHook(torch)

# This call fails with an IndexError
x_aligned = mtcnn(im)
```
The error is
```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-5-44b80875f4ab> in <module>
----> 1 x_aligned = mtcnn(im)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/mtcnn.py in forward(self, img, save_path, return_prob)
    245         # Detect faces
    246         with torch.no_grad():
--> 247             batch_boxes, batch_probs = self.detect(img)
    248 
    249         # Determine if a batch or single image was passed

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/mtcnn.py in detect(self, img, landmarks)
    352                 self.pnet, self.rnet, self.onet,
    353                 self.thresholds, self.factor,
--> 354                 self.device
    355             )
    356 

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/utils/detect_face.py in detect_face(imgs, minsize, pnet, rnet, onet, threshold, factor, device)
     73         reg, probs = pnet(im_data)
     74 
---> 75         boxes_scale, image_inds_scale = generateBoundingBox(reg, probs[:, 1], scale, threshold[0])
     76         boxes.append(boxes_scale)
     77         image_inds.append(image_inds_scale)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/utils/detect_face.py in generateBoundingBox(reg, probs, scale, thresh)
    210     mask_inds = mask.nonzero()
    211     image_inds = mask_inds[:, 0]
--> 212     score = probs[mask]
    213     reg = reg[:, mask].permute(1, 0)
    214     bb = mask_inds[:, 1:].type(reg.dtype).flip(1)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    167                 except BaseException as e:
    168                     # we can make some errors more descriptive with this method
--> 169                     raise route_method_exception(e, self, args, kwargs)
    170 
    171             else:  # means that there is a wrapper to remove

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    163 
    164                 try:
--> 165                     response = method(*args, **kwargs)
    166 
    167                 except BaseException as e:

IndexError: The shape of the mask [111, 226] at index 0 does not match the shape of the indexed tensor [1, 111, 226] at index 0
```
and appears to be caused by the line `score = probs[mask]`, so I presume it is the same indexing issue.If there are technical reasons for why it is not possible, it would be nice to at least have a function which removes the hook from torch. That way one could arbitrarily switch between some standard (local) torch operations not supported by PySyft and some private operations on secretly shared data.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	5	2020-07-06 18:54:53	2020-12-21 00:16:12	2020-12-21 00:16:12
https://github.com/OpenMined/PySyft/issues/3819	['bug ', 'status: stale :bread:']	"Cannot using the command "".share()"" in distributed environment"	"Cannot using the command "".share()"" in distributed environment## Description
When I send the tensor X from python notebook to bob worker that running by using WebsockerServer instead of the virtual machine in another instance (IP address: A). I also create another instance Alice worker by using WebsocketServer (IP address: B).  I cannot run this command ""x.share(Alice, bob)"" They said cannot serialize the WebsocketClientWorker.
`
## How to Reproduce

```
from torchvision.models.resnet import ResNet, BasicBlock
import syft as sy
from torchvision.datasets import MNIST
import torch.nn.functional as F
from tqdm.autonotebook import tqdm
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import inspect
import time
from torch import nn, optim
import torch
from torchvision.transforms import Compose, ToTensor, Normalize, Resize
from torch.utils.data import TensorDataset, DataLoader
from torchvision import datasets, transforms
from syft.workers.websocket_client import WebsocketClientWorker                                                                                                                                                                                   hook = sy.TorchHook(torch)
# verbose mode
kwargs_websocket_worker_alice = {""host"": ""xx.xx.xx.xx"", ""hook"": hook,""verbose"":False}
kwargs_websocket_worker_bob = {""host"": ""x.xx.xxx.xxx"", ""hook"": hook,""verbose"":False}
alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_worker_alice)
bob = WebsocketClientWorker(id=""bob"", port=8778, **kwargs_websocket_worker_bob)
test = torch.tensor([25]).send(bob)
check = test.share(bob,alice)
```
The error that I got.
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-4ac801f8f830> in <module>
      1 test = torch.tensor([25]).send(bob)
----> 2 check = test.share(bob,alice)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
    907                 dtype=dtype,
    908                 crypto_provider=crypto_provider,
--> 909                 **kwargs_,
    910             )
    911         else:
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
    380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
    381 
--> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
    383         return response
    384 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    624                 cmd_name, target, args_, kwargs_, return_ids, return_value
    625             )
--> 626             ret_val = self.send_msg(message, location=recipient)
    627         except ResponseSignatureError as e:
    628             ret_val = None
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    269 
    270         # Step 1: serialize the message to a binary
--> 271         bin_message = sy.serde.serialize(message, worker=self)
    272 
    273         # Step 2: send the message and wait for a response
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
     43         strategy = serialize
     44 
---> 45     return strategy(obj, worker, simplified, force_full_simplification)
     46 
     47 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
    335 
    336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
--> 337     return _serialize_msgpack_binary(simple_objects)
    338 
    339 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
    289     # 2) Serialize
    290     # serialize into a binary
--> 291     binary = msgpack_lib.dumps(simple_objects)
    292 
    293     # 3) Compress
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
     33     See :class:`Packer` for options.
     34     """"""
---> 35     return Packer(**kwargs).pack(o)
     36 
     37 
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
TypeError: can not serialize 'WebsocketClientWorker' object
```
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.> ## Description
> When I send the tensor X from python notebook to bob worker that running by using WebsockerServer instead of the virtual machine in another instance (IP address: A). I also create another instance Alice worker by using WebsocketServer (IP address: B). I cannot run this command ""x.share(Alice, bob)"" They said cannot serialize the WebsocketClientWorker.
> `
> 
> ## How to Reproduce
> ```
> from torchvision.models.resnet import ResNet, BasicBlock
> import syft as sy
> from torchvision.datasets import MNIST
> import torch.nn.functional as F
> from tqdm.autonotebook import tqdm
> from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
> import inspect
> import time
> from torch import nn, optim
> import torch
> from torchvision.transforms import Compose, ToTensor, Normalize, Resize
> from torch.utils.data import TensorDataset, DataLoader
> from torchvision import datasets, transforms
> from syft.workers.websocket_client import WebsocketClientWorker                                                                                                                                                                                   hook = sy.TorchHook(torch)
> # verbose mode
> kwargs_websocket_worker_alice = {""host"": ""xx.xx.xx.xx"", ""hook"": hook,""verbose"":False}
> kwargs_websocket_worker_bob = {""host"": ""x.xx.xxx.xxx"", ""hook"": hook,""verbose"":False}
> alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_worker_alice)
> bob = WebsocketClientWorker(id=""bob"", port=8778, **kwargs_websocket_worker_bob)
> test = torch.tensor([25]).send(bob)
> check = test.share(bob,alice)
> ```
> 
> The error that I got.
> 
> ```
> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-7-4ac801f8f830> in <module>
>       1 test = torch.tensor([25]).send(bob)
> ----> 2 check = test.share(bob,alice)
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
>     907                 dtype=dtype,
>     908                 crypto_provider=crypto_provider,
> --> 909                 **kwargs_,
>     910             )
>     911         else:
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
>     380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
>     381 
> --> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
>     383         return response
>     384 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
>     624                 cmd_name, target, args_, kwargs_, return_ids, return_value
>     625             )
> --> 626             ret_val = self.send_msg(message, location=recipient)
>     627         except ResponseSignatureError as e:
>     628             ret_val = None
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
>     269 
>     270         # Step 1: serialize the message to a binary
> --> 271         bin_message = sy.serde.serialize(message, worker=self)
>     272 
>     273         # Step 2: send the message and wait for a response
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
>      43         strategy = serialize
>      44 
> ---> 45     return strategy(obj, worker, simplified, force_full_simplification)
>      46 
>      47 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
>     335 
>     336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
> --> 337     return _serialize_msgpack_binary(simple_objects)
>     338 
>     339 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
>     289     # 2) Serialize
>     290     # serialize into a binary
> --> 291     binary = msgpack_lib.dumps(simple_objects)
>     292 
>     293     # 3) Compress
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
>      33     See :class:`Packer` for options.
>      34     """"""
> ---> 35     return Packer(**kwargs).pack(o)
>      36 
>      37 
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> TypeError: can not serialize 'WebsocketClientWorker' object
> ```

I had the same problem. Did you solve it?"	2	2020-07-05 06:12:24	2020-09-03 05:40:42	2020-08-12 00:10:07
https://github.com/OpenMined/PySyft/issues/3814	['bug ']	.serve_model() throws error while serving MPC model on the grid platform	".serve_model() throws error while serving MPC model on the grid platform## Description
Tutorial: [Grid as a Secure MLaaS ](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/Part%2002%20-%20Grid%20as%20a%20Secure%20MLaaS%20to%20Cloud%20Providers.ipynb)

While serving the model, this error is thrown:
JSONDecodeError: Expecting value: line 1 column 1 (char 0)

in line:
cloud_grid_service.serve_model(model,id=model.id,allow_remote_inference=True, mpc=True)

## How to Reproduce
1. Setup grid network(PyGridNetwork) and nodes(PyGridNode).
2. Create a model which extends Plan Parent Class.
3. Serve the model

## Expected Behavior
It should split the model weights into pieces by distributing it through grid network.


## System Information
 - OS: Linux(Ubuntu)
 - OS: 20.4
 - Language Version: Python 3.8.3
 - Package Manager Version: Conda 4.6.11
 - Browser: Google ChromeThis issue was related to PyGridNetwork so I am closing this issue.This issue was related to PyGridNetwork so I am closing this issue."	2	2020-07-03 17:43:15	2020-07-03 21:23:22	2020-07-03 21:23:10
https://github.com/OpenMined/PySyft/issues/3806	['bug ', 'status: stale :bread:']	Type conversion from float to int on remote server is not working	"Type conversion from float to int on remote server is not working## Description
Type conversion from float to int on remote server is not working.

## How to Reproduce

```
somefloat = torch.tensor([1.0, 0.5])
pointer_to_somefloat = somefloat.send(bob)
floatsum = pointer_to_somefloat.sum()
floatsum.get()
> return tensor(1.5000)
```

Since the code above works, I think code below also works.  
But it's not.

```
somefloat = torch.tensor([1.0, 0.5])
pointer_to_somefloat = somefloat.send(bob)
pointer_to_somefloat.int()
> return tensor([], dtype=torch.int32) not even a pointer
```
If someone know how to convert float into int on remote server, please let me know.  
Thanks in advance.

## Expected Behavior
```pointer_to_somefloat.int()``` should return pointer to integer tensor.

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.7
 - Package Manager Version: Conda 4.6.11

## Additional Context
It could be specification. but some model like speech recognition need to convert float into int on remote server....This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-07-01 11:22:34	2020-08-08 00:10:08	2020-08-08 00:10:08
https://github.com/OpenMined/PySyft/issues/3800	['bug ', 'status: stale :bread:']	Createplan script in notebook fails	"Createplan script in notebook fails## Description
I am trying to set up the SwiftSyft project according to the instructions and I have the iOS client compiling and in theory the python environment up and running but when I get to step 22 in the CreatePlan notebook I get this error:
```
Cannot insert Placeholder, chain does not contain AutogradTensor tensor type.
````

## How to Reproduce
I have just followed the instructions in the readme.

## Expected Behavior
The notebook executes.

## Screenshots
![Screenshot 2020-06-29 at 15 39 28](https://user-images.githubusercontent.com/7461655/86012848-c380ba00-ba1e-11ea-9cc3-9a832f4e71de.png)


## System Information
 - OS: MacOS
 - OS Version: Catalina
 - Language Version: Python 3.7

## Additional Context
Add any other context about the problem here.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-06-30 10:21:31	2020-08-07 00:10:28	2020-08-07 00:10:28
https://github.com/OpenMined/PySyft/issues/3796	['bug ', 'status: stale :bread:']	add_dataset() function doesn't exist in websocket_server	"add_dataset() function doesn't exist in websocket_server## Description
https://github.com/OpenMined/PySyft/blob/275efceca60e4f8b58e5b5c98f18b8bebd15f889/run_websocket_server.py#L87

It seems like the add_dataset() function has been removed from websocket_server file.

## How to Reproduce
run the example involving this: https://github.com/OpenMined/PySyft/blob/master/run_websocket_server.py


## Expected Behavior
Adding a dataset to websocket server to be discoverable.

The new version does not support websocket. It seems that they can not solve it at this moment...This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-06-30 01:05:56	2020-08-20 00:10:39	2020-08-20 00:10:39
https://github.com/OpenMined/PySyft/issues/3794	['bug ', 'status: stale :bread:']	PyGrid example do not work 	"PyGrid example do not work ## Description
The example for pygrid do not work. 

## How to Reproduce

I want to run the example of mnist and spam_prediction in PySyft-master/examples/tutorials/grid/federated_learning/, but both failed. 

For example of mnist, it failed for  ```NodeClient(hook, node)```:
```
import syft as sy
from syft.workers.node_client import NodeClient
import torch
import pickle
import time
import torchvision
from torchvision import datasets, transforms
import tqdm

hook = sy.TorchHook(torch)

# Connect directly to grid nodes
nodes = [""ws://localhost:3000/"",
         ""ws://localhost:3001/""]

compute_nodes = []
for node in nodes:
    compute_nodes.append( NodeClient(hook, node) )
```

The error information is:
```
Traceback (most recent call last):
  File ""C:/Users/qiang_zhang.neu/Desktop/test/testGrid.py"", line 18, in <module>
    compute_nodes.append( NodeClient(hook, node) )
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\node_client.py"", line 65, in __init__
    None,  # initial data
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 64, in __init__
    self.connect()
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 76, in connect
    self.ws = websocket.create_connection(**args_)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 201, in _open_socket
    raise err
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it
```

Should we need to create a server firstly?

On the other hand, the tutorial ""Federated_SMS_Spam_prediction [Part 1] - Populate a Grid Network (Dataset).ipynb"" require that:

```
To start the gateway:
cd gateway
python gateway.py --start_local_db --port=5000

To start one grid node:
cd app/websocket/
python websocket_app.py --start_local_db --id=alice --port=3001 --gateway_url=http://localhost:5000
```
Actually, I can not find the folder of 'gateway' and 'app'. 

## Expected Behavior
I hope PySyft can provide an example for PyGrid. And more importantly, we expect an example of clinetworker and serverworker data loading and model training in real federate learning scenario. It should be run without error.

## System Information
 - OS: win10
 - Language Version: Python 3.7
 - Package Manager Version: syft 0.2.6

## Additional Context
Really need an example.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-06-29 07:08:35	2020-08-06 00:09:45	2020-08-06 00:09:45
https://github.com/OpenMined/PySyft/issues/3786	['bug ', 'status: stale :bread:']	Cifar10 accuracy with resnet18 on a single client is stuck at 75%	"Cifar10 accuracy with resnet18 on a single client is stuck at 75%## Description
Cifar10 accuracy with resnet18 on a single client is stuck at 75%
I ran for 200 epochs with a learning rate schedule of (0.1 till epoch100, 0.01 from 100-150, 0.001 from 150-200)
The accuracy I achieve on the test set is around 75%
Cifar10 accuracy with resnet18 should reach around 88-90% on centralized data.

I used the same hyper-parameters as in centralized implementation

## How to Reproduce
here is my code for a single client execution

import syft as sy  # <-- NEW: import the Pysyft library
import torch
torch.set_default_tensor_type(torch.cuda.FloatTensor)
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms, models

hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob

### modifying lr during training
def lr_function(epoch, first_lr_drop, second_lr_drop, third_lr_drop, initial_lr):
	if (epoch >= third_lr_drop):
		return initial_lr*0.1*0.1*0.1
	elif (epoch >= second_lr_drop):
		return initial_lr*0.1*0.1
	elif (epoch >= first_lr_drop):
		return initial_lr*0.1
	else:
		return initial_lr

class Arguments():
	def __init__(self):
		self.batch_size = 64
		self.test_batch_size = 1000
		self.epochs = 200
		self.lr = 0.1
		self.momentum = 0.9
		self.no_cuda = False
		self.seed = 1
		self.log_interval = 100
		self.save_model = False
		self.first_lr_drop = 100
		self.second_lr_drop = 150
		self.third_lr_drop = 200

args = Arguments()

use_cuda = not args.no_cuda and torch.cuda.is_available()

torch.manual_seed(args.seed)

device = torch.device(""cuda"" if use_cuda else ""cpu"")


transform = transforms.Compose(
	[ transforms.RandomCrop(32, padding=4),
	transforms.RandomHorizontalFlip(),
	transforms.ToTensor(),
	#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
	])

transform_test = transforms.Compose([
		transforms.ToTensor()
	])

federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
	datasets.CIFAR10('../data', train=True, download=True,
				   transform=transform)
	.federate([bob]), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
	batch_size=args.batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(
	datasets.CIFAR10('../data', train=False, transform=transform_test),
	batch_size=args.test_batch_size, shuffle=True)

print(device)
model = models.resnet18(pretrained=False)
model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)
model = model.to(device)

bobs_model = model.copy().send(bob) 

bobs_criterion = nn.CrossEntropyLoss()

criterion = nn.CrossEntropyLoss()

for epoch in range(args.epochs):
	bobs_model.train()

	bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=args.lr, momentum=args.momentum, weight_decay=2e-4)

	for param_group in bobs_opt.param_groups:
		param_group['lr'] = lr_function(epoch, args.first_lr_drop, args.second_lr_drop, args.third_lr_drop, args.lr)

	for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
		location = data.location
		data, target = data.to(device), target.to(device)
		bobs_opt.zero_grad()
		bobs_output = bobs_model(data)
		bobs_loss = bobs_criterion(bobs_output, target)
		bobs_loss.backward()
		bobs_opt.step()
		loss = bobs_loss.detach().get()

		if batch_idx % args.log_interval == 0:
			print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
				epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
				100. * batch_idx / len(federated_train_loader), loss.item()), flush=True)

	bobs_model.get()

	test_loss = 0
	correct = 0
	with torch.no_grad():
		for data, target in test_loader:
			data, target = data.to(device), target.to(device)
			output = bobs_model(data)
			test_loss += criterion(output, target).item() # sum up batch loss
			pred = output.argmax(1, keepdim=True) # get the index of the max log-probability 
			correct += pred.eq(target.view_as(pred)).sum().item()

	test_loss /= len(test_loader.dataset)

	print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
		test_loss, correct, len(test_loader.dataset),
		100. * correct / len(test_loader.dataset)))

	bobs_model.send(bob)


## Expected Behavior
I run the code with a single client 
Output after 200 epochs:

Optimizer lr:  0.0010000000000000002
Train batch size:  128
Train Epoch: 199 [0/50048 (0%)]	Loss: 0.000341
Train Epoch: 199 [6400/50048 (13%)]	Loss: 0.000293
Train Epoch: 199 [12800/50048 (26%)]	Loss: 0.000387
Train Epoch: 199 [19200/50048 (38%)]	Loss: 0.000356
Train Epoch: 199 [25600/50048 (51%)]	Loss: 0.000346
Train Epoch: 199 [32000/50048 (64%)]	Loss: 0.000281
Train Epoch: 199 [38400/50048 (77%)]	Loss: 0.000394
Train Epoch: 199 [44800/50048 (90%)]	Loss: 0.000462
Training avg batch loss: 0.0004
Epoch time:  196.71481251716614
Number of batches in epoch:  390

Test set: avg cln loss: 1.2113, cln acc: 7599/10000 (76%)

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - Linux (Ubuntu)
 - Red Hat Enterprise Linux Server release 7.6
 - Python 3.7
 - Conda 4.8.3
## Additional Context
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-06-25 17:30:16	2020-08-02 00:09:51	2020-08-02 00:09:51
https://github.com/OpenMined/PySyft/issues/3778	['bug ', 'status: stale :bread:']	argument of type 'WindowsPath' is not iterable	"argument of type 'WindowsPath' is not iterable## Description
Run examples/advance/websockets_mnist
ERROR:
argument of type 'WindowsPath' is not iterable

## How to Reproduce
cd path/PySyft-master/examples/tutorials/advanced/websockets_mnist
python start_websocket_servers.py

Then, I modify the start_websocket_servers.py as following:
```
...

FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py"")
FILE_PATH = str(FILE_PATH)
print(FILE_PATH)
...
```
The error of 'WindowsPath' is gone. Is it right to fix this bug?

However, a new error happen:
No module named 'pythreepio'



## System Information
 - OS: win10
 - Language Version: python 3.7.4
 - Package Manager Version: syft 0.2.6


This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-06-24 07:53:26	2020-08-01 00:09:36	2020-08-01 00:09:36
https://github.com/OpenMined/PySyft/issues/3774	['bug ']	Connection Refused Error	"Connection Refused ErrorThe connection error is reported in my computer. 

The code is very easy:
```
import torch
import syft
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host='localhost',
                            hook=hook,
                            id=2,
                            port=8181)
```
And the error is:
```
Traceback (most recent call last):
  File ""E:/FederatedLearning/code/test/client.py"", line 11, in <module>
    port=8181)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 64, in __init__
    self.connect()
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 76, in connect
    self.ws = websocket.create_connection(**args_)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 201, in _open_socket
    raise err
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [WinError 10061]  No connection could be made because the target machine actively refused it。
```
However, a test code for socket is OK:
```
import socket
import sys
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
host = socket.gethostname()
port = 9999
s.connect((host, port))
msg = s.recv(1024)
s.close()
print(msg.decode('utf-8'))
```

Then, I set the  socket.gethostname() to WebsocketClientWorker, and the code is:
```
import torch
import syft
import socket
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host=socket.gethostname(),
                            hook=hook,
                            id=2,
                            port=8181)
```
But the same error is reported.

How can I fixed this error? Finally, I find the solution. 

Using socket, we must create the server firstly, and then create the client. Those, the following code should be run firstly:

```
import syft as sy
import os
import sys
import logging
import torch
hook = sy.TorchHook(torch)

from syft.workers.websocket_server import WebsocketServerWorker

server_worker  = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182)

server_worker.start()  # Might need to interrupt with `CTRL-C` or some other means

```
Then, do not close it, and run the following code:

```
import torch
import syft
import socket
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host='localhost',
                            hook=hook,
                            id=2,
                            port=8182)
```
Then, it is OK."	1	2020-06-23 09:59:53	2020-06-24 02:46:17	2020-06-24 02:46:17
https://github.com/OpenMined/PySyft/issues/3716	[]	error: symbol not found	"error: symbol not foundWhen I test the syft, there is an error:

`ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/aiortc/codecs/_opus.abi3.so, 2): Symbol not found: ____chkstk_darwin`

It seems to be a problem caused by the version of Mac. However, I have no clue how to fix it without reinstall the Mac system.Appreciate for any commentsSolved by updating the system to 10.15.5"	2	2020-06-18 02:30:02	2020-06-22 06:14:03	2020-06-22 06:13:51
https://github.com/OpenMined/PySyft/issues/3706	['bug ', 'status: stale :bread:']	Part 2 of the Grid Tutorials Series throws TypeError in Step 2.2	"Part 2 of the Grid Tutorials Series throws TypeError in Step 2.2## Description
Running part 2 step 2.2 of the grid tutorial series with `mpc = True` throws `TypeError: can not serialize ‘NodeClient’ object`. With `mpc = False` the tutorial section works. This seems to be related to #3648.

## How to Reproduce
Just run the tutorial.

## Expected Behavior
An error message as below.

## Screenshots
```
TypeError                                 Traceback (most recent call last)
<ipython-input-4-e72cafd212c8> in <module>
      9 receive the mpc results and aggregate it, returning the inference's result.
     10 '''
---> 11 result = cloud_grid_service.run_remote_inference(""convnet"", user_input_data, mpc=True)# If mpc flag is False, It will send your real data to the platform.
     12 print(""Inference's result: "", result) # ( [2.0, 4.0] * [5.0, 3.0] ) + [1000] = [1022]

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/grid/public_grid.py in run_remote_inference(self, id, data, mpc)
    103             return self._run_unencrypted_inference(id, data)
    104         else:
--> 105             return self._run_encrypted_inference(id, data)
    106 
    107     def _serve_unencrypted_model(

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/grid/public_grid.py in _run_encrypted_inference(self, id, data, copy)
    285         # Perform Inference
    286         fetched_plan = self.hook.local_worker.fetch_plan(id, host_node, copy=copy)
--> 287         return fetched_plan(shared_data).get().float_prec()
    288 
    289     def __connect_with_node(self, node_id, node_url):

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/execution/plan.py in __call__(self, *args)
    348                 self.input_types.input_check(self, args)
    349             self.role.instantiate_inputs(args)
--> 350             result = self.role.execute()
    351             if len(result) == 1:
    352                 return result[0]

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/execution/role.py in execute(self)
    165         """"""
    166         for action in self.actions:
--> 167             self._execute_action(action)
    168 
    169         output_placeholders = tuple(

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/execution/role.py in _execute_action(self, action)
    226             response = method(*args_, **kwargs_)
    227         else:
--> 228             response = getattr(_self, cmd)(*args_, **kwargs_)
    229 
    230         if not isinstance(response, (tuple, list)):

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py in tracing_method(self, *args, **kwargs)
    174         def create_tracing_method(base_method, name):
    175             def tracing_method(self, *args, **kwargs):
--> 176                 response = base_method(self, *args, **kwargs)
    177                 command = (name, self, args, kwargs), response
    178                 if self.tracing:

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_syft_method(self, *args, **kwargs)
    114 
    115             # Send it to the appropriate class and get the response
--> 116             response = getattr(new_self, attr)(*new_args, **new_kwargs)
    117 
    118             # Put back SyftTensor on the tensors found in the response

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    208                 # Send the new command to the appropriate class and get the response
    209                 method = getattr(new_self, method_name)
--> 210                 response = method(*new_args, **new_kwargs)
    211 
    212                 # For inplace methods, just directly return self

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py in matmul(self, *args, **kwargs)
    430 
    431         # Send it to the appropriate class and get the response
--> 432         response = getattr(new_self, ""matmul"")(*new_args, **new_kwargs)
    433 
    434         # Put back SyftTensor on the tensors found in the response

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in matmul(self, other)
    646             return self._public_mul(other, ""matmul"")
    647 
--> 648         return self._private_mul(other, ""matmul"")
    649 
    650     def mm(self, *args, **kwargs):

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in _private_mul(self, other, equation)
    536             raise AttributeError(""For multiplication a crypto_provider must be passed."")
    537 
--> 538         shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field, self.dtype)
    539 
    540         return shares

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/mpc/spdz.py in spdz_mul(cmd, x_sh, y_sh, crypto_provider, field, dtype)
     32     # Get triples
     33     a, b, a_mul_b = request_triple(
---> 34         crypto_provider, cmd, field, dtype, x_sh.shape, y_sh.shape, locations
     35     )
     36 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/mpc/beaver.py in request_triple(crypto_provider, cmd, field, dtype, a_size, b_size, locations)
     37 
     38     shares = (
---> 39         res.share(*locations, field=field, dtype=dtype, crypto_provider=crypto_provider).get().child
     40     )
     41     a_shared = shares[: a.numel()].reshape(a_size)

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
    907                 dtype=dtype,
    908                 crypto_provider=crypto_provider,
--> 909                 **kwargs_,
    910             )
    911         else:

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
    380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
    381 
--> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
    383         return response
    384 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    624                 cmd_name, target, args_, kwargs_, return_ids, return_value
    625             )
--> 626             ret_val = self.send_msg(message, location=recipient)
    627         except ResponseSignatureError as e:
    628             ret_val = None

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    269 
    270         # Step 1: serialize the message to a binary
--> 271         bin_message = sy.serde.serialize(message, worker=self)
    272 
    273         # Step 2: send the message and wait for a response

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
     43         strategy = serialize
     44 
---> 45     return strategy(obj, worker, simplified, force_full_simplification)
     46 
     47 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
    335 
    336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
--> 337     return _serialize_msgpack_binary(simple_objects)
    338 
    339 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
    289     # 2) Serialize
    290     # serialize into a binary
--> 291     binary = msgpack_lib.dumps(simple_objects)
    292 
    293     # 3) Compress

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
     33     See :class:`Packer` for options.
     34     """"""
---> 35     return Packer(**kwargs).pack(o)
     36 
     37 

msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

TypeError: can not serialize 'NodeClient' object
```
## System Information
 - OS: MacOS
 - OS Version: 10.15.5
 - Language Version: Python 3.7.7
 - Package Manager Version: pip 20.1.1I am facing the same issue. Has it been resolved for you?No, unfortunately for me there is no solution yet.Hi, I found a solution for this, take a look here https://github.com/kuronosec/PySyft/commit/bd69d25c22aa106bbbeb13764e09a938bb617858 and here https://github.com/kuronosec/syft-proto/commit/e63901e5ffb003fec2c6bf98fe5b10b863c3e6db. But I don't know if that's the right solution or just a workaround. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	4	2020-06-14 15:44:30	2020-08-16 00:10:41	2020-08-16 00:10:41
https://github.com/OpenMined/PySyft/issues/3688	['bug ', 'status: stale :bread:']	Error handling when CrypTen computation crashes	"Error handling when CrypTen computation crashes## Description
Distributed CrypTen computation could fail due to many issues at the distributed worker level or in the local worker. We need to handle the different errors and share information between different workers in order to display clear error messages to the user accordingly.

## Expected Behavior
A clear message should be displayed to the user with enough information.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-06-10 09:51:17	2020-08-16 00:10:44	2020-08-16 00:10:44
https://github.com/OpenMined/PySyft/issues/3671	['bug ', 'priority: 1 - immediate :fire:']	FV cipher-text data change during decryption.	"FV cipher-text data change during decryption.## Description
During the decryption process, the ciphertext was soft copied and it changed the ciphertext value during decryption. So we lose the value of ciphertext.
## How to Reproduce
1. Create a ciphertext
2. Decrypt that ciphertext
3. Retry to decrypt the same ciphertext (wrong result)
This issue was not caught by earlier tests because for every test of encryption-decryption process new parameters were generated and every ciphertext was tested for correct values only ones"	1	2020-06-05 17:31:25	2020-06-06 05:29:34	2020-06-06 05:29:34
https://github.com/OpenMined/PySyft/issues/3667	['bug ', 'status: stale :bread:', 'question ']	Train models with new approch of grid	"Train models with new approch of grid## Question
Does the tool already have documentation support for training models with the new grid approach?

## Further Information
For example, I am trying to train a model, following the steps of the notebook that is available [p1](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb) and [p2](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-2%20%5D%20-%20Train%20a%20Model.ipynb), with the **Net** model and **mnist** database, but with the new grid approach, described below.

```sh
import syft as sy
import torch as th

hook = sy.TorchHook(th)
alice = sy.grid.register()

node1 = alice.connect(""bob"")
```

```sh
node1.search(""#mnist"")
    Tags: #mnist 
    Shape: torch.Size([5000, 1, 28, 28])]
```
For training I use the old approach. But the prediction is in a loop. Is training done any other way?

Loop line:

```sh
pred = model(data[i][j])
```

## System Information
 - OS: Linux
 - OS Version: Ubuntu 18
 - Language Version: Python 3.7
 - Package Manager Version: Conda

Ps.: The new approach to the grid is really cool, I'm really enjoying using it :)This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-06-03 19:30:34	2020-07-21 00:08:58	2020-07-21 00:08:57
https://github.com/OpenMined/PySyft/issues/3648	['bug ', 'status: stale :bread:']	Cannot serialize NodeClient when `test_mul_shared_tensors()` using GridNode as remote server	"Cannot serialize NodeClient when `test_mul_shared_tensors()` using GridNode as remote server## Description
When multiplying two encrypted tensors, it occurs a `Cannot serialize NodeClient object` error
However, there's no error when the version of `syft` changed to 0.2.5
## How to Reproduce
```
import syft as sy
import torch as th
from syft.workers.node_client import NodeClient

hook = sy.TorchHook(th)
alice = NodeClient(hook, ""ws://<ip>:<port>"", id=""alice"")
bob = NodeClient(hook, ""ws://<ip>:<port>"", id=""bob"")
charlie = NodeClient(hook, ""ws://<ip>:<port>"", id=""charlie"")
grid = sy.PrivateGridNetwork(alice, bob, charlie)

x = th.tensor([[ 0.9039,  0.6291,  1.0795],
        [ 0.1586,  2.1939, -0.4900],
        [-0.1909, -0.7503,  1.9355]])

y = th.tensor([[ 0.9039,  0.1586, -0.1909],
        [ 0.6291,  2.1939, -0.7503],
        [ 1.0795, -0.4900,  1.9355]])

x_s = x.fix_prec().share(alice, bob, crypto_provider=charlie)
y_s = y.fix_prec().share(alice, bob, crypto_provider=charlie)
result_s = x_s.matmul(y_s)
```

## Expected Behavior
An error message as below

## Screenshots
```
Traceback (most recent call last):
  File ""test_mul_shared_tensors_copy_1.py"", line 24, in <module>
    result_s = x_s.matmul(y_s)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/generic/frameworks/hook/hook.py"", line 210, in overloaded_native_method
    response = method(*new_args, **new_kwargs)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/precision.py"", line 432, in matmul
    response = getattr(new_self, ""matmul"")(*new_args, **new_kwargs)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 648, in matmul
    return self._private_mul(other, ""matmul"")
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 538, in _private_mul
    shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field, self.dtype)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/mpc/spdz.py"", line 34, in spdz_mul
    crypto_provider, cmd, field, dtype, x_sh.shape, y_sh.shape, locations
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/mpc/beaver.py"", line 39, in request_triple
    res.share(*locations, field=field, dtype=dtype, crypto_provider=crypto_provider).get().child
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/native.py"", line 909, in share
    **kwargs_,
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/generic/pointers/pointer_tensor.py"", line 382, in share
    response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/workers/base.py"", line 628, in send_command
    ret_val = self.send_msg(message, location=recipient)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/workers/base.py"", line 272, in send_msg
    bin_message = sy.serde.serialize(message, worker=self)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/serde/serde.py"", line 45, in serialize
    return strategy(obj, worker, simplified, force_full_simplification)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/serde/msgpack/serde.py"", line 337, in serialize
    return _serialize_msgpack_binary(simple_objects)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/serde/msgpack/serde.py"", line 291, in _serialize_msgpack_binary
    binary = msgpack_lib.dumps(simple_objects)
  File ""/home/billy/miniconda3/envs/py3.6-0529/lib/python3.6/site-packages/msgpack/__init__.py"", line 35, in packb
    return Packer(**kwargs).pack(o)
  File ""msgpack/_packer.pyx"", line 286, in msgpack._cmsgpack.Packer.pack
  File ""msgpack/_packer.pyx"", line 292, in msgpack._cmsgpack.Packer.pack
  File ""msgpack/_packer.pyx"", line 289, in msgpack._cmsgpack.Packer.pack
  File ""msgpack/_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack/_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack/_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  [Previous line repeated 3 more times]
  File ""msgpack/_packer.pyx"", line 283, in msgpack._cmsgpack.Packer._pack
TypeError: can not serialize 'NodeClient' object

```

## System Information
 - OS Version: Ubuntu 18.04
 - Syft: 0.2.6
 - Language Version: Python 3.6
 - Package Manager Version: Conda 4.8.2
Thanks @bobsonlin26 , could you include the label `grid`?> Thanks @bobsonlin26 , could you include the label `grid`?

I don't know how to add a new label....
(I've tried to edit this issue, but no option for me to apply a new label)
Maybe it's because I'm not a contributor/member (?@LaRiffle @Syzygianinfern0  , I guess you have been working in multiplication of AST . I remember a bug related with this #3496 and maybe is related...This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.I'm wondering why would a NodeClient need to be sent?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	6	2020-05-31 17:47:10	2020-08-23 00:12:28	2020-08-23 00:12:28
https://github.com/OpenMined/PySyft/issues/3580	['bug ', 'status: stale :bread:']	torch.tensor.size() function may get wrong shape after the tensor is sending to a gpu.	"torch.tensor.size() function may get wrong shape after the tensor is sending to a gpu.I use syft to execute a FL task, I found sometimes the torch.tensor.size() will get wrong results.
Here I implement the following code in a ubuntu 16 system to show this bug: 
>>> import torch
>>> import syft as sy
>>> data = torch.randn([8, 24, 24, 24, 3, 5])
>>> target = torch.randn([8, 24, 24, 24, 3, 5])
>>> data = data.cuda()
targe>>> target = target.cuda()
>>> hook = sy.TorchHook(torch=torch)
>>> worker1 = sy.VirtualWorker(hook, id=""worker1"")
>>> data.send(worker1)
(Wrapper)>[PointerTensor | me:32788080090 -> worker1:15663574719]
>>> data.location
>>> data = data.send(worker1)
>>> data.location
<VirtualWorker id:worker1 #objects:1>
>>> target = target.send(worker1)
>>> target.location
<VirtualWorker id:worker1 #objects:2>
>>> data.size()
torch.Size([0])
>>> target.size()
torch.Size([0])
>>> data.shape
torch.Size([8, 24, 24, 24, 3, 5])
>>> target.shape
torch.Size([8, 24, 24, 24, 3, 5])
>>> 

As shown above, we can see that when one tensor has been sent to a gpu and a worker , it's .size() function get torch.Size([0]), I don't know why this happens, and it's .shape attribute still works.

Another problem I found is for a torch.nn.Module object, we name it as model, model.send(worker).cuda() may throw exception, while model.cuda().send(worker) works.Sadly, this is a known issue that we don't currently have a way to fix. See previous discussions in #2201, #2527, #3163, #3382, and #3554.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-05-21 08:02:51	2020-06-28 00:07:09	2020-06-28 00:07:09
https://github.com/OpenMined/PySyft/issues/3562	['bug ', 'status: stale :bread:', 'status: investigating :mag:']	Error: add_() takes 1 positional argument but 2 were given	"Error: add_() takes 1 positional argument but 2 were givenHi there, I'm trying out FL on the wisonsin breast cancer dataset, and I get the following error while I try to train.
 `Error : add_() takes 1 positional argument but 2 were given`
Here's a snippet of the training function, any help on why this occurs would be appreciated. Let me know if anything else is needed.
`def train(args, model, device, train_loader, optimizer, epoch):`
    `model.train()`
    `for batch_idx, (inputs, targets) in enumerate(federated_train_loader):` # <-- now it is a distributed   
       dataset
        `model.send(inputs.location)` # <-- NEW: send the model to the right location
        `inputs, targets = inputs.to(device), targets.to(device)`
        `optimizer.zero_grad()`
        `output = model(inputs.float())`
        `loss = criterion(output, targets.float())`
        `loss.backward()`
        `optimizer.step()`
        `model.get()` # <-- NEW: get the model back
        `if (batch_idx % args.log_interval) == 0:`
          `loss_int = loss.get()`
`device = torch.device(""cpu"")`
`for epoch in range(1, args.epochs):`
    `train(args, model, device, federated_train_loader, opt, epoch)`Hello! Thank you for reporting this, could you provide:

1. the full script to reproduce the error.
2. the stack trace/logging if you have.
3. syft and OS version.

Thank you!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-05-20 14:39:26	2020-07-06 00:08:25	2020-07-06 00:08:25
https://github.com/OpenMined/PySyft/issues/3558	['bug ']	'VirtualWorker' object has no attribute '_tensors' in tutorial - 9	"'VirtualWorker' object has no attribute '_tensors' in tutorial - 9I am completely new to PySyft and got an error of ""VirtualWorker' object has no attribute '_tensors"", when I am working in Encrypted Domain Computation. Please help me.

import torch
import syft as sy
hook = sy.TorchHook(torch)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
bill = sy.VirtualWorker(hook, id=""bill"")

x = torch.tensor([25])

x
tensor([25])

x = torch.tensor([25]).share(bob, alice, bill)

bobs_share = list(bob._tensors.values())[0]


---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-6-66d08ba6d652> in <module>()
     13 x = torch.tensor([25]).share(bob, alice, bill)
     14 
---> 15 bobs_share = list(bob._tensors.values())[0]

AttributeError: 'VirtualWorker' object has no attribute '_tensors'@vtanwar-iitr I think this was broken by a recent change. Try `bob.object_store._tensors`? @karlhigley Thanks for your reply..

I tried ""ob.object_store._tensors"" but this is not working showing same error..

VirtualWorker' object has no attribute 'object_store

However, I reinstalled the complete Syft and other dependencies in a new Conda environment. It's working great.

The query has been resolved , therefore I am closing this issue."	3	2020-05-20 07:25:12	2020-05-20 17:08:25	2020-05-20 17:08:25
https://github.com/OpenMined/PySyft/issues/3542	['bug ', 'status: stale :bread:']	Assignment operator *= gives the wrong result! (for AdditiveSharingTensors)	"Assignment operator *= gives the wrong result! (for AdditiveSharingTensors)The assignment operator `*=` doesn't multiply properly for AdditiveSharingTensors.

See this example:

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
x = x.share(bob, alice, crypto_provider=bob)

z = x[0]
for i in range(1, len(x)):
    z *= x[i]
z.get()  # <-- returns tensor(1)!
```

This gives `tensor(1)`, which is totally wrong!

Doing the assignment explicitly works, e.g. `z = z * x[i]`.

The addition assignment operator seems to work with no problems, e.g. `z += x[i]` works correctly.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.AdditiveSharingTensors can be multiplied with long tensors and fixedPrecisionTensors
Don't directly multiply floats with AdditiveSharingTensor  as an error will come when you multiply an AdditiveSharingTensors with a FloatTensor.
But sharing with fixed_precision we will be able to handle float values like parameters in an encrypted way. 

1)if decrypt z
```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1,2,3,4])
x = x.share(bob, alice, crypto_provider=bob)
z = x[0].get() #z got decrypted 
for i in range(1, len(x)):
    z *= x[i]
z.get()  # <-- returns tensor(24)
```

2) if we use fixed_Precision
```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1.,2,3,4])
x = x.fix_prec().share(bob, alice, crypto_provider=bob)
z = x[0] # <--- z is encrypted
for i in range(1, len(x)):
    z *= x[i] # <-- inplace mul
z.get().float_prec()  # <-- returns tensor(24)
```"	2	2020-05-18 05:48:56	2020-07-20 08:15:54	2020-06-28 00:07:13
https://github.com/OpenMined/PySyft/issues/3541	['bug ', 'status: stale :bread:']	tensor.prod() does not return the right result (on an AdditiveSharingTensor) 	"tensor.prod() does not return the right result (on an AdditiveSharingTensor) `tensor.prod()` does not return the right result for an AdditiveSharingTensor. See:

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
print(x.prod())  # <- tensor(24)

x = x.share(bob, alice)
print(x.prod().get())  # <- tensor(-3063412363143033624)
```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1,2,3,4])
print(x.prod())  # <- tensor(24)
x.fix_prec().share(bob, alice, crypto_provider=bob)
x.prod() # <- tensor(24)
```

AST can be multiplied with long tensors and fixedPrecisionTensors
Don't directly multiply floats with AdditiveSharingTensor (AST) as an error will come when you multiply an AST with a FloatTensor."	2	2020-05-18 05:02:16	2020-07-20 08:15:43	2020-06-28 00:07:14
https://github.com/OpenMined/PySyft/issues/3540	['bug ', 'status: stale :bread:']	Error when testing equality of AdditiveSharingTensors (without a crypto_provider?)	"Error when testing equality of AdditiveSharingTensors (without a crypto_provider?)When I try to test equality of two AdditiveSharingTensors (`x == y`), it fails with a `ObjectNotFoundError` error. 

Here's a basic code sample to reproduce:

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
y = th.tensor([2,-1,1,0])
x = x.share(bob, alice)
y = y.share(bob, alice)

z = x == y
z.get()
```

This fails on the `==` line with: 

```
ObjectNotFoundError: Object ""7070927336"" not found on worker!!! You just tried to interact with an object ID:7070927336 on <VirtualWorker id:me #objects:0> which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines. If you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!
```

However, this seems to work if I add a separate worker as the `crypto_provider`. For example, if you replace the two lines with `.share()` above with:

```python
secure_worker = sy.VirtualWorker(hook, id=""secure_worker"")
x = x.share(bob, alice, crypto_provider=secure_worker)
y = y.share(bob, alice, crypto_provider=secure_worker)
```

^This works. Is this a bug? Or intended behavior (where is it documented)? Same problem for multiplication!

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
y = th.tensor([2,-1,1,0])
x = x.share(bob, alice)
y = y.share(bob, alice)

z = x * y  # <-- ObjectNotFoundError
z.get()
```

Only addition (`x + y`) works without specifying a `crypto_provider`.> Same problem for multiplication!
> 
> ```python
> import syft as sy
> import torch as th
> hook = sy.TorchHook(th)
> 
> bob = sy.VirtualWorker(hook, id=""bob"")
> alice = sy.VirtualWorker(hook, id=""alice"")
> 
> x = th.tensor([1,2,3,4])
> y = th.tensor([2,-1,1,0])
> x = x.share(bob, alice)
> y = y.share(bob, alice)
> 
> z = x * y  # <-- ObjectNotFoundError
> z.get()
> ```
> 
> Only addition (`x + y`) works without specifying a `crypto_provider`.

Hey, so AST uses secure multiparty communication (SMPC) to perform the operations like multiplication, division. It uses `crypto provider` to generate the triplets which are necessary to perform this operations. So crypto provider is kind of necessary 🙂It seems like `share()` is overly permissive then. Until recently (when @Prtfw added an exception), `share()` could be called with no arguments. Something similar should probably happen here: a required argument that's missing should immediately raise an exception rather than allowing incorrect behavior.Thanks @sukhadj, I figured it was something like that. A few beginner questions:

1. What is AST?
2. Why does `x + y` work without a crypto provider and not `x * y`?
3. Can I read more about this in the documentation somewhere?
4. If `crypto_provider` is not always required for `.share()`, as an alternative to @karlhigley's suggestion, can the error message be more specific? e.g. `crypto_provider required for * operation on AdditiveSharingTensors` rather than an `ObjectNotFoundError`.I also had this equality issue, even with a crypto provider, only when `requires_grad = False`> Thanks @sukhadj, I figured it was something like that. A few beginner questions:
> 
>     1. What is AST?
AdditiveSharingTensor
>     2. Why does `x + y` work without a crypto provider and not `x * y`?
So addition is just basically adding alice's share of x with alice's share of y and then module it. You can see implementation of addition [here](https://github.com/OpenMined/PySyft/blob/6b55ba01e411537e5c43f44235d24c33bdbaadf0/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L413).
>     3. Can I read more about this in the documentation somewhere?
PySyft currently don't have extensive documentation right now. But you can find more about SPDZ and triplets [here](https://mortendahl.github.io/2017/09/03/the-spdz-protocol-part1/) (Not an expert of the subject so maybe others can suggest better resources maybe :smile: )
>     4. If `crypto_provider` is not always required for `.share()`, as an alternative to @karlhigley's suggestion, can the error message be more specific? e.g. `crypto_provider required for * operation on AdditiveSharingTensors` rather than an `ObjectNotFoundError`.
That's correct we should definitely raise a warning during the sharing and exception when multiplying rather than object not found error. 
> I also had this equality issue, even with a crypto provider, only when `requires_grad = False`
Can you try again with pulling the master?
It works now when provided with crypto provider. Maybe changed in @LaRiffle's  FSS PR.Does `==` work if you set `requires_grad = False` in the `share` method?Will be solved by #3578 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	10	2020-05-18 04:07:20	2020-06-28 00:07:15	2020-06-28 00:07:15
https://github.com/OpenMined/PySyft/issues/3516	[]	Update how rank_to_worker_id is stored in workers	"Update how rank_to_worker_id is stored in workers**Describe the bug**

An issue we had was that WebsocketServerWorker was storing the received rank_to_worker_id dictionary into `self` then our `crypten.load_from_party` function was trying to get that from `syft.local_worker`, a quick fix was made to store it in `syft.local_worker` as well as self, this will causes issues if :

- The worker running the server is also doing some crypten computation
- The worker running the server is doing crypten computation locally (using virtual workers)

The former was already present, but the second got introduced by the quick fix.

**Possible solution**

Store it in `self` and fetch it from the specific worker on `load_from_party`.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-05-13 13:52:52	2020-06-18 12:42:27	2020-06-18 12:42:27
https://github.com/OpenMined/PySyft/issues/3514	['bug ', 'status: stale :bread:', 'status: investigating :mag:']	"model.copy().get() cause ""clone() got an unexpected keyword argument 'memory_format'"" error"	"model.copy().get() cause ""clone() got an unexpected keyword argument 'memory_format'"" errorI tried to implement model averaging using the function provided by Tutorial 
""Federated Learning of a Recurrent Neural Network for text classification""

I uncomment this line:

""model_pointers = fed_avg_every_n_iters(model_pointers, iter, args.federate_after_n_batches)""

to run this function:
def fed_avg_every_n_iters(model_pointers, iter, federate_after_n_batches):
        models_local = {}
        
        if(iter % args.federate_after_n_batches == 0):
            for worker_name, model_pointer in model_pointers.items():
                #need to assign the model to the worker it belongs to.
                models_local[worker_name] = model_pointer.copy().get() ############# error here
            model_avg = utils.federated_avg(models_local)
           
            for worker in workers_virtual:
                model_copied_avg = model_avg.copy()
                model_ptr = model_copied_avg.send(worker) 
                model_pointers[worker.id] = model_ptr
                
        return(model_pointers)     

and the error message was:
TypeError: clone() got an unexpected keyword argument 'memory_format'@ZhechunZhou I have some guesses where this might come from, but it's a little bit difficult to pin down. Could you post a stack trace for this error?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.I meet the same problem. The key is to call get for the weight of the model instead of the model itself."	3	2020-05-13 11:03:44	2020-07-15 20:03:27	2020-07-05 00:08:44
https://github.com/OpenMined/PySyft/issues/3507	[]	Adam and other stateful optimizers do not work on federated models	"Adam and other stateful optimizers do not work on federated modelsI have [a very basic FL setup](https://gist.github.com/kennysong/80b5c02f2506de39b5aa7c2abd6c4140) with 10 virtual workers training on MNIST.

Training the models works correctly with `torch.optim.SGD`. Switching to `torch.optim.Adam` or any other stateful optimizer (e.g. SGD with momentum, RMSProp, Adagrad) fails with this error on the `opt.step()` line:

```
TypeError: add_() takes 1 positional argument but 2 were given
```

Seems like a bug with how the PySyft hook overrides tensor methods. 

Here's [a notebook](https://gist.github.com/kennysong/80b5c02f2506de39b5aa7c2abd6c4140) that replicates the error.
Oh, just found a few duplicate bugs:

- #2070 
- #3349 

Looks like this is fixed by using the new PySyft optim wrapper."	1	2020-05-12 10:01:05	2020-05-12 10:08:13	2020-05-12 10:08:12
https://github.com/OpenMined/PySyft/issues/3471	['bug ', 'testing ', 'status: stale :bread:', 'status: investigating :mag:']	`test_torch_tanh_approx` is flaky	"`test_torch_tanh_approx` is flaky**Describe the bug**
`test_torch_tanh_approx` often fails during automated PR-checking test runs.

**To Reproduce**
Run the test or the test suite a few times until it fails.

**Expected behavior**
Should pass reliably.

**Screenshots**
```
 ____________________ test_torch_tanh_approx[sigmoid-3-0.1] _____________________
 
 method = 'sigmoid', prec_frac = 3, tolerance = 0.1
 workers = {'alice': <VirtualWorker id:alice #objects:7>, 'bob': <VirtualWorker id:bob #objects:7>, 'charlie': <VirtualWorker id:charlie #objects:6>, 'james': <VirtualWorker id:james #objects:6>, ...}
 
     @pytest.mark.parametrize(
         ""method, prec_frac, tolerance"",
         [
             (""chebyshev"", 3, 3 / 100),
             (""chebyshev"", 4, 2 / 100),
             (""sigmoid"", 3, 10 / 100),
             (""sigmoid"", 4, 5 / 100),
         ],
     )
     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
         """"""
         Test the approximate tanh with different tolerance depending on
         the precision_fractional considered
         """"""
         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
     
         t = torch.tensor(range(-10, 10)) * 0.5
         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
         r_sh = t_sh.tanh(method)
         r = r_sh.get().float_prec()
         t = t.tanh()
         diff = (r - t).abs().max()
         norm = (r + t).abs().max() / 2
     
 >       assert (diff / (tolerance * norm)) < 1
 E       assert (tensor(0.1001) / (0.1 * tensor(1.0000))) < 1
 
 test/torch/tensors/test_precision.py:512: AssertionError
```

**Additional context**
Possible that several of the parameterized cases are flaky.
I will look on this.Seen this again, here:
```
2020-05-15T10:08:51.0720029Z =================================== FAILURES ===================================
2020-05-15T10:08:51.0721859Z ____________________ test_torch_tanh_approx[sigmoid-3-0.1] _____________________
2020-05-15T10:08:51.0722192Z 
2020-05-15T10:08:51.0722841Z method = 'sigmoid', prec_frac = 3, tolerance = 0.1
2020-05-15T10:08:51.0723543Z workers = {'alice': <VirtualWorker id:alice #objects:1>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:0>, ...}
2020-05-15T10:08:51.0723844Z 
2020-05-15T10:08:51.0724137Z     @pytest.mark.parametrize(
2020-05-15T10:08:51.0724423Z         ""method, prec_frac, tolerance"",
2020-05-15T10:08:51.0724702Z         [
2020-05-15T10:08:51.0724982Z             (""chebyshev"", 3, 3 / 100),
2020-05-15T10:08:51.0725298Z             (""chebyshev"", 4, 2 / 100),
2020-05-15T10:08:51.0725575Z             (""sigmoid"", 3, 10 / 100),
2020-05-15T10:08:51.0725839Z             (""sigmoid"", 4, 5 / 100),
2020-05-15T10:08:51.0726117Z         ],
2020-05-15T10:08:51.0726385Z     )
2020-05-15T10:08:51.0726666Z     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
2020-05-15T10:08:51.0726956Z         """"""
2020-05-15T10:08:51.0727241Z         Test the approximate tanh with different tolerance depending on
2020-05-15T10:08:51.0727539Z         the precision_fractional considered
2020-05-15T10:08:51.0727820Z         """"""
2020-05-15T10:08:51.0728136Z         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
2020-05-15T10:08:51.0728430Z     
2020-05-15T10:08:51.0728923Z         t = torch.tensor(range(-10, 10)) * 0.5
2020-05-15T10:08:51.0729246Z         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
2020-05-15T10:08:51.0729547Z         r_sh = t_sh.tanh(method)
2020-05-15T10:08:51.0729828Z         r = r_sh.get().float_prec()
2020-05-15T10:08:51.0730108Z         t = t.tanh()
2020-05-15T10:08:51.0730596Z         diff = (r - t).abs().max()
2020-05-15T10:08:51.0730890Z         norm = (r + t).abs().max() / 2
2020-05-15T10:08:51.0731163Z     
2020-05-15T10:08:51.0731433Z >       assert (diff / (tolerance * norm)) < 1
2020-05-15T10:08:51.0731714Z E       assert (tensor(0.1021) / (0.1 * tensor(1.0000))) < 1
2020-05-15T10:08:51.0731925Z 
```
[Link](https://pipelines.actions.githubusercontent.com/tPFNPqeRbvWdN0L3FU84cUvH4mGjAPQ3yYz8CFZWN08ePzUDwG/_apis/pipelines/1/runs/4726/signedlogcontent/4?urlExpires=2020-05-15T10%3A58%3A25.7158601Z&urlSigningMethod=HMACV1&urlSignature=LC4XWEEH8D9P7UbpZMTe1olEd4B3XTD2qrq7Frc81oU%3D)@gmuraru Is this a case where we should increase the tolerance on this test? I've hesitated to fix it that way, because I don't know how much that weakens the test assertion, but think I remember seeing similar tests adjusted that way in the past.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	4	2020-05-08 13:38:36	2020-07-05 00:08:48	2020-07-05 00:08:48
https://github.com/OpenMined/PySyft/issues/3467	['bug ', 'testing ']	test_fit[gaussian_mixture-1-cpu] is flaky	"test_fit[gaussian_mixture-1-cpu] is flaky**Describe the bug**
test_fit[gaussian_mixture-1-cpu] has undefined behavior between multiple runs.

**To Reproduce**
Run the tests multiple times.

**Expected behavior**
To be deterministic between similar runs.

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version: 20

Error:
assert loss_after < loss_before
assert tensor(0.6931, grad_fn=<NllLossBackward>) < tensor(0.6931, grad_fn=<NllLossBackward>)Closed because it was added an ```=``` sign in this [PR](https://github.com/OpenMined/PySyft/pull/3461/files#diff-1b4e80baf02b99d38e2a1837ac3620a8)Does it still fail though? (I think it does, but could be wrong.)Each time I have seen this failing was because there were the same values. Maybe we need to keep an eye open for this issue and if we see it again, re-open this? Cool, will reopen if I see it happen."	4	2020-05-08 09:51:38	2020-05-31 14:17:50	2020-05-31 02:29:12
https://github.com/OpenMined/PySyft/issues/3464	['bug ']	New PySyft workers are created with FSS `Plans` in their object storage	"New PySyft workers are created with FSS `Plans` in their object storage**Describe the bug**
When a new worker is created, it comes with some `Plans` already loaded into the object storage:
```
{67822474598: <Plan Plan id:67822474598 owner:bob Tags: #fss_eq_plan_1 built>,
 42739784794: <Plan Plan id:42739784794 owner:bob Tags: #fss_eq_plan_2 built>,
 98376427733: <Plan Plan id:98376427733 owner:bob Tags: #fss_comp_plan_1 built>,
 48876976143: <Plan Plan id:48876976143 owner:bob Tags: #fss_comp_plan_2 built>,
 22552634480: <Plan Plan id:22552634480 owner:bob Tags: #xor_add_1 built>,
 96804360037: <Plan Plan id:96804360037 owner:bob Tags: #xor_add_2 built>}
```

**To Reproduce**
```
hook = TorchHook(torch)
bob = syft.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
bob._objects
```

**Expected behavior**
New workers should start with empty object stores.

**Additional context**
Probably a result of the recent Function Secret Sharing PR.
I confirm this bug as well"	1	2020-05-07 17:57:13	2020-05-14 16:03:08	2020-05-14 16:03:08
https://github.com/OpenMined/PySyft/issues/3463	[]	Value Error in torch_serde._detail_torch_tensor when calling async_fit from LAN WebSocketWorker	"Value Error in torch_serde._detail_torch_tensor when calling async_fit from LAN WebSocketWorkerHello All,

I'm referencing the advanced tutorial: [websocket-mnist-parallel](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets_mnist_parallel) and I'm running into a `ValueError: not enough values to unpack (expected 9, got 7)`. When running the servers and notebook from the same device, there are no issues, but when I switch to a different device for the notebook, get thrown the above error.

Again, the error locates when calling `async_fit` and specifically in the function `syft/serde/msgpack/torch_serde.py in _detail_torch_tensor(worker, tensor_tuple)`.

Running on two MBP on the same local network.
Syft version 0.2.4, syft-proto version 0.4.2, python version 3.8.2 on both devices.

Here's a full traceback:
```ValueError                                Traceback (most recent call last)
<ipython-input-24-40944cb95694> in <module>
      5     logger.info(""Training round %s/%s"", curr_round, args.training_rounds)
      6 
----> 7     results = await asyncio.gather(
      8         *[
      9             rwc.fit_model_on_worker(

~/Documents/async_learning/run_websocket_client.py in fit_model_on_worker(worker, traced_model, batch_size, curr_round, max_nr_batches, lr)
    368     )
    369     train_config.send(worker)
--> 370     loss = await worker.async_fit(dataset_key=""bank"", return_ids=[0])
    371     model = train_config.model_ptr.get().obj
    372     return worker.id, model, loss

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/workers/websocket_client.py in async_fit(self, dataset_key, device, return_ids)
    173 
    174         # Return the deserialized response.
--> 175         return sy.serde.deserialize(response)
    176 
    177     def fit(self, dataset_key: str, **kwargs):

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/serde.py in deserialize(binary, worker, strategy)
     67         object: the deserialized form of the binary input.
     68     """"""
---> 69     return strategy(binary, worker)

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in deserialize(binary, worker)
    380 
    381     simple_objects = _deserialize_msgpack_binary(binary, worker)
--> 382     return _deserialize_msgpack_simple(simple_objects, worker)
    383 
    384 

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in _deserialize_msgpack_simple(simple_objects, worker)
    371     # as msgpack's inability to serialize torch tensors or ... or
    372     # python slice objects
--> 373     return _detail(worker, simple_objects)
    374 
    375 

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in _detail(worker, obj, **kwargs)
    497     """"""
    498     if type(obj) in (list, tuple):
--> 499         val = detailers[obj[0]](worker, obj[1], **kwargs)
    500         return _detail_field(obj[0], val)
    501     else:

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/torch_serde.py in _detail_torch_tensor(worker, tensor_tuple)
    180     """"""
    181 
--> 182     (
    183         tensor_id,
    184         tensor_bin,

ValueError: not enough values to unpack (expected 9, got 7)```
PySyft doesn't yet support Python 3.8, so it could be related to that. Could you post the versions of PySyft and syft-proto running on each machine?After updating to lates version of syft (0.2.5), the issue has disappeared. Closing issue"	2	2020-05-07 16:09:13	2020-05-07 16:26:09	2020-05-07 16:26:09
https://github.com/OpenMined/PySyft/issues/3439	['bug ', 'status: stale :bread:']	flatten() removes the object!	"flatten() removes the object!**Describe the bug**
when .flatten() is called on AST or a remote torch tensor it removes the original tensor from the worker
**To Reproduce**
A= torch.rand(4)
a=A.fix_prec().share(bob, alice, crypto_provider=james) #or A.send(bob)
b=a.flatten()
a.get()

note: this happens only with 1D tensor, 2D works fine@Syzygianinfern0 is this related to your recent GC fixes?Hey, 
I had a look at this, and I think the issue is that in torch the .flatten operation on 1d array is actually an _inplace_ operation. You can do the above example with .view(-1) and it will work fine.
I have fixed the issue locally by modifying the is_inplace_method in torch_attributes.py
```
        try:
            return self.inplace_methods[method_name]
        except KeyError:
            is_inplace = True if re.search(self._inplace_pattern, method_name) else False
            is_inplace = True if method_name == ""flatten"" else is_inplace # This would fix problem with flatten
            self.inplace_methods[method_name] = is_inplace
            return is_inplace
```
But note that this would only work for 1d array.
Not entirely sure what would be a good fix to this, as I don't think we use the input shape in anyway to decide if the operation is inplace.> @Syzygianinfern0 is this related to your recent GC fixes?

Seems to be the case (confirmed from a `git bisect`). Although don't know if I can look into it right away. 

> .flatten operation on 1d array is actually an _inplace_ operation

@MaksymPetyak I had tried the same thing earlier today but that didn't seem to be solving the issue. Can you confirm if that is the only change required with a recent copy of the codebase. > operation ... is actually an inplace operation

The number of such edge cases that might be hidden for pretty much every method we have scares me now 
:open_mouth:Hey @MaksymPetyak , would you make a pull request with your changes?> b=a.flatten()
> a.get()

After some discussion with @MaksymPetyak it's important to be noted that if anyone is working on this, **don't** use `a.get()` to decide if the pointer exists or not. It is easily misinterpretable that you have a solution if you've managed to make this work. This is since, if made into an inplace operation, it just creates `a` to be a duplicate of `b` and hence it pretends that the tensor exists :thinking: 

Use this instead
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)
alice = sy.VirtualWorker(hook, id=""alice"")
bob = sy.VirtualWorker(hook, id=""bob"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")

torch = th
syft = sy

# a = torch.ones(1, 5)  # <<<Toggle between this (works as expected)
a = torch.rand(4)  # <<< and this (broken)
a = a.encrypt(workers=[alice, bob], crypto_provider=crypto_provider)

print(f""Before: {len(alice._tensors)}"")  # 1 (expected: 1)
b = a.flatten()
print(f""After: {len(alice._tensors)}"")  # 1 (expected: 2)
```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	7	2020-05-02 15:54:28	2020-06-11 00:06:14	2020-06-11 00:06:14
https://github.com/OpenMined/PySyft/issues/3401	['bug ', 'good first issue :mortar_board:', 'testing ', 'status: stale :bread:']	`test_torch_tanh_approx` is flaky	"`test_torch_tanh_approx` is flaky**Describe the bug**
The ```test_torch_tanh_approx``` test fails intermittently during automated PR testing.

**To Reproduce**
Run the test (or full suite) until it fails.

**Screenshots**
```
2020-04-24T13:00:44.9923763Z method = 'sigmoid', prec_frac = 3, tolerance = 0.1
2020-04-24T13:00:44.9925054Z workers = {'alice': <VirtualWorker id:alice #objects:112>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:88>, ...}
2020-04-24T13:00:44.9925523Z 
2020-04-24T13:00:44.9927154Z     @pytest.mark.parametrize(
2020-04-24T13:00:44.9928770Z         ""method, prec_frac, tolerance"",
2020-04-24T13:00:44.9929162Z         [
2020-04-24T13:00:44.9929727Z             (""chebyshev"", 3, 3 / 100),
2020-04-24T13:00:44.9930283Z             (""chebyshev"", 4, 2 / 100),
2020-04-24T13:00:44.9931907Z             (""sigmoid"", 3, 10 / 100),
2020-04-24T13:00:44.9932292Z             (""sigmoid"", 4, 5 / 100),
2020-04-24T13:00:44.9932554Z         ],
2020-04-24T13:00:44.9932811Z     )
2020-04-24T13:00:44.9933080Z     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
2020-04-24T13:00:44.9933338Z         """"""
2020-04-24T13:00:44.9933695Z         Test the approximate tanh with different tolerance depending on
2020-04-24T13:00:44.9934214Z         the precision_fractional considered
2020-04-24T13:00:44.9934531Z         """"""
2020-04-24T13:00:44.9935194Z         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
2020-04-24T13:00:44.9935474Z     
2020-04-24T13:00:44.9936409Z         t = torch.tensor(range(-10, 10)) * 0.5
2020-04-24T13:00:44.9936742Z         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
2020-04-24T13:00:44.9937146Z         r_sh = t_sh.tanh(method)
2020-04-24T13:00:44.9937583Z         r = r_sh.get().float_prec()
2020-04-24T13:00:44.9937975Z         t = t.tanh()
2020-04-24T13:00:44.9938588Z         diff = (r - t).abs().max()
2020-04-24T13:00:44.9938866Z         norm = (r + t).abs().max() / 2
2020-04-24T13:00:44.9939168Z     
2020-04-24T13:00:44.9939675Z >       assert (diff / (tolerance * norm)) < 1
2020-04-24T13:00:44.9940476Z E       assert (tensor(0.1101) / (0.1 * tensor(1.0000))) < 1
2020-04-24T13:00:44.9940636Z 
2020-04-24T13:00:44.9942016Z test/torch/tensors/test_precision.py:512: AssertionError
```
**Expected behavior**
The test should always pass

**Additional context**
This started being an issue when the order of the test suite was randomized (specifically to shake out flaky tests like this.)
Can i work on this issue? is it open?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2020-04-24 13:32:40	2020-06-16 00:06:39	2020-06-16 00:06:39
https://github.com/OpenMined/PySyft/issues/3400	[]	TypeError: expected str, bytes or os.PathLike object, not PosixPath	"TypeError: expected str, bytes or os.PathLike object, not PosixPathHey, can anybody please tell me what is the cause of this error while running start_websocket_servers.py ? is it because of using subprocess.py file in the anaconda path?

> shekhar$ python start_websocket_servers.py 
Starting server for Alice
Traceback (most recent call last):
  File ""start_websocket_servers.py"", line 17, in <module>
    subprocess.Popen(call_alice)
  File ""/anaconda3/lib/python3.6/subprocess.py"", line 709, in __init__
    restore_signals, start_new_session)
  File ""/anaconda3/lib/python3.6/subprocess.py"", line 1275, in _execute_child
    restore_signals, start_new_session, preexec_fn)
TypeError: expected str, bytes or os.PathLike object, not PosixPath
this error was there because due to whatsoever reason, in this python file, the interpreter was not able to load the path of the file  start_websocket_servers.py.

this cause of error got confirmed because of the realization that no matter what was the path value in this command FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py”)  in the start_websocket_servers.py file, there was no change in the error output. so the solution what i did was that i hardcoded the path of the file run_websocket_server.py in the command like this:  call_alice = [python,  ""run_websocket_server.py"", ""--port"", ""8777"", ""--id"", ""alice”]
instead of original 
[
FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py"")

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]
]

this solved the problem ."	1	2020-04-24 08:49:19	2020-04-25 19:38:36	2020-04-25 19:38:35
https://github.com/OpenMined/PySyft/issues/3388	[]	 syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file	"syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol filewhile running the start_websocket_servers.py, this issue (syft.exceptions.UndefinedProtocolTypeError) shows up. does anybody have a solution?
following below is the complete error:
File ""/Users/shekhar/PySyft/syft/serde/msgpack/proto.py"", line 71, in proto_type_info
    raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")
    raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")
syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file
syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file
    raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")
syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file

That sounds like a mismatch between PySyft and `syft-proto` versions. I'd try re-installing the PySyft requirements from `pip-dep/requirements.txt` and see if that resolves it.> That sounds like a mismatch between PySyft and `syft-proto` versions. I'd try re-installing the PySyft requirements from `pip-dep/requirements.txt` and see if that resolves it.

I had the same problem. Re-installing the requirements solved it. Thank you. hey man, thanks a lot. although I did this earlier. it showed

>  [ERROR: syft 0.2.4 has requirement syft-proto~=0.2.5.a1, but you'll have syft-proto 0.2.9a2 which is incompatible. ]
then I quit this step of upgrading syft-proto but after your answer, I did that anyway and the error got resolved."	3	2020-04-22 03:47:23	2020-04-24 05:01:36	2020-04-24 05:01:35
https://github.com/OpenMined/PySyft/issues/3382	['bug ', 'status: stale :bread:']	PySyft Tensor shape and size() call returns different values	"PySyft Tensor shape and size() call returns different values**Describe the bug**
After sending tensor to a worker the size() call returns `torch.Size([0])` while .shape returns correct value.



**To Reproduce**
Steps to reproduce the behavior:
1. 
data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)
bobs_data = data.send(bob)
print(bobs_data.shape) -> torch.Size([4, 2])
print(bobs_data.size()) -> torch.Size([0])



**Expected behavior**
size() method call should return correct value

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [Ubuntu]
 - Version [18]

**Additional context**
This is very important as Pytorch essentially uses size() for getting shape/size of attribute, shape attribute is only to give some similarity with numpy.  
And in most of pre-defined Pytorch models size() is used. So it won't  be **possible to use most pre-defined Pytorch** models with PySyft
Hey, this is a known issue: it is not possible to hook the size like we did for the shape because the size is used by the print function, which for Pointers wrapped into an empty torch tensor needs to be applied on this wrapper and not on the remote value.
Well maybe there is a way to fix this, but this is why we didn't manage to get it working :)@LaRiffle 
![image](https://user-images.githubusercontent.com/16415585/81976943-45e02680-95f7-11ea-948f-6d919d58ee7b.png)

If I am not mistaken now we are getting the size of the (empty) torch tensor, How does this happen differently when it comes to Size method only?
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hi @LaRiffle, any news about this issue?
The (big) problem related to this is that models cannot be executed on private tensors :( Hey @xanderwallace85!
This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?> Hey @xanderwallace85!
> This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?

Hi @LaRiffle ! Apparently, even simple CNN models do not work when using private tensors. I believe this is due to the size function :(  For instance, a model like the one below won't work as the function size is required (by the nn.Linear?).
```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```

Is there an alternative to private tensors? As I am looking for a solution to hide the data in the nodes (so not allowing the .get(), for example). 
Would be a pity to not be able to fully exploit private tensors though :("	7	2020-04-21 13:55:20	2020-09-24 18:11:17	2020-07-05 00:08:50
https://github.com/OpenMined/PySyft/issues/3369	[]	securenn.maxpool2d isn't implemented appropriately	"securenn.maxpool2d isn't implemented appropriately **Describe the bug**
securenn.maxpool2d is implemented with arg a_sh that must be a **wrapped** AdditiveSharingTensor. and after calling .fix_prec() on it the chain becomes `fixed_prec>wrapper(torch.Tensor)>AdditiveSharingTensor` which is confused with a normal fixed_prec tensor chain `fixed_prec>torch.Tensor`
I could change the conditions to identify if it's a wrapper (I did that as a hot fix) but I don't know if that's the best solution since we'll have to change it in a lot of other places

**To Reproduce**
Steps to reproduce the behavior:
```
import torch
import syft as sy
import cProfile
from torch import nn

hook = sy.TorchHook(torch)
import torch.nn.functional as F

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


resnet = Net()
resnet.fix_prec().share(bob, alice, crypto_provider=crypto_provider)
data = torch.ones(1, 1, 32, 32).fix_prec().share(bob, alice, crypto_provider=crypto_provider)

cProfile.run(resnet(data))
```
run it in the debugger if you will :)

**Desktop (please complete the following information):**
 - OS: windows
 - Version 10

**Expected behavior:** 
securenn.maxpool2d(a_sh: AdditiveSharingTensor) not securenn.maxpool2d(a_sh: torch.Tensor)Might be good to fix this issue independently, but Syft Core has concluded that we should remove wrappers from the code base entirely. (It'll take a while.)"	1	2020-04-17 12:04:29	2020-04-17 19:39:58	2020-04-17 19:39:58
https://github.com/OpenMined/PySyft/issues/3355	['bug ', 'testing ']	`test_local_remote_gradient_clipping` is flaky	"`test_local_remote_gradient_clipping` is flaky**Describe the bug**
An issue that started to happen when running the tests in random order.

**To Reproduce**
Run the test (or full suite) until it fails.

**Expected behavior**
The test should reliably pass.

**Screenshots**
```
        # Remote gradient clipping
        remote_parameters = alice_model.parameters()
        total_norm_remote = nn.utils.clip_grad_norm_(remote_parameters, 2)
    
        # Local gradient clipping
        local_alice_model = alice_model.get()
        local_parameters = local_alice_model.parameters()
        total_norm_local = nn.utils.clip_grad_norm_(local_parameters, 2)
    
        # Is the output of the remote gradient clipping version equal to
        # the output of the local gradient clipping version?
>       assert total_norm_remote.get() == total_norm_local
E       assert tensor([1.3774]) == 1.3774276244053927
E         +tensor([1.3774])
E         -1.3774276244053927
```

**Additional context**
This started being an issue when the order of the test suite was randomized (specifically to shake out flaky tests like this.)Resolved by #3356."	1	2020-04-14 14:28:43	2020-04-14 17:37:51	2020-04-14 17:37:51
https://github.com/OpenMined/PySyft/issues/3333	[]	Need changes in Experimental notebook for PaillierTensor	"Need changes in Experimental notebook for PaillierTensor**To Reproduce**
Run PySyft/examples/experimental/PaillierTensor.ipynb and on running 3rd block it will throw an error.

**Expected behavior**
Should encrypt tensor without throwing the error 😁

**Additional context**
change encrypt and decrypt like:
x = th.Tensor([1,2,3]).encrypt(protocol=""paillier"", public_key=pub)
out = out.decrypt(protocol=""paillier"", private_key=pri)
What's the error? Post a stack trace.> What's the error? Post a stack trace.

Error is due to the recent changes in encrypt method.
```
AttributeError                            Traceback (most recent call last)
 in 
----> 1 x = th.Tensor([1,2,3]).encrypt(pub)
      2 y = th.Tensor([2,2,2])

~/Desktop/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in encrypt(self, protocol, **kwargs)
   1018 
   1019         """"""
-> 1020         if protocol.lower() == ""mpc"":
   1021             workers = kwargs.pop(""workers"")
   1022             crypto_provider = kwargs.pop(""crypto_provider"")

AttributeError: 'PaillierPublicKey' object has no attribute 'lower'
```@Syzygianinfern0 I think this changed most recently in one of your PRs. Give it a look?Ok. @karlhigley"	4	2020-04-09 20:03:04	2020-04-19 15:08:51	2020-04-19 15:08:51
https://github.com/OpenMined/PySyft/issues/3261	['bug ']	fix_precision() is inplace when applied to a pointer tensor.	"fix_precision() is inplace when applied to a pointer tensor.**Description of the bug**
The method fix_precision() applied on pointers is 'inplace'. This should not be the case

In the following code:

```
a = torch.Tensor([2., 3.]).send(bob)
a.fix_precision()
a = a.get()
print(type(a))
```

The variable  `a` after calling `get()` is a fixed precision tensor which is a bug, because the original variable `a` defined as `torch.Tensor([2., 3.])` is not a fixed precision tensor.

However, this bug is not existing in case when  `a` is not a pointer:

```
a = torch.Tensor([2., 3.])
a.fix_precision()
print(type(a))
```

`a` here is not a fixed precision tensor. which is the desired behavior.


**Desktop:**
 - OS: Archlinux
 - Version 0.3.2


I can take this!!Hey @AlanAboudib @karlhigley @LaRiffle ,
so if I understand this correctly,

```python
x = th.Tensor([1.,2.,3.]).send(bob)
x_fx = x.fix_precision()
x = x_fx.get()

```
x_fx is a `PointerTensor` and expected behavior is to be a `FixedPrecisionTensor` with `PointerTensor` as child?

Moreover when we .get() the x_fx, it returns `FixedPrecisionTensor`, which I think is a correct behavior, as we haven't called float_precision yet.not exactly, fix_precision() should be applied anyway on the remote value when called on a pointer (and it works fine)

the issue is that currently we have this for pointers:
```
a = torch.Tensor([2., 3.]).send(bob)
a_fp = a.fix_precision()
# a_fp is a pointer to a fixed precision, but a is too!
```
while for non pointers:
```
a = torch.Tensor([2., 3.])
a_fp = a.fix_precision()
# a_fp is a wrapper onto a fixed precision, but a is not!
```

So for pointers, `fix_precision` behaves as `fix_precision_` while it shouldn't"	3	2020-03-27 13:48:18	2020-03-31 19:44:14	2020-03-31 19:44:14
https://github.com/OpenMined/PySyft/issues/3260	[]	Websocket Secure error SSL: CERTIFICATE_VERIFY_FAILED	"Websocket Secure error SSL: CERTIFICATE_VERIFY_FAILEDI am running the old version of [websockets_mnist_parallel](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets_mnist_parallel) example with `websocket secure`. It seems the initial handshake is fine but once computing the loss in `run_websocket_client.py` script, it produces the error:

> Traceback (most recent call last):
  File ""asynchronous_federated_learning.py"", line 124, in <module>
    asyncio.run(main(args,device))
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/runners.py"", line 43, in run
    return loop.run_until_complete(main)
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/base_events.py"", line 583, in run_until_complete
    return future.result()
  File ""asynchronous_federated_learning.py"", line 65, in main
    for worker in worker_instances
  File ""run_websocket_client.py"", line 114, in fit_model_on_worker
    loss = await worker.async_fit(dataset_key=""mnist"", return_ids=[0])
  File ""/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 149, in async_fit
    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL
  File ""/miniconda3/envs/pysyft/lib/python3.7/site-packages/websockets/client.py"", line 517, in __aenter__
    return await self
  File ""/miniconda3/envs/pysyft/lib/python3.7/site-packages/websockets/client.py"", line 535, in __await_impl__
    transport, protocol = await self._create_connection()
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/base_events.py"", line 985, in create_connection
    ssl_handshake_timeout=ssl_handshake_timeout)
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/base_events.py"", line 1013, in _create_connection_transport
    await waiter
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/sslproto.py"", line 530, in data_received
    ssldata, appdata = self._sslpipe.feed_ssldata(data)
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/sslproto.py"", line 189, in feed_ssldata
    self._sslobj.do_handshake()
  File ""/miniconda3/envs/pysyft/lib/python3.7/ssl.py"", line 774, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1076)

Just to note that I am using `PySyft 0.2.4` and `Python 3.7`.Would something like [this](https://github.com/cloudfoundry-community/cf-python-client/issues/51#issuecomment-536428838) work to address that?Actually I am not sure. I followed the advise proposed to add the following code at the beginning of my code and it does not work:

```python 
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    # Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
    # Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context
``` 

I have also tried adding to the `WebsocketClientWorker`, but no success. Done the same thing with `WebsocketServerWorker` and no success either.I tried to manually give WebsocketClientWorker the cert file but I faced another error:

> ssl.SSLError: [SSL] called a function you should not call

@IonesioJunior did you try the `WebsocketClientWorker` and `WebsocketServerWorker` in `async` mode?I have done these changes and I think now it works. In the constructor of the class `WebsocketClientWorker` I add:

```Python
if self.secure:
    self.ssl_context = ssl._create_unverified_context()
```

and in the `async_fit` function, instead of:

```Python 
async with websockets.connect(
                    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL
            ) as websocket:
```
I add the `ssl=self.ssl_context` to have:

```Python 
async with websockets.connect(
                    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL,ssl=self.ssl_context
            ) as websocket:
```Would be great to capture these changes in a PR somehow, so that anyone else running locally in secure mode doesn't hit the same problem. 👍 @karlhigley Ok, I ll make the PR ready and submit it"	6	2020-03-27 13:35:41	2020-04-05 09:27:31	2020-04-01 08:08:54
https://github.com/OpenMined/PySyft/issues/3259	['bug ']	Indexing pointer tensors with a list	"Indexing pointer tensors with a listWhen running the following code
```python
hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")

a = torch.tensor([10,20,30])
print(a[[0,2]])

b = torch.tensor([10,20,30]).send(bob)
print(b[[0,2]])
```
the first tensor `a` get displayed correctly as 
```python
tensor([10, 30])
```
but the second tensor raises the following error:
```python
IndexError: too many indices for tensor of dimension 1
```

I have Python 3.7.6, PySyft 0.2.4 and PyTorch 1.4.0.

I'm new to PySyft, so maybe it is an expected behavior for some reasons, but I don't really see why (since remote tensors are supposed to have the same functionalities as normal tensors as far as I understand). I can take a look."	1	2020-03-27 12:46:06	2020-04-07 13:59:24	2020-04-07 13:59:24
https://github.com/OpenMined/PySyft/issues/3250	['bug ']	Cannot find dataset pointers sent to a remote client 	"Cannot find dataset pointers sent to a remote client **Describe the bug**
After tagging a tensor and sending it to the NodeClient object, nothing comes out of the ClientNode. The search method returns no objects.

**To Reproduce**
- Setup a remote client (Grid node)
- Create a simple tensor `data = torch.tensor([1, 1, 1, 1, 1])`
- Tag the tensor `data.tag('mytag')`
- Send the tensor to the remote node `data.send(remote_node)`
- Search for the tenor `remote_node.search('mytag')`  -> This will return an empty list []
- Search for the tensor on the grid gateway (`grid_gateway.search('mytag')`) . It will return an empty list []


I checked the redis db and I found the tags but they won't show up in the search method:
`redis_db.hgetall('key')`


**Screenshots**
![Screen Shot 2020-03-24 at 6 50 31 PM](https://user-images.githubusercontent.com/18373707/77392705-6adac900-6e00-11ea-81ff-06222b0df71c.png)

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - PySyft 0.2.4 msgpack 1.0.0


worker.search() is for local use only. for a remote worker use `me.request_search(['mytag'], location= worker)`. this will send you back an object_pointer that points to the dataset. that enables you to call .get() on it only for now not full functionality of dataset_pointer.
update: me.request_search() returns a dataset_pointer now"	1	2020-03-24 05:52:09	2020-04-29 15:13:27	2020-04-29 15:13:27
https://github.com/OpenMined/PySyft/issues/3245	['bug ']	Error with PySyft federated learning remote worker 	"Error with PySyft federated learning remote worker **Describe the bug**
TrainConfig.send() to a remote client throw an error

**To Reproduce**
Steps to reproduce the behavior:
1- Create a remote client on a different server.
2- Run the code in Introduction To TrainConfig notebook.
3- replace localhost with the IP of the remote server that has the worker running
4- train_config.send(alice) will throw an error

**Error Message **
This is the error message from the worker side:

`worker <WebsocketServerWorker id:alice #objects:0> received WorkerCommandMessage ('_log_msgs', ((), {'value': False}, []))
Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'ObjectMessage' object has no attribute 'contents'"")>
Traceback (most recent call last):
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py"", line 317, in recv_msg
    print(f""worker {self} received {type(msg).__name__} {msg.contents}"")
AttributeError: 'ObjectMessage' object has no attribute 'contents'
Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'ObjectMessage' object has no attribute 'contents'"")>
Traceback (most recent call last):
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py"", line 317, in recv_msg
    print(f""worker {self} received {type(msg).__name__} {msg.contents}"")
AttributeError: 'ObjectMessage' object has no attribute 'contents'`

**Screenshots**
Notebook Screenshot:
![Screen Shot 2020-03-24 at 12 21 16 AM](https://user-images.githubusercontent.com/18373707/77311739-8fce2e00-6d65-11ea-9e17-144749eea3df.png)

**Desktop (please complete the following information):**
 - OS: Amazon Linux x86_64
 - Python 3.7
- PySyft 0.2.4


You probably run it with `--verbose` arg which causes the `msg.contents` print. Try running the remote worker without the param, as a temporary fix.I think the underlying issue [is in `BaseWorker`](https://github.com/OpenMined/PySyft/blob/master/syft/workers/base.py#L316-L317). The problem is that the base `Message` class no longer has a `contents` property, so none of the sub-classes do either.I think this issue is already fixed in the following commit:
https://github.com/OpenMined/PySyft/commit/e4b5cab232910968036f8bac1d499b19356de41c

@karlhigley If you agree this issue could be closed"	3	2020-03-23 11:26:37	2020-05-05 18:44:08	2020-05-05 18:44:08
https://github.com/OpenMined/PySyft/issues/3228	[]	Update our custom crypten load to only wrap the original one	"Update our custom crypten load to only wrap the original one**Is your feature request related to a problem? Please describe.**
We can't track updates to crypten.load and update our custom one.

**Describe the solution you'd like**
As CrypTen has introduced a [new way](https://github.com/facebookresearch/CrypTen/pull/53) to load cryptensors, we can now only wrap around their function while loading tensors using their tags.

**Additional context**
This might not be possible at the current time, as this functionality comes with a version of CrypTen that isn't compatible with syft, however, we should keep an eye on this.This was addressed in a different PR"	1	2020-03-19 19:10:03	2020-04-18 14:40:15	2020-04-18 14:40:15
https://github.com/OpenMined/PySyft/issues/3214	['bug ']	Fix parameter serialization	"Fix parameter serializationIn some situations, parameters are not serialized properly. I suspect this is due to our implementation of parameter.data

Here is one example:
```python
class Net(sy.Plan):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(1, 1)

    def forward(self, x):
        return self.fc1(x)

plan = Net()
plan.build(th.tensor([1.2]))

x = th.tensor([-1.0])
expected = plan(x)

plan.fix_precision().share(alice, bob, crypto_provider=charlie)
print(plan.state.tensors())
ptr_plan = plan.send(james)

# Fetch plan
fetched_plan = plan.owner.fetch_plan(ptr_plan.id_at_location, james)
print('***')
print(fetched_plan.state.tensors())
```
Output
```
[Parameter containing:
(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:94226517866 -> alice:74685210613]
	-> [PointerTensor | me:30028513485 -> bob:91228892047]
	*crypto provider: charlie*, Parameter containing:
(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:16955185561 -> alice:5015164314]
	-> [PointerTensor | me:77573712688 -> bob:21883177159]
	*crypto provider: charlie*]
***
[FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:94226517866 -> alice:74685210613]
	-> [PointerTensor | me:30028513485 -> bob:91228892047]
	*crypto provider: charlie*, FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:16955185561 -> alice:5015164314]
	-> [PointerTensor | me:77573712688 -> bob:21883177159]
	*crypto provider: charlie*]
```I can take a look"	1	2020-03-17 23:33:26	2020-03-27 13:17:25	2020-03-27 13:17:25
https://github.com/OpenMined/PySyft/issues/3208	[]	Setting requires_grad as True in Pysyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb	"Setting requires_grad as True in Pysyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb**Describe the bug**

In the file: Pysyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb

Only the weights are needed to be updated. Why did we set requires_grad as True for x and y? I think it can be confusing for beginners.

data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)
target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)


@eceisik Send a PR that fixes it? 😄 Could be related to #3180"	2	2020-03-17 12:35:20	2020-03-18 11:30:57	2020-03-18 11:30:57
https://github.com/OpenMined/PySyft/issues/3207	['bug ', 'status: stale :bread:']	Inconsistency in remote_send and remote_get operations	"Inconsistency in remote_send and remote_get operations**Describe the bug**
The remote pointer operations, remote_get and remote_send work fine together, but break when used in a sequence. Found this issue while working on #2864 

**To Reproduce**
```import torch
import syft as sy
hook = sy.TorchHook(torch)

def print_config():
    print('-'*10)
    print('   me:',  me._objects)
    print('  bob:', bob._objects)
    print('alice:',alice._objects)
    print('-'*10)

def check_remote_get():
    print(""Checking remote_get"")
    # me (pointer) -> alice (pointer)-> bob (tensor)
    p2p2x = torch.tensor([1,2,3,4]).send(alice).send(bob)
    print('p2p2x:', p2p2x)
    print_config()

    # after calling remote_get on p2p2x
    # me (pointer) -> alice (tensor)
    p2x = p2p2x.remote_get()
    print('p2x:', p2x)
    print_config()
    print('***remote_get() works fine***')
    print('\n', '*'*10, '\n')

def check_remote_send():
    print(""Checking remote_send"")
    # me (pointer) -> bob (tensor)
    p2x = torch.tensor([1,2,3,4]).send(bob)
    print('p2x:', p2x)
    print_config()

    # after calling remote_send on p2x
    # me (pointer) -> bob (pointer) -> alice (tensor)
    p2p2x = p2x.remote_send(alice)
    print('p2p2x:', p2p2x)
    print_config()
    print('***remote_send() works fine***')
    print('\n', '*'*10, '\n')

def check_remote_operations_sequence():
    # me (pointer) -> bob (tensor)
    print(""Checking remote_send and remote_get sequence"")
    p2x = torch.tensor([1,2,3,4]).send(bob)
    print('p2x:', p2x)
    print_config()

    # after calling remote_send on p2x
    # me (pointer) -> bob (pointer) -> alice (tensor)
    p2p2x = p2x.remote_send(alice)
    print('p2p2x:', p2p2x)
    print_config()

    # after calling remote_get on p2p2x
    # me (pointer) -> bob (tensor)
    p2x_ = p2p2x.remote_get()
    print('p2x_:', p2x_)
    print_config()

    # Throws ObjectNotFoundError
    z = p2x_ + p2x_

def clear_objects():
    bob.clear_objects()
    alice.clear_objects()
    
if __name__ == ""__main__"":
    me = sy.local_worker
    bob = sy.VirtualWorker(hook, id='bob')
    alice = sy.VirtualWorker(hook, id='alice')
    clear_objects()
    
    check_remote_get()
    clear_objects()

    check_remote_send()
    clear_objects()
    
    check_remote_operations_sequence()
    clear_objects()
```

**Output**
```Checking remote_get
p2p2x: (Wrapper)>[PointerTensor | me:89240781371 -> bob:20411805653]
----------
   me: {}
  bob: {20411805653: (Wrapper)>[PointerTensor | bob:20411805653 -> alice:69485423954]}
alice: {69485423954: tensor([1, 2, 3, 4])}
----------
p2x: (Wrapper)>[PointerTensor | me:89240781371 -> bob:20411805653]
----------
   me: {}
  bob: {20411805653: tensor([1, 2, 3, 4])}
alice: {}
----------
***remote_get() works fine***

 ********** 

Checking remote_send
p2x: (Wrapper)>[PointerTensor | me:9842172577 -> bob:52458556840]
----------
   me: {}
  bob: {52458556840: tensor([1, 2, 3, 4])}
alice: {}
----------
p2p2x: (Wrapper)>[PointerTensor | me:9842172577 -> bob:52458556840]
----------
   me: {}
  bob: {52458556840: (Wrapper)>[PointerTensor | bob:87311029150 -> alice:52458556840]}
alice: {52458556840: tensor([1, 2, 3, 4])}
----------
***remote_send() works fine***

 ********** 

Checking remote_send and remote_get sequence
p2x: (Wrapper)>[PointerTensor | me:76396849905 -> bob:80366686695]
----------
   me: {}
  bob: {80366686695: tensor([1, 2, 3, 4])}
alice: {}
----------
p2p2x: (Wrapper)>[PointerTensor | me:76396849905 -> bob:80366686695]
----------
   me: {}
  bob: {80366686695: (Wrapper)>[PointerTensor | bob:43416594800 -> alice:80366686695]}
alice: {80366686695: tensor([1, 2, 3, 4])}
----------
p2x_: (Wrapper)>[PointerTensor | me:76396849905 -> bob:80366686695]
----------
   me: {}
  bob: {80366686695: (Wrapper)>[PointerTensor | bob:43416594800 -> alice:80366686695], 43416594800: tensor([1, 2, 3, 4])}
alice: {}
----------

---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/Desktop/GSoC/OpenMined/PySyft/syft/generic/object_storage.py in get_obj(self, obj_id)
     68         try:
---> 69             obj = self._objects[obj_id]
     70         except KeyError as e:

KeyError: 80366686695

During handling of the above exception, another exception occurred:

ObjectNotFoundError                       Traceback (most recent call last)
<ipython-input-2-ca8d557e9987> in <module>
     78     clear_objects()
     79 
---> 80     check_remote_operations_sequence()
     81     clear_objects()

<ipython-input-2-ca8d557e9987> in check_remote_operations_sequence()
     60 
     61     # Throws Error
---> 62     z = p2x_ + p2x_
     63 
     64 def clear_objects():
.
.
.

ObjectNotFoundError: Object ""80366686695"" not found on worker!!! You just tried to interact with an object ID:80366686695 on <VirtualWorker id:alice #objects:0> which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines. If you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!
```

**Expected behavior**

The remote_get and remote_send operations are Pointer Chain Operations and intuitively should
- remote_get: call .get() on the last pointer in chain, move tensor from last worker to its predecessor worker in the pointer chain. Method call should return a PointerTensor, which is at the beginning of chain of pointers which ends at the tensor object.

- remote_send: call .send(new_worker) on the tensor at the end of pointer chain, move tensor from last worker to new_worker in the pointer chain. Method call should return a PointerTensor at the beginning of the chain of pointers which ends at the tensor object on new_worker's machine.
I guess the fault is with remote_send method.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	1	2020-03-17 05:58:10	2020-05-22 00:04:56	2020-05-22 00:04:56
https://github.com/OpenMined/PySyft/issues/3183	['bug ', 'status: stale :bread:']	KeyError: 'evaluate'	"KeyError: 'evaluate'**Describe the bug**

when I run PySyft/examples/tutorials/advanced/websockets-example-MNIST-parallel/run_websocket_client.py

/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
2020-03-12 13:36:22,100 | Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'dict' object has no attribute 'owner'"")>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 663, in register_response
    register_response_function = register_response_functions[attr_id]
KeyError: 'evaluate'





I will take a lookHey @ERICPENGZ 
I could not reproduce your problem. I ran the following commands in a docker container and everything worked fine:
python start_websocket_servers.py
python run_websocket_client.py

Could you try to pull the latest master and retest?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	3	2020-03-12 05:45:49	2020-05-22 00:05:00	2020-05-22 00:05:00
https://github.com/OpenMined/PySyft/issues/3180	['bug ']	Runtime Error asking all parameters to have requires_grad=True	"Runtime Error asking all parameters to have requires_grad=True**Describe the bug**
I'm trying to finetune a alexnet model and i've set the parameters except for the final layer of the model to requires_grad=False and have created a new classification layer with the desired outputs i want. However the .send() function keeps throwing a runtime error `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

```
import syft
import torch
from torchvision import models
import torch.nn as nn

hook = syft.TorchHook(torch)
worker = syft.VirtualWorker(hook, id=""worker"")

model = models.alexnet(pretrained=True)
for param in model.parameters():
    param.requires_grad=False
model.classifier[6] = nn.Linear(model.classifier[6].in_features, 3)
model.send(worker)
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-15-a250859d9a13> in <module>
----> 1 model.send(worker)

~/implementation/PyGrid/gateway/src/syft/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, force_send, *dest, **kwargs)
    608 
    609             if module_is_missing_grad(nn_self):
--> 610                 create_grad_objects(nn_self)
    611 
    612             for p in nn_self.parameters():

~/implementation/PyGrid/gateway/src/syft/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    600             for p in model.parameters():
    601                 o = p.sum()
--> 602                 o.backward()
    603                 if p.grad is not None:
    604                     p.grad -= p.grad

~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/trace.py in trace_wrapper(*args, **kwargs)
     81                 syft.hook.trace.logs.append((command, response))
     82             else:
---> 83                 response = func(*args, **kwargs)
     84 
     85             return response

~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    436                 except BaseException as e:
    437                     # we can make some errors more descriptive with this method
--> 438                     raise route_method_exception(e, self, args, kwargs)
    439 
    440             else:  # means that there is a wrapper to remove

~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    432 
    433                 try:
--> 434                     response = method(*args, **kwargs)
    435 
    436                 except BaseException as e:

~/anaconda3/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    193                 products. Defaults to ``False``.
    194         """"""
--> 195         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    196 
    197     def register_hook(self, hook):

~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
 
```@avinath1998 If you are trying to change the whole **model.classifier** block, then your input dimension (which you put 2) is wrong. The input dimension of **model.classifier** should be 256x6x6.
refer: https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py

```
self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )
```@imraniac Oh shoot, i only added this as an example and didnt see that. Regardless, the error still comes up, ive updated the issue accordinglyHave you still updated the issue with an example? Because it should be 256 * 6 * 6 and not 224@imraniac updated accordingly, still doesn't work, the error occursI will check this.@tudorcebere, assigned you"	6	2020-03-11 15:34:39	2020-03-16 12:32:12	2020-03-16 12:32:12
https://github.com/OpenMined/PySyft/issues/3174	[]	UnicodeDecodeError trying to get the loss back	"UnicodeDecodeError trying to get the loss backI am running the [mnist-federated-learning tutorial](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets-example-MNIST) on two separate machines. Once I try to get the loss back in  `train_on_batches` function of [run_websocket_client script](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/websockets-example-MNIST/run_websocket_client.py), I have received the following error:

> UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte


The traceback of the error is:

> File ""synchronous_federated_learning.py"", line 79, in <module>
    abort_after_one=abort_after_one)
  File ""/home/run_websocket_client.py"", line 129, in train
    worker, curr_batches, model, device, lr
  File ""/home/run_websocket_client.py"", line 66, in train_on_batches
    loss = loss.get()  # <-- NEW: get the loss back
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 578, in get
    tensor = self.child.get(*args, user=user, reason=reason, **kwargs)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/generic/pointers/pointer_tensor.py"", line 317, in get
    tensor = ObjectPointer.get(self, user=user, reason=reason, deregister_ptr=deregister_ptr)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py"", line 269, in get
    obj = self.owner.request_obj(self.id_at_location, self.location, user, reason)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/workers/base.py"", line 628, in request_obj
    obj = self.send_msg(ObjectRequestMessage((obj_id, user, reason)), location)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/workers/base.py"", line 285, in send_msg
    response = sy.serde.deserialize(bin_response, worker=self)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/serde/serde.py"", line 69, in deserialize
    return strategy(binary, worker)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/serde/msgpack/serde.py"", line 368, in deserialize
    simple_objects = _deserialize_msgpack_binary(binary, worker)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/serde/msgpack/serde.py"", line 343, in _deserialize_msgpack_binary
    simple_objects = msgpack_lib.loads(binary, use_list=False)
  File ""msgpack/_unpacker.pyx"", line 195, in msgpack._cmsgpack.unpackb
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte

Do you have any idea? Thank you.I have realized that the value of `binary` as the input of `simple_objects = msgpack_lib.loads(binary, use_list=False)` is encoded as `windows-1252` (which is expected to be `utf-8`), and that is the reason it is unable to decode with `utf-8`. I am not sure but the reason might be the fact that I use the three different Ubuntu virtual machines (one server and two workers) on top of my `Windows` operating system. Once I run it on an Ubuntu machine (server) with two other Ubuntu virtual machines (workers) on top of it, then it works fine."	1	2020-03-10 17:29:20	2020-03-12 11:11:30	2020-03-12 11:11:30
https://github.com/OpenMined/PySyft/issues/3131	[]	Sigmoid in SMPC failing for some shapes	"Sigmoid in SMPC failing for some shapes**Describe the bug**
 Examples to illustrate:

Working
```python
a = torch.Tensor([1,2,3])
a = a.fix_precision().share(bob, alice, crypto_provider = crypto_provider, requires_grad = True)
torch.nn.Sigmoid()(a)
```
Not working
```python
a = torch.Tensor([[1,2,3],[4,5,6]])
a = a.fix_precision().share(bob, alice, crypto_provider = crypto_provider, requires_grad = True)
torch.nn.Sigmoid()(a)
```
Error: `AssertionError: Must be batches of square matrices`

(same with `requires_grad=False`)

The error seems linked to tensor shape
It worked before by the way. Like a month agoMight need to add a test for this.I can take it @LaRiffle"	3	2020-03-02 15:50:38	2020-03-22 13:49:22	2020-03-22 13:49:22
https://github.com/OpenMined/PySyft/issues/3105	[]	Custom federated learning network (LSTM)	"Custom federated learning network (LSTM)So, Im practicing federated learning with PyTorch, and I want to implement LSTM network for text generation. 

Here is the network: 
`
class LSTM(nn.Module):

    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):
        super(LSTM, self).__init__()
        self.embed = nn.Embedding(vocab_size, embed_size)  
        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)
        self.linear = nn.Linear(hidden_size, vocab_size)

    def forward(self, x, h):
        x = self.embed(x)

        out, (h, c) = self.lstm(x, h)  # (input , hidden state)

        out = out.reshape(out.size(0) * out.size(1), out.size(2))

        out = self.linear(out)
        return out, (h, c)
`
But, because federated learning requires dataset to be in specific form:

`base = sy.BaseDataset(torch.tensor(train), torch.tensor(test))
base_federated = base.federate((bob, adrian, patrycja, alice))
federated_train_loader = sy.FederatedDataLoader(base_federated, batch_size=args.batch_size)
`
Im getting an error that wrong object is passed to the network:

`RuntimeError: input.size(-1) must be equal to input_size. Expected 6431, got 0
`

I know that, this is because of how the data is structured:
`(Wrapper)>[PointerTensor | me:29040208176 -> bob:89708341131]
`
`
20 # batch size 
`
`
<class 'torch.Tensor'> # type`

and what I actually need is:

> `tensor([[ 112,  193,  592,  ...,  503,  143,  630],
        [ 492,   96, 1080,  ...,  378, 1106,   73],
        [ 284,  386,   97,  ...,    0,  284, 1502],
        ...,
        [  44,   45,   17,  ..., 5666,    0, 5667],
        [ 783, 6020,    0,  ...,    0,  178,  206],
        [   0,  151,   79,  ..., 6408, 5044,   77]])`

bare tensor data. 

So my question is, how to strip that weird `(Wrapper)>[PointerTensor | me:29040208176 -> bob:89708341131]
`
and obtain raw data from that sensor ?

hi,
wher you able to fix this error message"	1	2020-02-26 10:40:47	2020-11-09 23:12:07	2020-02-26 10:55:47
https://github.com/OpenMined/PySyft/issues/3095	[]	TypeError in compute_q_noisy_max_approx function	"TypeError in compute_q_noisy_max_approx function**Describe the bug**
Type error because of the subtraction between `counts`(which is a list) and `counts[winner]`(which is a float). 

**Expected behavior**
The final answer to this computation should be 0.8

**Screenshots**
![Screenshot from 2020-02-25 21-50-19](https://user-images.githubusercontent.com/39258575/75266815-e86ae380-5818-11ea-9eb3-3cbab288bbcc.png)

**Desktop (please complete the following information):**
 - OS: Linux Ubuntu 16.04

**Additional context**
Add any other context about the problem here.
To solve this, there has to be a loop to iterate `counts` so that the correct code should be 
` 
for i in range(len(counts)):
   counts_normalized = noise_eps * (counts[i] - counts[winner])
`


Well sc should be a torch tensor, not a list.Ohh, my bad. Thank you for letting me know. You can close this issue.

On Tue, 25 Feb 2020 at 10:34 PM, Pierre Pocreau <notifications@github.com>
wrote:

> Well sc should be a torch tensor, not a list.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3095?email_source=notifications&email_token=AJLQTT6DAS3DTPBGXXDDB7DREVFSFA5CNFSM4K3N3NI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEM4VNFY#issuecomment-590960279>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJLQTTYYZXE6QISVMDMCETDREVFSFANCNFSM4K3N3NIQ>
> .
>"	2	2020-02-25 16:22:55	2020-02-26 05:20:38	2020-02-26 05:20:38
https://github.com/OpenMined/PySyft/issues/3091	[]	AttributeError: module 'syft.messaging' has no attribute 'plan'	"AttributeError: module 'syft.messaging' has no attribute 'plan'I get this problem when connecting to the WebSocketGridClient.  
Can anyone help me with this issue?
```
File ""/usr/local/lib/python3.7/site-packages/grid/__init__.py"", line 3, in <module>
   from grid.websocket_client import WebsocketGridClient
File ""/usr/local/lib/python3.7/site-packages/grid/websocket_client.py"", line 30, in <module>
    class WebsocketGridClient(WebsocketClientWorker, FederatedClient):
File ""/usr/local/lib/python3.7/site-packages/grid/websocket_client.py"", line 478, in WebsocketGridClient
    def serve_encrypted_model(self, encrypted_model: sy.messaging.plan.Plan) -> bool:
AttributeError: module 'syft.messaging' has no attribute 'plan'
```
It looks like that code was deprecated and later removed in #476, which [suggests](https://github.com/OpenMined/PyGrid/commit/2b543d075b86a6846d815ab5bdba45b551f48654#diff-b1ef8a3aed029ba9fb6663df43b6c7daL16) using PySyft's `syft.grid` module instead.@DanielMorales9 is this issue still present? Hi @gmuraru, after following this it works fine. 

> It looks like that code was deprecated and later removed in #476, which [suggests](https://github.com/OpenMined/PyGrid/commit/2b543d075b86a6846d815ab5bdba45b551f48654#diff-b1ef8a3aed029ba9fb6663df43b6c7daL16) using PySyft's `syft.grid` module instead."	3	2020-02-24 13:41:34	2020-03-14 14:17:42	2020-03-14 14:17:42
https://github.com/OpenMined/PySyft/issues/3079	[]	Attribute error	"Attribute errormodule 'syft' has no attribute 'ID_PROVIDER'
![tempsnip](https://user-images.githubusercontent.com/41802909/75015792-778d9980-54af-11ea-86bf-b77b93e19837.png)


@AnchalAgarwal21 What PySyft version are you using?@karlhigley 0.2.3a1@AnchalAgarwal21 Huh, haven't seen that issue with that version. Could you share the output of `pip list` and the imports above in the notebook?I have a silly question but have done a full ‘import syft as sy’ before?
I had a similar error when doing strange things during the syft import

What is the full sample of code you re trying to run?@karlhigley 
import torch as th
from torch import nn,optim
import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.exceptions import WorkerNotFoundExceptionI copied the entire code on another notebook and to my surprise, it didn't give any error but now I have encountered another error.
![tempsnip1](https://user-images.githubusercontent.com/41802909/75114484-2bdc1b00-567c-11ea-82c2-611d5c502344.png)
 You forgot to hook torch with `hook = sy.TorchHook(torch) `to extend torch tensors methods.Thank you @pierrepocreau ..I missed placing the hook torch."	8	2020-02-21 08:09:44	2020-02-25 17:40:13	2020-02-25 17:40:13
https://github.com/OpenMined/PySyft/issues/3063	[]	Asynchronous FL on MNIST: call WebsocketClientWorker evaluate() method causes error	"Asynchronous FL on MNIST: call WebsocketClientWorker evaluate() method causes errorHello! 
I am trying to run the example from [tutorials](https://github.com/OpenMined/PySyft/tree/09f052aae8654377ffea7faeb6b12d0f75ba319a/examples/tutorials/advanced/websockets-example-MNIST-parallel).  Everything works great until the models' evaluation. The script crashes with the error:

Client message

> RuntimeError                              Traceback (most recent call last)
> <ipython-input-14-63915de412fc> in async-def-wrapper()
>      37             )
>      38 
> ---> 39     # Federate models (note that this will also change the model in models[0]
>      40     for worker_id, worker_model, worker_loss in results:
>      41         if worker_model is not None:
> 
> <ipython-input-13-38da89661156> in evaluate_model_on_worker(model_identifier, worker, dataset_key, model, nr_bins, batch_size, print_target_hist)
>      67         nr_bins=nr_bins,
>      68         return_loss=True,
> ---> 69         return_raw_accuracy=True
>      70     )
>      71     test_loss = result[""loss""]
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in evaluate(self, dataset_key, return_histograms, nr_bins, return_loss, return_raw_accuracy)
>     221             nr_bins=nr_bins,
>     222             return_loss=return_loss,
> --> 223             return_raw_accuracy=return_raw_accuracy,
>     224         )
>     225 
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in _send_msg_and_deserialize(self, command_name, *args, **kwargs)
>     113         # Send the message and return the deserialized response.
>     114         serialized_message = sy.serde.serialize(message)
> --> 115         response = self._send_msg(serialized_message)
>     116         return sy.serde.deserialize(response)
>     117 
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in _send_msg(self, message, location)
>      81 
>      82     def _send_msg(self, message: bin, location=None) -> bin:
> ---> 83         return self._recv_msg(message)
>      84 
>      85     def _forward_to_websocket_server_worker(self, message: bin) -> bin:
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in _recv_msg(self, message)
>     102             if not self.ws.connected:
>     103                 raise RuntimeError(
> --> 104                     ""Websocket connection closed and creation of new connection failed.""
>     105                 )
>     106         return response
> 
> RuntimeError: Websocket connection closed and creation of new connection failed.

Server message:

> 2020-02-18 17:54:56,388 | Task exception was never retrieved
> future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /opt/conda/lib/python3.6/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'dict' object has no attribute 'owner'"",)>
> Traceback (most recent call last):
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
>     response = self._recv_msg(message)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
>     return self.recv_msg(message)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/base.py"", line 310, in recv_msg
>     response = self._message_router[type(msg)](msg.contents)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/base.py"", line 457, in execute_command
>     command_name, response, list(return_ids), self
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 665, in register_response
>     new_response = register_response_function(response, response_ids=response_ids, owner=owner)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 766, in <lambda>
>     return lambda x, **kwargs: f(lambdas, x, **kwargs)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 522, in two_fold
>     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 744, in <lambda>
>     else lambda i, **kwargs: register_tensor(i, **kwargs)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 712, in register_tensor
>     tensor.owner = owner
> AttributeError: 'dict' object has no attribute 'owner'

Exactly the same issue is described [here](https://stackoverflow.com/questions/60202610/pysyft-federated-learning-error-with-websockets?newreg=9254d6ab17014bcb896f3a2a45843b18)

Version of the lib is '0.2.3a1' See #2948 Sounds like we might need to release a new version with recent fixes.Wait, #2948 was included in 0.2.3.a1...I checked [2948](https://github.com/OpenMined/PySyft/pull/2948). It is not the source of the problem.The source of the problem is incorrect type of the function output. According to `Operation` class (from `syft/messaging/message.py`) the output must be `Tensor`. But `evaluate()` function (from `syft/federated/federated_client.py`) returns dictionary of floats. Facing the same Issue with recently published docker image also @karlhigley @karlhigley I have more or less the same problem running the same tutorial.  @9sashafr could you find any workaround?I'm in the process of doing some clean-up deep in the guts of Plans and Operations, starting with #3078. It may take a while to resolve this issue; not sure if making the output type more flexible or adding separate messages to the Syft protocol will turn out to be a preferable approach. Will keep this issue in mind as we sort through issues with the core abstractions.I was able to workaround by changing the generic/frameworks/hook/hook_args.py file so the register_tensor function is:

```python
def register_tensor(
    tensor: FrameworkTensorType, owner: AbstractWorker, response_ids: List = list()
):
    """"""
    Registers a tensor.

    Args:
        tensor: A tensor.
        owner: The owner that makes the registration.
        response_ids: List of ids where the tensor should be stored
            and each id is pop out when needed.
    """"""

    #tensor.owner = owner
    #try:
    #    tensor.id = response_ids.pop(-1)
    #except IndexError:
    #    raise exceptions.ResponseSignatureError

    owner.register_obj(tensor, response_ids.pop(-1))
```@brandonhee After doing, what you suggested I got another error saying dict object has no attribute 'id'. 

Any ideas?@Dhrumilsoni I have tried with the master and I think the bug has been fixed and it works now. Fixed in master and should work in the next release."	12	2020-02-18 15:33:40	2020-03-17 14:22:48	2020-03-17 14:22:48
https://github.com/OpenMined/PySyft/issues/3045	[]	Try fix problem regarding to {RuntimeError} in Ch06 (please see detail thanks)	"Try fix problem regarding to {RuntimeError} in Ch06 (please see detail thanks) The bug can be found here (my pull request)
[here](https://github.com/OpenMined/PySyft/pull/2766), which shows the attempt to fix the GPU error by myself.

It is my first time contributing to open source project, please let me if there is any mistake, thank you so much!

Let's keep the conversation on this issue over in #2766. Left a comment there about a test failure in the CI checks."	1	2020-02-10 14:19:30	2020-02-10 14:25:54	2020-02-10 14:25:54
https://github.com/OpenMined/PySyft/issues/3014	[]	ConnectionRefusedError: [Errno 111] Connection refused	"ConnectionRefusedError: [Errno 111] Connection refusedHi, I am using PyTorch 1.4.0, and syft version 0.2.3.a1. I am trying to run [grid tutorial on federated learning](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb). Once I do `compute_nodes.append( NodeClient(hook, node) )`, I get the following error:

> ConnectionRefusedError: [Errno 111] Connection refused

This is the full stack of the error:

> File ""./train.py"", line 26, in <module>
    compute_nodes.append( NodeClient(hook, node) )
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/node_client.py"", line 56, in __init__
    super().__init__(
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/websocket_client.py"", line 57, in __init__
    self.connect()
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/websocket_client.py"", line 69, in connect
    self.ws = websocket.create_connection(**args)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_core.py"", line 222, in connect
    self.sock, addrs = connect(url, self.sock_opt, proxy_info(**options),
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 201, in _open_socket
    raise err
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [Errno 111] Connection refusedDid you initiate each node/grid?This is the code snippet I used:
```python
import syft as sy 
from syft.workers.node_client import NodeClient
from syft.grid.public_grid import PublicGridNetwork
import torch

hook = sy.TorchHook(torch)
nodes = [""ws://localhost:3000/"",""ws://localhost:3001/""]
compute_nodes = []
for node in nodes:
    compute_nodes.append( NodeClient(hook, node) )
```But if you just did it without support of docker/command line, that's not supposed to work. You have to initiate the gateway and both node using docker from [grid](https://github.com/OpenMined/PyGrid/) documentation or using the following commands:

Gateway (at grid/gateway):
`python gateway.py --port=5000 --start_local_db`

Each node (at grid/app/websocket):
`python websocket_app.py --id=bob --port=3001 --gateway_url=http://localhost:5000`
`python websocket_app.py --id=alice --port=3001 --gateway_url=http://localhost:5000`thank you so much. It works when I run them as you said, in the background."	4	2020-02-05 11:42:07	2020-02-18 11:48:46	2020-02-18 11:48:46
https://github.com/OpenMined/PySyft/issues/3001	['bug ', 'status: stale :bread:']	Issue with Encrypted Aggregation	"Issue with Encrypted AggregationTutorial Part 10, when I call 

```
# iterate through each parameter
for param_i in range(len(params[0])):

    # for each worker
    spdz_params = list()
    for remote_index in range(len(compute_nodes)):
        
        # select the identical parameter from each worker and copy it
        copy_of_parameter = params[remote_index][param_i].copy()
        
        # since SMPC can only work with integers (not floats), we need
        # to use Integers to store decimal information. In other words,
        # we need to use ""Fixed Precision"" encoding.
        fixed_precision_param = copy_of_parameter.fix_precision()
        
        # now we encrypt it on the remote machine. Note that 
        # fixed_precision_param is ALREADY a pointer. Thus, when
        # we call share, it actually encrypts the data that the
        # data is pointing TO. This returns a POINTER to the 
        # MPC secret shared object, which we need to fetch.
        encrypted_param = fixed_precision_param.share(bob, alice, crypto_provider=james)
        
        # now we fetch the pointer to the MPC shared value
        param = encrypted_param.get()
        
        # save the parameter so we can average it with the same parameter
        # from the other workers
        spdz_params.append(param)

    # average params from multiple workers, fetch them to the local machine
    # decrypt and decode (from fixed precision) back into a floating point number
    new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2
    
    # save the new averaged parameter
    new_params.append(new_param)
```
I get this error:

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    662         # Load the utility function to register the response and transform tensors with pointers
--> 663         register_response_function = register_response_functions[attr_id]
    664         # Try running it

KeyError: 'numpy'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-15-34467fe3bdcd> in <module>
     12         # to use Integers to store decimal information. In other words,
     13         # we need to use ""Fixed Precision"" encoding.
---> 14         fixed_precision_param = copy_of_parameter.fix_precision()
     15 
     16         # now we encrypt it on the remote machine. Note that

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, storage, field_type, no_wrap, *args, **kwargs)
    765 
    766         max_precision = _get_maximum_precision()
--> 767         need_large_prec = self._requires_large_precision(max_precision, base, prec_fractional)
    768 
    769         if storage == ""crt"":

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in _requires_large_precision(self, max_precision, base, precision_fractional)
    837         # We need to use NumPy here as log2 is not yet implemented for LongTensor PyTorch objects
    838         return np.any(
--> 839             np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision
    840         )
    841 

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/trace.py in trace_wrapper(*args, **kwargs)
     81                 syft.hook.trace.logs.append((command, response))
     82             else:
---> 83                 response = func(*args, **kwargs)
     84 
     85             return response

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    475                 # Send the new command to the appropriate class and get the response
    476                 method = getattr(new_self, method_name)
--> 477                 response = method(*new_args, **new_kwargs)
    478 
    479                 # For inplace methods, just directly return self

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    638             command = (attr, self, args, kwargs)
    639 
--> 640             response = owner.send_command(location, command)
    641 
    642             # For inplace methods, just directly return self

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    510         try:
    511             ret_val = self.send_msg(
--> 512                 Operation(cmd_name, cmd_owner, cmd_args, cmd_kwargs, return_ids), location=recipient
    513             )
    514         except ResponseSignatureError as e:

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in send_msg(self, message, location)
    275 
    276         # Step 2: send the message and wait for a response
--> 277         bin_response = self._send_msg(bin_message, location)
    278 
    279         # Step 3: deserialize the response

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/virtual.py in _send_msg(self, message, location)
      5 class VirtualWorker(BaseWorker, FederatedClient):
      6     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 7         return location._recv_msg(message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/virtual.py in _recv_msg(self, message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:
---> 10         return self.recv_msg(message)

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in recv_msg(self, bin_message)
    308 
    309         # Step 1: route message to appropriate function
--> 310         response = self._message_router[type(msg)](msg.contents)
    311 
    312         # Step 2: Serialize the message to simple python objects

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in execute_command(self, message)
    455             try:
    456                 response = hook_args.register_response(
--> 457                     command_name, response, list(return_ids), self
    458                 )
    459                 return response

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    670         register_response_functions[attr_id] = register_response_function
    671         # Run it
--> 672         new_response = register_response_function(response, response_ids=response_ids, owner=owner)
    673 
    674     # Remove the artificial tuple

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in <lambda>(x, **kwargs)
    764         f = many_fold
    765 
--> 766     return lambda x, **kwargs: f(lambdas, x, **kwargs)

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    520 
    521 def two_fold(lambdas, args, **kwargs):
--> 522     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    523 
    524 

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in <lambda>(i, **kwargs)
    742         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    743         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 744         else lambda i, **kwargs: register_tensor(i, **kwargs)
    745         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    746     ]

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    710             and each id is pop out when needed.
    711     """"""
--> 712     tensor.owner = owner
    713     try:
    714         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```

OS: Ubuntu 18.04.3 LTS
Python 3.7
PyTorch 1.4I would like to work on this issueI have same issue.

I seems the problem was already fixed at https://github.com/OpenMined/PySyft/pull/2990 .
But still I could not how to avoid this error...> I would like to work on this issue

Hey Nilesh did you find any solution?
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	4	2020-02-03 13:26:06	2020-05-22 00:05:31	2020-05-22 00:05:31
https://github.com/OpenMined/PySyft/issues/2927	['bug ']	Small rounding errors in handcrafted Conv2d and Pool2d Layers	"Small rounding errors in handcrafted Conv2d and Pool2d Layers**Describe the bug**
There is a small rounding error in these layers, as discussed in https://github.com/OpenMined/PySyft/pull/2896/files/fa21f480c8bfe4196dac2f911cd938db7ff96f03#diff-369e971f29cf5226c9b64f75072095ac

**To Reproduce**
Run the following unit tests

https://github.com/OpenMined/PySyft/blob/39d2be0aeb4b5aa0413b6b8696cccb7fb960ab0d/test/torch/nn/test_conv.py#L7

https://github.com/OpenMined/PySyft/blob/39d2be0aeb4b5aa0413b6b8696cccb7fb960ab0d/test/torch/nn/test_pool.py#L6


**Expected behavior**
Ideally there would be 0 rounding error, but this might be a PyTorch issue not us.

I investigated this a bit and it seems we need to do a direct summation instead of calculating sum of sums. The following modifications are required:
* [`conv.py`](https://github.com/OpenMined/PySyft/blob/acdc96828cebae674817d238f68e0e81dfd41071/syft/frameworks/torch/nn/conv.py#L94-L95) - change `.sum(3).sum(3)` to `.sum((3, 4))`
* [`pool.py`](https://github.com/OpenMined/PySyft/blob/acdc96828cebae674817d238f68e0e81dfd41071/syft/frameworks/torch/nn/pool.py#L65) - change `.sum(2).sum(2)` to `.sum((2, 3))`

By making the above changes, we get exactly the same output for both the pooling implementations. However, a rounding error is still present for convolution possibly due to floating-point arithmetic as indicated [here](https://discuss.pytorch.org/t/pytorch-conv2d-vs-numpy-reference-different-outcomes-rounding-error-or-mistake/8921).@arshjot Thanks for looking into it! Could you submit a PR with those changes?Yes, I'll be happy to do so!Incredible work! 

Sent from my iPhone

> On 21 Jan 2020, at 19:20, Arshjot Singh Khehra <notifications@github.com> wrote:
> 
> ﻿
> Yes, I'll be happy to do so!
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
As reported - there is still rounding error in the Conv2d implementation. This issue should stay open until it is resolved. I have spent a few more hours looking into it and haven't found anything yet.That's strange, it looks like the PR solved it and chnaged the test form approx to exact check didn't it?The issue is solved for the pooling implementation but not for Conv2d. The Conv2d implementation also had the same discrepancy but even after rectifying it we do not get an exact match. I guess I should have specified that the PR solves *part* of this issue.This issue was fixed by #2964 (for the conv2d layer) and #2945 (for the pooling layer)"	8	2020-01-18 16:00:31	2020-01-27 22:00:06	2020-01-27 22:00:05
https://github.com/OpenMined/PySyft/issues/2861	[]	RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363	"RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363Runtime error when running:

` def train( ):
  opt = torch.optim.SGD(params=model.parameters(),lr=0.1)
  for epoch in range (20):
    model.train()
    print(""Training started.."")

    for x_data,y_data in datasets:

      model.send(x_data.location) 
      
      opt.zero_grad()
      
       #forwardpass
       #the model here is the linear regression model
      y_pred = model(x_data)

      #ComputeLoss
      loss=criterion(y_pred,y_data)

      #BackwardPass
      loss.backward()

      opt.step()

      model.get() #MIGHT HAVE AN ERROR, since .get() method is used only on pointers

      print(loss.get())`

**Error message:**

` PureFrameworkTensorFoundError             Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    287             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
--> 288                 cmd, args, kwargs, return_args_type=True
    289             )

25 frames
PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    320             # in the execute_command function
    321             if isinstance(args, tuple):
--> 322                 response = eval(cmd)(*args, **kwargs)
    323             else:
    324                 response = eval(cmd)(args, **kwargs)

RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363`


**Expected behavior**
I expect the error message to be clearer and easily understandable. I find it very difficult to understand the error.

Not 100% sure, but I think the `PureFrameworkTensorFoundError` is telling you that Syft expected to receive a pointer to a remote tensor but got a local Torch tensor instead, and the second error is coming from deep with PyTorch's linear algebra library, where it's trying to do tensor math but not getting valid parameters (maybe as a result of the first issue.) I can't quite trace all the way through the code to verify that's exactly what's happening, but hopefully it's enough to point in a useful direction.> Not 100% sure, but I think the `PureFrameworkTensorFoundError` is telling you that Syft expected to receive a pointer to a remote tensor but got a local Torch tensor instead, and the second error is coming from deep with PyTorch's linear algebra library, where it's trying to do tensor math but not getting valid parameters (maybe as a result of the first issue.) I can't quite trace all the way through the code to verify that's exactly what's happening, but hopefully it's enough to point in a useful direction.

Yes! you were right, moving the model.get() outside loop helped Thanks! But I now face a dimension error saying, ""Dimension out of range (expected to be in range of [-1, 0], but got 1)"" Hmm, not sure I've helped much yet. At least we know it's the `model.get()` where the problem occurs, but I think you already knew that.Check this issue if the RunTime error persists. https://github.com/pytorch/pytorch/issues/20006
This error is related to PyTorch."	4	2019-12-26 09:37:02	2020-11-18 18:39:12	2020-01-02 09:23:42
https://github.com/OpenMined/PySyft/issues/2858	[]	Bind Address Fail when starting a local socketServerWorker	"Bind Address Fail when starting a local socketServerWorker**Describe the bug**
When I Use python commandline prompt to run the script in websocket tutorial, I cannot bind the address when start the worker.
* error message:
`OSError: [Errno 99] error while attempting to bind on address ('::1', 8182, 0, 0): cannot assign requested address`

**To Reproduce**
Steps to reproduce the behavior:
1. use terminal (not notebook)
1. run`python`
1. run (this code is copied from *PySyft/examples/tutorials/websocket/*):
```python
import torch
import os
import sys
import logging
import syft as sy
hook = sy.TorchHook(torch)
from syft.workers.websocket_server import WebsocketServerWorker
local_worker = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182)
local_worker.start()
```

**Expected behavior**
server is launched with no error

**Screenshots**
![image](https://user-images.githubusercontent.com/35265996/71463583-d2797c00-27f1-11ea-883a-93f00c833950.png)

**Desktop (please complete the following information):**
* OS: Ubuntu 18.04
* pytorch version: 1.3.0
* syft version: 0.2.0a2

Thanks very much!
[This ipython issue](https://github.com/ipython/ipython/issues/6193) has some potentially relevant info about this socket error. Long story short, IPv6 `::1`, IPv4 `127.0.0.1`, and the `localhost` hostname are often but not always interchangeable. What happens if you change the `WebSocketServerWorker` instantiation to set `host=""127.0.0.1""`?Wow you genius! It works!!I've just seen these kinds of issues recently. 😄 Hi @karlhigley 
I am not sure if my question is relevant to this thread. I am running the [Federated Learning - MNIST Example of grid tutorial](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb) on Google Colab. Once using ``` NodeClient(hook, node) ```, I got the following error:

```
OSError: [Errno 99] Cannot assign requested address
```
Do you have any idea? Thank you."	4	2019-12-26 07:15:26	2020-01-27 09:51:55	2019-12-30 09:05:24
https://github.com/OpenMined/PySyft/issues/2796	[]	No module named 'syft.frameworks.torch.fl'	"No module named 'syft.frameworks.torch.fl'Hello,

when running the example:
'Federated learning with websockets and federated averaging.ipynb'


I am getting this error at very beginning: 

ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-3-720bf18bab2b> in <module>
      5 from torchvision import datasets, transforms
      6 
----> 7 from syft.frameworks.torch.fl import utils

ModuleNotFoundError: No module named 'syft.frameworks.torch.fl'

Any ideas?you need to import like  `from syft.frameworks.torch.federated import utils`Which version of syft are you using? In the latest one it should be working... Tell me if it doesn'tHere is my output:

pi@rasp-m:~ $ python3
Python 3.7.3 (default, Apr  3 2019, 05:39:12)
[GCC 8.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import torch
>>> print(torch.__version__)
1.3.0a0+de394b6
>>> import syft as sy
>>> print(sy.__version__)
0.2.0a2
>>>@abdulbasitds is working 👍 
replace: ""from syft.frameworks.torch.fl import utils""
with
""from syft.frameworks.torch.federated import utils""@LaRiffle It does not work in the official docker image providedThe Docker image is out of date. We’re working on getting updates published.I am seeing the same issue still with the openmined/pysyft-notebook image. I am also using the code ""syft.frameworks.torch.federated"""	7	2019-12-08 15:55:27	2021-12-07 11:21:33	2019-12-09 07:37:11
https://github.com/OpenMined/PySyft/issues/2795	[]	torrch.jit. script RuntimeError: undefined value _Reduction:	"torrch.jit. script RuntimeError: undefined value _Reduction:**Describe the bug**
I was trying to reproduce Asynchronous-federated-learning-on-MNIST fromadvanced example. where `@torrch.jit.script`  is used before loss function. I am getting this error and have no clue what this is about

> RuntimeError: 
> undefined value _Reduction:
> at /home/ab/.virtualenvs/aic/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py:1829:20
>   reduction = _Reduction.legacy_get_string(size_average, reduce)
                    ~~~~~~~~~~ <--- HERE
It is actually caused by these lines

```
@torch.jit.script
def loss_fn(pred, target):
    return F.nll_loss(input=pred, target=target)

train_config = sy.TrainConfig(
        model=traced_model,
        loss_fn=loss_fn,
        batch_size=batch_size,
        shuffle=True,
        max_nr_batches=max_nr_batches,
        epochs=1,
        optimizer=""SGD"",
        optimizer_args={""lr"": lr},
    )
```

![Screenshot from 2019-12-08 03-43-51](https://user-images.githubusercontent.com/33634518/70383366-1ef93680-196d-11ea-98e1-7a188fe9d7e8.png)
Issue solved after moving jit function to top of the file"	1	2019-12-08 02:45:23	2019-12-13 06:22:42	2019-12-13 06:22:42
https://github.com/OpenMined/PySyft/issues/2789	[]	Broken backprop from given gradient	"Broken backprop from given gradient**Describe the bug**
The bug occurs when performing backprop from a given gradient when the gradient and variable are held on a remote host. 

**To Reproduce**
I have made two notebooks. One demonstrates what should [what should be happening](https://github.com/blockpass-identity-lab/PySyft/blob/dev/examples/experimental/Split%20Neural%20Network/Simple-VanillaSplitNN-NoPySyft.ipynb).

The other demonstrates [what happens when I try to do this function on a worker](https://github.com/blockpass-identity-lab/PySyft/blob/dev/examples/experimental/Split%20Neural%20Network/Simple-VanillaSplitNN.ipynb)

**Desktop:**
 - OS: Im using MacOS Catalina
 - Version 10.15

Hey @H4LL.

It is working now? What was the problem? :) The backward function was not on the list of ambiguous methods so the vesrion of backward() that i needed was not cached. Fixed though by this commit; https://github.com/OpenMined/PySyft/pull/2799"	2	2019-12-06 16:36:05	2019-12-12 10:34:07	2019-12-11 17:38:11
https://github.com/OpenMined/PySyft/issues/2784	[]	fix_prec() doesn't work for crt or large	"fix_prec() doesn't work for crt or large**Describe the bug**
Converting a model to fixed precision doesn't work for LargePrecision or CRTPrecision.

**To Reproduce**
Steps to reproduce the behavior:
1. Run tutorial Part 11 - Secure Deep Learning Classification up to `model.fix_precision().share(alice, bob, crypto_provider=crypto_provider)`
If you're planning to run multiple tests, you may want to save the model and reload it as it can take awhile to train.
2. Change the parameters to `model.fix_prec(storage='crt')` or `model.fix_prec(storage='large')`

**Expected behavior**
Convert the model parameters to the specified precision strategy.

**Screenshots**
`model.fix_prec(storage='crt')`

> ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-25-e8fb399cdba4> in <module>()
> ----> 1 model.fix_prec(storage='crt').share(alice, bob, crypto_provider=crypto_provider)
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_share_(nn_self, *args, **kwargs)
>     613             """"""Overloads fix_precision for torch.nn.Module.""""""
>     614             # TODO: add .data and .grad to syft tensors
> --> 615             if module_is_missing_grad(nn_self):
>     616                 create_grad_objects(nn_self)
>     617 
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_is_missing_grad(model)
>     543             """"""Checks if all the parameters in the model have been assigned a gradient""""""
>     544             for p in model.parameters():
> --> 545                 if p.grad is None:
>     546                     return True
>     547             return False
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in grad(self)
>     343 
>     344             if hasattr(self, ""child""):
> --> 345                 to_return = self.child.attr(""grad"")
>     346                 if to_return is not None and isinstance(to_return.child, PointerTensor):
>     347                     if to_return.child.is_none():
> 
> AttributeError: 'CRTPrecisionTensor' object has no attribute 'attr'


`model.fix_prec(storage='large')`

> ---------------------------------------------------------------------------
> RuntimeError                              Traceback (most recent call last)
> <ipython-input-15-c2e4c0429286> in <module>()
> ----> 1 model.fix_prec(storage='large').share(alice, bob, crypto_provider=crypto_provider)
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_fix_precision_(nn_self, *args, **kwargs)
>     630 
>     631             for p in nn_self.parameters():
> --> 632                 p.fix_precision_(*args, **kwargs)
>     633 
>     634             return nn_self
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec_(self, *args, **kwargs)
>     721         """"""
>     722         # We specify id to make sure the inplace op doesn't change the tensor id
> --> 723         self.child = self.fix_prec(*args, no_wrap=True, id=self.id, **kwargs)
>     724         self.is_wrapper = True
>     725         return self
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, storage, field_type, no_wrap, *args, **kwargs)
>     687             fpt_tensor = (
>     688                 syft.LargePrecisionTensor(*args, **kwargs)
> --> 689                 .on(self, wrap=False)
>     690                 .fix_large_precision()
>     691             )
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/large_precision.py in fix_large_precision(self)
>     184 
>     185     def fix_large_precision(self):
> --> 186         self.child = self._create_internal_representation()
>     187         return self
>     188 
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/large_precision.py in _create_internal_representation(self)
>      71     def _create_internal_representation(self):
>      72         """"""Decompose a tensor into an array of numbers that represent such tensor with the required precision""""""
> ---> 73         self_scaled = self.child.numpy() * self.base ** self.precision_fractional
>      74 
>      75         # floor is applied otherwise, long float is not accurate
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
>     379                 except BaseException as e:
>     380                     # we can make some errors more descriptive with this method
> --> 381                     raise route_method_exception(e, self, args, kwargs)
>     382 
>     383             else:  # means that there is a wrapper to remove
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
>     376 
>     377                 try:
> --> 378                     response = method(*args, **kwargs)
>     379                 except BaseException as e:
>     380                     # we can make some errors more descriptive with this method
> 
> RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.

**Desktop (please complete the following information):**
 - OS: MacOS
 - Version 10.14.5
Is this issue still open? If yes, I can work on it.@sukhadj There's [an open PR](https://github.com/OpenMined/PySyft/pull/2982) that removes both of these classes. I'll leave this issue open until that PR gets merged, but probably not worth trying to fix the issue as described."	2	2019-12-05 03:18:28	2020-04-21 05:33:57	2020-04-21 05:33:57
https://github.com/OpenMined/PySyft/issues/2725	['bug ', 'status: stale :bread:']	Parameter update error using set_() in Encrypted Gradient Aggregation	"Parameter update error using set_() in Encrypted Gradient AggregationHi,
I've got a question concerning the tutorial 10 ""Federated Learning with Encrypted Gradient Aggregation"".

I followed the instructions of this tutorial to use this technology and adapted it to my image classification task, but I've encountered some problems.

The first iteration of the ""main loop"" (following the exact code from the tutorial) in the train function `for data_index in range(len(remote_dataset[0])-1):` works fine, iterating through the first batch of data of both `alice` and `bob`.

However, the second iteration of this loop, which should process the second batches throws an exception. In detail, it does so on the first try of updating his model at the `pred = model(data)` step, specifically at the first convolutional layer of my NN. 

The error which gets thrown is ""weight should have at least three dimensions"" - which is quite interesting, because it always works fine on the first iteration of `alice` and `bob` data. 

The following is my quite basic neural net.
```
    def forward(self, x):
        x = F.relu(self.conv0(x))
        x = self.pool(F.relu(self.conv1(x)))
        x = F.relu(self.conv2(x))
        x = self.pool(F.relu(self.conv3(x)))
        x = self.dropout(x)
        x = x.view(-1, 256*4*4)
        x = self.fc0(x)
        x = self.dropout(x)
        x = self.fc1(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```

Does someone have an idea why this happens?

OS: Windows 10
Python: 3.7
torch: 1.1.0
syft: 0.1.28a1

The following is the whole error:

```
---------------------------------------------------------------------------
PureFrameworkTensorFoundError             Traceback (most recent call last)
c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    286             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
--> 287                 cmd, args, kwargs, return_args_type=True
    288             )

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in unwrap_args_from_function(attr, args, kwargs, return_args_type)
    165         # Try running it
--> 166         new_args = hook_args(args)
    167 

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in <lambda>(x)
    358 
--> 359     return lambda x: f(lambdas, x)
    360 

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in seven_fold(lambdas, args, **kwargs)
    573     return (
--> 574         lambdas[0](args[0], **kwargs),
    575         lambdas[1](args[1], **kwargs),

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in <lambda>(i)
    336         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 337         else lambda i: forward_func[type(i)](i)
    338         for a, r in zip(args, rules)  # And do this for all the args / rules provided

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\hook\hook_args.py in <lambda>(i)
     20     if hasattr(i, ""child"")
---> 21     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     22     torch.nn.Parameter: lambda i: i.child

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\hook\hook_args.py in <genexpr>(.0)
     20     if hasattr(i, ""child"")
---> 21     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     22     torch.nn.Parameter: lambda i: i.child

PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-12-69ad3b15b6dc> in <module>
      2 for epoch in range(1, 201):
      3     print(f""Epoch {epoch}"")
----> 4     trainSMPC(epoch)
      5     test()

<ipython-input-10-9fd0824454ee> in trainSMPC(epoch)
      6             print(data)
      7             print(target)
----> 8             models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])
      9 
     10         print(""aggregation"")

<ipython-input-9-c309a36730fe> in update(data, target, model, optimizer)
     19     model.send(data.location)
     20     optimizer.zero_grad()
---> 21     pred = model(data)
     22     loss = F.cross_entropy(pred, target)
     23     loss.backward()

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-8-0497bcc9c994> in forward(self, x)
     19     def forward(self, x):
     20         print(x.shape)
---> 21         x = F.relu(self.conv0(x))
     22         x = self.pool(F.relu(self.conv1(x)))
     23         x = F.relu(self.conv2(x))

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\torch\nn\modules\conv.py in forward(self, input)
    336                             _pair(0), self.dilation, self.groups)
    337 
--> 338         return F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)
    339 
    340 

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook.py in overloaded_func(*args, **kwargs)
    426                 handle_func_command = syft.framework.Tensor.handle_func_command
    427 
--> 428             response = handle_func_command(command)
    429 
    430             return response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    295             new_command = (cmd, None, new_args, new_kwargs)
    296             # Send it to the appropriate class and get the response
--> 297             response = new_type.handle_func_command(new_command)
    298             # Put back the wrappers where needed
    299             response = hook_args.hook_response(cmd, response, wrap_type=args_type)

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\pointers\object_pointer.py in handle_func_command(cls, command)
     87 
     88         # Send the command
---> 89         response = owner.send_command(location, command)
     90 
     91         return response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in send_command(self, recipient, message, return_ids)
    485 
    486         try:
--> 487             ret_val = self.send_msg(Operation(message, return_ids), location=recipient)
    488         except ResponseSignatureError as e:
    489             ret_val = None

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in send_msg(self, message, location)
    256 
    257         # Step 2: send the message and wait for a response
--> 258         bin_response = self._send_msg(bin_message, location)
    259 
    260         # Step 3: deserialize the response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\virtual.py in _send_msg(self, message, location)
      5 class VirtualWorker(BaseWorker, FederatedClient):
      6     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 7         return location._recv_msg(message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\virtual.py in _recv_msg(self, message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:
---> 10         return self.recv_msg(message)

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in recv_msg(self, bin_message)
    290             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    291         # Step 1: route message to appropriate function
--> 292         response = self._message_router[msg_type](contents)
    293 
    294         # Step 2: Serialize the message to simple python objects

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in execute_command(self, message)
    430                 command = getattr(command, path)
    431 
--> 432             response = command(*args, **kwargs)
    433 
    434         # some functions don't return anything (such as .backward())

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook.py in overloaded_func(*args, **kwargs)
    426                 handle_func_command = syft.framework.Tensor.handle_func_command
    427 
--> 428             response = handle_func_command(command)
    429 
    430             return response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    319             # in the execute_command function
    320             if isinstance(args, tuple):
--> 321                 response = eval(cmd)(*args, **kwargs)
    322             else:
    323                 response = eval(cmd)(args, **kwargs)

RuntimeError: weight should have at least three dimensions
```It turns out that the models are not correctly updated, even if 
```
for remote_index in range(len(compute_nodes)):
        for param_index in range(len(params[remote_index])):
            params[remote_index][param_index].set_(new_params[param_index])
```
is correctly called.

Following tutorial 10, the `params` list is updated, but the update of these values are not updated neither in `alices_model.parameters()` nor `bobs_model.parameters()`.

Unfortunately, I don't know how to fix this

I've updated pytorch to 1.3.0 and pysyft to 0.2.0a2, and by rerunning the notebooks I now receive the same error as issue #2634 #issuecomment-546368259 

Fix see #2634 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	3	2019-11-08 18:30:09	2020-05-24 00:08:23	2020-05-24 00:08:23
https://github.com/OpenMined/PySyft/issues/2715	['bug ', 'status: stale :bread:']	WebsocketClientWorker:  TimeoutError:Connection timed out	"WebsocketClientWorker:  TimeoutError:Connection timed outI use ""python run_websocket_server.py --port 8780 --id bob --host 10.0.0.5"" on my Mac to run the run_websocket_server.py under the examples/tutorials/advanced/websockets-example-MNIST-parallel folder. And I want to connect it with Linux server. I import packages and run the following codes in ipython.
hook = sy.TorchHook(torch)
kwargs_websocket = {""host"": ""10.0.0.5"", ""hook"": hook, ""verbose"": False}
bob = WebsocketClientWorker(id=""bob"", port=8780, **kwargs_websocket)
But it reports an error--TimeoutError: [Errno 110] Connection timed out
How could I solve this problem?
If possible, could you write a detailed document that implements federated learning on different computer devices? I sincerely hope there can be an example realized by different computers, but not all servers in one computer.Hi, does it work in local mode? (connected through the localhost)

Also, cross device computation will increasingly handled in PyGrid 
https://github.com/OpenMined/PyGridIf both servers' ""host"" are ""localhost"", it is OKInteresting! So yes I _think_ Websocket with PySyft currently only work in local networks. You need to use PyGrid across devices, but maybe the PyGrid team can confirmOK, thank youThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	5	2019-11-04 12:20:20	2020-05-24 00:08:31	2020-05-24 00:08:31
https://github.com/OpenMined/PySyft/issues/2682	[]	Plans Notebook is Broken	"Plans Notebook is Broken**Describe the bug**
When I try to create a neural network plan, I get an error.

**To Reproduce**
Steps to reproduce the behavior:
Run this notebook: https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2008%20-%20Introduction%20to%20Plans.ipynb

and you'll see:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-15-1df7f0407b15> in <module>()
----> 1 net = Net()

<ipython-input-14-87940bb14ced> in __init__(self)
      5         self.fc2 = nn.Linear(3, 2)
      6 
----> 7         self.add_to_state('fc1', 'fc2')
      8 
      9     def forward(self, x):

AttributeError: 'Net' object has no attribute 'add_to_state'
```

**Desktop (please complete the following information):**
 - OS: OSX 10.14.6
 - Version 0.1.29a1

**Additional context**
Add any other context about the problem here.
Fixed by https://github.com/OpenMined/PySyft/pull/2671"	1	2019-10-19 17:36:05	2019-10-21 11:29:25	2019-10-21 11:29:25
https://github.com/OpenMined/PySyft/issues/2669	[]	Send tensor to worker bug	"Send tensor to worker bug**Describe the bug**
If you send a tensor to a worker and you don't save the apprioriate pointer, you get an empty response list using the search functionality.

**To Reproduce**
Steps to reproduce the behavior:

`import torch as th`
`import syft as sy`

`hook = sy.TorchHook(th)`

`bob=sy.VirtualWorker(hook, id=""bob"")`

`x = th.tensor([1, 2, 3]).tag('#dataset')`
`x.send(bob)`
`results = bob.search(['#dataset'])`
`pointer = results[0]`
`print(pointer)`

**Expected behavior**
Results list shouldn't be empty.

Server traceback:

`IndexError                                Traceback (most recent call last)`
`<ipython-input-2-33a97d2ca3b1> in <module>`
`      9 x.send(bob)`
`     10 results = bob.search(['#dataset'])`
`---> 11 pointer = results[0]`
`     12 print(pointer)`

`IndexError: list index out of range`

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Python Version: 3.7.4
 - PyTorch Version: 1.1.0 
 - PySyft Version: 0.1.29a1

**Additional context**
Using `x_ptr = x.send(bob)` instead of `x.send(bob)` works fine.
@luggi961 I tried to reproduce it, but it seems it got fixed.
Could you also retest it on the latest version?`send` is not inplace, you need to do: `p = x.send(bob)` instead of `x.send(bob)`"	2	2019-10-17 07:20:37	2019-11-13 00:37:36	2019-11-13 00:37:36
https://github.com/OpenMined/PySyft/issues/2631	['bug ']	MPC not working with more than or equal to 3 workers	"MPC not working with more than or equal to 3 workersI tried training a model using MPC, using 2 workers was successful. (A minor issue I noticed when using refresh() in computing loss, the loss values are good, otherwise it's computes big large values, which is not interpretable, any clue why this happens can be great to my research.)
Anyways but when using 3 or more workers, I'm facing errors.
First I got error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-902fb9b77716> in <module>
     12 x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
     13 m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
---> 14 o=m(x)

/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)
     90     @weak_script_method
     91     def forward(self, input):
---> 92         return F.linear(input, self.weight, self.bias)
     93 
     94     def extra_repr(self):

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    745                 handle_func_command = TorchTensor.handle_func_command
    746 
--> 747             response = handle_func_command(command)
    748 
    749             return response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    310             new_command = (cmd, None, new_args, new_kwargs)
    311             # Send it to the appropriate class and get the response
--> 312             response = new_type.handle_func_command(new_command)
    313             # Put back the wrappers where needed
    314             response = syft.frameworks.torch.hook_args.hook_response(

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in handle_func_command(cls, command)
    236             # Try to get recursively the attributes in cmd = ""<attr1>.<attr2>.<attr3>...""
    237             cmd = cls.rgetattr(cls, cmd)
--> 238             return cmd(*args, **kwargs)
    239         except AttributeError:
    240             pass

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in linear(*args)
    201                     Un-hook the function to have its detailed behaviour
    202                     """"""
--> 203                     return torch.nn.functional.native_linear(*args)
    204 
    205                 module.linear = linear

/usr/local/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)
   1406         ret = torch.addmm(bias, input, weight.t())
   1407     else:
-> 1408         output = input.matmul(weight.t())
   1409         if bias is not None:
   1410             output += bias

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in method_with_grad(*args, **kwargs)
    138                 )
    139 
--> 140                 result = getattr(new_self, name)(*new_args, **new_kwargs)
    141 
    142                 # Put back SyftTensor on the tensors found in the response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py in matmul(self, *args, **kwargs)
    414 
    415         # Send it to the appropriate class and get the response
--> 416         response = getattr(new_self, ""matmul"")(*new_args, **new_kwargs)
    417 
    418         # Put back SyftTensor on the tensors found in the response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in matmul(self, other)
    515             return self._public_mul(other, ""matmul"")
    516 
--> 517         return self._private_mul(other, ""matmul"")
    518 
    519     def mm(self, *args, **kwargs):

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in _private_mul(self, other, equation)
    413             raise AttributeError(""For multiplication a crypto_provider must be passed."")
    414 
--> 415         shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field)
    416 
    417         return shares

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/crypto/spdz.py in spdz_mul(cmd, x_sh, y_sh, crypto_provider, field)
     43         j = sy.MultiPointerTensor(children=[j1, j0])
     44     else:
---> 45         j = sy.MultiPointerTensor(children=[j1] + j0.child.values())
     46 
     47     delta_b = cmd(delta, b)

TypeError: can only concatenate list (not ""dict_values"") to list
```

I tried cloning the repo, fixing this issue by passing  `j0.child.values()` to list constructor. Then I faced another error:

```

Traceback (most recent call last):
   <ipython-input-7-902fb9b77716> in <module>
     o=m(x)
   File ""/Users/sandeep/syft/venv/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
     result = self.forward(*input, **kwargs)
   File ""a3.py"", line 31, in forward
     x=F.relu(self.fc1(x))
   File ""/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py"", line 413, in overloaded_func
     response = handle_func_command(command)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/native.py"", line 297, in handle_func_command
     response = new_type.handle_func_command(new_command)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 237, in handle_func_command
     return cmd(*args, **kwargs)
  File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 207, in relu
     return tensor.relu()
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 141, in method_with_grad
     result = getattr(new_self, name)(*new_args, **new_kwargs)
   File ""/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py"", line 306, in overloaded_syft_method
     response = getattr(new_self, attr)(*new_args, **new_kwargs)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 793, in relu
     return securenn.relu(self)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/crypto/securenn.py"", line 427, in relu
     alice, bob = a_sh.locations
ValueError: too many values to unpack (expected 2)
```

**To Reproduce**
Run this to reproduce:
```
def connect_to_workers(n_workers):
    return [
        sy.VirtualWorker(hook, id=f""worker{i+1}"")
        for i in range(n_workers)
    ]
def connect_to_crypto_provider():
    return sy.VirtualWorker(hook, id=""crypto_provider"")

workers = connect_to_workers(n_workers=3)
sw = connect_to_crypto_provider()

x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
o=m(x)
```

**Desktop (please complete the following information):**
 - OS: MacOS
 - Version 10.14.6
I'm having the same issue. I know this is a bit old but have you found a solution for this? (Not necessarily using PySyft, but on any Federated Learning solution)"	1	2019-09-27 10:45:27	2020-05-08 01:26:04	2020-05-08 01:26:04
https://github.com/OpenMined/PySyft/issues/2618	[]	Why does Input to Model requires gradient when using Secure MPC.	"Why does Input to Model requires gradient when using Secure MPC.**Describe the bug**
When we share the model and data to different virtual workers, then obviously it's the Model whose requires_grad should be True and data's requires_grad should be False, but when I pass this data which doesn't requires gradient to the model, I get following error:
""RuntimeError: bool value of Tensor with more than one value is ambiguous""

While when set requires_grad True for Data as well, then it works perfectly fine.  But when doing this, I get model gradients as None after backward

**To Reproduce**

```
import torch as th
import torch.nn.functional as F
import syft as sy
import random
import numpy as np

hook = sy.TorchHook(th)

bob=sy.VirtualWorker(hook, id=""bob"")
alice=sy.VirtualWorker(hook, id=""alice"")
sw=sy.VirtualWorker(hook, id=""SecureWorker"")

bob.clear_objects()
alice.clear_objects()
sw.clear_objects()

bob.add_workers([alice, sw])
alice.add_workers([bob, sw])
sw.add_workers([alice, bob])

x = th.tensor([[0,0], [0,1], [1,0], [1,1]]).to(th.float)
y = th.tensor([0,0,1,1]).to(th.float)

model=th.nn.Linear(2,1)

#print(list(model.parameters()))
enc_model = model.fix_precision().share(alice, bob, crypto_provider=sw, requires_grad=True)
optimizer = th.optim.SGD(enc_model.parameters(), lr=0.1)
optimizer = optimizer.fix_precision()

enc_data = x.fix_precision().share(alice, bob, crypto_provider=sw)
enc_target = y.fix_precision().share(alice, bob, crypto_provider=sw)

max_epochs=1
for i in range(max_epochs):
    optimizer.zero_grad()
    enc_pred = enc_model(enc_data).squeeze(1)
    l = (((enc_pred - enc_target) ** 2)).sum().refresh()
    l.backward()
    optimizer.step()
    l = l.get().float_precision()
    print(l.item())

model = enc_model.get().float_precision()
for params in model.parameters():
    print(params.grad)
print(enc_pred.get().float_precision())
```


Just run above code to reproduce error. Add ```requires_grad=True``` to enc_data and enc_target, to reproduce other error.

Please fix this.
Thanks.Hey, thanks for your feedback.
> While when set requires_grad True for Data as well, then it works perfectly fine. But when doing this, I get model gradients as None after backward

This is a bug related to `.squeeze(1)`. Remove this and you will get the gradient. I opened an Issue #2621 

> When we share the model and data to different virtual workers, then obviously it's the Model whose requires_grad should be True and data's requires_grad should be False

You're 100% right. However, if you know about PySyft, you know it relies chain of tensors like `Parameter>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]...`. We currently hardly handle operating tensors with different chain structure, and in particular we don't support currently operating tensors with autograd and some who don't have them, that's why we asked `require_grad=True` for every tensor. But I'll report this as an issue and we'll try to have a better support. #2622 Okay. Thanks. I'll close this then."	2	2019-09-17 11:31:44	2019-09-27 10:11:57	2019-09-27 10:10:55
https://github.com/OpenMined/PySyft/issues/2615	[]	method2plan is not supported anymore error in Introduction to plan part 08	"method2plan is not supported anymore error in Introduction to plan part 08in Introduction to plan part 08 there is method2plan but it is not supported anymore

**To Reproduce**
Steps to reproduce the behavior:
Run 14th code cell in the tutorial

I was working on google colabHey,
The tutorial has been updated, you should update your repo :)
https://github.com/OpenMined/PySyft/pull/2569/commits/36330ab3a7df7c874819b320071e3dc2a7252b4d"	1	2019-09-13 14:45:07	2019-09-22 13:27:45	2019-09-22 13:27:45
https://github.com/OpenMined/PySyft/issues/2609	['bug ', 'status: stale :bread:']	Grid search test breaks if we wrap the search results.	"Grid search test breaks if we wrap the search results.**Describe the bug**

Grid search test breaks if we wrap the search results.

https://github.com/OpenMined/PySyft/blob/dev/syft/workers/base.py#L890

Do we really need to wrap the search results?

I think I know what the problem is, when we wrap the pointer we register it on `._objects` but we're running a loop on the keys in _objects so then we get: “RuntimeError: dictionary changed size during iteration”
@LaRiffle This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2019-09-10 22:38:47	2020-05-24 00:08:53	2020-05-24 00:08:53
https://github.com/OpenMined/PySyft/issues/2607	[]	TypeError: object of type 'NoneType' has no len()	"TypeError: object of type 'NoneType' has no len()**Describe the bug**
TypeError: object of type 'NoneType' has no len()

**My code**
```python
x_train = torch.tensor(train_x)
y_train = torch.tensor(train_y)

import syft as sy
# Hook that extends the Pytorch library to enable all computations with pointers of tensors sent to other workers
hook = sy.TorchHook(torch)

# Creating 2 virtual workers
bob = sy.VirtualWorker(hook, id=""bob"")
anne = sy.VirtualWorker(hook, id=""anne"")
#datasets=[]
# threshold indexes for dataset split (one half for Bob, other half for Anne)
train_idx = int(len(x_train)/2)


# Sending toy datasets to virtual workers
#data_bob = x_train[:train_idx].send(bob)
#data_anne = x_train[train_idx:].send(anne)
#target_bob = y_train[:train_idx].send(bob)
#target_anne = y_train[train_idx:].send(anne)

#bob_train_dataset = sy.BaseDataset(data_bob , target_bob).send(bob)
#anne_train_dataset = sy.BaseDataset(data_anne, target_anne).send(anne)

#datasets = [(data_bob,target_bob),(data_anne,target_anne)]
#federated_train_dataset = sy.FederatedDataset([(data_bob,target_bob), (data_anne, target_anne)])
#bob_train_dataset = sy.BaseDataset(data_bob, target_bob).send(bob)
#anne_train_dataset = sy.BaseDataset(data_anne, target_anne).send(anne)
# Creating federated datasets, an extension of Pytorch TensorDataset class
#federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])


# Creating federated dataloaders, an extension of Pytorch DataLoader class
#federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=64)


# Hook that extends the Pytorch library to enable all computations with pointers of tensors sent to other workers
#hook = sy.TorchHook(torch)

# Creating 2 virtual workers
#bob = sy.VirtualWorker(hook, id=""bob"")
#anne = sy.VirtualWorker(hook, id=""anne"")

# threshold indexes for dataset split (one half for Bob, other half for Anne)
#train_idx = int(len(train_labels)/2)

# Sending toy datasets to virtual workers
bob_train_dataset = sy.BaseDataset(x_train[:train_idx], y_train[:train_idx]).send(bob)
anne_train_dataset = sy.BaseDataset(x_train[train_idx:], y_train[train_idx:]).send(anne)

# Creating federated datasets, an extension of Pytorch TensorDataset class
federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])
# Creating federated dataloaders, an extension of Pytorch DataLoader class
federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=64)

class GRUNet(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):
        super(GRUNet, self).__init__()
        self.hidden_dim = hidden_dim
        self.n_layers = n_layers
        
        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
        
    def forward(self, x, h):
        out, h = self.gru(x, h)
        out = self.fc(self.relu(out[:,-1]))
        return out, h
    
    def init_hidden(self, batch_size):
        weight = next(self.parameters()).data
        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)
        return hidden

class LSTMNet(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):
        super(LSTMNet, self).__init__()
        self.hidden_dim = hidden_dim
        self.n_layers = n_layers
        
        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
        
    def forward(self, x, h):
        out, h = self.lstm(x, h)
        out = self.fc(self.relu(out[:,-1]))
        return out, h
    
    def init_hidden(self, batch_size):
        weight = next(self.parameters()).data
        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),
                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))
        return hidden

batch_size = 64
def train(federated_train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=""GRU""):
    
    # Setting common hyperparameters
    input_dim = next(iter(federated_train_loader))[0].shape[2]
    output_dim = 1
    n_layers = 2
    # Instantiating the models
    if model_type == ""GRU"":
        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)
    else:
        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)
    model.to(device)
    
    # Defining loss function and optimizer
    criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)
    
    model.train()
    print(""Starting Training of {} model"".format(model_type))
    epoch_times = []
    # Start training loop
    for epoch in range(1,EPOCHS+1):
        start_time = time.clock()
        h = model.init_hidden(batch_size)
        avg_loss = 0.
        counter = 0
        for x, label in federated_train_loader:
            worker = x.location
            #h = torch.Tensor(np.zeros((batch_size))).send(worker)
            model.send(worker)
            counter += 1
            if model_type == ""GRU"":
                h = h.data
            else:
                h = tuple([e.data for e in h])
            model.zero_grad()
           
            
            out, h = model(x.to(device).float(), h)
            loss = criterion(out, label.to(device).float())
            loss.backward()
            optimizer.step()
            avg_loss += loss.item()
            if counter%200 == 0:
                print(""Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}"".format(epoch, counter, len(train_loader), avg_loss/counter))
        current_time = time.clock()
        print(""Epoch {}/{} Done, Total Loss: {}"".format(epoch, EPOCHS, avg_loss/len(train_loader)))
        print(""Time Elapsed for Epoch: {} seconds"".format(str(current_time-start_time)))
        epoch_times.append(current_time-start_time)
    print(""Total Training Time: {} seconds"".format(str(sum(epoch_times))))
    return model
```
**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version : 16.04

**Additional context**
Starting Training of GRU model

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-37-6d641218ab70> in <module>()
      1 lr = 0.001
      2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

<ipython-input-36-ba6a40ede7c3> in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
     38 
     39 
---> 40             out, h = model(x.to(device).float(), h)
     41             loss = criterion(out, label.to(device).float())
     42             loss.backward()

Actually, I do not know what happen on my dataset?
Why my data is Nonetype?When using `model.to(device)` you are trying to move your data structure to a GPU, right? Well, as far as I know, this operation is not supported in PySyft yet. Keep the computation on the CPU for now.> When using `model.to(device)` you are trying to move your data structure to a GPU, right? Well, as far as I know, this operation is not supported in PySyft yet. Keep the computation on the CPU for now.

Thanks for your reply. I solved my previous problem because the version of PySyft was too old. Now there is a new bug.
RuntimeError                              Traceback (most recent call last)
<ipython-input-62-6d641218ab70> in <module>()
      1 lr = 0.001
      2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

<ipython-input-61-0ac6d91a093c> in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
     48             print(x.shape)
     49             print(label.shape)
---> 50             out, h = model(x, h)
     51             loss = criterion(out, label.float())
     52             loss.backward()

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-54-a172098b1c99> in forward(self, x, h)
     10 
     11     def forward(self, x, h):
---> 12         out, h = self.gru(x, h)
     13         out = self.fc(self.relu(out[:,-1]))
     14         return out, h

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
    205             hx = self.permute_hidden(hx, sorted_indices)
    206 
--> 207         self.check_forward_args(input, hx, batch_sizes)
    208         _impl = _rnn_impls[self.mode]
    209         if batch_sizes is None:

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
    173 
    174     def check_forward_args(self, input, hidden, batch_sizes):
--> 175         self.check_input(input, batch_sizes)
    176         expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
    177 

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
    151             raise RuntimeError(
    152                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--> 153                     self.input_size, input.size(-1)))
    154 
    155     @weak_script_method

RuntimeError: input.size(-1) must be equal to input_size. Expected 5, got 0Can you please show me how the `device` variable is defined?

Also, you may want to try your code without the `.to(device)` call in your code.> Can you please show me how the `device` variable is defined?
> 
> Also, you may want to try your code without the `.to(device)` call in your code.
```python
# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False
is_cuda = torch.cuda.is_available()

# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.
if is_cuda:
    device = torch.device(""cuda"")
else:
    device = torch.device(""cpu"")
```Yes, that's exactly what I meant. PySyft does not support CUDA GPUs yet, though we'd like to support this functionality in the future @robert-wagner 

What is the result of running your code when removing all statements `.to(device)` @niklausliu ?> Yes, that's exactly what I meant. PySyft does not support CUDA GPUs yet, though we'd like to support this functionality in the future @robert-wagner
> 
> What is the result of running your code when removing all statements `.to(device)` @niklausliu ?

Thanks for your reply. But I have a new bug about rnn.py, you can see more detail as follow:

RuntimeError Traceback (most recent call last)
in ()
1 lr = 0.001
2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
48 print(x.shape)
49 print(label.shape)
---> 50 out, h = model(x, h)
51 loss = criterion(out, label.float())
52 loss.backward()

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)
491 result = self._slow_forward(*input, **kwargs)
492 else:
--> 493 result = self.forward(*input, **kwargs)
494 for hook in self._forward_hooks.values():
495 hook_result = hook(self, input, result)

in forward(self, x, h)
10
11 def forward(self, x, h):
---> 12 out, h = self.gru(x, h)
13 out = self.fc(self.relu(out[:,-1]))
14 return out, h

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)
491 result = self._slow_forward(*input, **kwargs)
492 else:
--> 493 result = self.forward(*input, **kwargs)
494 for hook in self._forward_hooks.values():
495 hook_result = hook(self, input, result)

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
205 hx = self.permute_hidden(hx, sorted_indices)
206
--> 207 self.check_forward_args(input, hx, batch_sizes)
208 _impl = _rnn_impls[self.mode]
209 if batch_sizes is None:

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
173
174 def check_forward_args(self, input, hidden, batch_sizes):
--> 175 self.check_input(input, batch_sizes)
176 expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
177

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
151 raise RuntimeError(
152 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--> 153 self.input_size, input.size(-1)))
154
155 @weak_script_method

RuntimeError: input.size(-1) must be equal to input_size. Expected 5, got 0Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.

Alternatively, @andrelmfarias  could have some other ideas?

Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?> Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.
> 
> Alternatively, @andrelmfarias could have some other ideas?
> 
> Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?

But I found that I deleted all the statements about the device or the bug I described above.> > Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.
> > Alternatively, @andrelmfarias could have some other ideas?
> > Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?
> 
> But I found that I deleted all the statements about the device or the bug I described above.

Sorry, I mean, I deleted all the statements about the device, but it did not work and the bug still exists.Can you please print the output you get from your dataset before and after hooking torch?> Can you please print the output you get from your dataset before and after hooking torch?
![image](https://user-images.githubusercontent.com/31737021/64689120-4781a980-d4c0-11e9-95d4-6ea294a36e95.png)

![image](https://user-images.githubusercontent.com/31737021/64689149-5cf6d380-d4c0-11e9-94f4-75359fe1e289.png)

![image](https://user-images.githubusercontent.com/31737021/64689251-929bbc80-d4c0-11e9-9a5b-737aba54f4d9.png)

![image](https://user-images.githubusercontent.com/31737021/64689279-9cbdbb00-d4c0-11e9-9966-108178b67676.png)
> Can you please print the output you get from your dataset before and after hooking torch?

![image](https://user-images.githubusercontent.com/31737021/64689389-db537580-d4c0-11e9-8718-1e374d581df4.png)
@niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.

Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

But I have seen many examples of syft GRUs module and have not found any difference with my pytorch native GRUs. Can you give me a few examples of the syft GRUs module?
> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

And I can not find syft.framworks.torch.nn in this website https://pysyft.readthedocs.io/en/latest/modules/syft.core.frameworks.html They were recently added to pysyft, so they are not included in the main documentation yet.

You can take a look at the modules here:
https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/nn/rnn.py

But in fact, they work exactly as PyTorch API (same args, etc.) you just need to import them from `syft.frameworks.torch.nn` (eg: `from syft.frameworks.torch.nn import GRU, LSTM, RNN` ) and manage them the same way you would manage a pytorch GRU> They were recently added to pysyft, so they are not included in the main documentation yet.
> 
> You can take a look at the modules here:
> https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/nn/rnn.py
> 
> But in fact, they work exactly as PyTorch API (same args, etc.) you just need to import them from `syft.frameworks.torch.nn` (eg: `from syft.frameworks.torch.nn import GRU, LSTM, RNN` ) and manage them the same way you would manage a pytorch GRU

Thanks for your help. I will adjust my code again and I will tell you any updates. Thank you again for your help.> Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.

@niklausliu - **We're happy to help in the OpenMined community.**  But as a general rule, we're not tech support.  While you may have a problem running PySyft, and there may be a legitimate issue here, **everyone** who works on the OpenMined project works for free.  If we spent all of our time fixing people's implementations of PySyft, we'd never have time to write code for PySyft itself. 
 Either way, providing our personal email addresses so that you can ping us questions is not acceptable.

I'm going to close this issue for now as it seems that problem you're now having is totally unrelated to the original issue.  If that's not the case, please send me a message on Slack and I'll be happy to re-open the issue.> > Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.
> 
> @niklausliu - **We're happy to help in the OpenMined community.** But as a general rule, we're not tech support. While you may have a problem running PySyft, and there may be a legitimate issue here, **everyone** who works on the OpenMined project works for free. If we spent all of our time fixing people's implementations of PySyft, we'd never have time to write code for PySyft itself.
> Either way, providing our personal email addresses so that you can ping us questions is not acceptable.
> 
> I'm going to close this issue for now as it seems that problem you're now having is totally unrelated to the original issue. If that's not the case, please send me a message on Slack and I'll be happy to re-open the issue.

I am sorry for my impoliteness. However, I did not ask OpenMined workers to provide me with free technical support. It may be that there is a problem with my expression. I apologize again for this. I really appreciate the efforts of the OpenMined workers for the PySyft project, and I hope to contribute to the community as a whole.Not a problem @niklausliu!  We're happy to have people passionate about the project like yourself.  It seems this particular issue has gotten off-topic.  I'd suggest you post your questions in the #team_pysyft channel on Slack and give 1-2 days for someone to reply.  If not, submit a new issue here.> Not a problem @niklausliu! We're happy to have people passionate about the project like yourself. It seems this particular issue has gotten off-topic. I'd suggest you post your questions in the #team_pysyft channel on Slack and give 1-2 days for someone to reply. If not, submit a new issue here.

OK, I got it! Thank you for your help!!!"	23	2019-09-10 14:37:18	2019-09-11 15:30:21	2019-09-11 14:53:48
https://github.com/OpenMined/PySyft/issues/2587	[]	MNIST example using PySyft	"MNIST example using PySyft**Describe the bug**
I made a code snippet for MNIST example using PySyft based on the tutorial:
```python
from __future__ import print_function                                                                                                                                                                                                                                                                                                                                                                                                                                                          
import argparse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
from tqdm import tqdm                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
import torch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
import torch.nn as nn                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
import torch.nn.functional as F                                                                                                                                                                                                                                                                                                                                                                                                                                                                
import torch.optim as optim                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
from torchvision import datasets, transforms                                                                                                                                                                                                                                                                                                                                                                                                                                                   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
import syft as sy                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
from torch.multiprocessing import set_start_method                                                                                                                                                                                                                                                                                                                                                                                                                                             
try:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
     set_start_method('forkserver')                                                                                                                                                                                                                                                                                                                                                                                                                                                            
except RuntimeError:                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
    pass                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
class Net(nn.Module):                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
    def __init__(self):                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
        super(Net, self).__init__()                                                                                                                                                                                                                                                                                                                                                                                                                                                            
        self.conv1 = nn.Conv2d(1, 20, 5, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                    
        self.conv2 = nn.Conv2d(20, 50, 5, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                   
        self.fc1 = nn.Linear(4*4*50, 500)                                                                                                                                                                                                                                                                                                                                                                                                                                                      
        self.fc2 = nn.Linear(500, 10)                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
    def forward(self, x):                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
        x = F.relu(self.conv1(x))                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = F.max_pool2d(x, 2, 2)                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = F.relu(self.conv2(x))                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = F.max_pool2d(x, 2, 2)                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = x.view(-1, 4*4*50)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
        x = F.relu(self.fc1(x))                                                                                                                                                                                                                                                                                                                                                                                                                                                                
        x = self.fc2(x)                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
        return F.log_softmax(x, dim=1)                                                                                                                                                                                                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
def train(args, model, device, train_loader, optimizer, epoch):                                                                                                                                                                                                                                                                                                                                                                                                                                
    model.train()                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
    with tqdm(enumerate(train_loader), total=len(train_loader), desc=""epoch {:02d}"".format(epoch)) as t:                                                                                                                                                                                                                                                                                                                                                                                       
        for batch_idx, (data, target) in t:                                                                                                                                                                                                                                                                                                                                                                                                                                                    
            model.send(data.location)                                                                                                                                                                                                                                                                                                                                                                                                                                                          
            data, target = data.to(device), target.to(device)                                                                                                                                                                                                                                                                                                                                                                                                                                  
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
            optimizer.zero_grad()                                                                                                                                                                                                                                                                                                                                                                                                                                                              
            output = model(data)                                                                                                                                                                                                                                                                                                                                                                                                                                                               
            loss = F.nll_loss(output, target)                                                                                                                                                                                                                                                                                                                                                                                                                                                  
            loss.backward()                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
            optimizer.step()                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
            model.get()                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
    #if batch_idx % args.log_interval == 0:                                                                                                                                                                                                                                                                                                                                                                                                                                                    
    loss = loss.get() # <-- NEW: get the loss back                                                                                                                                                                                                                                                                                                                                                                                                                                             
    print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(                                                                                                                                                                                                                                                                                                                                                                                                                            
        epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size,                                                                                                                                                                                                                                                                                                                                                                                                               
        100. * batch_idx / len(train_loader), loss.item()))                                                                                                                                                                                                                                                                                                                                                                                                                                    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
def test(args, model, device, test_loader):                                                                                                                                                                                                                                                                                                                                                                                                                                                    
    model.eval()                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
    test_loss = 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
    correct = 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
    with torch.no_grad():                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
        for data, target in test_loader:                                                                                                                                                                                                                                                                                                                                                                                                                                                       
            data, target = data.to(device), target.to(device)
            output = model(data)

            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss
            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))


def main():
    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch + PySyft MNIST Example')
    parser.add_argument('--batch-size', type=int, default=256, metavar='N',
                        help='input batch size for training (default: 256)')
    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=100, metavar='N',
                        help='number of epochs to train (default: 100)')
    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
                        help='learning rate (default: 0.01)')
    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
                        help='SGD momentum (default: 0.5)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disable CUDA training')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')
    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
    args = parser.parse_args()

    torch.manual_seed(args.seed)
    #torch.set_default_tensor_type(torch.cuda.FloatTensor)

    use_cuda = not args.no_cuda and torch.cuda.is_available()
    device = torch.device(""cuda"" if use_cuda else ""cpu"")

    hook = sy.TorchHook(torch)

    bob = sy.VirtualWorker(hook, id=""bob"")
    alice = sy.VirtualWorker(hook, id=""alice"")

    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

    federated_train_loader = sy.FederatedDataLoader(
        datasets.MNIST('../data', train=True, download=True,
            transform=transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])).federate((bob, alice)),
        batch_size=args.batch_size, shuffle=True, **kwargs)

    test_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=False, transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=args.test_batch_size, shuffle=False, **kwargs)

    model = Net().to(device)
    optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment

    for epoch in range(1, args.epochs + 1):
        train(args, model, device, federated_train_loader, optimizer, epoch)
        test(args, model, device, test_loader)

    if (args.save_model):
        torch.save(model.state_dict(), ""mnist_cnn.pt"")


if __name__ == '__main__':
    main()
```
When I got two problems:
1. without `torch.set_default_tensor_type(torch.cuda.FloatTensor)`, it produces a RuntimeError as:
```
Traceback (most recent call last):
  File ""main.py"", line 142, in <module>
    main()
  File ""main.py"", line 130, in main
    model = Net().to(device)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 386, in to
    return self._apply(convert)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 193, in _apply
    module._apply(fn)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 199, in _apply
    param.data = fn(param.data)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py"", line 393, in data
    self.set_(new_data)
RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 'source'
```
2. with the `set_default_tensor_type`, it shows another error as:
```
Traceback (most recent call last):
  File ""main.py"", line 142, in <module>
    main()
  File ""main.py"", line 135, in main
    test(args, model, device, test_loader)
  File ""main.py"", line 65, in test
    for data, target in test_loader:
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 193, in __iter__
    return _DataLoaderIter(self)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 469, in __init__
    w.start()
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py"", line 112, in start
    self._popen = self._Popen(self)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/context.py"", line 291, in _Popen
    return Popen(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/popen_forkserver.py"", line 35, in __init__
    super().__init__(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/popen_fork.py"", line 20, in __init__
    self._launch(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/popen_forkserver.py"", line 47, in _launch
    reduction.dump(process_obj, buf)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/reduction.py"", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed
```

**To Reproduce**
If you have `torch`, `torchvision`, and `pysyft`, just do
```
python main.py
```

**Expected behavior**
Obtain the proper operation without errors

**Screenshots**
None

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version: 18.04
 - Python: 3.7.4

**Additional context**
Add any other context about the problem here.
Hey!
Thanks for thee feedback,
So only CPU is supported currently :/ this explains PB 1
Regarding the 2nd one, which version of PyTorch are you using? I think `multiprocessing` is responsible for the failure, and should be deactivated is this makes senseThanks @LaRiffle ! 
I used PyTorch 1.1.0. but 1.2.0 also shows the same. so could you let me know more clearly how to deactivate the `multiprocessing`?
and what time line you will add GPU support? MNIST is very simple task so it's okay to use CPU, but typically GPU is very critical and inevitable to train a big model and big data.
Try on the latest code of the dev branch. I just tested your code there and it works."	3	2019-09-04 14:46:27	2019-11-18 10:14:40	2019-11-18 10:14:40
https://github.com/OpenMined/PySyft/issues/2576	[]	syft.frameworks.torch.tensors.interpreters.native.Tensor.shape BUG	"syft.frameworks.torch.tensors.interpreters.native.Tensor.shape BUG**Describe the bug**
When attempting to call .shape on a Syft tensor contained in a BaseDataset, it always return torch.Size([0]).

**To Reproduce**
```
t = torch.tensor([1.,2.,3.])
t.shape                         # torch.Size([3])
bds = sy.BaseDataset(t, t)
bds.send(bob)
bds.data.shape                  # expected torch.Size([3]), but got torch.Size([0])
```

**Desktop (please complete the following information):**
 - OS: win10
 - Version: Pytorch 1.1.0, PySyft 0.1.24a1

That's strange, I have torch.Size([3])
Maybe update the syft package and rerun this snippetSolved after bumping up to 0.1.26a1. :)"	2	2019-08-29 10:17:15	2019-09-07 17:53:54	2019-09-07 17:53:54
https://github.com/OpenMined/PySyft/issues/2559	['bug ']	relu and relu_deriv require serializable workers	"relu and relu_deriv require serializable workers**This is a blocker for having [EMLaaS implemented](https://github.com/OpenMined/Grid/issues/203)**.

Relu and relu_derive require serializable workers. Apparently these operations require serializable workers in order to execute `.share` with pointer tensors. GridWorkers are currently not serializable.@iamtrask and @LaRiffle pointed out that serializing workers is not actually a problem since this consists basically of sending the worker id over the wire.

But the problem is that currently only VirtualWorkers are serializable which means that GridWorkers or WebsocketWorkers will not be able to run these operations."	1	2019-08-26 14:35:20	2019-08-29 07:58:54	2019-08-29 07:58:54
https://github.com/OpenMined/PySyft/issues/2556	['bug ']	Argmax on encrypted  data fails	"Argmax on encrypted  data failsThe argmax-call on an encrypted tensor throws an exception. Minimal code example for reproduction:
```
import torch
import syft as sy
hook = sy.TorchHook(torch)

alice = sy.VirtualWorker(hook, 'alice')
bob = sy.VirtualWorker(hook, 'bob')

a = torch.arange(6)
enc_a = a.share(alice, bob)
print(enc_a.argmax())
```
Executing this script results in a `KeyError: 'Object ""44504679185"" not found on worker!!!You just tried to interact with an object ID:44504679185 on <VirtualWorker id:alice #objects:36> which does not exist!!!`

My python environment (Ubuntu 18.04):
torch 1.1.0
syft 0.1.24a1This should work :)
Add a crypto_provider and call fix_precision() 

```python
import torch
import syft as sy
hook = sy.TorchHook(torch)

alice = sy.VirtualWorker(hook, 'alice')
bob = sy.VirtualWorker(hook, 'bob')
crypto_provider = sy.VirtualWorker(hook, 'crypto_provider')

a = torch.arange(6).fix_precision()
enc_a = a.share(alice, bob, crypto_provider=crypto_provider)
print(enc_a.argmax())
```Thank you! I checked that both modifications are necessary to fix the problem.I assumed that I did not need fix precision encoding on an integer tensor. The need for an explicit crypto provider wasn't clear to me either. Could you explain on both?So actually you should have to do it, even if it doesn't raise an error: even if you work with integers, fix precision elements are in a field while integers are not, so it is a  best practice. And actually for some reason it doesn't work if you don't do it (argmax does smthg strange)
Same for crypto provider, it should be possible to not explicitoit,  but it doesn't work for some reason :/"	4	2019-08-26 07:41:36	2019-09-03 17:07:02	2019-09-03 15:24:56
https://github.com/OpenMined/PySyft/issues/2554	['bug ', 'status: stale :bread:', 'status: investigating :mag:']	.federate() does not work with torchvision's ImageFolder dataset	".federate() does not work with torchvision's ImageFolder dataset**Describe the bug**
When you try to federate a `torchvision.datasets.ImageFolder`, you get the custom exception AttributeError(""Could not find inputs in dataset"")

**To Reproduce**
Steps to reproduce the behavior:

1) Have the following file structure locally:
```
+-- dataset
|   +-- class1
|   |   +-- whatever1.jpg
|   |   +-- whatever2.jpg
```
Those jpgs can be any image of at least 256x256 size.

2) Run: 
```
import torch
from torchvision import datasets, transforms
import syft as sy  

hook = sy.TorchHook(torch)  
bob = sy.VirtualWorker(hook, id=""bob"")  
alice = sy.VirtualWorker(hook, id=""alice"")

imagefolder_dataset = datasets.ImageFolder(root='./dataset/', transform = transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor()
    ]))


fed_dataset = imagefolder_dataset.federate((bob, alice)) # Raises exception
```

**Expected behavior**
`fed_dataset` should be created without raising any exception

**Actual behavior**
An exception ""Could not find inputs in dataset"" is raised:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-21c009d642db> in <module>
      7 
----> 8 fed_dataset = imagefolder_dataset.federate((bob, alice))
      9 

c:\...\syft\frameworks\torch\federated\dataset.py in dataset_federate(dataset, workers)
    148             dataset.data = dataset.test_data
    149         else:
--> 150             raise AttributeError(""Could not find inputs in dataset"")
    151     if not hasattr(dataset, ""targets""):
    152         if hasattr(dataset, ""train_labels""):

AttributeError: Could not find inputs in dataset
```

**Desktop (please complete the following information):**
 - OS: Windows 10

**Additional context**
 - torchvision: 0.3.0
 - pytorch: 1.1.0
 - pysyft: 0.1.22a1

**Workaround**
Before calling `.federate()` you can create the following dummy fields to prevent the exception:
`imagefolder_dataset.data = imagefolder_dataset.targets = True`  
Created PR to fix this: https://github.com/OpenMined/PySyft/pull/2555

There is harmful defensive code (that I removed) on `dataset_federate` function. It was checking for the data/train_data/test_data/targets/train_labels/test_labels fields in the dataset in a mandatory way. Which is not needed, and it's causing an exception that shouldn't exist.
What matters is that on each iteration of the dataset, it has to return a tuple in the form (data, target), which ImageFolder complies.
With the fix, `ImageFolder` and other datasets with the same problem now can be federated with `.federate()`

@iamtrask can you please review?@edgarinvillegas are you still working on the PR?Hi,
Is this issue sorted because I'm facing the same on the PyPi version
ThanksHello,
I have a class that inherits the Dataset class, but I can't apply the .federate() method on an instance of this class. Can someone explain why?
Thank you.

class UCI_HAR(Dataset):
    def __init__(self, samples, labels):
        self.samples = samples
        self.labels = labels
        
    def __getitem__(self, index):
        sample, target = self.samples[index], self.labels[index]
        return sample, target

    def __len__(self):
        return len(self.samples)

 Hello @ChedidJM , thank you for reporting this bug,

Could you please provide:
1. full script to reproduce the bug.
2. stack tracke/logging if you have any.
3. OS and syft version.

Thank you!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	6	2019-08-26 00:05:38	2020-07-06 00:08:36	2020-07-06 00:08:36
https://github.com/OpenMined/PySyft/issues/2546	[]	Call fix_precision() on a remote model	"Call fix_precision() on a remote model**Describe the bug**
Call fix_precision() on a remote model fails due to a weird gradient initialization procedure for model parameters (see stacktrace)

**To Reproduce**
```
model = nn.Linear(2, 1)
model.fix_precision()
model.send(charlie)
model.share(alice, charlie, crypto_provider=crypto_provider, requires_grad=True)
model.get()

assert isinstance(model.weight.child, sy.AutogradTensor)
```

**Stack trace context**
```python
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-12-9b6b1f2f50de> in <module>
     25 model = nn.Linear(2, 1)
     26 model.fix_precision()
---> 27 model.send(charlie)
     28 model.share(alice, charlie, crypto_provider=crypto_provider, requires_grad=True)
     29 model.get()

~/code/PySyft/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, force_send, *dest, **kwargs)
    996 
    997             if module_is_missing_grad(nn_self):
--> 998                 create_grad_objects(nn_self)
    999 
   1000             for p in nn_self.parameters():

~/code/PySyft/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    989             for p in model.parameters():
    990                 o = p.sum()
--> 991                 o.backward()
    992                 p.grad -= p.grad
    993 

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    691                 # Send the new command to the appropriate class and get the response
    692                 method = getattr(new_self, method_name)
--> 693                 response = method(*new_args, **new_kwargs)
    694 
    695                 # For inplace methods, just directly return self

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_syft_method(self, *args, **kwargs)
    638 
    639             # Send it to the appropriate class and get the response
--> 640             response = getattr(new_self, attr)(*new_args, **new_kwargs)
    641 
    642             # Put back SyftTensor on the tensors found in the response

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    677                 except BaseException as e:
    678                     # we can make some errors more descriptive with this method
--> 679                     raise route_method_exception(e, self, args, kwargs)
    680 
    681             else:  # means that there is a wrapper to remove

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    674 
    675                 try:
--> 676                     response = method(*args, **kwargs)
    677                 except BaseException as e:
    678                     # we can make some errors more descriptive with this method

~/code/env/pysyft/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    105                 products. Defaults to ``False``.
    106         """"""
--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    108 
    109     def register_hook(self, hook):

~/code/env/pysyft/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---> 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```
Solved by #2590"	1	2019-08-22 17:53:29	2019-09-10 08:18:53	2019-09-10 08:18:53
https://github.com/OpenMined/PySyft/issues/2527	['bug ', 'good first issue :mortar_board:']	Calling .size() on a PointerTensor always returns a size of 0	"Calling .size() on a PointerTensor always returns a size of 0**Describe the bug**
Not sure if this was reported before. Couldn't find any issue about it. It seems like `.size()` method is not implemented for PointerTensors, making the Wrapper return `torch.Size([0])`

**To Reproduce**
Here's a script demonstrating the issue
```python
import torch
import syft

hook = syft.TorchHook(torch)

alice = syft.VirtualWorker(id=""alice"", hook=hook)

x = torch.Tensor([[1,2,3]])
print(x.size()) #=> torch.Size([1, 3]) 

# send x to alice and call size
x = x.send(alice)
print(x.size()) #=> torch.Size([0])
```

**Expected behavior**
`.size()` should return the size of the tensor being pointed at.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave
 - Version 0.1.23a1
Hey,
I would recommend using .shape instead of .size()
We have trouble with .size(), as explained here: https://github.com/OpenMined/PySyft/issues/2201@LaRiffle not sure why I couldn't find that issue at the time of posting this. Since this is a duplicate, I'll close this issue."	2	2019-08-18 17:32:02	2019-08-23 14:59:25	2019-08-23 14:59:25
https://github.com/OpenMined/PySyft/issues/2503	['bug ']	URGENT: bug in encrypted autograd	"URGENT: bug in encrypted autograd**Describe the bug**
For some reason, calling loss.backward() on a pointer using normal autograd then breaks our ability to call loss.backward() on an encrypted loss variable even on two totally separate examples.

**To Reproduce**
```
import torch
import torch as th
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import syft as sy

# Set everything up
hook = sy.TorchHook(torch) 

big_hospital = sy.VirtualWorker(hook, id=""big_hospital2"")
small_hospital = sy.VirtualWorker(hook, id=""small_hospital2"")
crypto_provider = sy.VirtualWorker(hook, id=""crypto_provider2"")

# A Toy Model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 2)
        self.fc2 = nn.Linear(2, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x
    
def federated():
    # A Toy Dataset
    data = th.tensor([[0,0],[0,1],[1,0],[1,1.]])
    target = th.tensor([[0],[0],[1],[1.]])

    model = Net()

    # Training Logic
    opt = optim.SGD(params=model.parameters(),lr=0.1)

    data = data.send(big_hospital)
    target = target.send(big_hospital)

    # NEW) send model to correct worker
    model.send(data.location)

    # 1) erase previous gradients (if they exist)
    opt.zero_grad()

    # 2) make a prediction
    pred = model(data)

    # 3) calculate how much we missed
    loss = ((pred - target)**2).sum()

    # 4) figure out which weights caused us to miss
    loss.backward()
    
    print(""Done!"")
    
def encrypted():
    # A Toy Dataset
    data2 = th.tensor([[0,0],[0,1],[1,0],[1,1.]])
    target2 = th.tensor([[0],[0],[1],[1.]])

    model2 = Net()

    # We encode everything
    data2 = data2.fix_precision().share(big_hospital, small_hospital, crypto_provider=crypto_provider, requires_grad=True)
    target2 = target2.fix_precision().share(big_hospital, small_hospital, crypto_provider=crypto_provider, requires_grad=True)
    model2 = model2.fix_precision().share(big_hospital, small_hospital, crypto_provider=crypto_provider, requires_grad=True)

    opt2 = optim.SGD(params=model2.parameters(),lr=0.1).fix_precision()


    # 1) erase previous gradients (if they exist)
    opt2.zero_grad()

    # 2) make a prediction
    pred2 = model2(data2)

    # 3) calculate how much we missed
    loss2 = ((pred2 - target2)**2).sum()

    # 4) figure out which weights caused us to miss
    loss2.backward()

#     # 5) change those weights
#     opt2.step()

#     # 6) print our progress
#     print(loss2.get().float_precision())
        
    print(""Done"")
    
run_broken = True

# make sure to re-start your jupyter notebook / environment with each test.
if(run_broken):
    # Breaks
    federated()
    encrypted() # breaks here - something about loss2.backward() causes the federated() demo to break 
else:
    # Works fine
    encrypted()
    federated()
```

Throws error:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-db6dbbeffaa2> in <module>()
    100     # Breaks
    101     federated()
--> 102     encrypted() # breaks here - something about loss2.backward() causes the federated() demo to break
    103 else:
    104     # Works fine

<ipython-input-1-db6dbbeffaa2> in encrypted()
     84 
     85     # 4) figure out which weights caused us to miss
---> 86     loss2.backward()
     87 
     88 #     # 5) change those weights

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    683                 # Put back the wrappers where needed
    684                 response = syft.frameworks.torch.hook_args.hook_response(
--> 685                     method_name, response, wrap_type=type(self), new_self=self
    686                 )
    687 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in hook_response(attr, response, wrap_type, wrap_args, new_self)
    243         response_hook_function = hook_method_response_functions[attr_id]
    244         # Try running it
--> 245         new_response = response_hook_function(response)
    246 
    247     except (IndexError, KeyError, AssertionError):  # Update the function in cas of an error

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    502         f = many_fold
    503 
--> 504     return lambda x: f(lambdas, x)
    505 
    506 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    520 
    521 def two_fold(lambdas, args, **kwargs):
--> 522     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    523 
    524 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    480         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    481         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 482         else lambda i: backward_func[wrap_type](i, **wrap_args)
    483         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    484     ]

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     73 backward_func = {
     74     TorchTensor: lambda i: i.wrap(),
---> 75     torch.Tensor: lambda i: i.wrap(),
     76     torch.nn.Parameter: lambda i: torch.nn.Parameter(data=i),
     77     PointerTensor: lambda i: i,

AttributeError: 'NoneType' object has no attribute 'wrap'
```

**Additional context**
latest version of PySyft from PyPI ('0.1.22a1')
Is this the error you get? 
```
File ""PySyft/syft/frameworks/torch/hook/hook_args.py"", line 75, in <lambda>
    torch.Tensor: lambda i: i.wrap()
AttributeError: 'NoneType' object has no attribute 'wrap'
```YupI will try what happens if you force the function to not be taken from the dictionary in the hook. There might be a conflict there.You rock. Thank you @midokura-silvia ```
    # Try this
    federated()
    
    sy.frameworks.torch.hook.hook_args.hook_method_args_functions = {}
    sy.frameworks.torch.hook.hook_args.hook_method_response_functions = {}
    sy.frameworks.torch.hook.hook_args.get_tensor_type_functions = {}

    encrypted() # runs through
```"	5	2019-08-14 12:55:13	2019-09-10 16:03:00	2019-09-10 16:03:00
https://github.com/OpenMined/PySyft/issues/2494	[]	"spdz_mul() - TypeError: can only concatenate list (not ""dict_values"") to list"	"spdz_mul() - TypeError: can only concatenate list (not ""dict_values"") to listError in `spdz_mul()` [Line 44](https://github.com/OpenMined/PySyft/blob/2e5af85043a29d5122243761e2e2d7cf2a5cb952/syft/frameworks/torch/crypto/spdz.py#L44) when concatenating list with dictionary values:

When the number of workers is greater than 2 I get the error:
`TypeError: can only concatenate list (not ""dict_values"") to list `

![image](https://user-images.githubusercontent.com/8993371/62837450-4ee53700-bc24-11e9-9b1d-a04fad18c5c8.png)

To me it seems like [line 44](https://github.com/OpenMined/PySyft/blob/2e5af85043a29d5122243761e2e2d7cf2a5cb952/syft/frameworks/torch/crypto/spdz.py#L44) should be:

`j = sy.MultiPointerTensor(children=[j1] + list(j0.child.values()))`


I haven't been working with PySyft for very long so please let me know if I am missing something!
Can anyone fix this to the original PySyft Repo? I'm also facing same issue, when workers are greater than 2.I started looking into this, but it looks like most or all the functions in securenn.py only allow for two workers (alice, bob to be specific). Since I am relatively new to PySyft it's starting to look a little more intense than just changing the syntax to what I suggested earlier.Apparently it has been fixed :)I am still seeing the same issue. I even tried making changes according to commit in the thread, still seeing the same error.

![image](https://user-images.githubusercontent.com/8968772/71577789-8e50e900-2b1b-11ea-993e-5d022fed38a8.png)"	4	2019-08-11 17:48:21	2019-12-30 10:16:39	2019-12-09 03:28:28
https://github.com/OpenMined/PySyft/issues/2490	[]	fix_precision() on sent model raises AttributeError exception	"fix_precision() on sent model raises AttributeError exception**Describe the bug**
Trying to run `fix_precision()` on sent models raises exception `AttributeError: 'numpy.ndarray' object has no attribute 'wrap'`. This is because the model's parameters are in this form: `Parameter>[PointerTensor | me:93626055963 -> alice:78685905360]`, and `fix_precision()` assumes that if there's no wrapper on the tensor, then it's a syft tensor (normal or pointer tensor). Therefore, tries to operate on the `Parameter` object.

**To Reproduce**
Working script demonstratin the issue:
```python
import torch as th
from torch import nn
import syft as sy

hook = sy.TorchHook(th)

# Create a worker
alice = sy.VirtualWorker(id=""alice"", hook=hook)

# Create a model and send it to worker
model = nn.Linear(2, 1).send(alice)

# Try to run fix_precision()
model.fix_precision() # AttributeError: 'numpy.ndarray' object has no attribute 'wrap'
```

**Expected behavior**
`fix_precision()` should work on a model even if it is on another location.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.5
 - Version 0.1.22a1

**Additional context**
This may have some relation to #2352, and some discussion about `wrap()` special cases in `float_prec()` and `fix_prec()` has been done on #2443. Also, I used to be able to do `fix_prec()` on sent models in version 0.1.19a1.
I think this has been fixed!"	1	2019-08-09 16:19:27	2019-11-15 09:14:31	2019-11-15 09:14:31
https://github.com/OpenMined/PySyft/issues/2478	[]	Encrypted Training on MNIST tutorial test model on training data itself	Encrypted Training on MNIST tutorial test model on training data itselfMax Zenk pointed out on slack(beginner channel) that in the tutorial: **Part 12 bis - Encrypted Training on MNIST** ```get_private_data_loaders``` functions loads the training set for training and testing.Issue Fixed :)	1	2019-08-09 01:52:16	2019-08-13 01:09:31	2019-08-12 11:06:06
https://github.com/OpenMined/PySyft/issues/2461	[]	Fix import issues	"Fix import issuesFix TODO https://github.com/OpenMined/PySyft/blob/06ce023225dd613d8fb14ab2046135b93ab22376/syft/frameworks/torch/hook/hook.py#L617

Fix TODO https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/autograd.py#L242

Fix TODO
https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L912

Fix TODO
https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/abstract.py#L158

Fix TODO
https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/multi_pointer.py#L195

Fix TODO https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/precision.py#L613This has been fixed"	1	2019-08-08 00:31:05	2019-12-09 03:30:26	2019-12-09 03:30:26
https://github.com/OpenMined/PySyft/issues/2447	[]	Unexpected behavior with AutogradTensors in remote workers	"Unexpected behavior with AutogradTensors in remote workers**Describe the bug**
Transforming a remote tensor into an `AutogradTensor` with `.share(*workers, requires_grad=True)` creates an `AutogradTensor` that points to a `Wrapper` instead of the opposite, as it should be expected. We want this to behave correctly as our objective is to work with data in remote servers (i.e. remote tensors) and do encrypted training using MPC with this data.

**To Reproduce**
The code below:
```
t = torch.Tensor([3]).send(bob) # t is a remote tensor located at the remote worker Bob
t = t.fix_precision().share(alice, jon, crypto_provider=crypto_provider, requires_grad=True)
t.get()
```

Gives this output:
```
AutogradTensor>(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]
    -> [PointerTensor | me:48986511531 -> alice:2051851770]
    -> [PointerTensor | me:48878799575 -> jon:38113753813]
    *crypto provider: crypto_provider*
```

**Expected behavior**
When working with local tensors and sharing them for MPC with autograd we have a `Wrapper` at the top
```
t = t.fix_precision().share(alice, jon, crypto_provider=crypto_provider, requires_grad=True)
t
```
```
(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]
    -> [PointerTensor | me:78465969403 -> alice:24923297626]
    -> [PointerTensor | me:39395163768 -> jon:22928149946]
    *crypto provider: crypto_provider*
```


**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.4
 - Version `syft==0.1.22a1` Actually I can still see the issue. I'm on the latest version of `dev` branch.
![image](https://user-images.githubusercontent.com/24773652/63579510-0b43e300-c5bd-11e9-9f24-41de3c3829dc.png)"	1	2019-08-07 11:07:35	2019-08-23 08:45:37	2019-08-22 19:17:33
https://github.com/OpenMined/PySyft/issues/2442	[]	Tensors remain in server memory if websocketclient connection closes abruptly  	"Tensors remain in server memory if websocketclient connection closes abruptly  **Describe the bug**
Tensors remain in websocket server memory if websocket client connection closes abruptly 

**To Reproduce**
Steps to reproduce the behavior:
1. Start the websocket server ""run_websocket_server.py --port 8777 --id alice""
2. Start a websocketclient and connect on port 8777 using id=""alice"".
3. Send a tensor to alice on the socket created in step 2. 
4. Close the client abruptly.
5. Check on the websocketserver console. The ""WebSocket connection created in step 2 gets closed""
4. Connect another websocketclient to port 8777 and use any random id say ""some_random_id""
5. Now call ""some_random_id.list_objects_remote()"" on the websocket created in step 4
6. Tensors sent to alice on the websocket in step 3 are clearly visible to this client with ""some_random_id"". 

**Expected behavior**
When socket connection gets closed all the tensors in server memory sent on that connection should be removed if any. This would ensure that if a websocket client closes abruptly due to network issues, etc its private tensors should not remain on the server which could be retrieved by any other client which connects to the server on the same port later. 

 - OS: Windows 10This is an important feature - but it requires user auth to know the difference between the same user re-connecting and another user re-connecting, which means this is more a feature for https://github.com/OpenMined/Grid

@IonesioJunior - I believe you'll be working on a user, based system. This is an important characteristic!"	1	2019-08-05 08:03:25	2019-08-05 12:07:31	2019-08-05 12:07:31
https://github.com/OpenMined/PySyft/issues/2428	[]	The WebSocketServer could be prone to a DoS attack	"The WebSocketServer could be prone to a DoS attack**Describe the bug**
The WebSocketServer could be prone to a DoS attack from a malicious script

**To Reproduce**
Steps to reproduce the behavior:
1. Start a websocketserver using run_websocket_server.py --port 8777 --id alice 
2. Create a client script which calls WebsocketClientWorker to connect to the websocketserver created above in a loop say 100000 times
3. Now start another client script which tries to connect to the above server using WebsocketClientWorker and tries sending a tensor to the remote worker
4. This client script in step 3 cannot perform any operations since it appears to hang due to DoS.

**Expected behavior**
This client script in step 3 should be able to perform its operations.

**Desktop (please complete the following information):**
 - OS: Windows 10Does it work after 1 time? I *think* WebSocketServer only allows one client to connect.Yes it works after 1 time. So i think it shouldn't be an issue then.
One question though, cannot see the objects of a remote socket worker using for e.g. ""bob._objects"". Is this for security reason?"	2	2019-08-01 19:24:51	2019-08-02 13:54:15	2019-08-02 13:54:15
https://github.com/OpenMined/PySyft/issues/2426	[]	Local worker *me* not recognized by other workers when explicitly declared as crypto provider	"Local worker *me* not recognized by other workers when explicitly declared as crypto provider**Describe the bug**
Sharing a sent tensor between workers, and explicitly declaring the crypto provider as `sy.local_worker` causes the warning `Worker [worker_id] couldn't recognize worker me`. This warning causes problems when trying to execute get() on the sent, shared tensor, throwing an exception `AttributeError: 'str' object has no attribute 'id'`. Strange enough, this doesn't happen if `sy.local_worker` is implicitly assigned as crypto provider by not providing any crypto provider while sharing the tensor.

**To Reproduce**
Working script to demonstrate the problem.
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)

# Declare workers
alice = sy.VirtualWorker(id=""alice"", hook=hook)
bob = sy.VirtualWorker(id=""bob"", hook=hook)
jack = sy.VirtualWorker(id=""jack"", hook=hook)

# create a tensor
a = th.zeros(1).long()

# send the tensor
a = a.send(alice)

# share the tensor with me as an implicit crypto provider
a = a.share(bob, jack) # No warning is shown here

# get the shared tensor
a = a.get() # AdditiveSharingTensor returned, *crypto provider: me*

# Redeclare tensor
a = th.zeros(1).long()

# send the tensor
a = a.send(alice)

# share the tensor with me as an explicit crypto provider
a = a.share(bob, jack, crypto_provider=sy.local_worker) 
# W0801 11:56:01.096644 4346246592 base.py:577] Worker alice couldn't recognize worker me

# get the shared tensor
a = a.get() # AttributeError: 'str' object has no attribute 'id'
```

**Expected behavior**
There should be no difference between implicit and explicit declaration of the local worker as crypto provider.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.5
 - Version `syft==0.1.19a1`

**Additional context**
A similar script can be seen inside `syft/frameworks/torch/crypto/securenn.py`, for example in `_shares_of_zero()` declaration:
```python
def _shares_of_zero(size, field, crypto_provider, *workers):
    """"""
    Return n in [0, max_value-1] chosen by a worker and sent to all workers,
    in the form of a MultiPointerTensor
    """"""
    u = (
        torch.zeros(size)
        .long()
        .send(workers[0])
        .share(*workers, field=field, crypto_provider=crypto_provider, **no_wrap)
        .get()
        .child
    )

    return u
```
and causes errors when trying to run functions inside `securenn.py` while using tensors without explicit declaration of a crypto provider. This assigns `crypto_provider` to the local worker, and gets explicitly assigned as crypto provider in the line `.share(*workers, field=field, crypto_provider=crypto_provider, **no_wrap)`.
Very interesting bug - I do wonder how deep this bug goes. Is the local worker listed in bob._known_workers?@iamtrask the local worker is not recognized by any of the virtual workers.
```python
print(alice._known_workers)
# => {'alice': <VirtualWorker id:alice #objects:10>, 'bob': <VirtualWorker id:bob #objects:14>, 'jack': <VirtualWorker id:jack #objects:12>}
# The results are the same for bob and jack
```@iamtrask I'm seeing two problems here:
1. VirtualWorkers are not recognizing the local worker.
2. letting the class `AdditiveSharingTensor` assign the default crypto_provider to local_worker behaves differently as explicitly assigning it to local_worker.

As of 1:
when declaring a new worker, the `_known_workers` dict is populated by copying `sy.hook.local_worker._known_workers`. If we run this script
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)
hook.local_worker._known_workers
# => {}
```
returns an empty dictionary, which means that `hook.local_worker` is not aware of itself, which explains why any other worker won't recognize it. I'm guessing this should be another issue by itself?

As of 2.
I still don't get it, if I don't assign a crypto_provider, then it gets automatically assigned as `sy.hook.local_worker`, which should behave the same as explicitly assigning it to the same value. Any ideas?PR #2431 fixes this problem. So I'm going to close this issue."	4	2019-08-01 17:03:48	2019-08-02 17:31:13	2019-08-02 17:31:12
https://github.com/OpenMined/PySyft/issues/2396	[]	Openmined `client` tutorial is broken and needs fixing	"Openmined `client` tutorial is broken and needs fixing**Describe the bug**
The Colab version of the `Client` notebook needs fixing, as the code version it was based on is now deprecated. 

**To Reproduce**
Steps to reproduce the behavior:
1. Go to [https://colab.research.google.com/drive/1Je1rk7olA9uTWWaqvvt4_gXf7yX1rTBm](https://colab.research.google.com/drive/1Je1rk7olA9uTWWaqvvt4_gXf7yX1rTBm), or follow the web link on [https://www.openmined.org/](https://www.openmined.org/)
2. Check the outputs of the cells in that notebook
3. See error

**Expected behavior**
A good notebook should be as a bare minimum functional yet informative, especially in this context. 

**Desktop (please complete the following information):**
 - Google Colaboratory

**Additional context**
The code base of the websocket* workers might need to be modified to achieve the desired effect. 
I would really like to work on this issue though... which is not to be confused with #1905, which deals with the accompanying `Server` tutorial notebook hosted on Colab. I am guessing to make the tutorial run perfectly on Colab this is what we need to do: https://research.google.com/colaboratory/local-runtimes.htmlAm actively working on this issue, and will open a PR to follow up soon. @kakirastern Is this done? Can we close this issue?Yup, I have modified the file on Google Colab so it should be fine now. At least it was the last time I checked."	5	2019-07-25 17:33:09	2019-10-09 12:55:37	2019-10-09 12:55:37
https://github.com/OpenMined/PySyft/issues/2392	[]	One-worker Bug	"One-worker Bug**Describe the bug**
When we set **only one client/work** in federated learning task, the corresponding _FederatedDataLoader_ does not work:

""....\syft\frameworks\torch\federated\dataloader.py"", line 245, in __next__
    iterator = self.iterators[0]
IndexError: list index out of range

I checked the code of **dataloader.py** and found the probable problem here:
```       
        if iter_per_worker:
            self.num_iterators = len(self.workers)
        else:
            # You can't have more iterators than n - 1 workers, because you always
            # need a worker idle in the worker switch process made by iterators
            self.num_iterators = min(num_iterators, len(self.workers) - 1)
```
where the num_iterators is set to 1, making the last statement of the codes above yields 0 (because min(1, 1-1) = 0) when len(self.workers) = 1. Consequently, no iterators available and thus the dataloader fails to work.

I wanted to test one-work FL for some reason and this bug appeared.I'll look into this @wentaiwu92 you can use ```iter_per_worker=True``` while calling FederatedDataLoader. That will allow you to have one iterator for one worker.
I hope that will help if not let me know I would be happy to help :)Close this issue :) ?Thanks ShivamSRS and kamathhrishi, **PySyft** is really helpful for FL."	4	2019-07-25 09:49:47	2019-08-02 15:53:02	2019-08-02 15:53:02
https://github.com/OpenMined/PySyft/issues/2378	[]	about error in websocket mnist example 	"about error in websocket mnist example **Describe the bug**
KeyError: (wrapper)>[PointerTensor | me:some series of numbers -> alice:some series of number]

**To Reproduce**
Add the code in run_websocket_client.py:
```
kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}
alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
workers = [alice]
```
I run the lines:
python3 run_websocket_server.py --host 127.0.0.1 --port 8777 --id alice
python3 run_websocket_client.py

It shows the bug.

**Desktop (please complete the following information):**
RedHat Linux 7.2, python3.6.8, pysyft==0.1.13a1, torch==1.0.1, torchvision==0.2.2
nvidia-driver==410.48, cuda==10.0, cudnn==7.5

**Additional context**
I change to: pysyft==0.1.19a1, torch==1.1.0, torchvision==0.3.0
or I use the VirtualHook.
The bug still have.I also see this error! But when i use 2 workers it works fine."	1	2019-07-22 00:20:07	2020-01-30 13:35:18	2019-07-22 01:49:39
https://github.com/OpenMined/PySyft/issues/2365	[]	When sharing a model where bias equals true, not all parameters get shared	"When sharing a model where bias equals true, not all parameters get shared

**To Reproduce**
Steps to reproduce the behavior:
Run attached notebook until you get an error. When you look at the args of the call to addmm, one of the args is a torch tensor when all should be ast. This implies that either the weights or the bias is not being shared (Im pretty sure)
[reproduce_error.ipynb.zip](https://github.com/OpenMined/PySyft/files/3403467/reproduce_error.ipynb.zip)
@shivramsrsThe pb is that the data is not shared correctly here:

The model can be shared in-place but data can't be:
```python
model.share(...) # Is OK
model = model.share(...) # Is OK

data.share(...) # IS *NOT* OK
data = data.share(...) # Is OK
```
Additionally, all the parameters of the model get shared by default: we loop on model.parameters()"	3	2019-07-17 19:19:58	2019-07-18 14:41:20	2019-07-18 14:41:20
https://github.com/OpenMined/PySyft/issues/2361	[]	Gradient updates not generated in remote backpropagation with custom GRU/RNN	"Gradient updates not generated in remote backpropagation with custom GRU/RNN**Describe the bug**

No gradient is produced following the remote backpropagation step neither in the model's parameters nor in the worker's parameters.
**To Reproduce**

Steps to reproduce the behavior:
1. Extract all the files in the `minimal_GRU_2.0.zip` archive to a folder of your choice. The files' download link is at the bottom of this Issue
2. Navigate to the folder where the files have been extracted
3.  Run the following command:
`python3 minimal_gru_init.py`
4. See the [0,0,...0] tensors being generated as model's gradient parameters, meaning that the gradients did not get updated. 
5. Inspect the code. The issue lies in file `minimal_gru_init.py` in the function `train_remote_model_one_epoch` at line: `loss.backward()`.

To inspect the gradient, just check the lines:

```python
 for param_remote in remote_model.parameters():
            #produces a matrix containing just zeroes
            print(param_remote.grad.copy().get())
```




**Expected behavior**

I would expect that the parameter's gradient updates are actually generated. In a local version of the same code, where backpropagation is performed locally, the gradient update is indeed generated for all parameters.

**Screenshots**

LOCAL gradient (first parameter of the model) - Correct behaviour 

![local_gradient](https://user-images.githubusercontent.com/4907418/61353477-37f33500-a870-11e9-92d1-3ce1f1b9f8e4.png)

REMOTE gradient (first parameter of the model): - Erroneous behaviour

![image](https://user-images.githubusercontent.com/4907418/61353820-f6af5500-a870-11e9-8f3e-53adf230eabe.png)


**Desktop **
 - OS: Ubuntu 
 - Version 18.04 LTS

**Additional context**
I've been stuck on this issue for a weeks now and it's extremely important for the work I'm conducting with PySyft to have it fixed. Any help would be greatly appreciated. I tried to experiment with AutogradTensor to see if there was any difference in terms of gradient produced, but the gradient updates still were not produced. 

Also note that you're going to need the .size() method to test RNNs-GRUs. You may clone the repository of this PR to get its implementation: https://github.com/OpenMined/PySyft/pull/2343

Minimal code example and dataset: [minimal_GRU_2.0.zip](https://github.com/OpenMined/PySyft/files/3400495/minimal_GRU_2.0.zip)
@LaRiffle @robert-wagner @iamtrask @mari-linhares  Thoughts? . Any ideas or help would be greatly appreciated.Hey @DanyEle What happens if you don't call `.copy` before `.get`You can't .get() on a data attribute (syft.exceptions.CannotRequestObjectAttribute)Rip okay. What is the result of copy locally?If you want to inspect in a preserving manner you can directly access the remote object:
```
worker = sy.hook.local_worker.get_worker(param_remote.location)
print(worker._objects[param_remote.id_at_location].grad)
```You get 8 param grad, the 6 first are only zeros but not the two last one:
zeros: encoder.weight, rnn.weight_ih, rnn.weight_hh, rnn.bias_ih, rnn.bias_hh
non-zeros: decoder.weight & decoder.biasTry this for your forward pass: (check carefully the differences with the send/get stufff to understand better what was not working)
```python
    def forward(self, input, hidden, worker=None):
        print(input)
        emb = self.drop(self.encoder(input))

        output = []
        if self.rnn_type in ['GRU', 'GRUCell']:
            hx = hidden
            for i in range(emb.shape[0]): #Daniele: was emb.size(0)

                hx = self.rnn(emb[i, :], hx)
                output.append(hx.unsqueeze(0))

            output = torch.cat(output, dim=0)
        else:
            # else do smthg to instantiate output
            raise ValueError
                
        output = self.drop(output)
        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))
        return (decoded.view(output.size(0), output.size(1), decoded.size(1)), hx)
```

And to print the grad safely do:
```python
#BACKPROPAGATION - ISSUES OCCUR HERE! Gradients are [0,0,...,0]
        for k, param_remote in remote_model.named_parameters():
            print(k)
            worker = sy.hook.local_worker.get_worker(param_remote.location)
            print(worker._objects[param_remote.id_at_location].grad)
            #print(param_remote.grad.get())
```
It works on my side I get non-zero gradientsThe `minimal_gru_init.py` does not run completely as we said because the hook on size() can't work: just replace the occurence of size() with .shape in your implem, remove the hook of size() and this error should disappearYes, it's indeed working!! Also the quantization example, after removing calls to clone() on the input , but operating in place on the variables, is working!!!! :)"	9	2019-07-17 06:58:11	2019-07-17 17:52:37	2019-07-17 17:22:49
https://github.com/OpenMined/PySyft/issues/2359	[]	Error when call fix_precision() in PySyft/examples/tutorials/Part 10 - Federated Learning with Secure Aggregation.ipynb	"Error when call fix_precision() in PySyft/examples/tutorials/Part 10 - Federated Learning with Secure Aggregation.ipynb**Describe the bug**
when it call the function of fix_precision(),
on the line _“fixed_precision_param = copy_of_parameter.fix_precision()”_
and the line: _spdz_params.append(params[remote_index][param_i].copy().fix_precision().share(bob, alice, crypto_provider=james).get())_,
it will occur:
`AttributeError: 'numpy.ndarray' object has no attribute 'owner'`

entire error log:
```
KeyError                                  Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    656         # Load the utility function to register the response and transform tensors with pointers
--> 657         register_response_function = register_response_functions[attr_id]
    658         # Try running it

KeyError: 'numpy'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
15 frames
<ipython-input-17-8762fe587994> in <module>()
     11         # to use Integers to store decimal information. In other words,
     12         # we need to use ""Fixed Precision"" encoding.
---> 13         fixed_precision_param = copy_of_parameter.fix_precision()
     14 
     15         # now we encrypt it on the remote machine. Note that

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, *args, **kwargs)
    645         prec_fractional = kwargs.get(""precision_fractional"", 3)
    646         max_precision = _get_maximum_precision()
--> 647         if self._requires_large_precision(max_precision, base, prec_fractional):
    648             return (
    649                 syft.LargePrecisionTensor(*args, **kwargs)

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in _requires_large_precision(self, max_precision, base, precision_fractional)
    670         # We need to use NumPy here as log2 is not yet implemented for LongTensor PyTorch objects
    671         return np.any(
--> 672             np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision
    673         )
    674 

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    675                 # Send the new command to the appropriate class and get the response
    676                 method = getattr(new_self, method_name)
--> 677                 response = method(*new_args, **new_kwargs)
    678 
    679                 # For inplace methods, just directly return self

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    511             command = (attr, self, args, kwargs)
    512 
--> 513             response = owner.send_command(location, command)
    514 
    515             return response

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    425 
    426         try:
--> 427             ret_val = self.send_msg(codes.MSGTYPE.CMD, message, location=recipient)
    428         except ResponseSignatureError as e:
    429             ret_val = None

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_msg(self, msg_type, message, location)
    221 
    222         # Step 2: send the message and wait for a response
--> 223         bin_response = self._send_msg(bin_message, location)
    224 
    225         # Step 3: deserialize the response

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      8 class VirtualWorker(BaseWorker, FederatedClient):
      9     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
---> 10         return location._recv_msg(message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _recv_msg(self, message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:
---> 13         return self.recv_msg(message)
     14 
     15     @staticmethod

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in recv_msg(self, bin_message)
    252             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    253         # Step 1: route message to appropriate function
--> 254         response = self._message_router[msg_type](contents)
    255 
    256         # Step 2: Serialize the message to simple python objects

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in execute_command(self, message)
    391             try:
    392                 response = sy.frameworks.torch.hook_args.register_response(
--> 393                     command_name, response, list(return_ids), self
    394                 )
    395                 return response

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    664         register_response_functions[attr_id] = register_response_function
    665         # Run it
--> 666         new_response = register_response_function(response, response_ids=response_ids, owner=owner)
    667 
    668     # Remove the artificial tuple

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(x, **kwargs)
    757         f = many_fold
    758 
--> 759     return lambda x, **kwargs: f(lambdas, x, **kwargs)

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    514 
    515 def two_fold(lambdas, args, **kwargs):
--> 516     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    517 
    518 

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i, **kwargs)
    735         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    736         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 737         else lambda i, **kwargs: register_tensor(i, **kwargs)
    738         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    739     ]

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    706             and each id is pop out when needed.
    707     """"""
--> 708     tensor.owner = owner
    709     try:
    710         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```

**To Reproduce**
Steps to reproduce the behavior:
1.just pip isntall syft on google colab
and run this tutorials ipynb


**Desktop (please complete the following information):**
 - OS: [Google Colab & Ubuntu 16.04 ]

**Additional context**
I have debugged, it occur when call .fix_precision()
@LaRiffle Hey @bluerxing,

I believe this was fixed in this PR #2353. You should be able to have the correct behavior by using the dev version of this repo or using pip in the next few days (when the new version of pysyft is submitted).

I'll close this issue, but feel free to leave comments here if you face any issues.

@mari-linhares Have the new version of pysyft is submitted already?"	3	2019-07-15 09:40:27	2019-08-04 03:39:29	2019-07-15 20:25:36
https://github.com/OpenMined/PySyft/issues/2352	['bug ', 'priority: 2 - high :cold_sweat:']	Fix precision on pointers Error	"Fix precision on pointers Error**Describe the bug**
Fix_precision on pointer tensor fails because of change in fix_prec method which make use of numpy ops.

**To Reproduce**
```python
#[classic imports]
x = torch.tensor([1.])
x_ptr = x.send(alice)
x_fp = x_ptr.fix_prec()
``` 

Or run Tutorial Part 10.

![image](https://user-images.githubusercontent.com/8157164/61076178-8a1cfc00-a413-11e9-8dc3-dfba2ae73261.png)



**Error**
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    656         # Load the utility function to register the response and transform tensors with pointers
--> 657         register_response_function = register_response_functions[attr_id]
    658         # Try running it

KeyError: 'numpy'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-1-95fc1ed4192b> in <module>
     13 x = torch.tensor([1.])
     14 x_ptr = x.send(alice)
---> 15 x_fp = x_ptr.fix_prec()

~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, *args, **kwargs)
    666         prec_fractional = kwargs.get(""precision_fractional"", 3)
    667         max_precision = _get_maximum_precision()
--> 668         if self._requires_large_precision(max_precision, base, prec_fractional):
    669             return (
    670                 syft.LargePrecisionTensor(*args, **kwargs)

~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in _requires_large_precision(self, max_precision, base, precision_fractional)
    691         # We need to use NumPy here as log2 is not yet implemented for LongTensor PyTorch objects
    692         return np.any(
--> 693             np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision
    694         )
    695 

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    675                 # Send the new command to the appropriate class and get the response
    676                 method = getattr(new_self, method_name)
--> 677                 response = method(*new_args, **new_kwargs)
    678 
    679                 # For inplace methods, just directly return self

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    511             command = (attr, self, args, kwargs)
    512 
--> 513             response = owner.send_command(location, command)
    514 
    515             return response

~/code/PySyft/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    425 
    426         try:
--> 427             ret_val = self.send_msg(codes.MSGTYPE.CMD, message, location=recipient)
    428         except ResponseSignatureError as e:
    429             ret_val = None

~/code/PySyft/syft/workers/base.py in send_msg(self, msg_type, message, location)
    221 
    222         # Step 2: send the message and wait for a response
--> 223         bin_response = self._send_msg(bin_message, location)
    224 
    225         # Step 3: deserialize the response

~/code/PySyft/syft/workers/virtual.py in _send_msg(self, message, location)
      8 class VirtualWorker(BaseWorker, FederatedClient):
      9     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
---> 10         return location._recv_msg(message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:

~/code/PySyft/syft/workers/virtual.py in _recv_msg(self, message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:
---> 13         return self.recv_msg(message)
     14 
     15     @staticmethod

~/code/PySyft/syft/workers/base.py in recv_msg(self, bin_message)
    252             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    253         # Step 1: route message to appropriate function
--> 254         response = self._message_router[msg_type](contents)
    255 
    256         # Step 2: Serialize the message to simple python objects

~/code/PySyft/syft/workers/base.py in execute_command(self, message)
    391             try:
    392                 response = sy.frameworks.torch.hook_args.register_response(
--> 393                     command_name, response, list(return_ids), self
    394                 )
    395                 return response

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    664         register_response_functions[attr_id] = register_response_function
    665         # Run it
--> 666         new_response = register_response_function(response, response_ids=response_ids, owner=owner)
    667 
    668     # Remove the artificial tuple

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in <lambda>(x, **kwargs)
    757         f = many_fold
    758 
--> 759     return lambda x, **kwargs: f(lambdas, x, **kwargs)

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    514 
    515 def two_fold(lambdas, args, **kwargs):
--> 516     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    517 
    518 

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in <lambda>(i, **kwargs)
    735         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    736         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 737         else lambda i, **kwargs: register_tensor(i, **kwargs)
    738         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    739     ]

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    706             and each id is pop out when needed.
    707     """"""
--> 708     tensor.owner = owner
    709     try:
    710         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```AttributeError: 'numpy.ndarray' object has no attribute 'owner'

Is this issue resolved? 

Infile : syft/frameworks/torch/tensors/interpreters/native.py
Having this line: np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision 
is causing issue."	1	2019-07-11 11:05:00	2020-02-21 17:13:23	2019-07-12 18:30:48
https://github.com/OpenMined/PySyft/issues/2341	['bug ', 'status: stale :bread:']	SecureNN with n_workers >= 3	"SecureNN with n_workers >= 3**Describe the bug**
When used with n>=3 workers with SecureNN

```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
crypto_prov = sy.VirtualWorker(hook, id=""crypto_prov"")
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks, crypto_provider=crypto_prov)
t = t * 2
t = t.get()
t = t.float_prec()
print(t)
```

This doesn't work correctly:
```
tensor([[-1.0000e-03,  0.0000e+00,  1.0000e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.0000e-03,  1.0000e-03,  1.8447e+13]])
```In this particular case where we multiply by a scalar, I think we do something useless:
we first multiply the multiplier by `base ** precision_fractional` and then truncate. When I remove this, the results are ok.
But I agree that there are still some problems when multiplying 2 ASTs shared between more than 2 workersEDIT **not enough**
> Use a crypto provider and that should be sufficientHmm @LaRiffle, this doesn't seem sufficient to fix the problem of >2 workers:

```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
crypto_prov = sy.VirtualWorker(hook, id=""crypto_prov"")
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks, crypto_provider=crypto_prov)
t = t * 2
t = t.get()
t = t.float_prec()
print(t)

tensor([[-1.8447e+13,  1.8447e+13,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.0000e-03, -1.8447e+13,  1.8447e+13]])
```@LaRiffle, a quick fix using the in-place operation somehow works:
```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks)
t *= 2
t = t.get()
t.float_prec()
```
For the very specific problem of multiplying by an integer, I submitted a pull request and it passed all tests.Here's another example - calculating avg of multiple zero tensors shared to multiple workers.
Works fine with `num = 2`.

```
num = 10
wks = [ sy.VirtualWorker(hook, id=""wk#%d"" % i) for i in range(num) ]
tensors = [ torch.zeros(5, 5).fix_prec(precision_fractional=16).share(*wks) for _ in range(num) ]
avg = tensors[0]
for i in range(num-1):
  avg += tensors[i+1]
avg /= len(tensors)
avg = avg.get().float_prec()
print(avg)

tensor([[ 1.0000e-16, -1.8447e+02, -1.8447e+02, -1.8447e+02, -1.8447e+02],
        [ 1.8447e+02,  9.2234e+01,  1.8447e+02, -1.8447e+02,  9.2234e+01],
        [ 1.8447e+02,  1.8447e+02,  0.0000e+00, -1.8447e+02,  1.8447e+02],
        [ 1.0000e-16, -1.8447e+02, -1.8447e+02,  1.8447e+02, -1.0000e-16],
        [ 1.8447e+02,  1.0000e-16,  0.0000e+00,  1.8447e+02, -1.8447e+02]])
```

Expected is tensor of zeros.
@vvmnnnkv, Division in FixedPrecisionTensor is not even implemented. @Jasopaum, maybe division by integer is a nice feature to be implemented soon.@Jasopaum A big problem with operations between more than 2 ast's is that when recombining each of them there is a greater likelyhood in losing precision in the least significant bit. An intuitive way to think about this problem is to think of the last digit as a float which adds up to 1 but is rounded. For the n=2 case, unless you split the number such that both are exactly equal to 0.5, one of the numbers will round to 1 and the other to 0. However, when n>2, it is likely that all will round to 0 leading to a loss in precisionWe actually used to have test for this which was super flakey due to the above instability@joseilberto, I think we left out the division for FixedPrecisionTensor on purpose, to avoid a loss of precision when division isn't exact... But I'm not sure why we couldn't have something like a floor division, you're right. Maybe @LaRiffle knows a bit more about FixedPrecisionTensors?@joseilberto we'd love to have division with fixed_precision! We haven't had a use case yet where division by a FixedPrecision divisor was needed, we only needed integer division, that's why you don't see an implementation so far.

One thing to notice, is that for example if you don't see a method (like `__truediv__`) in precision.py it doesn't mean it's not implemented, it means that the basic PyTorch behaviour will be used. For integer division for example you don't need to specify a specific behaviour different from PyTorch.
@LaRiffle, I do understand that what it does is exactly use whatever comes from the inheritance (that is why I suggested using the in-place multiplication operator and it works properly). In the division by integer case, we are constrained by the precision_fractional we have set and it performs poorly if we need more precision just as pointed by @vvmnnnkv. Hey yes you're right, but this is linked to the additive sharing part not the fixed_precision: take the same example  from @vvmnnnkv and remove .share() and .get() it will work

So as a **recap**  we have issues with additive shared tensor with mul or div with integers with n>2 workersIs there any update on this issue? Multiplying and dividing tensors by integers is a pretty common operation, and it took me a while to understand why `torch.mean` returned an absurd value when working with n>=3 workers.We just had a great PR merged (#2982) which will help for this issue which is still open!
https://github.com/OpenMined/PySyft/pull/3148 also adresses secure comparison for more workers, but @artix41 if yoy're willing to do the checks for multiplication & addition I'd be very graeful!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	16	2019-07-08 10:22:26	2020-07-02 00:08:35	2020-07-02 00:08:35
https://github.com/OpenMined/PySyft/issues/2333	['bug ']	Multiple workers with same id issues	"Multiple workers with same id issues**Describe the bug**
When multiple workers with the same id are declared, we observe some weird behaviour.
Could be just raise an Error when this happen? Alternatively, handle this in a consistent way.

**To Reproduce**
```python
import torch
import syft as sy
hook = sy.TorchHook(torch)

worker = sy.VirtualWorker(hook, id=""worker"")
worker.clear_objects()
ptr = torch.tensor([1,2,3]).send(worker)
print(worker._objects) # >>> Has 1 object!

worker = sy.VirtualWorker(hook, id=""worker"")
worker.clear_objects()
ptr = torch.tensor([1,2,3]).send(worker)
print(worker._objects) # >>> Empty!
```@LaRiffle I would like to take this up.Sure!"	2	2019-07-04 07:32:27	2019-07-09 19:48:18	2019-07-09 19:48:18
https://github.com/OpenMined/PySyft/issues/2332	[]	classification error	"classification error![image](https://user-images.githubusercontent.com/11493656/60638150-cff42600-9e4f-11e9-8a31-7b34084f636a.png)

The execution in part13 is OK, but the classification results are wrong. How can I fix it? Thank you very much.Hey @keenlykeenly,

I don't think this is an issue since the model is randomly initialized it's possible that it could classify the first images wrong. Having said that I'll close the issue for now.

But maybe is not a coincidence that it classified all images as zeros, have you trained the model? Can you check how your model classifies other images from the test set?

Thanks!"	1	2019-07-04 03:37:39	2019-07-04 16:08:25	2019-07-04 16:08:25
https://github.com/OpenMined/PySyft/issues/2313	['bug ', 'status: stale :bread:']	Transform ToTensor() on BaseDataset automatically executes get()	"Transform ToTensor() on BaseDataset automatically executes get()**Describe the bug**
Iterating with `FederatedDataLoader` on a federated dataset with `transforms.ToTensor()` will return the raw data tensor instead of a pointer to the tensor.

**To Reproduce**
Steps to reproduce the behavior:

This is a working script that demonstrates the issue.
```python
import torch as th
import syft as sy
import torchvision
from torchvision import transforms

hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

# DECLARE A TOY DATASET AS IMAGE DATA
data = th.tensor([[[1,1],[0,1],[1,0],[0,0]],[[1,1],[0,1],[1,0],[0,0]],[[1,1],[0,1],[1,0],[0,0]],[[1,1],[0,1],[1,0],[0,0]]]).type(th.uint8)
target = th.tensor([[1],[1], [0], [0]])

# DECLARE TRANSFORM WITH TOTENSOR
transform = transforms.ToTensor()

# SPLIT THE DATASET AND SEND TO WORKERS
bob_dataset = sy.BaseDataset(data[:2], target[:2], transform=transform).send(bob)
alice_dataset = sy.BaseDataset(data[2:], target[2:], transform=transform).send(alice)

# DECLARE THE FEDERATED DATASET AND DATALOADER
f_dataset = sy.FederatedDataset([bob_dataset, alice_dataset])
f_dataloader = sy.FederatedDataLoader(f_dataset, shuffle=True, batch_size=2)

# GET A BATCH FORM THE DATALOADER
data, label = next(iter(f_dataloader))  # This batch should be returned as pointers to the tensors


print(data) # UNEXPECTED: returns the raw data without using get()
print(label) # EXPECTED: returns the pointer to the tensor

```

**Expected behavior**
transforms should be run remotely and `FederatedDataLoader` should return the pointer to the remote data.

Specifically:
`data` should be a pointer tensor and not the data tensor itself.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.1
 - Version `syft==0.1.19a1`

I think as of now, Transforms cannot be applied to Pointer, Fixed Precision or Float Precision tensors. @mari-linhares, If you guys are planning to extend the Transforms to Pointer, Fixed Precision or Float Precision, I would like to get involved.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	2	2019-06-26 17:56:45	2020-05-25 00:08:28	2020-05-25 00:08:28
https://github.com/OpenMined/PySyft/issues/2281	['bug ', 'help wanted :wave:', 'status: stale :bread:']	All tests calling start_proc fail on windows	"All tests calling start_proc fail on windows**Describe the bug**
Start proc does not succeed on windows causing 9 tests to fail
**To Reproduce**
Call make test on windows

**Expected behavior**
Tests should work on all operating systems
**Desktop (please complete the following information):**
 - OS: windows
 - Version: all

**Additional context**

[-.txt](https://github.com/OpenMined/PySyft/files/3286916/-.txt)

I would like to take this up if this is still available.On Windows the web socket client also fails to connect giving the error below. 

OverflowError: timeout doesn't fit into C timeval

Appears to be due to the timeout interval (TIMEOUT_INTERVAL = 9_999_999) specified in websocket_client.py.I saw the PR ""[WIP] Implement start_remote_worker #2345"" where its mentioned that start_proc would get replaced with start_remote_worker. Hence, wanted to check if this issue is still valid and needs to be worked upon?Hey @amit-rastogi,

The new function actually uses `start_proc`, so yes, this issue is still valid.The web socket client overflow error on windows has been addressed by https://github.com/OpenMined/PySyft/pull/2395 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	6	2019-06-13 15:24:31	2020-05-25 00:08:32	2020-05-25 00:08:32
https://github.com/OpenMined/PySyft/issues/2279	['bug ', 'help wanted :wave:', 'good first issue :mortar_board:', 'testing ', 'status: stale :bread:']	3 Tests fail when local worker is verbose	"3 Tests fail when local worker is verbose**Describe the bug**
When hook.local_worker is set to verbose the following errors occur

```
FAILED test/torch/test_hook.py::test_RNN_grad_set_backpropagation - RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 57 and 128 in dimension 1 at ../aten/src/TH/generic/THTensor.cpp:711
FAILED test/torch/tensors/test_additive_shared.py::test_max - RuntimeError: Error, Please consider calling "".get"" method instead of "".item"" method, so you can be safely getting the item you need.
FAILED test/torch/tensors/test_additive_shared.py::test_argmax - RuntimeError: Error, Please consider calling "".get"" method instead of "".item"" method, so you can be safely getting the item you need.
```

**To Reproduce**
In test/conftest.py 
put the line `hook.local_worker.verbose=True` in the hook function

**Expected behavior**
Tests should pass regardless of if they are printing output

@robert-wagner I've had a discussion about this with @IonesioJunior some time ago, we think this is due to the fact that garbage collector ""gets stuck"" since every time you're printing something you're creating a new reference to it, that tries to be deleted but then is printed again, ... and so onHaving said that, if our intuition is right I'm not sure how easy is to get this fixedHello, please is anyone working on this. 
I will like to give it a try. ThanksI don't think so, you're very much welcome!@LaRiffle Is anyone working on this? Can I start working on this?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	7	2019-06-12 19:37:02	2020-05-25 00:08:33	2020-05-25 00:08:33
https://github.com/OpenMined/PySyft/issues/2234	[]	AttributeError: 'FixedPrecisionTensor' object has no attribute 'attr'	"AttributeError: 'FixedPrecisionTensor' object has no attribute 'attr'**Describe the bug**

When I run the demo of Part 11 - Secure Deep Learning Classification from the example.
In cell [12]  `model.fix_precision().share(alice, bob, crypto_provider=crypto_provider)`
I met an error as below:

![ERROR](https://user-images.githubusercontent.com/16660974/58936093-86a5ad80-87a1-11e9-85fe-f0d134bfd777.PNG)

Is that a bug ?

My env details:
python 3.6.8
pytorch 1.0.1
syft 1.12.a1
os WIN10
Let's start by updating PySyft. The latest version is 0.1.17.a1 which is 5 versions after the one you have.@AndyClouder did updating PySyft fix your issue?AttributeError                            Traceback (most recent call last)
<ipython-input-7-5b486064ddb2> in <module>()
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    112     """"""
    113 
--> 114     tfe_model = tfe.keras.Sequential()
    115 
    116     for keras_layer in keras_model.layers:

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\sequential.py in __init__(self, layers, name)
     10   """"""
     11   def __init__(self, layers=None, name=None):
---> 12     super(Sequential, self).__init__(name=name)
     13 
     14     self._layers = []

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in __init__(self, trainable, name, **kwargs)
     51 
     52     self.trainable = trainable
---> 53     self._init_set_name(name)
     54     self.built = False
     55 

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in _init_set_name(self, name, zero_based)
    108   def _init_set_name(self, name, zero_based=True):
    109     if not name:
--> 110       self._name = base_layer_utils.unique_layer_name(
    111           generic_utils.to_snake_case(self.__class__.__name__),
    112           zero_based=zero_based)

AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name'

How can I solve this problem? Thanks.Hi, this error is now related to #2255 
I will therefore close this one, and add you in the other one."	4	2019-06-05 06:52:43	2019-06-09 15:38:16	2019-06-09 15:38:16
https://github.com/OpenMined/PySyft/issues/2207	[]	Model.copy() is not working properly	"Model.copy() is not working properly**windows 10
python 3.7.3
pytorch=1.0.1
pysyft=0.1.13**
```
#Train Bob's and Alice's Models (in parallel) 

client_copy=[0]*2;
for epoch in range(1, 2):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
        if batch_idx==0:
            bobmodel=model.copy().send(data.location) # <-- NEW: send the model to the rig
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = bobmodel(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step() 
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # <-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
                100. * batch_idx / len(federated_train_loader), loss.data))
```

Give output:-
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.305134
Train Epoch: 1 [1920/60032 (3%)]	Loss: 2.306227
Train Epoch: 1 [3840/60032 (6%)]	Loss: 2.314577
Train Epoch: 1 [5760/60032 (10%)]	Loss: 2.301752
Train Epoch: 1 [7680/60032 (13%)]	Loss: 2.304796
Train Epoch: 1 [9600/60032 (16%)]	Loss: 2.305816
Train Epoch: 1 [11520/60032 (19%)]	Loss: 2.307251
Train Epoch: 1 [13440/60032 (22%)]	Loss: 2.305082
Train Epoch: 1 [15360/60032 (26%)]	Loss: 2.309973
Train Epoch: 1 [17280/60032 (29%)]	Loss: 2.296431
Train Epoch: 1 [19200/60032 (32%)]	Loss: 2.309648
Train Epoch: 1 [21120/60032 (35%)]	Loss: 2.313736
Train Epoch: 1 [23040/60032 (38%)]	Loss: 2.303707
Train Epoch: 1 [24960/60032 (42%)]	Loss: 2.308319
Train Epoch: 1 [26880/60032 (45%)]	Loss: 2.306007
Train Epoch: 1 [28800/60032 (48%)]	Loss: 2.307840
```

While without making copy of model:-
 `bobmodel=model.send(data.location)`
give output 
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.305134
Train Epoch: 1 [1920/60032 (3%)]	Loss: 2.156802
Train Epoch: 1 [3840/60032 (6%)]	Loss: 1.896611
Train Epoch: 1 [5760/60032 (10%)]	Loss: 1.440396
Train Epoch: 1 [7680/60032 (13%)]	Loss: 0.867146
Train Epoch: 1 [9600/60032 (16%)]	Loss: 0.654510
Train Epoch: 1 [11520/60032 (19%)]	Loss: 0.593326
Train Epoch: 1 [13440/60032 (22%)]	Loss: 0.455695
Train Epoch: 1 [15360/60032 (26%)]	Loss: 0.370735
Train Epoch: 1 [17280/60032 (29%)]	Loss: 0.303775
Train Epoch: 1 [19200/60032 (32%)]	Loss: 0.312882
Train Epoch: 1 [21120/60032 (35%)]	Loss: 0.369826
Train Epoch: 1 [23040/60032 (38%)]	Loss: 0.237517
Train Epoch: 1 [24960/60032 (42%)]	Loss: 0.187326
Train Epoch: 1 [26880/60032 (45%)]	Loss: 0.522530
Train Epoch: 1 [28800/60032 (48%)]	Loss: 0.225577
 ```

Model.copy() is not working properly. As loss is not decreasing in same input with model.copy while it is decreasing without copy in starting even before federated averaging.   



Hey, if you have the whole code I'd love to see it to better understand our use case. Should I infer that all the data is owned by bob, as you only the model once per epoch and to bob?

Also, you should update `pytorch=1.0.1 -> pytorch=1.1` and `pysyft=0.1.13 -> pysyft=0.1.15a1`; many changes are happening currently :)[`Link`](https://drive.google.com/file/d/1CnvBwgLMd4W1jtXlT2PBRuGjWQBmHpV0/view?usp=sharing)
If you change this line ""bobmodel=model.send(data.location)"" to ""bobmodel=model.copy().send(data.location)"" then loss is not decreasing.Run the whole code by replacing ""bobmodel=model.send(data.location)"" with ""bobmodel=model.copy().send(data.location)"" you see that loss is not decreasing for latter case.Oh yes of course!
You have given to your optimizer the parameters of the original model, not of the copy, thats why the copy of the model doesn't improve.
Another thing is that during an epoch, you only send once the model to the first worker, so when you will have data batches owned by the other worker, it will fail.

I believe this Issue is solved, if you have other issues related to your use case, please let us know!"	4	2019-05-31 12:30:01	2019-06-01 15:36:20	2019-06-01 15:36:19
https://github.com/OpenMined/PySyft/issues/2202	['bug ']	Error: Tuple of tensors being returned from websockets 	"Error: Tuple of tensors being returned from websockets **Describe the bug**
When invoking a method returning a tuple of tensors on a remote tensor that is stored on a remote **_websocket_**, an error occurs.

**To Reproduce**
Steps to reproduce the error:

1. Startup a remote websocket on the local machine

```
cd 
cd PySyft/examples/tutorials/advanced/websockets-example-MNIST
python3 run_websocket_server.py --id alice --host 127.0.0.1 --port 8777
```


2. In a new terminal, initialize syft and hook the remote websocket
```

import torch
import syft as sy
from syft.workers import WebsocketClientWorker
 
hook = sy.TorchHook(torch)

kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}
alice= WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
```

2. Initialize a tensor and send it to the remote worker:

```
random_tensor = torch.randn(5,3)
remote_tensor = random_tensor.send(alice)
positions, sorted_values = torch.sort(remote_tensor)
```

It seems to be somehow related to the way PySyft returns tuples of tensors. Notice that this issues does not occur on virtual sockets, but just on remote web socket!

Error in the remote console:

![image](https://user-images.githubusercontent.com/4907418/58690123-1d7cff00-8389-11e9-9b04-cf9550c39e95.png)
The reason of this error is that with virtualworkers, a `syft.exceptions.ResponseSignatureError` is sent back from servers workers to the client, which is not supported by socketworkers.
Maybe we would like to handle Exception forwarding through some serialization process.This issue #2214 is related
And #2219 attempts to give fix.HI @DanyEle - should we close?@iamtrask  If it's fixed in #2219, then sure!@DanyEle It is now merged!"	5	2019-05-31 07:45:18	2019-06-04 17:10:33	2019-06-04 17:10:33
https://github.com/OpenMined/PySyft/issues/2177	['bug ']	Fix ambiguous_functions in hook_args	"Fix ambiguous_functions in hook_argsin hook_args if you want to add function to `ambiguous_functions` like stack you need to add `torch.stack` and `stack` while only should be needed `torch.stack`
This is due to an error in overload_torch.py where we don't retrieve the module of functions correctly@LaRiffle could you clarify where the module of functions should be be retrieved in this file? There does not appear to be anything which explicitly checks to see if they are in the exclude_functions listAt l.50 we do
```
# Replace all syft tensor with their child attribute
            new_args, new_kwargs, new_type = syft.frameworks.torch.hook_args.hook_function_args(
                attr.__name__, args, kwargs
            )
```
But ideally we should be replace `attr.__name__` with smthg like `attr.__module__+'.'+attr.__name__`

However hooked functions have a module which is changed and we would like to keep the original module. Note the hooked functions are in hook.py and with @overload.module and @overload.function decorator in tensor definition files.

I'd like to underline that this is not a trivial issue"	2	2019-05-29 10:47:52	2019-11-15 09:17:53	2019-11-15 09:17:53
https://github.com/OpenMined/PySyft/issues/2168	['bug ']	Error: matmul operation with websocket workers	"Error: matmul operation with websocket workersI'm trying to run a [simple code snippet](https://hastebin.com/uhafamejey.py) that applies the matmul method on two SMPC tensors.

But I'm having problems when applying spdz multiplication (more precisely when trying to **reconstruct** the delta and epsilon tensors). 
https://github.com/OpenMined/PySyft/blob/734742554358f5fc8ef6942a4aca042746aafc89/syft/frameworks/torch/crypto/spdz.py#L31-L32

When creating a pp tensor by **sending** the SMPC tensor to the **first worker**.
https://github.com/OpenMined/PySyft/blob/734742554358f5fc8ef6942a4aca042746aafc89/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L178

 I get the following warnings on server side:
`
WARNING:root:Worker remote_worker0 couldn't recognize worker (crypto_provider)
` 
`
WARNING:root:Worker me couldn't recognize worker (remote_worker2)
`
`WARNING:root:Worker me couldn't recognize worker (remote_worker3)`
 

After that, when calling the function **remote_get ()** to get the value of pointer stored on previous worker, my websocket servers throw exceptions. 
https://github.com/OpenMined/PySyft/blob/734742554358f5fc8ef6942a4aca042746aafc89/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L179


If it is a bug, I would like to work on it. But I need someone to help me understand the behavior behind the tensors and workers.

**syft version: 0.1.14a1**I'm on it.Solving this might be moree of a Grid project than a PySyft one - primarily because it will require two people to be able to connect to the same worker and interact with the same tensors on that worker. This requires things like user roles and permission and managing multiple connections.I agree with @iamtrask, I'll close this issue for now and re-open it at [Grid](https://github.com/OpenMined/Grid/)"	3	2019-05-24 20:25:25	2019-05-31 23:10:45	2019-05-31 23:10:44
https://github.com/OpenMined/PySyft/issues/2156	[]	RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()	"RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()In the Part 2: Intro to Federated Learning，have a code running error：RuntimeError: set_storage is not allowed on Tensor created from .data or .detach().
![image](https://user-images.githubusercontent.com/46445562/58070014-03456300-7bca-11e9-9830-bdb9edff42f4.png)
Hey @songchuangyuan,

I've just executed the notebook using PySyft most current version (dev branch) and it works.

Can you check if you're using an updated version of PySyft and re-run the notebook? Thanks!"	1	2019-05-21 05:12:04	2019-06-04 22:00:09	2019-06-04 22:00:09
https://github.com/OpenMined/PySyft/issues/2135	[]	Demo Part 2 Failed	"Demo Part 2 FailedHi,
I just tried the part 2 example here, and it didn't work when calling the second train() and the error message is:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 5, in train
  File ""~/anaconda3/lib/python3.6/site-packages/syft-0.1.14a1-py3.6.egg/syft/frameworks/torch/hook.py"", line 929, in module_send_
  File ""~/anaconda3/lib/python3.6/site-packages/syft-0.1.14a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py"", line 330, in send_
  File ""~/anaconda3/lib/python3.6/site-packages/syft-0.1.14a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py"", line 279, in send
RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()

System info:
OS: Ubuntu 18.04.1 LTS
python version:  3.6.5 :: Anaconda, Inc.
pytorch version: 1.1.0Ok, downgrading pytorch back to version 1.0.0 works...."	1	2019-05-10 22:15:56	2019-05-11 00:22:45	2019-05-11 00:22:45
https://github.com/OpenMined/PySyft/issues/2132	['bug ']	Batchnorm Layer incompatible	"Batchnorm Layer incompatibleI am using trying to the notebook Part 8 - Federated Learning on MNIST using a CNN.ipynb but with a modified model. I have added a batchnorm layer as follows.
'
 class Net(nn.Module):
     def __init__(self):
         super(Net, self).__init__()
         self.conv1 = nn.Conv2d(1, 20, 5, 1)
         self.conv2 = nn.Conv2d(20, 50, 5, 1)
         self.fc1 = nn.Linear(4*4*50, 500)
         self.fc2 = nn.Linear(500, 10)
         self.bn1 = nn.BatchNorm2d(20)
        
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.bn1(x)
        x = F.max_pool2d(x, 2, 2)
        x = F.relu((self.conv2(x)))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)`

I get the following error :
`RuntimeError                              Traceback (most recent call last)
<ipython-input-8-9375ae22719e> in <module>()
      4 optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment
      5 for epoch in range(1, args.epochs + 1):
----> 6     train(args, model, device, federated_train_loader, optimizer, epoch)
      7     test(args, model, device, test_loader)
      8 

7 frames
<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

<ipython-input-5-090f8e67fd65> in forward(self, x)
     11     def forward(self, x):
     12         x = F.relu(self.conv1(x))
---> 13         x = self.bn1(x)
     14         x = F.max_pool2d(x, 2, 2)
     15         x = F.relu((self.conv2(x)))

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)
     58     @weak_script_method
     59     def forward(self, input):
---> 60         self._check_input_dim(input)
     61 
     62         exponential_average_factor = 0.0

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py in _check_input_dim(self, input)
    239     @weak_script_method
    240     def _check_input_dim(self, input):
--> 241         if input.dim() != 4:
    242             raise ValueError('expected 4D input (got {}D input)'
    243                              .format(input.dim()))

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    636                 except BaseException as e:
    637                     # we can make some errors more descriptive with this method
--> 638                     raise route_method_exception(e, self, args, kwargs)
    639 
    640             else:  # means that there is a wrapper to remove

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    630                 try:
    631                     if isinstance(args, tuple):
--> 632                         response = method(*args, **kwargs)
    633                     else:
    634                         response = method(args, **kwargs)

RuntimeError: bool value of Tensor with no values is ambiguous`

This error is I believe related to another issue. #2049 

Any help is greatly appreciated!@SohamMazumder We haven't hooked BatchNorm yet. So you will have to stick to Linear and CNN layers till then :/ I think the .dim() method has been fixed since this issue is open but I have now another error when trying to use Batchnorm with the same modification as above:

---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    157         # Run it
--> 158         new_args = args_hook_function(args)
    159 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in eight_fold(lambdas, args, **kwargs)
    556         lambdas[0](args[0], **kwargs),
--> 557         lambdas[1](args[1], **kwargs),
    558         lambdas[2](args[2], **kwargs),

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

<ipython-input-5-7560ae2ae6d3> in forward(self, x)
     10     def forward(self, x):
     11         x = F.relu(self.conv1(x))
---> 12         x = self.bn1(x)
     13         x = F.max_pool2d(x, 2, 2)
     14         x = F.relu(self.conv2(x))

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/batchnorm.py in forward(self, input)
     74             input, self.running_mean, self.running_var, self.weight, self.bias,
     75             self.training or not self.track_running_stats,
---> 76             exponential_average_factor, self.eps)
     77 
     78     def extra_repr(self):

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    706             cmd_name = f""{attr.__module__}.{attr.__name__}""
    707             command = (cmd_name, None, args, kwargs)
--> 708             response = TorchTensor.handle_func_command(command)
    709             return response
    710 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)
   1621     return torch.batch_norm(
   1622         input, weight, bias, running_mean, running_var,
-> 1623         training, momentum, eps, torch.backends.cudnn.enabled
   1624     )
   1625 

RuntimeError: running_mean should contain 11333 elements not 20
---------------------------------------------------------------------------

Where the 11333 seems to be a bit random (I tried several times and the error does not give the same number each time). Maybe it is now due to the .size() method (#2201)?I think this is the same as #2175, if not feel free to re-open."	3	2019-05-09 08:48:17	2019-06-15 18:50:02	2019-06-15 18:50:02
https://github.com/OpenMined/PySyft/issues/2122	[]	Backpropagation not producing gradients	"Backpropagation not producing gradientsI'm currently working on the implementation of the federated training of a Recurrent Neural Network, and I stumbled upon the following issue: when operating on the remote pointer of the loss function initialized with Negative Log Likelihood, the grad_fn function is not set and it will still say ""requires_grad=True"" despite the loss function being set in the code:

![requires_grad_True](https://user-images.githubusercontent.com/4907418/57189502-f826dd80-6f0f-11e9-9787-f2f8b39be1ae.png)

Instead, in the sequential version or when the input arguments of the loss function are "".get()"", the grad_fn is actually set in the loss function:

![requires_grad_fn](https://user-images.githubusercontent.com/4907418/57189535-40460000-6f10-11e9-8b8d-38f8442a703f.png)


Because of this issue, the backpropagation does not successfully generate all the model's gradient parameters (i.e.: only two parameters are generated in the remote version vs four parameters in the local version), hence preventing the model from converging in the remote version. I looked up if other people are having the same issue, and these pages seem to suggest that the graph is broken (?):  https://discuss.pytorch.org/t/list-model-parameters-0-grad-doubt-in-weight-updates/8422

To reproduce:

```
import torch.nn as nn
import torch
import syft as sy
import numpy as np

hook = sy.TorchHook(torch)  
dani = sy.VirtualWorker(hook, id=""dani"")  
ele = sy.VirtualWorker(hook, id=""ele"") 
workers_virtual = [dani, ele]

criterion = nn.NLLLoss()
output = torch.from_numpy(np.ones((1, 18)))
output.requires_grad_()
output_sent = output.send(dani)

category_single = torch.from_numpy(np.array([2]))
category_sent = category_single.send(dani)
#Non-working version, with requires_grad=True
loss = criterion(output_sent, category_sent) 
print(loss.copy().get()) #Requires_grad=True

#Working version, with grad_fn properly set.
loss_working = criterion(output_sent.copy().get(), category_sent.copy().get()) 
print(loss_working) #grad_fn = NllLossBackward

loss.backward()
```

#model just has 2 parameters with grad != None following the backpropagation. Consequently, during the training process, the model weights are not updated. 

for param in model_ptr.parameters():

Returns an error, as parameters at position [0] is not present.
I've tried to run the snippet above, and I got the following error:

```python
File ""original_syft_bug.py"", line 12, in <module>
    output = np.ones(1, 18)
  File ""/home/marianne/anaconda3/envs/syft/lib/python3.6/site-packages/numpy/core/numeric.py"", line 203, in ones
    a = empty(shape, dtype, order)
TypeError: data type not understood
```

I've changed line 12 to: `output = torch.from_numpy(np.ones((1, 18)))`

And the script doesn't break, it gives me the following output:

```python
tensor(-1., dtype=torch.float64, requires_grad=True)
tensor(-1., dtype=torch.float64, grad_fn=<NllLossBackward>)
```

I'm using syft from dev branch.Thank you for running my example!!
Yes, that's exactly the same output I got too. Isn't the pointed loss supposed to have grad_fn=<NllLossBackward> too? (the first tensor you're showing) . However, the issue is not in the loss per se,  but later on. In fact, after the backpropagation phase, not all the gradients are present as model's parameters in the federated version. (just 2 gradients are present among the model's parameters, whereas in the sequential version there are 4 gradients among the model parameters). So, it actually breaks here. This seems to be the same issue reported at: https://discuss.pytorch.org/t/list-model-parameters-0-grad-doubt-in-weight-updates/8422

```
  for param in model_ptr.parameters():
        #if(param.grad is not None):
        #Daniele: code breaks here, as not all gradient parameters are there
        param.data.add_(-args.learning_rate, param.grad.data)
```

I've attached a full example about my federated code for RNNs (kinda messy though). Bear in mind to change the following line before running it:

`os.chdir(""/home/daniele/py_thesis/RNN_Example"")`


I tried replicating my issue with the hidden layer, the model, the output and the input arguments obtained via the `""copy().get()""` function and the backpropagation seems to be successfully working in that case, with all gradients being present in the model's parameters.

This is the current non-working version:
![image](https://user-images.githubusercontent.com/4907418/57276202-20921180-70a1-11e9-9238-9fa10f6e9201.png)

Working version, with all variables extracted via the .get() function:

![image](https://user-images.githubusercontent.com/4907418/57276561-4bc93080-70a2-11e9-9cc4-b673a307bf07.png)


I presume there could be some issues the PySyft backpropagation function when operating on the remote pointers for such case?I believe the issue is related to the fact that the .grad and .data attributes are still not supported by PySyft, but there seems to be some code about it in syft/frameworks/torch about it. This comment seems to suggest that the .grad and .grad.data tensors are not supported yet?

            # TODO: add .data and .grad to syft tensors

However, it turns out that by de-commenting the following lines in syft/frameworks/torch/hook.py (which were previously commented), the gradients are properly computed following the backpropagation phase.

![image](https://user-images.githubusercontent.com/4907418/57285656-f6961a80-70b3-11e9-8fab-c5bc4cb2ed10.png)



Fixed by #2127, great job @DanyEle!"	5	2019-05-05 06:59:52	2019-05-08 20:19:47	2019-05-08 20:19:47
https://github.com/OpenMined/PySyft/issues/2083	['bug ', 'status: stale :bread:']	Error Creating Tensor of Tensors	"Error Creating Tensor of TensorsYou get an error stating TypeError: Not a Sequence when you create a tensor of tensors. This does not occur when test functions are called manually locally but occurs when Travis is run. I am guessing we haven't hooked the function that is used to create a tensor using tensors. 

`torch.tensor([torch.tensor(1),torch.tensor(2),torch.tensor(3)])`

I get this error too, when creating a tensor of tensors in a custom class. Does anyone have a work around for the moment?I did this 

```
def tensors_to_literals(tensor_list):
    """"""Converts list of torch tensors to list of integers/floats. Fix for not having the functionality which converts list of tensors to tensors
       Args:
           tensor_list[List]: List of torch tensors
        
       Returns:
           literal_list[List]: List of floats/integers
    """"""

    literal_list = []

    for tensor in tensor_list:
        literal_list.append(tensor.item())

    return literal_list
```

Also try using torch.cat to convert list of tensors into a single tensor. Thanks!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	4	2019-04-20 11:56:45	2020-05-25 00:08:56	2020-05-25 00:08:56
https://github.com/OpenMined/PySyft/issues/2081	[]	Problem at encrypted evaluation with remote workers	"Problem at encrypted evaluation with remote workers When I try to implement an encrypted evaluation application using remote workers, I am experiencing the following problems: 

> --- Logging error ---
Traceback (most recent call last):
  File ""/usr/lib/python3.6/logging/__init__.py"", line 994, in emit
    msg = self.format(record)
  File ""/usr/lib/python3.6/logging/__init__.py"", line 840, in format
    return fmt.format(record)
  File ""/usr/lib/python3.6/logging/__init__.py"", line 577, in format
    record.message = record.getMessage()
  File ""/usr/lib/python3.6/logging/__init__.py"", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File ""run_websocket_server.py"", line 48, in <module>
    server = start_proc(WebsocketServerWorker, kwargs)
  File ""run_websocket_server.py"", line 20, in start_proc
    p.start()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 277, in _Popen
    return Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 73, in _launch
    code = process_obj._bootstrap()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""run_websocket_server.py"", line 17, in target
    server.start()
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/websocket_server.py"", line 125, in start
    asyncio.get_event_loop().run_forever()
  File ""/usr/lib/python3.6/asyncio/base_events.py"", line 427, in run_forever
    self._run_once()
  File ""/usr/lib/python3.6/asyncio/base_events.py"", line 1440, in _run_once
    handle._run()
  File ""/usr/lib/python3.6/asyncio/events.py"", line 145, in _run
    self._callback(*self._args)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/websocket_server.py"", line 92, in _producer_handler
    response = self.recv_msg(message)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/base.py"", line 228, in recv_msg
    (msg_type, contents) = sy.serde.deserialize(bin_message, worker=self)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 151, in deserialize
    return _detail(worker, simple_objects)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1227, in _detail
    return detailers[obj[0]](worker, obj[1])
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 612, in _detail_collection_tuple
    pieces.append(_detail(worker, part))
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1227, in _detail
    return detailers[obj[0]](worker, obj[1])
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 426, in _detail_torch_tensor
    chain = _detail(worker, chain)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1227, in _detail
    return detailers[obj[0]](worker, obj[1])
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1014, in _detail_additive_shared_tensor
    owner=worker, id=tensor_id, field=field, crypto_provider=worker.get_worker(crypto_provider)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/base.py"", line 594, in get_worker
    logging.warning(""Worker"", self.id, ""couldn't recognize worker"", id_or_worker)
Message: 'Worker'
Arguments: ('alice', ""couldn't recognize worker"", 'crypto_provider')

Apparently, workers are failing to communicate / recognize.

When I replace remote workers with virtual workers, the application works perfectly.

Workers Manager application: https://hastebin.com/ruxuqejabi.py
Start remote workers app: https://hastebin.com/koxukoqoxa.makefile
Web socket server: https://hastebin.com/eciviwijib.pyHey @IonesioJunior, 

I'll have a look at this!@IonesioJunior, I've just tried using the `dev` branch and it works. Can you try again with the most updated version of `dev`?My current settings:
syft == 0.1.12a1
Python == 3.6.7
torch == 1.0.1.post2

The error still persists with these settings, but discarding the possibility of a bug has lessened my effort to find the problem. I believe it's something related to the multiple versions of python / libraries that I use on my machine. I'll dig deeper.
Thank you anyway  :smiley:."	3	2019-04-18 17:05:08	2019-04-19 20:53:02	2019-04-19 20:53:02
https://github.com/OpenMined/PySyft/issues/2076	['bug ']	Search remote data will cause the data being deleted	"Search remote data will cause the data being deletedI've experimented on getting PySyft to work with remote worker with its own dataset.
During these, I found out the `search` from local will cause the data deleted on the remote.

Relevant files in [this gist](https://gist.github.com/feigaoxyz/99dffd2f4336417f83f0cf4e1c80d8fd).

To trigger the error, 
1. First run `python remote.py` in one terminal window
2. Then run `python local.py` from another terminal window

You will see the results:

```sh
$ python remote.py
Objects: {94139650912: tensor([-1.,  2.])
	Tags: x
	Shape: torch.Size([2])}
worker <WebsocketServerWorker id:0 #tensors:1> received SEARCH (b'x',)
worker <WebsocketServerWorker id:0 #tensors:1> received OBJ_DEL 94139650912
Objects: {}
```

```sh
$ python local.py
Local objects before search {}
Search result: [(Wrapper)>[PointerTensor | me:68744693343 -> 0:13527568418]]
Local objects after search {}
```

As the first one showed: the remote worker actually received two actions `SEARCH` and `OBJ_DEL` in correspondence with the search command on Line 20 of local.py.

---

This error can also be reproduced by slightly modifying the `test/test_websocket_woker.py` by searching same term twice, see [L57 of updated test](https://gist.github.com/feigaoxyz/99dffd2f4336417f83f0cf4e1c80d8fd#file-test_websocket_woker-py).This is usually because a function (in this case search()) is returning pointers with self.garbage_collect_data==True. This means that when the pointers are deleted (garbage collected) that it sends a delete command to the remote machine.Have you gotten https://github.com/OpenMined/PySyft/tree/dev/examples/experimental/Federated%20Learning%20Experiment to work on your local setup?Yes, I can get this example working. 

(A side note, perhaps it would be better to have some detail instructions in files to help others running.)@feigaoxyz can you open a new issue (or issues) pointing to parts of the documentation that are not clear? 

Thank you!Hi @iamtrask 

Are you able to reproduce this error from your side?
The simplest way is to replicate the search and asserts again after the first round in [this standard test file for websocket worker](https://github.com/OpenMined/PySyft/blob/4251f728bdff186328b7c24603dedf09e3037230/test/workers/test_websocket_worker.py#L51-L55).
Hi @mari-linhares 

Some of my thoughts on the ""FL experiment"" example as its current state:
1. add a readme to guide user to run the server with either
  - `FLASK_APP=server.py flask run`; or
  - add `app.run()` in `server.py` and run `python server.py`
2. a clean-up on `ipynb`.

I might put a PR when I got some time."	6	2019-04-17 11:40:04	2019-05-17 10:25:10	2019-05-09 17:57:36
https://github.com/OpenMined/PySyft/issues/2071	['bug ', 'status: stale :bread:']	Federating datasets doesn't work with subsets	"Federating datasets doesn't work with subsetsI don't know if this is an issue of general interest but PySyft would be more versatile if it were more agnostic in the way it handles datasets in dataset.federate((...))

I wrote a little tool to convert Subsets (also of ImageFolder datasets) to regular Datasets as a fix but it ain't a pretty solution:

```
class DatasetFromSubset(Dataset):
    def __init__(self, subset):
        data, targets = self.subset_to_dataset(subset)
        self.data = data
        self.targets = targets

    def __len__(self):
        return len(self.targets)

    def __getitem__(self, index):
        return self.data[index, :], self.targets[index]

    @staticmethod
    def subset_to_dataset(subset):
        indices = subset.indices
        targets = subset.dataset.targets

        targets_subset = torch.tensor(
            [targets[ii] for ii in list(indices.data.numpy())]
        )

        # Empty definition
        concat_tensor = None

        dataloader = torch.utils.data.DataLoader(subset, batch_size=2000, shuffle=False)

        for ii, (data, target) in enumerate(dataloader):
            print(ii)

            if ii == 0:
                concat_tensor = data
            else:
                concat_tensor = torch.cat((concat_tensor, data), 0)

return concat_tensor, targets_subset
```Very interesting feature! What kind of subset are you interested in selecting?@iamtrask I assume it is linked to this example: https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py>  What kind of subset are you interested in selecting?
 
I'm using `torch.utils.data.random_split(dataset, size_set)` to split datasets into train, test and validation sets. This basically creates a new class that contains the original dataset and adds a list of indices assigned to each split. 


> I assume it is linked to this example: https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py

Exactly. I'm curious how imbalanced label distributions affect federated / distributed training. 
@2fasc thanks for posting your code. How do I use it to convert an imagefolder dataset to a dataset that I can federate? This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	5	2019-04-15 08:59:34	2020-05-25 00:08:57	2020-05-25 00:08:57
https://github.com/OpenMined/PySyft/issues/2070	['bug ']	Adam causes errors in training loop 	"Adam causes errors in training loop [Related to #1909]

I tracked down the error to 
 'optimizer = optim.Adam(model.parameters(), lr=1e-3)' in my code,  'optimizer = optim.SGD(model.parameters(), lr=1e-3)' works.

My guess is that this is related to me using PyTorch 1.0 .

The code can be found in https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py

```
Traceback (most recent call last):
  File ""/home/fasc/Documents/Distributed_Malaria/src/federated_training.py"", line 143, in <module>
    simple_federated_model()
  File ""/home/fasc/Documents/Distributed_Malaria/src/federated_training.py"", line 66, in simple_federated_model
    federated=True,
  File ""/home/fasc/Documents/Distributed_Malaria/src/auxiliaries.py"", line 111, in train
    optimizer.step()
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/torch/optim/adam.py"", line 94, in step
    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 650, in overloaded_native_method
    response = method(*new_args, **new_kwargs)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 486, in overloaded_pointer_method
    response = owner.send_command(location, command)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 364, in send_command
    _ = self.send_msg(MSGTYPE.CMD, message, location=recipient)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 198, in send_msg
    bin_response = self._send_msg(bin_message, location)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/virtual.py"", line 6, in _send_msg
    return location._recv_msg(message)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/virtual.py"", line 9, in _recv_msg
    return self.recv_msg(message)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 229, in recv_msg
    response = self._message_router[msg_type](contents)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 316, in execute_command
    getattr(_self, command_name)(*args, **kwargs)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 636, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 630, in overloaded_native_method
    response = method(*args, **kwargs)
TypeError: addcmul_() takes 2 positional arguments but 3 were given
```Hmm - it's not totally clear to me why this would be the case. Will require a deeper look. I don't think we have any unit tests around Adam so this might just require new functionality to get working.I'm looking at it right now
First observation: Adam optim works in the setting of https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb if you replace the SGD optim with Adam.Oh actually it fails, but after a certain number of batch iterations
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.303720
Train Epoch: 1 [1920/60032 (3%)]	Loss: 3.148396
Train Epoch: 1 [3840/60032 (6%)]	Loss: 4.953410
Train Epoch: 1 [5760/60032 (10%)]	Loss: 6.552952
Train Epoch: 1 [7680/60032 (13%)]	Loss: 8.274794
Train Epoch: 1 [9600/60032 (16%)]	Loss: 9.585523
Train Epoch: 1 [11520/60032 (19%)]	Loss: 11.709550
Train Epoch: 1 [13440/60032 (22%)]	Loss: 14.805451
Train Epoch: 1 [15360/60032 (26%)]	Loss: 14.508088
Train Epoch: 1 [17280/60032 (29%)]	Loss: 18.298759
Train Epoch: 1 [19200/60032 (32%)]	Loss: 16.543806
Train Epoch: 1 [21120/60032 (35%)]	Loss: 19.365683
Train Epoch: 1 [23040/60032 (38%)]	Loss: 23.546900
Train Epoch: 1 [24960/60032 (42%)]	Loss: 26.782951
Train Epoch: 1 [26880/60032 (45%)]	Loss: 28.923700
Train Epoch: 1 [28800/60032 (48%)]	Loss: 28.413818
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()
---> 10         optimizer.step()
     11         model.get() # <-- NEW: get the model back
     12         if batch_idx % args.log_interval == 0:

~/code/env/pysyft/lib/python3.7/site-packages/torch/optim/adam.py in step(self, closure)
     92                 # Decay the first and second moment running average coefficient
     93                 exp_avg.mul_(beta1).add_(1 - beta1, grad)
---> 94                 exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
     95                 if amsgrad:
     96                     # Maintains the maximum of all 2nd moment running avg. till now

~/code/PySyft/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    650                 # Send the new command to the appropriate class and get the response
    651                 method = getattr(new_self, method_name)
```I suspect there is a bug in the hooking as the loss is increasingOk here is the trouble: Adam uses momentum (actually: second moments of the gradients), which means it stores the gradients in a list and for each batch produces a correction of the current gradient based on the old ones. When changing of batch owner (so in Part 8 of tutorial at the middle of the epoch), you have now gradients from alice which you want to correct with moments of old gradients owned by bob: this is not possible as the data needs to be at the same location and it raises an error, which is here a bit tricky to find.
This is also why momentum is not supported so far on SGD.

The fix for this would probably imply to rewrite the optimizers. This is an important project and maybe could be correlated to the notions of aggregator needed for Federated or Secure Averaging.

Thank you for reporting the error!Is there a way for us to perhaps clear out the momentum as needed? (reset to None)Hey @2fasc - seems like the solution here is to have different optimizers for different machines (one for bob, another for alice, etc.) Eventually we'll write custom Federated optimizers but for now this is the solution :)Fastest way to do this is probably to have a dict of optimizers, the key being the data.location, this would keep the code simpleJust wondering, is this related to #1909 ?@mari-linhares exactly!Yes, according @iamtrask , you can write a optimizer list like Part4 or Par10, then you can use Adam, Adadelta or other optimizer with momentum. @2fasc @LaRiffle I've experienced the increasing loss issues with my Adam as well.

But, since it wasn't raising errors, I tried to see where things went numerically wrong.

Somehow, in Adam's `step()` method, changing this line
```
exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
```
to this line
```
exp_avg_sq.mul_(beta2).add_(grad.pow(2).mul_(1 - beta2))
```

and this line
```
p.data.addcdiv_(-step_size, exp_avg, denom)
```
to this line
```
p.data.add_(exp_avg.div(denom).mul_(-step_size))
```

made it work and the loss decreased with no problem.

So, it seems like `addcmul_()` and `addcdiv_()` functions have issues working with PySyft, but doing what those functions do step by step somehow fixes them.> @LaRiffle I've experienced the increasing loss issues with my Adam as well.
> 
> But, since it wasn't raising errors, I tried to see where things went numerically wrong.
> 
> Somehow, in Adam's `step()` method, changing this line
> 
> ```
> exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
> ```
> 
> to this line
> 
> ```
> exp_avg_sq.mul_(beta2).add_(grad.pow(2).mul_(1 - beta2))
> ```
> 
> and this line
> 
> ```
> p.data.addcdiv_(-step_size, exp_avg, denom)
> ```
> 
> to this line
> 
> ```
> p.data.add_(exp_avg.div(denom).mul_(-step_size))
> ```
> 
> made it work and the loss decreased with no problem.
> 
> So, it seems like `addcmul_()` and `addcdiv_()` functions have issues working with PySyft, but doing what those functions do step by step somehow fixes them.

coolWhen this is fixed remember to remove the TODO at https://github.com/OpenMined/PySyft/blob/319d59c9aa3ab9b8dfda95c42f7dd5978b3bc48a/examples/tutorials/advanced/websockets-example-MNIST/run_websocket_client.py#L55

https://github.com/OpenMined/PySyft/blob/ac3d6172c268e26bf0a7100c6ee0a7f4cc4d8890/examples/tutorials/advanced/Federated%20CIFAR10.ipynb#L465

https://github.com/OpenMined/PySyft/blob/2776cffc619dacf9486584f6e455104d80901928/examples/tutorials/Part%2006%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb#L378Just a small report, I'm running into a similar error, but it appears a few lines earlier:
```
exp_avg.mul_(beta1).add_(1 - beta1, grad)
```

The following error appears:
```
TypeError: add_() takes 1 positional argument but 2 were given
```

So it's to be a more general problem than only specific functions like `addcmul_()` and `addcdiv_()`> Just a small report, I'm running into a similar error, but it appears a few lines earlier:
> 
> ```
> exp_avg.mul_(beta1).add_(1 - beta1, grad)
> ```
> 
> The following error appears:
> 
> ```
> TypeError: add_() takes 1 positional argument but 2 were given
> ```
> 
> So it's to be a more general problem than only specific functions like `addcmul_()` and `addcdiv_()`

I encountered an error in the same line, but it raises 

> syft.exceptions.PureFrameworkTensorFoundError

Syft 0.1.26a1
Torch 1.1.0Any solutions yet?Yes - the solution was the FL Optimizer project. We can close this issue.

On Tue, Mar 17, 2020 at 12:49 PM Aditya Malte <notifications@github.com>
wrote:

> Any solutions yet?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2070#issuecomment-600052348>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEQSAB62MQJMRJT2MQTRH5WW5ANCNFSM4HF52S2Q>
> .
>
Could you give a link please?@aditya-malte 
https://github.com/OpenMined/PySyft/issues/3141
https://github.com/OpenMined/PySyft/pull/3179/files> 
> Yes - the solution was the FL Optimizer project. We can close this issue.
> […](#)
> On Tue, Mar 17, 2020 at 12:49 PM Aditya Malte ***@***.***> wrote: Any solutions yet? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#2070 (comment)](https://github.com/OpenMined/PySyft/issues/2070#issuecomment-600052348)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ABBAZEQSAB62MQJMRJT2MQTRH5WW5ANCNFSM4HF52S2Q> .

Alright, I'll close the issue then"	21	2019-04-15 08:53:42	2020-03-24 13:34:02	2020-03-24 13:34:02
https://github.com/OpenMined/PySyft/issues/2049	['bug ']	Custom Neural Network in Federated Learning	"Custom Neural Network in Federated LearningHi,
I've experienced a problem while replacing the simple Neural Network of the ""Federated CIFAR 10 Example"" with more complex ones - eg. those untrained models in torchvision.models. 

I've replaced `model = Net().to(device)` by 
`import torchvision.models as models; model = models.resnet18()` and left everything else untouched, but at `output = model(data)` I'm always receiving a ""RuntimeError: bool value of Tensor with no values is ambiguous"". 

It seems that the model tries to make a prediction on an empy tensor - however, the tensor should be there, as it's working with the simple model in the tutorial.

Do you have any suggestions? 
Thank you@flo257 Thank you for raising this issue.We haven't particularly thought of developing support for pretrained models from torch vision , but in the near future we will ensure the support for it is taken care of :) Hi @flo257 - it sounds like there's an issue with the way the model is deserialized. In particular, we have to wrap all of our custom tensor types (wrapped by empty tensors). There's no reason why your operation shouldn't work - but it's hard for me to debug without seeing the code. Can you upload what you've got here? How can I reproduce?Sure - I've used the ""Federated CIFAR 10 Example"" here on GitHub from `/examples/tutorials/advanced/`and only changed the line `model = Net().to(device)` into `import torchvision.models as models; model = models.resnet18().to(device)` while leaving everything else untouched. 

You can reproduce this by simply changing this line on the tutorial in the jupyter notebook and start the training process. I think this is related to #2175, I'm closing this for now. Feel free to re-open if after #2175 is fixed this is still a problem."	4	2019-04-09 07:25:00	2019-06-15 18:55:12	2019-06-15 18:55:12
https://github.com/OpenMined/PySyft/issues/2036	[]	Custom Federated Data Loader Tutorial 	"Custom Federated Data Loader Tutorial Create a tutorial explaining how the users could create custom Federated Data Loaders to load their data. Ideally an example of image and text dataset. Example of how this was done with text dataset is given in the <a href=""https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Advanced/Federated%20Word%20Vectors.ipynb"">Federated Word Vectors Tutorial</a> . Is there any major difference in the creation of a federated data loader to a regular pytorch data loader?@mari-linhares There are some minor differences which is why it helps to have a separate tutorial on it. 
For, instance unlike Torch data loader you can't load text inside the training loop and then convert them to torch tensors, you need to convert them beforehand so that they could be sent to the desired workers and there are some attributes that need to be created such as data and target. 
Although they aren't significant it helps to have the user informed about such intricacies and have code reference that works :) Cool, makes sense. Thanks for the great explanation!"	3	2019-04-02 15:25:40	2019-05-02 06:03:48	2019-05-02 06:03:48
https://github.com/OpenMined/PySyft/issues/2009	[]	Configuration of the system	"Configuration of the systemWhile working on `seder` I found out that more and more having a configuration would help when adding workers.
In the case of external workers (Android, web sockets) they do not have direct access to the configuration used when starting the federated setup. Though part of this information can be inserted in the stream sent and received by the workers other is only part of a set of assumptions

Having a configuration when a worker starts would have some benefits as:
* Knowing which serialisation is in use
* Homogenisation of the compression schemes. If a worker cannot use the compression scheme used by other, it could discard itself from the federation
* Check compatibility of backends

The configuration could be sent to a worker when it's first instantiated or when it first connects to a socket server or aggregation server

@mccorby is this still open (in discussion)?
There has not been much of a discussion about it. I still think it will be necessary if we intend to expand PySyft to other systems but we can reopen this if we need to
Or maybe I can come back with a plan :)"	2	2019-03-25 11:25:55	2019-05-05 07:51:28	2019-05-05 07:51:28
https://github.com/OpenMined/PySyft/issues/1992	['bug ']	Urgent: fail gracefully when initializing two VirtualWorker objects with the same id/name	"Urgent: fail gracefully when initializing two VirtualWorker objects with the same id/nameWhen people are introduced to PySyft, they often fall into the mistake (particularly in Jupyter Notebbooks) of initializing a VirtualWorker with the same ID twice. This causes really strange errors because both workers end up co-existing together. We need to modify the VirtualWorker (or perhaps the BaseWorker) API to make it so that this fails gracefully (aka... that the new worker actually becomes the old worker or all intensive purposes)

Aka - we want this code to function normally

bob = sy.VirtualWorker(hook, ""bob"")

x = th.tensor([1,2,3,4,5]).send(bob)

bob = sy.VirtualWorker(hook, ""bob"")

y = th.tensor([1,2,3,4,5]).send(bob)

z = x + y

z.get() # returns [2,4,6,8,10]


We should accomplish this by having both the new ""bob"" and the old ""bob"" point to the same underlying _objects dictionary.
At any moment, you can check all the virtual workers present on your process by retrieving syft.hook.local_worker.(known_workers) as they get automatically added to this list on __init__. Just making a search and returning the already existing one if any should fix the pb@LaRiffle Tried this out. Trying to naively return the known worker with the same id, causes over half of the tests to fail. I am of the impression it might be best to make this simply throw a verbose error for the moment. #2000 for reference to my changes @robert-wagner just tried your solution (#2000) with a small modification and it seems to work, can you check if it makes sense? I've just made the PR #2022. Thanks!"	3	2019-03-13 19:02:05	2019-03-29 14:09:43	2019-03-29 14:09:43
https://github.com/OpenMined/PySyft/issues/1981	[]	bug in Federated learning on MNIST using CNN while loading federated dataset !	"bug in Federated learning on MNIST using CNN while loading federated dataset !Hi,
In the FederatedDataLoader function
on the execution of this  statement
federated_train_loader = sy.FederatedDataLoader( datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])) .federate((bob, alice)), batch_size=args.batch_size, shuffle=True, **kwargs)

It gives this as an ERROR :-

'MNIST' object has no attribute 'federate'

 any suggestion or procedure can help!
Thank you.
Would you mind sharing the complete snippet of code you used?
Thanks!*THIS IS  THE CODE SNIPPET :- *
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

*THIS IS THE ERROR :- *

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-4085cd6569bc> in <module>
      3                    transform=transforms.Compose([
      4                        transforms.ToTensor(),
----> 5                        transforms.Normalize((0.1307,), (0.3081,))
      6                    ]))
      7     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset

AttributeError: 'MNIST' object has no attribute 'federate'
> Would you mind sharing the complete snippet of code you used?
> Thanks!

https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb

 I tried to run exact code from this link but it showed that error.Oh this is strange, and you didn't make any changes in the code or imports ?Hey @Adarshsng, are you still getting errors with the most updated version of syft and torch?Would be cool to see applications of CNN's in the field of construction and project management, nothing to do with bug fixes in code - but a life-saving idea nonetheless. I know most devs focus on merchandise and e-commerce when applying a convolutional, yet there exists a vast library of architecture and blueprints from companies in mech engineerin' (Caterpillar, John Deere, Toyota) that remain in the dark  Hopefully if you manage to debug the FederatedDataLoader you could find time to explore new datasets

Gears Churnin'> > Would you mind sharing the complete snippet of code you used?
> > Thanks!
> 
> https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb
> 
> I tried to run exact code from this link but it showed that error.

link broken.This error appears when you haven't hooked PySyft:
`hook = sy.TorchHook(torch) `
`bob = sy.VirtualWorker(hook, id=""bob"") `

Can you review you did that?"	8	2019-03-08 07:47:39	2019-09-23 14:29:47	2019-09-23 14:29:47
https://github.com/OpenMined/PySyft/issues/1978	[]	 Bug in Federated Learning on MNIST using a CNN	"Bug in Federated Learning on MNIST using a CNNHi, 
In the FederatedDataLoader function, `**kwargs` is passed as a parameter. 
> kwargs = {'num_workers': 1, 'pin_memory': True}

However, the DataLoader function implementation in Pysyft doesn't take `num_workers` and `pin_memory` as arguments as in pytorch. 

> **Hence running this below snippet results in an error:**

> `federated_train_loader = sy.FederatedDataLoader( 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), 
    batch_size=args.batch_size, shuffle=True, **kwargs)`

Shouldn't this argument be removed from this function?Hi, this has been fixed in #1982
The change should be already in dev branch, and next week in master
You can now use this code and it should work!Okay, thanks!"	2	2019-03-06 19:14:44	2019-03-09 13:51:19	2019-03-09 13:45:38
https://github.com/OpenMined/PySyft/issues/1945	[]	Looking for a runnable demo	"Looking for a runnable demoThe tutorial is almost broken, and unfinished.
I'd like to find pieces of example code on federated learning with SMC and DP.
Is there any of them?The tutorials on Federated Learning are very much working :) 

https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials for Torch1 version of PySyft. Currently, Torch 1 supports only federated learning and DP is under experimental which you could review if you would like to. 

 We did have SMPC on our previous version supported for torch 0.3.1 version only.

https://github.com/OpenMined/PySyft/tree/torch_031/examples/tutorials
Thanks a lot.
I'll try on torch_031 branch."	2	2019-02-25 07:33:38	2019-02-26 06:43:42	2019-02-26 06:43:42
https://github.com/OpenMined/PySyft/issues/1919	[]	.get() operation failed	".get() operation failedMy version is
PySyft-dev
Python 3.6.5
Pytorch '1.0.0'
I did the Tutorial Section 1.1 on page https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%201%20-%20The%20Basic%20Tools%20of%20Private%20Deep%20Learning.ipynb

The same code.

import syft as sy
from syft.frameworks.torch.tensors.interpreters import PointerTensor
from syft.frameworks.torch.tensors.decorators import LoggingTensor
import sys
import torch
hook = sy.TorchHook(torch)
from torch.nn import Parameter
import torch.nn as nn
import torch.nn.functional as F

bob = sy.VirtualWorker(hook, id=""bob"")
x=torch.tensor([1,2,3,4,5])
y=torch.tensor([1,1,1,1,1])
x_ptr=x.send(bob)
y_ptr=y.send(bob)
print(bob._objects)
z=x_ptr+x_ptr
print(z)
print(bob._objects)
print(x_ptr)
x_ptr.get()
print(y_ptr)
y_ptr.get()
z.get()
print(bob._objects)

When I do 'z.get()', errors shows below while bob._objects still has tensor z with the same number.

Error log:

Traceback (most recent call last):

  File ""<ipython-input-4-11b60d6ede25>"", line 1, in <module>
    runfile('D:/my_program/python/syft/start_test/test_start.py', wdir='D:/my_program/python/syft/start_test')

  File ""C:\Program_Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 705, in runfile
    execfile(filename, namespace)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""D:/my_program/python/syft/start_test/test_start.py"", line 52, in <module>
    z.get()

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\frameworks\torch\tensors\interpreters\native.py"", line 419, in get
    tensor = self.child.get(*args, **kwargs)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\frameworks\torch\tensors\interpreters\pointer.py"", line 209, in get
    tensor = self.owner.request_obj(self.id_at_location, self.location)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 455, in request_obj
    obj = self.send_msg(MSGTYPE.OBJ_REQ, obj_id, location)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 148, in send_msg
    bin_response = self._send_msg(bin_message, location)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\virtual.py"", line 6, in _send_msg
    return location._recv_msg(message)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\virtual.py"", line 9, in _recv_msg
    return self.recv_msg(message)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 179, in recv_msg
    response = self._message_router[msg_type](contents)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 381, in respond_to_obj_req
    obj = self.get_obj(obj_id)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 362, in get_obj
    raise KeyError(msg)

KeyError: 'Tensor ""16217007849"" not found on worker ""bob""!!! You just tried to interact with an object ID:16217007849 on worker bob which does not exist!!! Use .send() and .get() on all your tensors to make sure they\'reon the same machines. If you think this tensor does exist, check the ._objects dictionaryon the worker and see for yourself!!! The most common reason this error happens is because someone calls.get() on the object\'s pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven\'t already called .get() on this pointer!!!'
Does the code run when it is in the notebook?This is almost certainly because the VirtualWorker was created twice.> This is almost certainly because the VirtualWorker was created twice.

Can you tell me more? I just create bob once by 'bob = sy.VirtualWorker(hook, id=""bob"")'. Where is the other one? Do you mean that one 'hook = sy.TorchHook(torch)'? In the tutorial, you say that create 'me' (<VirtualWorker id:me #tensors:0>) automatically. But does it affact 'bob'? I saw 'z' belongs to 'bob' by the command 'print(z)' and can't get back.
Or can you tell me the right case?
Thank you!> Does the code run when it is in the notebook?

I run it in my spyder.I saw what happened. This happened just because I runed it twice on my spyder. Maybe this was what iamtrask said 'the VirtualWorker was created twice'.
This program can only run once on your python or restart it!!
Thank you all for help!"	5	2019-02-19 07:30:21	2019-02-20 07:55:53	2019-02-20 07:55:53
https://github.com/OpenMined/PySyft/issues/1910	['bug ']	Moving the result of an operation fails	"Moving the result of an operation failsI am using syft 0.1.0a1
                   torch 1.0.0
                   python 3.7
In IPython (spyder):

This minimal example fails:
```
from __future__ import print_function
import torch
import syft as sy


hook = sy.TorchHook(torch)
ss=sy.VirtualWorker(hook, id=""secure-server"")
w=sy.VirtualWorker(hook, id=""worker"")

#local data
t1=torch.tensor([1,1,1,1])
t2=torch.tensor([2,2,2,2])
z=torch.tensor([0.,0.,0.,0.])



#all necessary inputs are sent to w
t1=t1.send(w)
t2=t2.send(w)
z_w=z.send(w)

#sending z also to the secure server
z_ss=z.send(ss)

#Performing operations locally on worker w
t3=t1+t2
print(w._objects)

#This runs
t1.move(ss)
print(w._objects)
t2.move(ss)
print(w._objects)
z_w.move(ss)
print(w._objects)


#This never runs
t3.move(ss)
```

The error message I get is:
```
  File ""<ipython-input-1-2a2f4c66bf55>"", line 42, in <module>
    t3.move(ss)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 390, in move
    self.owner.send_command(message=(""mid_get"", ptr, ()), recipient=location)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 316, in send_command
    response = self.send_msg(MSGTYPE.CMD, message, location=recipient)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 144, in send_msg
    bin_response = self._send_msg(bin_message, location)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py"", line 6, in _send_msg
    return location._recv_msg(message)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py"", line 9, in _recv_msg
    return self.recv_msg(message)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 174, in recv_msg
    response = self._message_router[msg_type](contents)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 266, in execute_command
    tensor = getattr(_self, command)(*args, **kwargs)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 353, in mid_get
    del self.owner._objects[tensor.id]

KeyError: 39375020161
```
But the referred key is exactly the address that appears by doing t3.id_at_location. Is it intended behavior ?I've just executed the script with no error, probably this was naturally fixed by time. @LaRiffle, @robert-wagner Closing this, since I believe it's fixed in syft 0.1.13a1."	2	2019-02-14 14:43:02	2019-05-05 03:49:04	2019-05-05 03:48:00
https://github.com/OpenMined/PySyft/issues/1909	['bug ', 'status: stale :bread:']	Optimizer and momentum for remote tensors	"Optimizer and momentum for remote tensorsAs you know, optim with momentum keeps old gradients in a buffer.
However, when gradients are pointers, it becomes really tricky if you move the parameters from a worker to another, which is exactly what we do in tutorial Part 8. Let's say you move from bob to alice, then you will try to update parameters at alice using a buffer containing pointers to bob, and you get in real trouble.

So, how should we handle this? Drop the buffer by hand? Having different optimizers and different models? Or another solution?Any updates for this?I think this was solved by #3179, where each worker now maintains it's own optimizer. However I'm pretty new here so I may be missing something.I'm not sure that #3179 was intended to add full support for momentum-based optimizers. It certainly seems like a step in the right direction, but it's not clear that momentum-based optimizers are fully compatible with the rest of PySyft.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days."	4	2019-02-14 10:51:34	2020-05-25 00:09:17	2020-05-25 00:09:17
https://github.com/OpenMined/PySyft/issues/1906	[]	Where should I hook? Choosing the right level.	"Where should I hook? Choosing the right level.I'm currently working with fixed precision tensors (see PR #1897).
In this PR, I had to unhook nn.Linear because it contains the operation `a*x + b`. Indeed, multiplication should be controlled at the fixed precision level (for truncation after multiplication) which you can't do if you hook Linear. Because if you do, then `a*x + b` happens on the LongTensors which are below the precision tensor and the aggregation result is unusable.

Example:
 a = 2.0, x = 3.0, b = 1.0, precision_fractional = 3
 - without hook on Linear:
    a*x + b = [(2000 * 3000) / 10e3 + 1000 ] / 10e3 = 7.0
 - with hook on Linear
    a*x + b = [(2000 * 3000)  + 1000 ] / 10e3 = 6001.0

So there are some tensors like MPC or precision which can't handle ""high level"" functions, but they can deal with the native implementation of these functions (typically nn.Linear). So I'm incline to think that we could have a double level of hooking: a high level hook (typically you want pointer to handle nn.Linear and not to send the details operations of it; so hook every thing you can) and low-level hook (typically you want the precision tensor to understand what is the recipe for doing nn.Linear with low-level operations [and you definitely don't want to rewrite the recipe which is already in torch.nn.functional]; so hook nothing but low-level ops that you can handle specifically).TODO: make this string comparison more efficient

https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/tensors/interpreters/precision.py#L190solved by #2005"	2	2019-02-13 10:56:10	2019-03-28 08:11:21	2019-03-28 08:11:20
https://github.com/OpenMined/PySyft/issues/1884	[]	Spelling mistake in the README	"Spelling mistake in the READMEHi,
I was going through the README and found a minor spelling error in Siraj Raval's name. It says Rav**e**l, but should be Rav**a**l. 

Cheers,
PranavHi @pranav-ap,  Just make a PR with corrected spelling.Yeah, its done."	2	2019-02-07 15:24:05	2019-02-08 02:41:23	2019-02-08 02:35:00
https://github.com/OpenMined/PySyft/issues/1880	[]	More Verbose Documentation for PureTorchTensorFoundError and RemoteTensorFoundError	More Verbose Documentation for PureTorchTensorFoundError and RemoteTensorFoundErrorHey @LaRiffle could you clarifiy what you meant in the documentation of these errors. The documentation does not detail their purposeYes you're right I will do this :)Done! in #1892	2	2019-02-06 03:15:14	2019-02-08 22:10:43	2019-02-08 22:10:42
https://github.com/OpenMined/PySyft/issues/1817	['bug ']	Constructor of torch.Tensor is broken in the torch_1 branch	"Constructor of torch.Tensor is broken in the torch_1 branchCurrently in the torch_1 branch we are unable to construct tensors which require gradients (formerly known as variables). The proper way to do this is ` torch.Tensor(<list>, requires_grad=True)` On the current version this returns the error of
```
TypeError                                 Traceback (most recent call last)
<ipython-input-28-35439c5a0d54> in <module>
----> 1 x = torch.Tensor([1,2,3,4,5], requires_grad=True).send(bob)
      2 y = torch.Tensor([1,1,1,1,1], requires_grad=True).send(bob)

TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of:
 * (torch.device device)
 * (torch.Storage storage)
 * (Tensor other)
 * (tuple of ints size, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
 * (object data, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
```@LaRiffle @iamtrask if you had any insight on this issue that would be appreciatedtrask [3:30 PM]
x = torch.tensor([1.,2,3,45], requires_grad=True)

Théo Ryffel [3:30 PM]
`x = torch.tensor([1.,2,3,4,5], requires_grad=True)``

trask [3:30 PM]
:point_up: that works
x = torch.Tensor([1.,2,3,45], requires_grad=True)I am reopening this because we are unable to call send on torch.tensor which means either we need to hook torch.tensor or get pytorch to fix this issue upstream (ideally both) cc @iamtrask Note that hooking `torch.tensor` is not trivial since you can't add any attributes, if you try you get:
`AttributeError: 'builtin_function_or_method' object has no attribute 'my_attr'`
One work around for `owners` could be adding owner as a property:

```
@property
        def owner(self):
            if not hasattr(self, ""_owner""):
                self._owner = hook_self.local_worker
            return self._owner

        @owner.setter
        def owner(self, new_owner):
            self._owner = new_owner
            return self

        tensor_type.owner = owner
```Got this to work by just doing initialization normally then adding the attributes after"	6	2019-01-14 22:23:09	2019-02-05 14:41:31	2019-02-05 14:41:31
https://github.com/OpenMined/PySyft/issues/1816	[]	Issues about Tutorial Part-7	"Issues about Tutorial Part-7When trying to follow the tutorial part 7--Encrypting / Decentralizing the ledger, I found tensors after operation('+' or '-') will lose their dimension, is it the expected behavior, or a bug?
![ledge1](https://user-images.githubusercontent.com/33448800/51094287-974f8a00-17e6-11e9-9a97-19c334472b52.png)
![ledge2](https://user-images.githubusercontent.com/33448800/51094311-b6e6b280-17e6-11e9-9282-b60f9ff5e380.png)
This example is now part of a deprecated branch."	1	2019-01-14 02:27:04	2019-02-05 15:07:27	2019-02-05 15:07:27
https://github.com/OpenMined/PySyft/issues/1813	[]	Boston Housing server-client demo under /examples/torch	"Boston Housing server-client demo under /examples/torchHi, I mat some problems when trying these two demos:

https://github.com/OpenMined/PySyft/blob/master/examples/torch/Boston_Housing_Federated_Training%20with%20Diff%20Privacy%20SERVER.ipynb

https://github.com/OpenMined/PySyft/blob/master/examples/torch/Boston_Housing_Federated_Training%20with%20Diff%20Privacy%20CLIENT.ipynb

On client side, when coming to this line, error shows like this:
![client-side1](https://user-images.githubusercontent.com/33448800/50941363-91446b00-14bf-11e9-90e8-bae686205247.png)

Then when re-running this line, error changes into this:
![client-side2](https://user-images.githubusercontent.com/33448800/50941385-ac16df80-14bf-11e9-8aaa-b68ca71b334f.png)

When re-runing this line again( the 3rd time), error will disappear:
![client-side3](https://user-images.githubusercontent.com/33448800/50941447-e3858c00-14bf-11e9-9354-18f5b29f7f54.png)

Now, on server side, an error appears:
![server-side](https://user-images.githubusercontent.com/33448800/50941489-09ab2c00-14c0-11e9-9c6e-552d04d44819.JPG)

I run server side and client side on two different machines.This notebook has been deprecated on the master branch."	1	2019-01-10 02:12:37	2019-02-05 15:14:46	2019-02-05 15:14:46
https://github.com/OpenMined/PySyft/issues/1809	[]	Make send operations async	"Make send operations asyncThis a sub ticket of #1659. All work is happening in the torch_1 branch.

## Description

Make send operations async and by default raise an error if an on-going operation result is accessed. For this step in the implementation `c` will be a wrapper object (similar to a promise). But at the final implementation `c` will be an object that has an `id` so it can be used for the following operations.

## Async python
Threading is clean and easily readable. But the operational systems control when it's executed not us, and can be especially difficult to deal with shared data structures (structure would need to be locked).

Asyncio looks like a better option: async / await are builtin since python 3.5 and asyncio is an std library.

## Full working example

```
import syft as sy
import torch
hook = sy.TorchHook(torch)

me = sy.torch.hook.local_worker
alice = sy.VirtualWorker()

a = torch.Tensor([1, 2, 3])
b = torch.Tensor([1, 4, 5])

ptr_a = me.send(a, alice)
ptr_b = b.create_pointer(location=alice)
ptr_c = ptr_a + ptr_b  # running async
ptr_y = ptr_c + ptr_b  # raises an exception if previous operation is not done
```
@LaRiffle I've just made the description more clear, let me know if there's anything unclear to you. Thanks for the feedback!i'll be replacing this with a new issue soon which I believe to be stronger."	2	2019-01-08 15:53:59	2019-08-15 14:02:52	2019-08-15 14:02:52
https://github.com/OpenMined/PySyft/issues/1786	[]	Increase Test coverage to fail under 100	"Increase Test coverage to fail under 100Currently test coverage is set to fail under 95 percent. We should try to have tests for everything and manually exclude (using #pragma: no cover) functions or sections of functions which we do not want tested. This gives intentionality to what we are and are not testing.@LaRiffle @Nivek92 @Ogofo @iamtrask Would appreciate your feedback on thisI've been working on having a very high coverage, however at some point you end make a stupid test just to cover a single line which really doesn't gives you much. I'm a bit cautious about using quotes #pragma because it makes the code less readable
I think you can go up to 97% but I would prefer that we spend time doing tests that are really relevant and writing code :)"	2	2018-12-21 16:17:13	2019-02-01 13:39:48	2019-02-01 13:39:48
https://github.com/OpenMined/PySyft/issues/1777	[]	Wrong behavior in comparison operator	"Wrong behavior in comparison operatorPls confirm the behavior below. The behavior seems wrong.

```
import syft as sy

hook = sy.TorchHook(verbose=False)
me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
workers = [bob, alice]

y = sy.FloatTensor([1.]).fix_precision().share(*workers)
x = sy.FloatTensor([-1.]).fix_precision().share(*workers)

print(any(y<0), all(y<0))
print(any(x<0), all(x<0))
# False True
# False True
```Hi @0shimax,

**TL;DR**: I think this is the current expected behaviour, not sure if intended or not, but it seems to be the way that ""wrapper"" tensors are implemented.

To be clear I'm definetly not the best person to say if this is expected behaviour or not, but I would say that if we consider that  `fix_precision` creates a [`FixedPrecisionTensor_`](https://github.com/OpenMined/PySyft/blob/5403658ec2d9a9ea2043c4b3bf09fa23e957735d/syft/core/frameworks/torch/tensor.py#L1223) parent to the FloatTensor which is basically a wrapper to the sy.FloatTensor, it is expected behavior.

The wrapper doesn't behave as a tensor. What I mean with this is that if you compare the tensor values to any number it will not have direct access to the values on the tensor, it will just return a Fixed precision tensor:

```
>>> sy.FloatTensor([-1.0, 1.0, 11]).fix_precision() < 0
[Fixed precision tensor]
```

In other words, if you try to iterate on this tensor it's empty.
```
>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11])]
[-1.0, 1.0, 11.0]

>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11]).fix_precision()]
[]
```

On the other hand if you run the same operation with a Float tensor you'll see:

```
>>> sy.FloatTensor([-1.0, 1.0, 11]) < 0
 1
 0
 0
[syft.core.frameworks.torch.tensor.ByteTensor of size 3]
```
This ""wrapper behaviour"" can be seen in other situations, per instance, if you send a tensor to another virtual worker:

```
>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11]).send(bob)]
[]

>>> sy.FloatTensor([-1.0, 1.0, 11]).send(bob) < 0
FloatTensor[_PointerTensor - id:4734155120 owner:me loc:bob id@loc:23451730700]
```

So the wrapper tensor just return a tensor object, which is basically an empty iterator. If we check the documentation for any and all, we'll see that the default behaviour of the any function is to return False if the iterator is empty, and for the all function to return True.

```
Help on built-in function any in module builtins:

any(iterable, /)
    Return True if bool(x) is True for any x in the iterable.    
    If the iterable is empty, return False.

Help on built-in function all in module builtins:

all(iterable, /)
    Return True if bool(x) is True for all values x in the iterable.    
    If the iterable is empty, return True.
```

To have the expected output in the code snippet you just sent, a option would be to use the child tensors (I'm not sure if this is good practice, but probably not):

```
import syft as sy

hook = sy.TorchHook(verbose=False)
me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
workers = [bob, alice]

y = sy.FloatTensor([1., 2.0]).fix_precision().share(*workers)
x = sy.FloatTensor([-1., -2.0]).fix_precision().share(*workers)

def any_less_than_zero(wrapper_tensor):
    for element in wrapper_tensor.child.child:
        if element <= 0:
            return True
    return False
def all_less_than_zero(wrapper_tensor):
    for element in wrapper_tensor.child.child:
        if element >= 0:
            return False
    return True

print(any_less_than_zero(y), all_less_than_zero(y)) 
print(any_less_than_zero(x), all_less_than_zero(x))
# False False
# True True
```
Hi @mari-linhares,

Thank you for explaining in detail. 
Understand about the behavior. I need to call ""child"" of chain.

Thank you again for describing in detail :)@robert-wagner, @Ogofo any thoughts on this? Maybe close this issue if you think this is intended behaviour?

Thank you! Cheers!In the original comment x and y are both mpc shared variables. We currently do not have the functions any and all implemented for mpc tensors as it leaks information most of the time. This behavior should return an error rather than a result that doesn't make sense @robert-wagner 
Thank you for your kind reply. I got it."	5	2018-12-15 08:35:37	2018-12-18 22:46:17	2018-12-18 22:46:17
https://github.com/OpenMined/PySyft/issues/1756	['bug ']	Tests not Working 	"Tests not Working Tests were working all fine  until recently when I ran `make test` locally. 

I get these errors. Any idea on how I could resolve it?

```
test -e venv/bin/activate || python -m venv venv
Error: Command '['/Users/hrishikesh/Hrishikesh/Projects/PySyft/venv/bin/python', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.
make: *** [venv/bin/activate] Error 1
``` Hmm - I'm really not sure. Maybe try rebuilding your virtual environment?@iamtrask  That did the trick!"	2	2018-12-08 09:35:57	2018-12-31 10:00:51	2018-12-31 10:00:51
https://github.com/OpenMined/PySyft/issues/1725	[]	train() function in 'Intro to Federated Learning.ipynb' example code	"train() function in 'Intro to Federated Learning.ipynb' example codeHi,
First of all, great work Trask! Loving your work. 
I'm following the tutorials and in the Federated Learning notebook example, when passing each worker's dataset to the sent model, shouldn't we pass `data_bob` as a parameter to the function?

I'm talking about the function here :-

```
def train():
    # Training Logic
    opt = optim.SGD(params=model.parameters(),lr=0.1)
    for iter in range(20):
        
        # NEW) iterate through each worker's dataset
        for data,target in datasets:
            
            # NEW) send model to correct worker
            model.send(data.location)

            # 1) erase previous gradients (if they exist)
            opt.zero_grad()

            # 2) make a prediction
            pred = model(data)
```

I think that the function should have a parameter input as `def train(dataset)` in order to pass each worker's data. Am I wrong? Would love to clarify.

Thanks!Hi @miranthajayatilake!!! This function would be greatly improved if the ""model"" and ""datasets"" variables were passed in as a parameter! PR Welcome!Thank you very much for the response! I will look into it."	2	2018-11-23 04:18:31	2018-11-28 05:12:52	2018-11-28 05:12:52
https://github.com/OpenMined/PySyft/issues/1705	[]	Make tests pass	"Make tests passSome tests are failing. 

Fix the appropriate code to make the tests pass.Looks like all tests are passing here

https://github.com/OpenMined/PySyft/pull/1714"	1	2018-11-18 06:36:31	2018-11-20 15:38:45	2018-11-20 15:38:45
https://github.com/OpenMined/PySyft/issues/1699	[]	Add register_obj() to worker	"Add register_obj() to workerThis is a sub issue of #1697 

Objects given as args should be registered by the worker, meaning they should be included in the worker registry `self._objects`


That's already solved by `bob.send_obj(obj, alice)`I'm not sure, send_obj or receive object does not register any object at the moment. Have a look at the register_object method of worker in `master` to see the former registration process.What's missing in comparison to the original register_object method is the creation of a pointer and changing the owner of the obj. 

Other than that it will add the object to the _object dictionary using the id of the obj.

But do we need a seperate method than or wouldn't it be better to adjust one of the existing methods? e.g. the set_obj or recv_msgSometimes you want to register tensors that are included in a rather complex response, like tuples, dictionary which include tensors.
In this case I think a separate  method is useful to handle registration gracefully
But it could also be included in the deserialize logic since we already iterate in the response"	4	2018-11-16 16:08:02	2019-01-09 21:50:27	2019-01-09 21:50:27
https://github.com/OpenMined/PySyft/issues/1689	[]	Investigate if pickle for numpy arrays is secure	"Investigate if pickle for numpy arrays is secure@iamtrask is wondering whether pickle is a secure way to serialize numpy arrays.
By default pickle allows for arbitrary code injection so we don't want to use it for normal python objects. We have to investigate further as to whether this concern applies to numpy.I looked into it and found

https://intoli.com/blog/dangerous-pickles/ & https://checkoway.net/musings/pickle/ which describe the problem. 

So from my understanding the whole code injection is only a problem if we unpickle user generated data which isn't the case (except they manipulate the message that is send between client and server)

Aside from that I found that pickle.dumps is slower than using .tobytes on the array so I will change it anyway so we are safe on that side either way.

This sounds solved!"	2	2018-11-15 20:12:17	2019-02-05 15:21:11	2019-02-05 15:21:10
https://github.com/OpenMined/PySyft/issues/1647	[]	Downloading datasets via torchvision is not working after hooking	"Downloading datasets via torchvision is not working after hookingHey, please see the attached code.

After hooking torch, the torchvision method to download the MNIST Dataset fails. I can only assume that this is an unintended behavior. After hooking the functionality of torch/torchvision methods should be guaranteed. 

I will work on this issue in the future. 

```
>>> import torchvision
>>> import syft as sy
>>> from syft.core.frameworks.torch import TorchHook
>>> from syft.core.workers import VirtualWorker, SocketWorker
>>> hook = TorchHook(local_worker=SocketWorker(id=1, port=8290, is_pointer=False, is_client_worker=False))
Starting Socket Worker...
Ready to receive commands...
>>> transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))])
>>> root = ""./data""
>>> train_set = torchvision.datasets.MNIST(root=root, transform=transform, download=True)
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Processing...
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/mnist.py"", line 45, in __init__
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/mnist.py"", line 135, in download
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 135, in save
    return _with_file_like(f, ""wb"", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 117, in _with_file_like
    return body(f)
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 135, in <lambda>
    return _with_file_like(f, ""wb"", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 198, in _save
    pickler.dump(obj)
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/tensor.py"", line 131, in __reduce__
    args = self.__getstate__()
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/hook.py"", line 467, in _execute_method_call
    return worker._execute_call(attr, self, *args, **kwargs)
  File ""/Users/Philipp/PySyft/syft/core/workers/base.py"", line 1061, in _execute_call
    wrapper = torch_utils.wrap_command(result)
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 292, in wrap_command
    return type(obj)([wrap_command(o) for o in obj])
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 292, in <listcomp>
    return type(obj)([wrap_command(o) for o in obj])
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 273, in wrap_command
    bind_tensor_nodes(wrapper, obj)
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 258, in bind_tensor_nodes
    wrapper.child = child_obj
AttributeError: 'tuple' object has no attribute 'child'
```Great find!"	1	2018-10-29 14:05:39	2018-12-06 19:36:48	2018-12-06 19:36:48
https://github.com/OpenMined/PySyft/issues/1645	[]	Variable-Tensors are not completely removed from the receiver after get()	"Variable-Tensors are not completely removed from the receiver after get()Hey, check out this quick example:

```
import syft as sy
import torch
from torch.autograd import Variable as Var
hook = sy.TorchHook(verbose=True)
me = hook.local_worker
bob = sy.VirtualWorker(id=""Bob"", hook=hook, is_client_worker=False)
x_var = Var(torch.FloatTensor([1,2,3,4]))
print(bob._objects)

>>>> {}

x_var.send(bob)
print(bob._objects)

>>>> {
           59413128941: [_LocalTensor - id:59413128941 owner:Bob], 
           54679542725: [_LocalTensor - id:54679542725 owner:Bob], 
           49424246791: [_LocalTensor - id:49424246791 owner:Bob], 
           84172249055: [_LocalTensor - id:84172249055 owner:Bob]
     }

x_var.get()
print(bob._objects)

>>>> {84172249055: [_LocalTensor - id:84172249055 owner:Bob]}
```

Registering a variable creates 4 objects in the local registry (`base.py:register(self, result)`). `get()`only triggers `de_register()` on the three of them, leaving out `self.register(variable.grad.data.child)`. I'm not sure wether the issue is in `get()` or within the `de_register()` method, but I would like to fix this issue. Close please @iamtrask."	1	2018-10-29 08:22:53	2018-11-02 11:04:36	2018-11-02 11:04:36
https://github.com/OpenMined/PySyft/issues/1642	[]	WebSocketWorker example code doesn't work	"WebSocketWorker example code doesn't workThe example code from WebSocketWorker docstring breaks. The first line imports TorchHook from a no longer existing module:
```>>> from syft.core.hooks import TorchHook```
The hook is available in syft now. When this is fixed, after a few steps a nonexistent function utils.PythonJSONDecoder is called on the server side. I don't know what else needs to be updated.

There are no tests for this Worker.I'd like to fix this Worker and add a test or two.Are you making any progress on this issue and do you need help?I see a lot of broken code in workers, fixing this is not a ""fun issue"" and may take a little more time.

If you're interested, take a look at [workers_test.py](https://github.com/OpenMined/PySyft/blob/4036adcac0ea20d702d5f9eee314a188b2e297d2/test/core/workers_test.py). There's only one test. ~~Try executing example code from [VirtualWorker's docstring](https://github.com/OpenMined/PySyft/blob/4036adcac0ea20d702d5f9eee314a188b2e297d2/syft/core/workers/virtual.py#L45-L72). It brakes.~~ (I made a mistake. This one works). Adding any worker tests ~~or fixing VirtualWorker~~ would be nice. If you still want to help with workers, maybe try checking other docstring examples and adding tests, so we don't get in each other's way or spend time both doing exactly the same thing.

Or you can take a look at ""good first issues"" here: https://github.com/OpenMined/PySyft/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22

Do you have a branch that you are actively working on or a list of broken things that need to be repaired? That would help us do not get in each other's way. 

A potential issue I found is if the WebSocketWorker is initialized with `is_client_worker=True` which is the default, he will not register any received objects in either `_objects` or `_tmp_objects`. This is because  `set_obj(self, remote_key, value, force=False, tmp=False)`of BaseWorker only allows client worker to register temporary objects, but the `tmp` variable is not set to `True`. The WebSocketWorker and SocketWorker APIs are (at present) quite tricky. As an aside - very open to suggestions for how we could simplify it or have some of the configuration happen automatically. In particular, we use the same class for the Server config of each socket based worker (is_client_worker==False, and it's what actually does the computation) and the Client config (is_client_worker==True) which is just designed to send messages to a particular server.

We also don't yet have this documented in our tutorials section (https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)Yes, I got a little stuck in this issue. We're talking with Ogofo and Nivek92 on Slack. I think this weekend I'll create a pull request with what I have: a correctly failing test and some small incomplete fixes. Or maybe it will be in my repo only, because I think I have no permissions to create a PR to a new branch here and I don't want this to be a pull request to master.Should this issue be closed?Hello!
I think this issue still needs discussion and bigger rewrite. I've been a little out of touch lately and I'm not sure what's the plan exactly. Please don't close it yet.I suggest creating a ticket to implement the WebSocket worker in torch_1 branch. I don't think we should put more work than necessary into an outdated version of the repository :)"	9	2018-10-23 21:27:08	2018-12-20 18:50:26	2018-12-20 18:50:26
https://github.com/OpenMined/PySyft/issues/1592	[]	URGENT: remove all % operators and replace with torch.fmod()	"URGENT: remove all % operators and replace with torch.fmod()@channel - BUG IN PYTORCH 0.3.1

The modulus operator doesn't always work.
https://github.com/pytorch/pytorch/issues/1164

torch.fmod() works correctly
torch.remainder() and the % sign do NOT work.

We need to swap out all uses of % for torch.fmod() prontoI think I can take this. @iamtrask Thank you @ionlights !!Note that % work fine if it's just between two python ints... it's only when it's computing on one or more torch tensors that it's an issueHey @ionlights - how's it goin?:wave: Sorry, got caught up finishing up some assignments due an hour ago. :joy:

I should be able to finish this up towards late afternoon today (Oct 08) in EST."	5	2018-10-04 21:35:47	2018-11-26 15:53:40	2018-11-26 15:53:40
https://github.com/OpenMined/PySyft/issues/1581	[]	Mid-Chain Commands	"Mid-Chain CommandsRight now there's a both ambiguity and a sortof barrier to doing some API calls on the middle sections of chains. For example, if I have:

x = Pointer[bob] -> Pointer[alice] -> Pointer[james] -> LocalTensor[bill]

if would be really nice if I could call

y = x.child.get()

which would return a new chain ""y"" which equals

Pointer[bob] -> Pointer[alice] -> LocalTensor[bill]

Basically - the idea being that we should be able to dynamically point to parts of the chain we want to make calls on. This is particularly true for complex MPC protocols which often require an ""orchestrating party"" such as a crypto provider to request that tensors be moved around to which it does not have direct access.So it's almost like we want a .get() which copies the pointer locally instead of deleting the one that's also somewhere else. Then we can overload Pointer.child with that method. That way, if you go:

x.child

then you get another pointer but it doesn't get registered locally and it doesn't delete the pointer that exists on the other worker. It just copies the remote x.child object to the local machine.This has been solved in torch_1"	2	2018-09-29 14:58:43	2019-02-05 15:07:27	2019-02-05 15:07:26
https://github.com/OpenMined/PySyft/issues/1542	[]	Tensors shouldn't store information about commands	"Tensors shouldn't store information about commands## Context
The _PlusIsMinusTensor has been created as a canonical example of what can be done by extending the SyftTensor.However, it does not make sense that we modify the behaviour of commands from an argument.

This underlines that the architecture is very much argument oriented, which is excellent when we send tensor or transform them in MPCTensor, but rather unefficient and complicated when we want to execute command on them.

Idea: using contexts defining workers involved and mpc. PR #1543 https://github.com/OpenMined/PySyft/pull/1543 gives extended explanation of a possible solution.

A typical example would be:
```
x = sy.FloatTensor([1.2])

#x.send(bob) #<- This is what you don't need to do

with sy.session(bob):
    # Here all the commands and ensors are sent to bob
    z = torch.add(x, x)

#z.get() or x.get() #<- This is what you don't need to do

print(z) # This is FloatTensor
```^^^^ I just added an example of what I meant by context.I assume we'll be leaving in .send() and .get() as backups? There are some cases when it will be very challenging to use the indented case (such as when you're working with tensors in multiple places at once or pointers to pointers.Exactly, .send() and .get() will be kept. Sending a tensor to bob before opening a context session with bob for example means that when the session ends, that tensor still is at bob (example: the data when doing training over epochs).
If you have two remote datasets at bob and alice as it is the case in most of our examples, you would probably iterate on each batch, and depending of whom stores it, you would open the appropriate remote session."	3	2018-09-21 20:00:46	2019-02-05 15:17:02	2019-02-05 15:17:02
https://github.com/OpenMined/PySyft/issues/1513	[]	Add Subtraction, Negation, and Power function to MPCTensor	"Add Subtraction, Negation, and Power function to MPCTensorIn this project, I'll be adding several basic operators to MPCTensor.got sub working 

    def __sub__(self, other):
        gp_response = spdz.spdz_add(self.shares, spdz.spdz_neg(other.shares))
        response = _MPCTensor(gp_response).wrap(True)
        return response

Maybe the question of negative values is related as well:
trt this:
```
x = torch.LongTensor([3])
y = torch.LongTensor([-5])

mpc_x = x.share(alice, bob)
mpc_y = y.share(alice, bob)

mpc_z = mpc_x + mpc_y
mpc_z.get()
```
You get a negative value -2 because I did a hacky fix, but without it because of the modulo you would have <field_value> - 2I might skip pow since torch.LongTensor doesn't seem to have it either.Hit a speedbump - this seems to fail

```
x = torch.LongTensor([[1, 2], [-3, -4]])

x = x.share(bob, alice)

z = -x
assert (z.get() == torch.LongTensor([[-1, -2], [3, 4]])).all()
```z.get() returns

 2.1475e+09  2.1475e+09
 3.0000e+00  4.0000e+00
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]Curiously these work fine

```
x = torch.LongTensor([[1, 2], [3, 4]])

x = x.share(bob, alice)

z = -x
# assert (z.get() == torch.LongTensor([[-1, -2], [3, 4]])).all()

z.get()
```



AND




```
x = torch.LongTensor([[-1, -2], [-3, -4]])

x = x.share(bob, alice)

z = -x
# assert (z.get() == torch.LongTensor([[-1, -2], [3, 4]])).all()

z.get()
```@robert-wagner had some good things to say in Slack

yo - there seems to be an issue with the negation logic in spdz.py

https://github.com/OpenMined/PySyft/issues/1513

bobby [9:08 PM]
Are you decoding the value before checking what it is or just summing the result
Because if you're summing the result it will definitely be wrong for negative numbers

trask [9:10 PM]
i have no idea
lo
def __neg__(self):
       gp_response = spdz.spdz_neg(self.shares)
       response = _MPCTensor(gp_response).wrap(True)
       return response
that's what i did

bobby [9:13 PM]
How is get sum defined? Or I'll be back on laptop in 5

trask [9:13 PM]
sum?
where is sum?

bobby [9:13 PM]
Get_sum
It's on mpc tensor

trask [9:13 PM]
oh - it's defined how you defined it

bobby [9:13 PM]
Theo wrote it

trask [9:13 PM]
def get(self, deregister_ptr=False):
       # TODO: have deregister_ptr do something
       value = self.shares.child.sum_get() % spdz.field
       if (value > spdz.torch_max_value).all(): # TODO: value per value
           return value - spdz.torch_field
       else:
           return value

bobby [9:14 PM]
The comment needs to be fixed
We need to have it do that subtraction on every entry greater than the max value
I'll write up a fix in a few

trask [9:15 PM]
oh - so mask and subtract
ok i'm going to copy paste this into the github issue for referenceMerged in some improvements from Bobby - but they aren't finished yet https://github.com/OpenMined/PySyft/pull/1518

Now whenever i call .get() on an MPC tensor I get an error 
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-14-f01fae6ab1b3> in <module>()
----> 1 z.get()

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py in get(self, deregister_ptr, update_ptr_wrapper)
   1182                     and tensor is not None \
   1183                     and tensor.dim() > 0:
-> 1184                 self.native_set_(tensor)
   1185             torch_utils.fix_chain_ends(self)
   1186             torch_utils.assert_is_chain_well_formed(self)


TypeError: set_ received an invalid combination of arguments - got (torch.FloatTensor), but expected one of:
 * no arguments
 * (torch.LongTensor source)
      didn't match because some of the arguments have invalid types: (torch.FloatTensor)
 * (torch.LongStorage storage)
      didn't match because some of the arguments have invalid types: (torch.FloatTensor)
 * (torch.LongStorage sourceStorage, int storage_offset, torch.Size size)
 * (torch.LongStorage sourceStorage, int storage_offset, torch.Size size, tuple stride)
```Traced the issue to

```
def decode(field_element, precision_fractional=PRECISION_FRACTIONAL, mod=field):
    neg_values = field_element.gt(mod)
    # pos_values = field_element.le(field)
    # upscaled = field_element*(neg_valuese+pos_values)
    field_element[neg_values] = mod - field_element[neg_values]
    rational = field_element.float() / BASE ** precision_fractional
    return rational
```

the .float() casting seems to be the issue. Changing it to 

```
def decode(field_element, precision_fractional=PRECISION_FRACTIONAL, mod=field):
    neg_values = field_element.gt(mod)
    # pos_values = field_element.le(field)
    # upscaled = field_element*(neg_valuese+pos_values)
    field_element[neg_values] = mod - field_element[neg_values]
    rational = field_element / BASE ** precision_fractional
    return rational
```

gets rid of the error but then negative numbers stop working again.

```
x = torch.LongTensor([[-1,2],[3,4]])
x = x.share(bob, alice)
x.get()
```

 ```
2.1475e+09  2.0000e+00
 3.0000e+00  4.0000e+00
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```

Notice that all the numbers are correct except the negative one... makes me think something's broken in decode(). Looking into it now.Ok, made some progress by looking back at what it was before (https://github.com/OpenMined/PySyft/blob/trask2/syft/core/frameworks/torch/tensor.py)

   ```
 def get(self, deregister_ptr=False):
        # TODO: have deregister_ptr do something
        value = self.shares.child.sum_get() % spdz.field
        if (value > spdz.torch_max_value).all(): # TODO: value per value
            return value - spdz.torch_field
        else:
            return value
```

and then just focusing on implementing that TODO there... using some basic masking.

  ```
  def get(self, deregister_ptr=False):
        # TODO: have deregister_ptr do something
        value = self.shares.child.sum_get() % spdz.field

        gate = (value > spdz.torch_max_value).long()

        neg_nums = (value - spdz.torch_field) * gate
        pos_nums = value * (1 - gate)
        result = neg_nums + pos_nums

        return result
```

Seems to be working so far.

```
x = torch.LongTensor([[1,-2],[-3,-4]])
x = x.share(bob, alice)
x.get()

 1 -2
-3 -4
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```going to try testing it with the other functions nowNo dice yet - doesn't work with matrix multiplication

```
x = torch.LongTensor([[1, 2], [3, 4]])
y = torch.LongTensor([[5, 6], [7, 8]])

x = x.share(bob, alice)
y = y.share(bob, alice)

x.mm(y).get()
```

```
-8.4013e+08  3.0743e+08
 9.2008e+08 -5.7132e+08
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```Ok - this piece is kindof annoying - looks like the old version of .get() doesn't work with matrix multiplication anymore either..., something else must have changed

```
x = torch.LongTensor([[1, 2], [3, 4]])
y = torch.LongTensor([[5, 6], [7, 8]])

x = x.share(bob, alice)
y = y.share(bob, alice)

z = x.mm(y)


value = z.child.shares.child.sum_get() % spdz.field

if (value > spdz.torch_max_value).all(): # TODO: value per value
    out = value - spdz.torch_field
else:
    out = value
out
```

```
2.4780e+08  1.2492e+09
 1.0811e+09  5.7968e+08
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```Ok... good news is that the implementation on branch trask2 still works for matrix multiplication... so going to compare the two branches (trask and trask2) to figure out where matrix multiplication differs.Ok, i'm almost completely sure that some other PR has messed up matrix multiplication, so i'm going to check that subtraction and negation work properly and then merge thisfixed by https://github.com/OpenMined/PySyft/pull/1514"	16	2018-09-19 19:37:56	2018-09-20 12:07:51	2018-09-20 12:07:34
https://github.com/OpenMined/PySyft/issues/1511	['bug ']	Bugfix in Matrix Multiplication for MPC	"Bugfix in Matrix Multiplication for MPCimport random
import syft as sy
from syft.core import utils
from syft.core.frameworks.torch import utils as torch_utils
from syft.core.frameworks import encode

from syft.core.frameworks.torch.tensor import _GeneralizedPointerTensor
from syft.mpc import spdz
from syft.core.frameworks.torch.tensor import _MPCTensor
import torch
import torch.nn.functional as F
from torch.autograd import Variable as Var
import json

hook = sy.TorchHook(verbose=True)

me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
james = sy.VirtualWorker(id=""james"", hook=hook, is_client_worker=False)

x = torch.LongTensor([[1,2],[3,4]])
y = torch.LongTensor([[5,6],[7,8]])
xptr = x.share(bob, alice)
yptr = y.share(bob, alice)
z = x.mm(y)


z.child isn't an MPCTensor..., it's just a GeneralizedPointerTensor. Working on a fix.

oh wait... i'm an idiot...


i should have put down xptr.mm(yptr)AhahahThere was a small bug to fix but now it's done - although i noticed that x and y are getting inline modified to become GeneralizedPointerTensors when they probably shouldn't be.Hum yes you're right this should be avoided!"	4	2018-09-19 18:59:00	2018-09-19 19:14:33	2018-09-19 19:09:15
https://github.com/OpenMined/PySyft/issues/1510	[]	Fixed Precision Tensor 	"Fixed Precision Tensor We want the ability to wrap any LongTensor or IntTensor object with a Fixed Precision (decimal point) interpretation. For this, we want to implement a new FixedPrecision tensor type which allows for arbitrary precision.I'm picking this up now - I'm going to focus on something that can wrap any torch tensor (aka, LongTensor or IntTensor) with FixedPrecision features.Picking this up again - got a little distracted by some other more pressing IssuesBasic fixed precision tensor works!

```
x = torch.FloatTensor([0.1, 0.2, 0.3, -0.5]).fix_precision()
y = torch.FloatTensor([1,1,1,1]).fix_precision()
x
```
```
[Fixed precision]

 0.1000
 0.2000
 0.3000
-0.5000
[syft.core.frameworks.torch.tensor.FloatTensor of size 4]
```

```
z = x + y
z
```

```
[Fixed precision]

 1.1000
 1.2000
 1.3000
 0.5000
[syft.core.frameworks.torch.tensor.FloatTensor of size 4]
```"	3	2018-09-19 18:48:20	2018-09-20 16:14:21	2018-09-20 16:14:21
https://github.com/OpenMined/PySyft/issues/1503	[]	Numpy Remote Execution Bug	"Numpy Remote Execution BugIn the process of creating the Numpy Federated Learning Demo (https://github.com/OpenMined/PySyft/blob/master/examples/numpy/Federated%20Learning.ipynb), I discovered that np.dot(a,b) doesn't work for remote numpy arrays while a.dot(b) does. Similarly, I also discovered that a.T does not work with remote tensors but a.transpose() does. Closing this Issue is about getting these functions to work.

To reproduce the error, just run the Federated Learning demo above with the function np.dot() instead of the method x.dot(y) (or similarly for transpose).Ill take it 👍 Hey Ian - how's this PR going? @amit-rastogi is interested in picking it up if you've moved on from the project.Hey @amit-rastogi - Ian messaged me offline that this project is all yours! :)Thanks @iamtrask I'm picking this up."	4	2018-09-19 18:04:59	2019-02-05 15:09:11	2019-02-05 15:09:11
https://github.com/OpenMined/PySyft/issues/1502	[]	MPC Based Secure Aggregation for Federated Learning	"MPC Based Secure Aggregation for Federated LearningThis issue depends on https://github.com/OpenMined/PySyft/issues/1501 being completed.

This issue requires creating a demo using MPC for the secure aggregation of gradients. Multiple different workers should create a weight update (in the usual Federated Learning fashion) but instead of sending the gradients directly to the model owner, they should use MPC to securely aggregate their gradients wherein only the aggregated update is sent to the model owner.

Issue #1501 has been completed - this issue is ready for someone to pick up. I'm dealing with some broken unit tests but i'll pick it up when i'm done if no-one else has.I'm picking this up now."	2	2018-09-19 18:01:09	2018-09-22 22:34:31	2018-09-22 22:34:31
https://github.com/OpenMined/PySyft/issues/1452	[]	Tensor object located at VirtualWorker giving dimension error on being passed throughs DNN	"Tensor object located at VirtualWorker giving dimension error on being passed throughs DNNI am trying to use Federated Learning with DNNs. 
1) Split the data and sent it to Alice and Bob (2 virtual workers)
2) Made a loop which selects datasets for each worker and sends the model to them.
3) On passing the datasets to the model(), I receive a
RuntimeError: dimension specified as 0, but tensor has no dimensions

This error occurs in the forward function of my DNN, where I am trying to create Embeddings.
I do not know if PySyft is compatible with DNNs and embeddings etc. as of now. Any insight would help.

Line of code causing the error: This is inside the forward function in my DNN class.
emb = [getattr(self, 'emb_layer_'+col)(X_d[:,self.deep_column_idx[col]].long())
               for col,_,_ in self.embeddings_input]

This is basically trying to get a list of embedding columns by indexing each required column and passing it through the embedding created with proper dimensions, example, 
emb_layer_userId = nn.Embedding(a, b)  (Created in the init function in the same class)

Also, this code works without PySyft.
PyTorch version 0.3.1
Edit: Tested with test_emb = Embedding(15, 60)
and Variable containing FloatTensor of dimension 667 (Column has 15 unique values, hence used embedding input as 15)My suspicion is that it's the casting that might be broken... I'm not sure I've tried doing .long() before. Perhaps this example will be helpful to you

https://github.com/OpenMined/PySyft/blob/master/examples/SocketWorker%20Boston%20Housing%20Client.ipynbClosing due to inactivity."	3	2018-08-14 12:09:45	2019-02-05 15:18:43	2019-02-05 15:18:43
https://github.com/OpenMined/PySyft/issues/1451	[]	[Pointers are Tensors] Custom made tensors' attributes disappear after conversion	"[Pointers are Tensors] Custom made tensors' attributes disappear after conversion# Issue Template
## Context
### User Story:
Custom made tensors are now easier than ever to make with [pointers are tensors](https://github.com/OpenMined/PySyft/pull/1394). In `_PlusIsMinusTensor` everything works since, we're only overriding the existing methods (in this case torch.add) but if a tensor requires a custom made method if we want to add an attribute to it, they disappear during the conversion from the custom made tensor to torch supported tensor. 

## Expected Behavior

```
import syft as sy
import torch
hook = sy.TorchHook()

x = torch.FloatTensor([2, 4, 2])
x = sy._PlusIsMinusTensor().on(x)
print(hasattr(x.abs(), 'is_plusisminustensor'))

True
```

## Current Behavior

What is the current behavior?

```
import syft as sy
import torch
hook = sy.TorchHook()

x = torch.FloatTensor([2, 4, 2])
x = sy._PlusIsMinusTensor().on(x)
print(hasattr(x.abs(), 'is_plusisminustensor'))

True
```

## Failure Information (for bugs)

Please help provide information about the failure if this is a bug. If it is not a bug, please remove the rest of this template.

### Steps to Reproduce (for bugs)
Simply add `self.is_plusisminustensor` to [this line](https://github.com/OpenMined/PySyft/blob/75402439cfc78238c4bf2bad16dc1b88810c746a/syft/core/frameworks/torch/tensor.py#L496).



### Relevant Literature or Examples (for features)
https://github.com/OpenMined/PySyft/pull/1394The current behavior seems to be the same as the expected behavior. Perhaps another description?This is an issue on a deprecated branch"	2	2018-08-05 16:48:38	2019-02-05 15:17:17	2019-02-05 15:17:16
https://github.com/OpenMined/PySyft/issues/1442	[]	Unable to use nn.RNN module on remote workers. No .shape parameter	"Unable to use nn.RNN module on remote workers. No .shape parameter## Context
I was experimenting with PySyft and RNN's when i got errors. I was unable to use the sent model with data on a remote worker. I did some testing with a very simple RNN. It worked on the local machine, but when it was sent over to a worker it had same error as before. The error i was getting was when the RNN was trying to get the batch size from the input tensor.



**Test Configuration**:

* PySyft Version: 3.1


## Current Behavior

Throws Error Messages


### Steps to Reproduce 

1. creating a float tensor as data
2. reshaping it for rnn input (batch_size,step,seq)
3. Creating the RNN using (torch.nn.RNN)
4. sending data to worker (data.send(worker1))
5. sending model to worker (model.send(worker1))
6. Computing with the data and model (model(data)) ERROR

[Google Colab](https://colab.research.google.com/drive/1K9N74jjsWVwOzlXe97m2_57UrEwA-mOq)
### Failure Logs
[https://gist.github.com/haruza/5a5b021fda1ed5a966ad969c59b00409](https://gist.github.com/haruza/5a5b021fda1ed5a966ad969c59b00409)

Any chance you could copy paste some code to reproduce (or even better... attach a colab?) [Here is the colab](https://colab.research.google.com/drive/1K9N74jjsWVwOzlXe97m2_57UrEwA-mOq)It is a work around by using nn.RNNCell instead of the nn.RNN Brilliant! This is perfect! Thank you so much Ozzy!No problem at all :DHi @iamtrask . I have been receiving the same error. My error occurs when the remote tensor is passed through the Embeddings variable. Is it because PySyft does not support embeddings as of now? Hmmm - honestly not sure yet. We don't support GPU yet though so that could be the problem. Are you running on the CPU or GPU?i believe .shape has been fixed"	8	2018-08-02 10:29:26	2019-02-05 15:10:59	2019-02-05 15:10:59
https://github.com/OpenMined/PySyft/issues/1403	[]	Automatic Documentation Rebuilding	"Automatic Documentation RebuildingWe use Sphynx for the creation of automatic documentation in the PySyft project. The [build.sh](https://github.com/OpenMined/PySyft/blob/master/scripts/build.sh) script will rebuild documentation from scratch (adding any new functionality you've added). This documentation shows up in the [docs](https://github.com/OpenMined/PySyft/tree/master/docs) folder.

The main concern here, however, is that contributors as a whole haven't been rebuilding documentation as they go in Pull Requests. Thus, whenever someone does get around to it, it creates a very challenging PR to read/review because it encapsulates documentation updates for the past several PRs (sometimes many!). 

A great project would be to help resolve this issue using automation, by writing a Github bot or script which will automatically rebuild our documentation whenever we submit or merge a PR.So, I talked to some of my dev friends. Jenkins seems to be the best way to go forward with this. I will do some more research. 
Any ideas and suggestions are welcome.

UPDATE 1. Jenkins would require us to buy a host, looking into CircleCi
https://stackoverflow.com/a/48763205/7127317So I think this portion of the ticket was solved via (https://pysyft.readthedocs.io/en/latest/) - although the documentation itself still seems to be broken."	2	2018-07-16 19:56:39	2018-10-07 11:11:32	2018-10-07 11:11:32
https://github.com/OpenMined/PySyft/issues/1396	[]	N-ary methods/iterable methods do not work remotely	"N-ary methods/iterable methods do not work remotely# Issue Template
## Context
### User Story:
When iterable methods are called on remote objects, the get() method returns an empty tensor. See expected and current behavior for more info.

`torch.stack` and `torch.cat` are great examples of such methods.
[torch.stack](https://pytorch.org/docs/0.3.1/torch.html#torch.stack)
[torch.cat](https://pytorch.org/docs/0.3.1/torch.html#torch.cat)

## Expected Behavior
```
>>> x = torch.FloatTensor([1,2,3,4]).send(remote)
>>> y = torch.FloatTensor([3,4,1,2]).send(remote)
>>> z = torch.FloatTensor([5,2,1,4]).send(remote)
>>> torch.stack([x,y,z]).get()

 1  2  3  4
 3  4  1  2
 5  2  1  4
[torch.FloatTensor of size 3x4]
```

## Current Behavior
What is the current behavior?
```
>>> x = torch.FloatTensor([1,2,3,4]).send(remote)
>>> y = torch.FloatTensor([3,4,1,2]).send(remote)
>>> z = torch.FloatTensor([5,2,1,4]).send(remote)
>>> torch.stack([x,y,z]).get()
[torch.FloatTensor with no dimension]
```
## Failure Information (for bugs)
When iterable methods are called on remote objects, the get() method returns an empty tensor. 
### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)

```
>>> x = torch.FloatTensor([1,2,3,4]).send(remote)
>>> y = torch.FloatTensor([3,4,1,2]).send(remote)
>>> z = torch.FloatTensor([5,2,1,4]).send(remote)
>>> torch.stack([x,y,z]).get()
```



For such methods, arrays are not supported as an argument and a tensor of tensors should be only used.Hey @alhparsa, I'm reopening this.  Maintaining the original semantics of PyTorch is very important, and I think this should be covered when #1395 lands.  We'll close when that happens.Yes, my PR fix this, I will add a unit testdoing this works for stack and cat
torch.stack([x.get(),y.get(),z.get()])

 1  2  3
 2  3  4
 5  6  7
[torch.FloatTensor of size 3x3]

I added the unittests based on this.This also works!

```
t = torch.FloatTensor([x,y,z])
torch.stack(t).get()
```
@bartimaeus12 your code actually doesn't apply the function remotely. What it does is that it gets the tensors and then it applies the function locally on them. What we want is something like `torch.stack(some array of arrays or a tensor of tensors).get()` this way the function is applied remotely first and then by calling the `get()` method we receive the data."	5	2018-07-10 15:54:08	2018-07-14 17:30:48	2018-07-14 17:30:48
https://github.com/OpenMined/PySyft/issues/1391	[]	torch.matmul does not work when the output is numeric	"torch.matmul does not work when the output is numeric# Issue Template

## Context
### User Story:
torch.matmul does not work when the output is numeric.


Please delete (for bugs) or (for features) sections that are not relevant to the Issue you are creating.

Please provide any relevant information about your setup. This is important in case the issue is not reproducible except for under certain conditions.

**Test Configuration**:
* CPU:
* GPU:
* PySyft Version:
* Unity Version:
* OpenMined Unity App Version:


## Expected Behavior

the output should be 16.0.
## Current Behavior

What is the current behavior?

`    registration, torch_type, var_data, var_grad = response
ValueError: not enough values to unpack (expected 4, got 1)`
## Failure Information (for bugs)

Please help provide information about the failure if this is a bug. If it is not a bug, please remove the rest of this template.

The `_execute_remote_call` function in `hook.py` expects a tensor as an output, but the output is just a numeric value.

### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)


```
from syft.core.hooks.torch import TorchHook
from syft.core.workers import VirtualWorker
import torch

hook = TorchHook()
local = hook.local_worker
remote = VirtualWorker(hook, 1)
local.add_worker(remote)

x = torch.FloatTensor([1, 2, 3, 4])
y = torch.FloatTensor([1, 2, 1, 2])
x.send(remote)
y.send(remote)
z = torch.matmul(x, y)
print(z.get())
```

Solved! https://github.com/OpenMined/PySyft/pull/1393"	1	2018-07-07 08:26:50	2018-07-10 14:47:09	2018-07-10 14:47:08
https://github.com/OpenMined/PySyft/issues/1386	[]	Remote operations don't work for fixed-precision variables	"Remote operations don't work for fixed-precision variables### User Story:
Mathematical operations are not applied properly when they're performed remotely on the variables.


## Expected Behavior

The output should be:

```
Hooking into Torch...
Overloading complete.

 2.0000e+07
 4.0000e+07
 6.0000e+07
 8.0000e+07
 1.0000e+08
[torch.LongTensor of size 5]

```
## Current Behavior

What is the current behavior?

```
Hooking into Torch...
Overloading complete.

 1.0001e+07
 2.0002e+07
 3.0003e+07
 4.0004e+07
 5.0005e+07
[torch.LongTensor of size 5]

```
## Failure Information (for bugs)

Regular torch operations are applied when variables are only available remotely and fixed-precision operations are not called. 

### Steps to Reproduce (for bugs)


```
import torch
from syft.core.hooks import TorchHook
hook = TorchHook()
from syft.core.workers import VirtualWorker

local = hook.local_worker
remote = VirtualWorker(id=1,hook=hook)
local.add_worker(remote)

hook = TorchHook(verbose=False)

x = torch.FloatTensor([1, 2, 3, 4, 5]).set_precision(3)
y = torch.FloatTensor([1, 2, 3, 4, 5]).set_precision(7)

y.send(remote)
x.send(remote)

z = x + y

z.get()

print (z)

```

### Relevant Literature or Examples (for features)
https://github.com/OpenMined/PySyft/pull/1378When the function method_router is called, line 171 should be:

`if hasattr(self, 'is_pointer') and self.is_pointer and not self.fixed_precision:
`
but then the problem is that the tensor return by line 176 does not have the owner attribute:

`return hook_self._execute_fixed_precision_call(self, _method, args, kwargs)
`

New function is needed to handle remote fixed_precision calls"	1	2018-07-04 15:17:36	2019-02-05 15:10:26	2019-02-05 15:10:26
https://github.com/OpenMined/PySyft/issues/1381	[]	Mnist Example Not Working For GPU	"Mnist Example Not Working For GPU## Context

The new experimental example on training MNIST dataset works fine without GPU. But, throws error messages when GPU is used.

For Working CPU version, see this : https://colab.research.google.com/drive/1cpTIxtebCMRsHEmJreI7ycyzS42OjXM8 
(Run without enabling GPU)

### Test Configuration

Colab Python 3
PyTorch - 0.3.0

### Expected Behavior

The Code should work fine with GPU as it worked with CPU.

### Current Behavior

Throws Error Messages

### Steps to Reproduce

Run the GPU colab notebook link with GPU activated.
 

For GPU version, see this: https://colab.research.google.com/drive/1U6B3mp2dK0gDW1UwlBSVWS0iKF6DNplUWe still haven't Inherited the methods required for it to work on GPU."	1	2018-07-03 12:31:05	2019-02-05 15:06:51	2019-02-05 15:06:51
https://github.com/OpenMined/PySyft/issues/1367	['bug ', 'help wanted :wave:']	Fix up special case of overloading __repr__ to print big tensors	"Fix up special case of overloading __repr__ to print big tensorsChild of OpenMined/Grid#171 and OpenMined/Grid#190 (see those and their discussion for reference/instructions)From the stacktrace below obtained when printing which involves `new___repr__`, it seems that the problem is caused by `row[-truncate:]` which uses the `select()` method on a Tensor, (which we haven't rewritten as it is in the `self.exclude` of the hook) 

`Traceback (most recent call last):`
`  File ""<stdin>"", line 1, in <module>`
`  File ""/Users/ryffel/Documents/Code/PySyft/syft/core/hooks.py"", line 622, in new___repr__`
`    return self.old__repr__()`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/tensor.py"", line 144, in __repr__`
`    return str(self)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/tensor.py"", line 151, in __str__`
`    return _tensor_str._str(self)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py"", line 297, in _str`
`    strt = _matrix_str(self)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py"", line 246, in _matrix_str`
`    strt += __repr_row(row, indent, fmt, scale, sz, n)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py"", line 202, in __repr_row`
`    ' '.join(fmt.format(val / scale) for val in row[-truncate:]) +`
`  File ""/Users/ryffel/Documents/Code/PySyft/syft/core/hooks.py"", line 298, in send_to_workers`
`    if self.is_pointer:`
`AttributeError: 'torch.FloatTensor' object has no attribute 'is_pointer'`

Can't we just fix this by modifying the `new___rpr__` as follows ?

`def new___repr__(self):`
`      _id_in_owners = hook_self.local_worker.id in self.owners`
`      if (hook_self.local_worker in self.owners or _id_in_owners):`
          **tensor_type.is_pointer = False**
`          return self.old__repr__()`
`      else:`
`          ...`

It fixes the basic examples given in the related issues, and passes tests, but I not sure it is ok in general."	1	2018-06-25 20:23:48	2019-02-05 15:07:18	2019-02-05 15:07:18
https://github.com/OpenMined/PySyft/issues/1364	[]	The send method does not work when sending a torch.autograd.Variable to a SocketWorker	"The send method does not work when sending a torch.autograd.Variable to a SocketWorker# The send method does not work when sending a torch.autograd.Variable to a SocketWorker

## Context
When trying to send a torch.autograd.Variable object to a SocketWorker server with the send() method, the program freeze and never ends.
**Test Configuration**:
A Docker container with:
Python 3.6.5
Jupyter Notebook 5.5.0
IPython 6.4.0
PyTorch 0.3.1


## Expected Behavior

The program is supposed to send the object to the server and return the location of the object.

## Current Behavior

The program just block and force me to kill it.

## Failure Information (for bugs)

Here is the StackTrace of the **Server** when I interrupt it:
```
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-1-d8091d55efea> in <module>()
      7                             port=8002,
      8                             is_pointer=False,
----> 9                             is_client_worker=False)

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in __init__(self, hook, hostname, port, max_connections, id, is_client_worker, objects, tmp_objects, known_workers, verbose, is_pointer, queue_size)
   1033             if(not is_client_worker or self.is_pointer):
   1034                 print(""Ready to receive commands..."")
-> 1035                 self._listen()
   1036             else:
   1037                 print(""Ready!"")

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _listen(self)
   1049                 while True:
   1050                     # collapse buffer of messages into a string
-> 1051                     message = self._process_buffer(connection)
   1052 
   1053                     # process message and generate response

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _process_buffer(socket, buffer_size, delimiter)
   1087         # WARNING: will hang if buffer doesn't finish with newline
   1088 
-> 1089         buffer = socket.recv(buffer_size).decode('utf-8')
   1090         buffering = True
   1091         while buffering:
```
Here is the StackTrace of the **Client** when I interrupt it:
```
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-1-821e5d0475a4> in <module>()
     16 target = Var(torch.FloatTensor([[0],[0],[1],[1]]))
     17 
---> 18 remote_data = data.send(remote_worker)
     19 remote_target = target.send(remote_worker)

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in send_(self, workers)
    964                 # TODO: sync or async? likely won't be worth doing async,
    965                 #       but should check (low priority)
--> 966                 hook_self.local_worker.send_obj(self, worker)
    967 
    968             # NEW IS_POINTER STATUS. This line changes the is_pointer flag to true.

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in send_obj(self, obj, recipient, delete_local)
    834         _obj = self.send_msg(message=self.prepare_send_object(obj, delete_local),
    835                              message_type='obj',
--> 836                              recipient=recipient)
    837 
    838         if(delete_local):

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in send_msg(self, message, message_type, recipient)
    147 
    148         self.message_queue = []
--> 149         return self._send_msg(message_wrapper_json_binary, recipient)
    150 
    151     def compile_composite_message(self):

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _send_msg(self, message_wrapper_json_binary, recipient)
   1079         recipient.clientsocket.send(message_wrapper_json_binary)
   1080 
-> 1081         response = self._process_buffer(recipient.clientsocket)
   1082 
   1083         return response

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _process_buffer(socket, buffer_size, delimiter)
   1094                 return line + delimiter
   1095             else:
-> 1096                 more = socket.recv(buffer_size).decode('utf-8')
   1097                 if not more:
   1098                     buffering = False

```

### Steps to Reproduce (for bugs)
The Server code: https://gist.github.com/Kerat/408322d369dc5a21f6cb1a593ba6d658#file-server-py
The Client code: https://gist.github.com/Kerat/408322d369dc5a21f6cb1a593ba6d658#file-client-py
I believe this was fixed."	1	2018-06-25 16:40:16	2018-11-14 16:48:11	2018-11-14 16:48:10
https://github.com/OpenMined/PySyft/issues/1355	[]	Ensure notebooks work as part of travis testing	"Ensure notebooks work as part of travis testingJust a possible feature request. I know with my own repos functions often get changed or moved around an the notebooks get out of date, so it would be useful to have them 'tested' (initially just does nbconvert run without errors)
This would be a great feature to have!@kmader are you in the Slack (http://slack.openmined.org/)? What is your handle?"	2	2018-06-22 08:03:39	2018-06-22 18:42:04	2018-06-22 18:42:04
https://github.com/OpenMined/PySyft/issues/1350	['bug ']	Cannot .send_() Variable objects if .grad != None	"Cannot .send_() Variable objects if .grad != None# Issue Template

## Context

When running the following code,

```
from syft.core.hooks import TorchHook
from syft.core.workers import VirtualWorker
import torch
import torch.nn as nn
from torch.autograd import Variable as Var
import torch.optim as optim
# this is our hook
hook = TorchHook()
local = hook.local_worker
remote = VirtualWorker(id=1,hook=hook)
local.add_worker(remote)

data = Var(torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]))
target = Var(torch.FloatTensor([[0],[0],[1],[1]]))

# model = nn.Linear(2,1)
model = Var(torch.zeros(2,1),requires_grad=True)

# generates grad objects
pred = data.mm(model)
loss = ((pred - target)**2).sum()
loss.backward()

model.send_(remote)
```

## Expected Behavior

I expect that when I call model.send_(remote), that it will send the Variable to the remote VirtualWorker. 

## Current Behavior

It errors out and does not send the variable with the following stacktrace.

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-14-4207de4e45fd> in <module>()
     10 loss.backward()
     11 
---> 12 model.send_(remote)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in send_(self, workers)
    907                                                    owners=self.owners, is_pointer=True)
    908 
--> 909             return hook_self._var_to_pointer(self, hook_self)
    910 
    911         setattr(torch.autograd.variable.Variable, 'send_', send_)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in _var_to_pointer(self, var, hook_self)
    982         print(""_var_to_pointer:"" + str(var.data.id))
    983         if var.grad is not None:
--> 984             self._var_to_pointer(var.grad, hook_self)
    985 
    986         var.data.old_set_(var.data.__class__(0))

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in _var_to_pointer(self, var, hook_self)
    989                                           id=var.data.id,
    990                                           owners=var.owners,
--> 991                                           is_pointer=True)
    992         return var
    993 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in register_object(self, worker, obj, force_attach_to_worker, temporary, **kwargs)
    508             raise RuntimeError(
    509                 'Invalid registry: is_pointer is {} but owners is {} on tensor {}'.format(
--> 510                     obj.is_pointer, obj.owners, obj.id))
    511         # print(""setting object:"" + str(obj.id))
    512         self.set_obj(obj.id, obj, force=force_attach_to_worker, tmp=temporary)

RuntimeError: Invalid registry: is_pointer is True but owners is [0] on tensor 2841986768
```
## Failure Information (for bugs)

Some investigation has indicated that this only happens when attempting to send a variable that has a gradient object attached to it.

### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)

1. Run code above
2. Observe error :)
The troubleshooting for this Issue is at the end of this livestream https://www.twitch.tv/videos/275575625Can close with merged PR!"	2	2018-06-20 22:07:17	2018-06-21 19:03:17	2018-06-21 19:03:17
https://github.com/OpenMined/PySyft/issues/1314	['bug ']	IntTensor methods sin(), cos() are broken	"IntTensor methods sin(), cos() are broken@ChatSam commented on [Wed Jan 31 2018](https://github.com/OpenMined/OpenMined/issues/409)

The IntTensor methods which return objects of type FloatTensor which are sin() and cos() are broken.

<img width=""1105"" alt=""screen shot 2018-01-31 at 12 17 58 am"" src=""https://user-images.githubusercontent.com/6478266/35606314-656cb044-061c-11e8-918a-3d7ea7345cb2.png"">


Claiming this issue #1314. Found a fixPR for the bugfix - https://github.com/OpenMined/PySyft/pull/1315
Added integration tests for the fix -PR -  https://github.com/OpenMined/OpenMined/pull/410"	2	2018-01-31 05:29:41	2018-02-16 17:10:13	2018-02-16 17:10:13
https://github.com/OpenMined/PySyft/issues/721	[]	Stuck in trying to initialize FloatTensor - zmq TCP issue	"Stuck in trying to initialize FloatTensor - zmq TCP issueHi,
Your library looks really great!
I'm trying to follow the basic notebooks, however when initializing a FloatTensor I get a hang --
`target = FloatTensor(data).autograd(True) # my poor code`
```
# stepping into the initialization code (tensor.py):
self.id = int(self.controller.send_json({""objectType"": ""IntTensor"",
                                                     ""functionCall"": ""create"",
                                                     ""data"": list(data.flatten()),
""shape"": self.data.shape})) # --> stuck in this call
```
and then into controller.py:
```
# send the command
        socket.send_json(
            cmd_func(name, params=params))
        # receive output from command
        res = socket.recv_string() --> stuck in this call
```

I guess this happens because I'm behind a proxy. However I set in /etc/environment NO_PROXY=""localhost, localaddress, 127.0.0.1""
(also tried to post a question on [Stack Overflow](https://stackoverflow.com/questions/47966721/python-zmq-open-tcp-socket-stuck-in-recv-string) - no comment yet :(
Much thanks!

Please delete (for bugs) or (for features) sections that are not relevant to the Issue you are creating.

Please provide any relevant information about your setup. This is important in case the issue is not reproducible except for under certain conditions.

**Test Configuration**:
* CPU: Intel Haswell
* GPU: NVidia Titan-X
* PySyft Version:
* Unity Version:
* OpenMined Unity App Version:


## Expected Behavior

Code works

## Current Behavior

Code stuck in wait (I guess)

## Failure Information (for bugs)

Please help provide information about the failure if this is a bug. If it is not a bug, please remove the rest of this template.

### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)

Hi,
Sorry for that. The Unity application wasn't running (failed to import Vuforia) and of course there wasn't TCP server. You can close the issue."	1	2017-12-28 09:21:30	2017-12-28 10:18:17	2017-12-28 10:18:17
https://github.com/OpenMined/PySyft/issues/695	[]	Order pysyft	"Order pysyft### User Story
pysyft.py is currently hard to navigate. We should order it!

### Discussion Points
Obvious route is alphabetic, ignoring __ and __i. 
Inline functions after returning functions and __ixxx__ after __xxx__

We could also put the __xxx__ ops first. And make another exception for __init__.

Thoughts?Also, have we decided whether we want to expose the operators as functions as well?
E.g. def __add__ as well as def add@Floev Good points!
Your navigation strategy sounds good to me. I'd categorize functions according to their job first (e.g. `no_params_func` is a different type of job than `_add_` or `_mul_`), and then reorganize lexicographically as you mention. What do you think?

Also, regarding the exposure of those methods, I think we should do it, so that we are still consistent with PyTorch:
<img width=""393"" alt=""screen shot 2017-12-13 at 22 57 59"" src=""https://user-images.githubusercontent.com/4405152/33974964-8a20abea-e059-11e7-98de-44f30e048333.png"">
@floev I'd like this too. In my PR https://github.com/OpenMined/PySyft/pull/701 (closed now), I ordered lexicographical inside semantic sections. Does this make sense? EditedHow do we feel about the current layout? The file was broken into pieces and seems certainly more organized before."	5	2017-12-13 04:44:23	2018-04-07 21:11:36	2018-04-07 21:11:36
https://github.com/OpenMined/PySyft/issues/393	[]	Paillier tensor multiplication throws an overflow error later during decryption	"Paillier tensor multiplication throws an overflow error later during decryption#### Description:
Paillier tensor multiplication throws an overflow error later during decryption. This happens when both numbers that have been multiplied have fractions.

#### Steps/Code to Reproduce: 

Example:
```
b = PaillierTensor(pk, np.array([10]))
boo = (b*1).decrypt(sk)  #works

b = PaillierTensor(pk, np.array([10]))
boo = (b*1.1).decrypt(sk)  #works

b = PaillierTensor(pk, np.array([10.1]))
boo = (b*1).decrypt(sk)  #works

b = PaillierTensor(pk, np.array([10.1]))
boo = (b*1.1).decrypt(sk)  #overflow
```

#### Other details:
This happen because of a bug in the fixed-point multiplication method `my__mul__` in `he/paillier/keys.py`

I believe #390 is because of the same reason (?)."	1	2017-11-02 19:15:14	2017-11-03 15:53:18	2017-11-03 15:53:18
https://github.com/OpenMined/PySyft/issues/390	[]	"Syft Error detected in PySonar tutorial: ""Sonar - Decentralized Model Training Simulation (local)"""	"Syft Error detected in PySonar tutorial: ""Sonar - Decentralized Model Training Simulation (local)""I am receiving a Decryption Overflow error in Step 3 -> Ln 14 of the tutorial. Even though it's a PySonar tutorial, this is a Syft error. I am having trouble understanding the cause of the error. See below for snapshot.

![image](https://user-images.githubusercontent.com/13172478/32207885-5a6b7c64-bdd5-11e7-95c7-ec16c24afedc.png)
I believe I have pinpointed the issue. Multiplying a Paillier Encrypted array with original elements less than 1, by a scalar less than one, produces the same error. I have reproduced the error by running the following code:

```
pubkey,prikey = KeyPair().generate(n_length=1024)

x = PaillierTensor(pubkey, np.array([ 0.43188777,
        0.93408112,
        0.72565632,
        0.92994132,
        0.63109912,
        0.68034936,
        0.53725333,
        0.89133874,
        0.89126486,
        0.31854688]))

(x*0.1).decrypt(prikey)
```I reproduced the bug on my machine. Can I take this issue?Commenting out this line:
https://github.com/OpenMined/PySyft/blob/489c3f31d0d1a68ad79632d663acd55e9b9f0136/syft/he/paillier/keys.py#L228
makes the problem go away. This issue is the same as #393.this was resolved with #394 (for the time being, but we should work a bit more on this)"	4	2017-10-31 04:50:02	2017-11-04 03:12:46	2017-11-04 03:12:46
https://github.com/OpenMined/PySyft/issues/383	[]	Implement Default split Functionality for Base Tensor Type.	"Implement Default split Functionality for Base Tensor Type.<!-- Please make sure that you review this: https://github.com/OpenMined/Docs/blob/master/contributing/guidelines.md  -->
<!-- If you are looking to file a bug make sure to look at the .github/BUG_ISSUE_TEMPLATE.md -->


#### User story: 
As a Data Scientist using Syft's Base Tensor type, I want to leverage a default method for computing operations on a Tensor of arbitrary type. For this ticket to be complete `split` should return a new tensor. For a reference on the operation these perform check out [PyTorch's](http://pytorch.org/docs/master/torch.html#torch.split) documentation.

<!-- Provide a detailed explaination about the proposed feature, you can draw inspiration from something like this: 
https://github.com/OpenMined/PySyft/issues/227 or https://github.com/OpenMined/PySyft/issues/12 -->

#### Acceptance Criteria: 

<!-- Provide an outline af all the things that needs to be addressed in order to close this Issue,
be as descriptive as possible -->
  - [x] If the Base Tensor type's attribute ""encrypted"" is set to True, it should return a NotImplemented error.
- [ ] corresponding unit tests demonstrating the correct operation on the Base Tensor type implemented over int and float Tensors.
 - [ ] inline documentation as described over [here](https://github.com/OpenMined/PySyft/blob/85bc68e81a2f4bfc0f0bf6c4252b88d6d7b54004/syft/math.py#L5). 


<!-- Thanks for your contributions! -->
I'll take this!"	1	2017-10-29 15:08:17	2017-11-01 09:04:23	2017-11-01 09:04:23
https://github.com/OpenMined/PySyft/issues/382	[]	Implement Default cross Functionality for Base Tensor Type.	"Implement Default cross Functionality for Base Tensor Type.<!-- Please make sure that you review this: https://github.com/OpenMined/Docs/blob/master/contributing/guidelines.md  -->
<!-- If you are looking to file a bug make sure to look at the .github/BUG_ISSUE_TEMPLATE.md -->


#### User story: 
As a Data Scientist using Syft's Base Tensor type, I want to leverage a default method for computing operations on a Tensor of arbitrary type. For this ticket to be complete `cross` should return a new tensor. For a reference on the operation these perform check out [PyTorch's](http://pytorch.org/docs/master/torch.html#torch.cross) documentation.

<!-- Provide a detailed explaination about the proposed feature, you can draw inspiration from something like this: 
https://github.com/OpenMined/PySyft/issues/227 or https://github.com/OpenMined/PySyft/issues/12 -->

#### Acceptance Criteria:

<!-- Provide an outline af all the things that needs to be addressed in order to close this Issue,
be as descriptive as possible -->
 - [ ] If the Base Tensor type's attribute ""encrypted"" is set to True, it should return a NotImplemented error.
 - [ ] corresponding unit tests demonstrating the correct operation on the Base Tensor type implemented over int and float Tensors.
 - [ ] inline documentation as described over [here](https://github.com/OpenMined/PySyft/blob/85bc68e81a2f4bfc0f0bf6c4252b88d6d7b54004/syft/math.py#L5). 

<!-- Thanks for your contributions! -->
@bharathgs I'd like to take this one up.can I too work on this?"	2	2017-10-29 14:39:56	2017-11-03 07:02:26	2017-11-03 07:02:26
https://github.com/OpenMined/PySyft/issues/353	[]	Encryption design	"Encryption designWe need to consider how we want to design the encryption functionality for Syft.

A lot of objects will have TensorBase members or even higher levels of nesting.
For such objects we want to provide ""encrypt"" and ""decrypt"" functionality, calling the corresponding functions on all its TensorBase and TensorBase-containing members.

This can lead to a lot of code duplication and boilerplate which can be avoided.
One idea would to use Mixins. The ""Encryptable"" mixin offers an ""encrypt"" method that iterates over all the members of the object and recursively calls ""encrypt"" on them, all the way down to TensorBase objects which actually get encrypted.

This is just a proposal, overall we should consider how to approach this problem.

We also need to consider, referring to issue #352, if we also want to encrypt the network hyperparameters (some might be obvious by inspecting object shapes)@MarcoROG If I undestood you correctly, this sounds like a great idea. I think we can judge its merits better when we actually start implementing those “higher level” objects that use Encrypted Tensors. But it looks good from a distance :)
This is inspired by Laravel Php traits. Where you have a Serializable trait/mixin and an attribute containing the list of fields you want that trait to apply to.
I'm fairly new to python (did mostly C++) so I don't know if it's a good pattern for the language"	2	2017-10-18 12:55:47	2017-11-22 23:46:30	2017-11-22 23:46:30
https://github.com/OpenMined/PySyft/issues/350	[]	Organize class methods and functions 	"Organize class methods and functions Currently there is no order of how methods appear, for example, within the TensorBase class and in math.py. There is no strict convention for organizing methods and functions but a general pattern to follow would be: 

<pre>
class SomeClass(object):
    def __magic_methods__(self):
        ""magic methods first, usually in alphabetical order""
    def _private_method(self):
        ""worker methods next, also in alphabetical order""
    def a_method(self):
        ""then normal methods, also in alphabetical order""`
Totally agree with you there! And I will implement this for my Code as well.

I also see a problem with class organization and how they interact with each other, because often the docs aren't sufficient explaining code interactions. I suggest a small diagram or a flow chart to get ppl to get our code faster and of course also easier!I've gone through all the current code and organized it in PR #351, and it might be a good thing to add also to the style guidelines for the project so we can try to stay consistent throughout.  Also totally agree with you, there should be a relatively easy to understand logic behind the class organization. We use draw.io quite frequently at my work for such things, so this could be a good tool for such a task.Sounds like a good idea, Im getting to it on my code!"	3	2017-10-18 09:44:18	2017-10-28 12:02:09	2017-10-28 12:02:09
https://github.com/OpenMined/PySyft/issues/349	[]	Error in tutorial notebook 	"Error in tutorial notebook  
![screenshot from 2017-10-18 01-23-35](https://user-images.githubusercontent.com/3435944/31707696-acd01606-b40a-11e7-832f-d4cc9c5d40c0.png)

1> I could not understand how to pass the ""pubkey"" variable though the function don't take any variable in the implementation 

![screenshot from 2017-10-18 13-49-42](https://user-images.githubusercontent.com/3435944/31707938-4f6a6100-b40b-11e7-97df-24cc9085997c.png)
2>I think  in ModelRepository() call  ipfs=IPFS(host='ipfs')  as previous tutorial This looks related to https://github.com/OpenMined/PySyft/pull/332. I was seeing the same thing, and noticed that there is inconsistency in the way that `encrypt()` was being used across examples in notebooks. I'm not sure exactly what the intended behavior is though, so maybe this needs to be reviewed. 

I think issue raised here is resolved and merged in #332. This issue can be closed."	2	2017-10-18 08:22:08	2017-10-25 11:35:40	2017-10-25 11:35:40
https://github.com/OpenMined/PySyft/issues/283	[]	TensorBase inherit from torch.Tensor	"TensorBase inherit from torch.TensorUser Story A: As a user of PySyft, I want the ability to use PyTorch's autograd on Syft tensors. Specifically, I want the ability to create a tensor ""x"" and then wrap it in a torch.autograd.Variable() object like so (torch.autograd.Variable(x)). As such, TensorBase needs to inherit from torch.Tensor. 

Acceptance Criteria:
- TensorBase inherits from torch.Tensor
- torch.autograd.Variable(a_tensorbase_tensor) works
- demonstrate .backprop() method working on a Variable object.
- notebook demo of a simple 3 layer neural network (with a nonlinearity) working using TensorBase and Variable based backprop.

I would like to take this up@iamtrask i checked this , it seems the Variable does a type check and not an instance check on the object passed to it. So it expects a tensor object as type. If we inherit from torch.Tensor even so the autograd.Variable would be throwing runtime error on passing our TensorBase. I was thinking maybe if we could return a torch tensor using an inbuilt function of our tensorbase like Tensor.numpy() does. Why not use a converter function, that way you can abstract from the TensorBase, so it does not need to know about pytorch, or any other Tensor based library that might come from future compatibility ?

```
def convert_to_torch_tensor(base):
     return # torch.Tensor instance built using base properties
```might want to check this up 
https://gist.github.com/radicalrafi/f2cd121143f6a3967a0d24159b1e09ec

@iamtrask @siarez 
https://github.com/aradhyamathur/PySyft/commit/1c30dc078a5fabe28ad35c4d21f46a352c6d971f could look at this once if this could be the way to go or should look into something else
 your ideas are good guys but remember main focus is encrypted operations from the PoC I showed we can get something going using a conversion as long as the data types are supported by PyTorch because Variable only support the standard types so a Paillier encrypted set won't actually work .yeah exactly i too did a similar implementation in above"	7	2017-10-03 11:13:22	2017-11-22 23:47:02	2017-11-22 23:47:02
https://github.com/OpenMined/PySyft/issues/274	[]	Convert dense matrix to sparse matrix	"Convert dense matrix to sparse matrixThis would speed up my matrix multiplies.can you write down a use case just like @iamtrask does? that would help others understand the issue better.@Ujjwal-9 
By Conversion you mean.
**Converting**:
```
A =
    0     0   11
    22    0    0
    0    33    0
```

**to something like**
```
S =
    (1,0)   22
    (2,1)   33
    (0,2)   11
```

Am I right here?That looks right to me!@iamtrask so what do you suggest?
I think making a new class inheriting from tensorbase and having functionalities like matmul and others.

As in the current scenarios  all the functionalities are present in math.py and the only possibility that I see is either make changes in the code of math.py or make a separate class with separate functionalities.I think that's the right thing to do. This also sounds very similar to PyTorch's sparse tensor implementation as well.we can do this with [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse) and for the above specific format you can check [`scipy.sparse.csr_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) so including this as a function in the *math.py* would probably be sufficient. Also, you might be interested in [this](https://github.com/pytorch/pytorch/issues/2885) and [this](https://discuss.pytorch.org/t/how-to-convert-a-dense-matrix-to-a-sparse-one/7809) @piyush2896 @Ujjwal-9 @bharathgs the second [link](https://discuss.pytorch.org/t/how-to-convert-a-dense-matrix-to-a-sparse-one/7809) you sent displays a limitation that -> The user needs to find the non zero indices to send and make sparse matrix..


```
dense = torch.randn(3,3)
dense[[0,0,1], [1,2,0]] = 0 # make sparse
indices = torch.nonzero(dense).t()
values = dense[indices[0], indices[1]] # modify this based on dimensionality
torch.sparse.FloatTensor(indices, values, dense.size())
```


I think it is redundant. What do you say?
I mean can't just the class (in the above case FloatTensor) getting the values modify the data to a sparse representation directly?@piyush2896 as you must have seen from the first link, pytorch does not let you do this directly(yet), so you have to do something as shown in that example. I think this is a nice feature to have natively, and we could probably put it in _math.py_ .Hey guys, I'd like to join in and help if necessary.Has anyone taken the lead on this? I'd like to help too.I don't get the impression anyone has claimed the leading role for this issue. @fmhall or @ivuckovic if you're interested go ahead and open up a branch (and drop the link here so we can all see it)I created branch on my fork https://github.com/ivuckovic/PySyft/tree/dense_to_sparse_matrix but haven't had time to do any changes, hopefully I'll start in next couple of days.yeh i was also looking forward to do it. But I've been very busy lately. 
Now i am free & would love to do it.😄I'm having problems with tests.
I'm trying to assert.Equal two numpy arrays that should be equal. They are both array(<2x2 sparse matrix of type '<class 'numpy.int64'>' with 1 stored elements in Compressed Sparse Row format>, dtype=object).
When I run test I get following error:
""E       AssertionError: array[60 chars]stored elements in Compressed Sparse Row format>, dtype=object) != array[60 chars]stored elements in Compressed Sparse Row format>, dtype=object)""

Any ides or suggestions how to solve this?"	14	2017-10-01 14:27:51	2017-11-04 02:46:09	2017-11-04 02:46:09
https://github.com/OpenMined/PySyft/issues/244	[]	Input values	Input valuesThe input data only works for values between 0 and 1, when I input values like 1.4 or greater than 1, I see error. Checked tensorbase library but could not debug @gautam1858 can you provide a code to replicate your error?	1	2017-09-21 13:13:47	2017-10-09 12:28:25	2017-10-09 12:28:25
https://github.com/OpenMined/PySyft/issues/241	[]	Close the issues that have been already implemented and merged	"Close the issues that have been already implemented and merged@iamtrask sir there are still many issues opened which have been solved and merged. This is thus causing a problem in finding non-implemented issues to fix.@sajalsubodh22 Can you let me which issues you are talking about? I'll check them out. Sorry about that @sajalsubodh22 !dammit... keep accidentally hitting ""Close and comment""... ironic... since this ticket is about my reluctance to close the right IssuesI don't know if this has been talked outside GH but these are some currently implemented-but-not-closed issues:

* Abs (#20) fixed by #124
* Cumsum (#35) fixed by #136 
* Equal (#40) fixed by #126 
* View (#108) fixed by #193 
* Rsqrt (#90) fixed by #179

ping: @iamtrask & @siarez Right now we are discussing whether we want to conform to PyTorch's conventions. And if not, come up with conventions of our own. In either case some of these functions will most likely have to be moved around. 
Maybe we can defer closing them untill then, or we can close them now and open another issue which addresses the convention issue.Closed. We should address the convention thoughts under the new ticket.
That way we keep the conversation focused in one spot (easier to follow)

On Wed, Sep 27, 2017 at 7:06 PM, Sia Rezaei <notifications@github.com>
wrote:

> Right now we are discussing whether we want to conform to PyTorch's
> conventions. And if not come up with conventions of our own. In either case
> some of these functions will most likely have to be moved around.
> Maybe we can defer closing them untill then, or we can close them now open
> another issue which addresses the convention issue.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/241#issuecomment-332607454>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEIMkpalrFb4djHXk_EdNheInb9juaYEks5smo6ugaJpZM4PeKqa>
> .
>"	6	2017-09-20 16:49:47	2017-10-04 02:39:06	2017-10-04 02:39:06
https://github.com/OpenMined/PySyft/issues/195	[]	TypeError in Paillier Homomorphic Encryption Example	"TypeError in Paillier Homomorphic Encryption ExampleLine 3: `x = pubkey.encrypt(np.array([1.0,2.0,3.0,4.0,5.0]))` throws this error.
I'm not sure if it is an issue with the phe package or PySyft, but I thought I should report it here.

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-f3a92114a210> in <module>()
----> 1 x = pubkey.encrypt(np.array([1.,2.,3.,4.,5.]))

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/keys.py in encrypt(self, x, same_type)
     63                 return np.array(out).reshape(sh)
     64             else:
---> 65                 return PaillierTensor(self, np.array(out).reshape(sh))
     66         else:
     67             print(""format not recognized"")

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/basic.py in __init__(self, public_key, data, input_is_decrypted)
     10         self.public_key = public_key
     11         if(type(data) == np.ndarray and input_is_decrypted):
---> 12             self.data = public_key.encrypt(data, True)
     13         else:
     14             self.data = data

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/keys.py in encrypt(self, x, same_type)
     59             out = list()
     60             for v in x_:
---> 61                 out.append(Float(self, v))
     62             if(same_type):
     63                 return np.array(out).reshape(sh)

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/basic.py in __init__(self, public_key, data)
     59         self.public_key = public_key
     60         if(data is not None):
---> 61             self.data = self.public_key.pk.encrypt(data)
     62         else:
     63             self.data = None

/Users/siavash/anaconda/lib/python3.6/site-packages/phe/paillier.py in encrypt(self, value, precision, r_value)
    169             encoding = value
    170         else:
--> 171             encoding = EncodedNumber.encode(self, value, precision)
    172 
    173         return self.encrypt_encoded(encoding, r_value)

/Users/siavash/anaconda/lib/python3.6/site-packages/phe/paillier.py in encode(cls, public_key, scalar, precision, max_exponent)
    602             else:
    603                 raise TypeError(""Don't know the precision of type %s.""
--> 604                                 % type(scalar))
    605         else:
    606             prec_exponent = math.floor(math.log(precision, cls.BASE))

TypeError: Don't know the precision of type <class 'syft.he.paillier.basic.Float'>.
```The demo notebook needs to change to use PaillierTensor instead (instead of using the public key directly on a numpy array). [PR #213](https://github.com/OpenMined/PySyft/pull/213) resolved this issue."	2	2017-08-31 00:46:38	2017-09-05 18:48:54	2017-09-05 18:48:54
https://github.com/OpenMined/PySyft/issues/194	[]	Import error in “Paillier Homomorphic Encryption Example”	"Import error in “Paillier Homomorphic Encryption Example”The very first line in the file notebook is
`from syft.he.Paillier import KeyPair`
I get an import error. Changing “Paillier” to “paillier” solved the problem. 
Python import has some quirks around case sensitivity on OSX which should be considered. In general “Modules should have short, all-lowercase names. ... ”
https://www.python.org/dev/peps/pep-0008/#package-and-module-namesCan this be my first PR to get my feet wet? certainly! however, i may have accidentally just pushed the fix from syft.he.paillier import KeyPair

my error is No module named 'syft.he'.
how to solve these error?"	3	2017-08-31 00:03:10	2019-04-16 05:35:35	2017-09-01 22:51:14
https://github.com/OpenMined/PySyft/issues/186	[]	Update make run command	"Update make run commandFollowing PR #175 The Docker image is updated without jupyter dependency, but make run has not been updated yet, thus people who run Usage:Start: `make run` will encounter something like this:
```
docker: Error response from daemon: oci runtime error: container_linux.go:262: starting container process caused ""exec: \""jupyter\"": executable file not found in $PATH"".
make: *** [run] Error 127
```
Hey, 

I created a Dockerfile to development local. And a command : 
`make custom  docker=""nameofcontainer"" `

More details in this [Pull Request](https://github.com/OpenMined/PySyft/pull/236)Closed with #270, please check if it works as expected"	3	2017-08-24 20:42:40	2017-10-08 17:49:53	2017-10-08 17:49:22
https://github.com/OpenMined/PySyft/issues/159	['bug ']	serializing with pickle	"serializing with picklePickle is very powerful, and therefore very dangerous. I would strongly suggest not serializing anything remotely related to crypto with it. 

Here is a quick proof of concept to steal a secret being encrypted by altering the public key before serialization. This using the (slightly tweaked) classes from [Paillier.py](https://github.com/OpenMined/PySyft/blob/develop/syft/he/Paillier.py), full code as a [gist](https://gist.github.com/hardbyte/62181849139d22ec0e2c4d9565876d08):

```python
keypair = KeyPair()
keypair.generate()

class DeviousPhePublicKey(paillier.PaillierPublicKey):

    def encrypt(self, x):
        print(""Sending the secret {} to my webserver..."".format(x))
        return super().encrypt(x)

pk_devious = DeviousPhePublicKey(keypair.public_key.pk.n)
pk_syft = PublicKey(pk_devious)

# So far nothing scary... now we serialize and send
# our public key to someone else though...

pk_s = pk_syft.serialize()
pk_reconstructed = PublicKey(pickle.loads(pk_s))
cipher_remote = pk_reconstructed.encrypt(42)

```
Output (assumed to be on a remote machine):
> Sending the secret 42 to my webserver...

Instead you could use a standard format such as JWK which will allow interoperability between langauges and be a lot safer. 

Also have you seen our [paillier keys](http://python-paillier.readthedocs.io/en/stable/serialisation.html#jwk-serialisation) jwk serialisation docs?@iamtrask I am interested in working on this. How do I start?@souravsingh great choice! This is very important functionality!

1) Look for where ""pickle"" is being used anywhere in the project (usually in a method called ""serialize"")
2) at each place, serialize using a better datastructure of your choosing (perhaps a string?)
3) implement the corresponding deserialization function to go with your new serialization  function
4) write unit tests for each!!!
5) Party with beer and pizza!!! (mandatory)

@hardbyte care to add any color re:security and performance?I'd recommend reading the spec that defines JSON Web Keys: [RFC 7517](https://tools.ietf.org/html/rfc7517#section-4)If this is still available, I would like to give it a go."	4	2017-08-19 02:00:04	2017-11-22 23:48:09	2017-11-22 23:48:09
https://github.com/OpenMined/PySyft/issues/158	[]	Adapt to README template	"Adapt to README templateUpdate the `README` to follow the new [README template](https://github.com/OpenMined/Docs/blob/develop/contributing/readme_template.md)

Currently missing
* Usage
* License
* TOCThis applies to all repositories or only PySyft?There's a similar issue for each repository. They should each be 5 minute fixes though :)Issue can be closed after @lucaslopesf commit - https://github.com/OpenMined/PySyft/commit/065a3a2e59ca3ece6acbbea3407cc3ef19584abf ?"	3	2017-08-19 00:17:19	2017-08-31 20:19:03	2017-08-31 20:19:03
https://github.com/OpenMined/PySyft/issues/142	['bug ']	addmm tests failing	"addmm tests failingAs of bb1e78015a51de36f58ce5beb74b8f0c120aa131 :

```
$ pytest
===================================================================== test session starts =====================================================================
platform darwin -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0
rootdir: /Users/swaroop/personal/openmined/PySyft, inifile:
collected 33 items                                                                                                                                             

tests/test_math.py .......
tests/test_tensor.py ......................FFFF

========================================================================== FAILURES ===========================================================================
______________________________________________________________________ addmm.testaddmm1d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm1d>

    def testaddmm1d(self):
        t1=TensorBase(np.array([1,2,3]))
        t2=TensorBase(np.array([2,3,4]))
        mat=TensorBase(np.array([5]))
        out=t1.addmm(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(out.data,[50]))
E       AssertionError: False is not true

tests/test_tensor.py:127: AssertionError
______________________________________________________________________ addmm.testaddmm2d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm2d>

    def testaddmm2d(self):
        t1=TensorBase(np.array([[1,2],[1,2]]))
        t2=TensorBase(np.array([[1,2],[1,2]]))
        mat=TensorBase(np.array([[2,3],[3,4]]))
        out=t1.addmm(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(out.data,[[10,18],[12,20]]))
E       AssertionError: False is not true

tests/test_tensor.py:134: AssertionError
_____________________________________________________________________ addmm.testaddmm_1d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm_1d>

    def testaddmm_1d(self):
        t1=TensorBase(np.array([1,2,3]))
        t2=TensorBase(np.array([2,3,4]))
        mat=TensorBase(np.array([5]))
        t1.addmm_(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(t1.data,[50]))
E       AssertionError: False is not true

tests/test_tensor.py:141: AssertionError
_____________________________________________________________________ addmm.testaddmm_2d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm_2d>

    def testaddmm_2d(self):
        t1=TensorBase(np.array([[1,2],[1,2]]))
        t2=TensorBase(np.array([[1,2],[1,2]]))
        mat=TensorBase(np.array([[2,3],[3,4]]))
        t1.addmm_(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(t1.data,[[10,18],[12,20]]))
E       AssertionError: False is not true

tests/test_tensor.py:148: AssertionError
============================================================= 4 failed, 29 passed in 0.24 seconds =============================================================
```The error is coming due to the new inplace implementations of +. I will make the changes with the newer implementation of addmm as disscussed with @samsontmr Done
More tests are failing after those were fixed:
![image](https://user-images.githubusercontent.com/6272414/29462390-cdb14a52-83f4-11e7-8782-f1daaa145c12.png)
okay there is a d missing in def will change it"	4	2017-08-15 09:13:58	2017-08-18 16:04:47	2017-08-18 16:04:46
https://github.com/OpenMined/PySyft/issues/118	['bug ']	__mul__ not correctly implemented	"__mul__ not correctly implementedIn the `PaillierFloat` implementation, multiplication with another `PaillierFloat` is also implemented, whereas in the `python-paillier` library, it is not possible to multiply two `EncodedNumber`s ([ref.](https://github.com/n1analytics/python-paillier/blob/master/phe/paillier.py#L746-L748)).

https://github.com/OpenMined/PySyft/blob/16dae46b154dd755c18e941409b4ec771f5e2ca5/syft/he/Paillier.py#L97
Great catch! Fixed. :)"	1	2017-08-11 21:27:49	2017-09-05 11:04:27	2017-09-05 11:04:26
https://github.com/OpenMined/PySyft/issues/74	[]	Implement Default nelement Functionality for Base Tensor Type	"Implement Default nelement Functionality for Base Tensor Type**User Story A:** As a Data Scientist using Syft's Base Tensor type, I want to leverage a default method for computing operations on a Tensor of arbitrary type. For this ticket to be complete, nelement() should return a new tensor. For a reference on the operation this performs check out [PyTorch](http://pytorch.org/docs/master/tensors.html)'s documentation.

**Acceptance Criteria:**
- If the Base Tensor type's attribute ""encrypted"" is set to True, it should return a NotImplemented error.
- a unit test demonstrating the correct operation on the Base Tensor type implemented over int and float Tensors.
- inline documentation in the python code. For inspiration on inline documentation, please check out [PyTorch](http://pytorch.org/docs/master/tensors.html)'s documentation for this operator.Referencing PyTorch's documentation of [`nelement()`](http://pytorch.org/docs/master/tensors.html#torch.Tensor.nelement), it appears that the operation should be returning an integer instead of a tensor. @iamtrask can you clarify please?ahhh yes definitely follow Pytorch's convention there... my bad :)great catch!"	3	2017-08-10 00:00:39	2017-10-01 05:06:04	2017-10-01 05:06:03
