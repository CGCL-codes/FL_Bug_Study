url,label,title,all_text,comments,created_time,updated_time,closed_time
https://github.com/OpenMined/PySyft/issues/6611,"['bug ', '0.2.x']",send doesn't affect Identity layers,"send doesn't affect Identity layers## Description
Identity layers, or models composed only from Identity layers, cannot be sent to a worker. It doesn't happen if there are other types of layers in the model (for example if the model has one Linear layer and one Identity layer), so I suppose this is due to Identity layers not including any tensors.
 
## How to Reproduce
bob = sy.VirtualWorker(hook, id=""bob"")
model = nn.Sequential(nn.Identity(10),nn.Identity(10))
model.send(bob)
print(model.location)
--> None

@JosephChataignon `sy.VirtualWorker` is from 0.2.x which is no longer supported.",1,2022-06-23 15:01:20,2022-06-24 01:24:53,2022-06-24 01:24:48
https://github.com/OpenMined/PySyft/issues/6424,['bug '],pip install syft==0.6.0 raise a warning about version incompatible,"pip install syft==0.6.0 raise a warning about version incompatible# Description
When i install pysyft 0.6.0, there is a conflict in packaging version.
'pip install syft==0.6.0', raise the ERROR below:
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
statsmodels 0.13.2 requires packaging>=21.3, but you have packaging 21.2 which is incompatible.

'pip install --upgrade packaging==21.3', raise the ERROR below:
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
syft 0.6.0 requires packaging==21.2, but you have packaging 21.3 which is incompatible.

# System Information
- OS: Red Hat 4.8.5-36
- Language: Python 3.7.11We have upgraded packaging to `21.3` in `dev` and the API in `0.6` and `dev` (0.7.0) is nearly identical.",1,2022-04-27 02:40:33,2022-06-08 06:45:09,2022-06-08 06:45:09
https://github.com/OpenMined/PySyft/issues/6418,['bug '],hagrid launch network is not working,"hagrid launch network is not working## Description
I am using pysyft version 0.6.0 and trying to launch network using the below commands and getting errors.
1. hagrid launch network 
      getting below message in loop and network is not launching
      **control: authRoutine: backoff: 13265 msec**

2. hagrid launch United Nations --type network 
      getting below error message
      **Error: No such option: --type** 

3. hagrid launch United Nations --port 8085 --type network
      getting below error message
      **Error: No such option: --port**

I am trying to follow the below notebook from pysyft github notebooks-
    https://github.com/OpenMined/PySyft/blob/dev/notebooks/trade_demo/mock_notebooks/Part%201%20-%20Setup%20Use%20Case.ipynb

## System Information
 - OS: Linux (ubuntu 20.04)
 - Language Version: [e.g. Python 3.8]
Hi @pgupta07 those notebooks are pretty old and are mock notebooks, please see the more up to date docs here: https://openmined.github.io/PySyft/",1,2022-04-22 08:39:28,2022-04-30 00:12:12,2022-04-30 00:12:12
https://github.com/OpenMined/PySyft/issues/6401,['bug '],bug,"bug## Description
 No module named 'syft_proto.frameworks.torch.tensors.interpreters.v1.placeholder_pb2'

python3.7
torch1.4.0
syft0.2.3a3Syft 0.2 is no longer supported.",1,2022-04-11 06:47:57,2022-06-08 06:38:05,2022-06-08 06:38:05
https://github.com/OpenMined/PySyft/issues/6389,"['bug ', '0.5']",module 'sympc' has no attribute 'merge',"module 'sympc' has no attribute 'merge'## Description
Hi, Openmined experts,
Per to https://github.com/OpenMined/PySyft/blob/0.6.0/notebooks/trade_demo/Part%204%20-%20Perform%20JOIN%20(backed%20by%20SMPC).ipynb, 

## How to Reproduce
Run the code below,
import sympc
merged_dataset_ptr = sympc.merge(
    left=ca_filtered_dataset_ptr,
    right=it_filtered_dataset_ptr,
    on=""Commodity Code"",
    how=""inner"",
    suffixes=(""_ca"", ""_it""),
)

The following error will occurs,
AttributeError: module 'sympc' has no attribute 'merge'

I check the sourcecode from  https://github.com/OpenMined/SyMPC,  and  no method 'merge' was found. So is there anything missing from ""Part 4 - Perform JOIN (backed by SMPC).ipynb"" ? @iamtrask  Thanks!
@yuanbw 0.6 and 0.7 (dev) do not use SyMPC, instead they use a built in SMPC implementation from the same authors @gmuraru and @rasswanth-s.

@rasswanth-s what is the equivalent of `merge` in 0.7?Hi @yuanbw,
The Old Notebook was one of our Nice to have features, 

It was not fully completed, There are some example smpc examples in https://github.com/OpenMined/PySyft/tree/dev/notebooks/smpc/Training%20Demo
For the initial Training,

To work with the example you would need to launch Domain Nodes through **hagrid**,
Our current syft documentation would help you in the same 
https://openmined.github.io/PySyft/

Creating new examples notebooks for our current architecture is at the top of my `TODO` list, within one or two week , I will create good Starting notebooks for SMPC.

I am closing this issue, as the feature was not implement.
Feel to reach out to me for any questions on OM slack,
Joining link: [OM Slack](https://slack.openmined.org)
My Slack handle: `@Rasswanth`",2,2022-04-02 09:43:02,2022-06-10 06:37:54,2022-06-10 06:37:53
https://github.com/OpenMined/PySyft/issues/6355,['bug '],Did Pysyft tensor supports floats and string features?,"Did Pysyft tensor supports floats and string features?## Description
We require the dataset to be created in Syft tensor format to upload to the domian created by Hagrid. I am able to wrap only the integer feature in Syft tensor format but it is not accepting the float features. Screenshot attached.

## Screenshots
![image](https://user-images.githubusercontent.com/73330091/158108147-438c1a0f-fabc-4460-a3a0-950bad0b205c.png)

## System Information
OS: Debian GNU/Linux 10 (buster)
OS Version: 10
Language Version: Python 3.9.7
Package Manager Version: conda 4.10.1

@Crazynovatech we temporarily had an int32 limitation which as been changed now to int64. The underlying implementations of our DP, SMPC and FixedPrecision tensors require different things under the hood. You should be able to load in a normal numpy array in the latest version and it will take care of it. Can you try this with the latests code on `dev`?",1,2022-03-14 05:07:09,2022-06-08 06:30:59,2022-06-08 06:30:59
https://github.com/OpenMined/PySyft/issues/6349,['bug '],"ConnectionClosedOK: code = 1000 (OK), no reason","ConnectionClosedOK: code = 1000 (OK), no reason## Description
A clear and concise description of the bug.
In Asynchronous learning - federated - learning - on - MNIST, changed the run_websocket_client. Py the model lead to the above problems, the complete error as follows  
ConnectionClosedOK                        Traceback (most recent call last)
<ipython-input-12-edf38bb6dbe9> in async-def-wrapper()
     19         ]
     20     )
---> 21     models = {}
     22     loss_values = {}
     23 

D:\Federated Learning\PySyft\examples\tutorials\advanced\websockets-example-MNIST-parallel\run_websocket_client.py in fit_model_on_worker(worker, traced_model, batch_size, curr_round, max_nr_batches, lr)
    170     )
    171     train_config.send(worker)
--> 172     loss = await worker.async_fit(dataset_key=""mnist"", return_ids=[0])
    173     model = train_config.model_ptr.get().obj
    174     return worker.id, model, loss

D:\anaconda\lib\syft\workers\websocket_client.py in async_fit(self, dataset_key, return_ids)
    156             serialized_message = sy.serde.serialize(message)
    157             await websocket.send(str(binascii.hexlify(serialized_message)))
--> 158             await websocket.recv()  # returned value will be None, so don't care
    159 
    160         # Reopen the standard connection

D:\anaconda\lib\websockets\protocol.py in recv(self)
    507                     # Wait until the connection is closed to raise
    508                     # ConnectionClosed with the correct code and reason.
--> 509                     await self.ensure_open()
    510 
    511         # Pop a message from the queue.

D:\anaconda\lib\websockets\protocol.py in ensure_open(self)
    810             # case self.close_connection_task will complete even faster.
    811             await asyncio.shield(self.close_connection_task)
--> 812             raise self.connection_closed_exc()
    813 
    814         # Control may only reach this point in buggy third-party subclasses.

ConnectionClosedOK: code = 1000 (OK), no reason



@yigedage We no longer support these old websocket versions of Grid. I believe the libraries have changed causing issues with how these old versions run now. I can highly recommend you checkout our latest version with:
```
$ pip install hagrid
$ hagrid launch domain to docker:8081 --tag=latest
$ pip install --pre syft
```

Then checkout some of our integration tests or notebooks for examples on how to use. More docs coming shortly.",1,2022-03-09 11:54:49,2022-06-08 06:28:17,2022-06-08 06:28:17
https://github.com/OpenMined/PySyft/issues/6328,['bug '],ERROR: 'network_mode' and 'networks' cannot be combined,"ERROR: 'network_mode' and 'networks' cannot be combined## Description
When i try to start PyGrid stack following the tutorial instructions https://github.com/OpenMined/PySyft/blob/dev/packages/grid/README.md, I got the error when executing docker-compose up:

`ERROR: 'network_mode' and 'networks' cannot be combined`

My OS environment:  macOS Big Sur 11.4

## How to Reproduce

## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: macOS Big Sur
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
@MissiontoMars My guess is that your docker version is out of date.
Please install the latest version of `docker desktop` and enable `docker compose v2` in the settings.",1,2022-02-24 03:16:35,2022-06-08 06:21:57,2022-06-08 06:21:57
https://github.com/OpenMined/PySyft/issues/6291,['bug '],Error from the tutorials 1,"Error from the tutorials 1In first tutorial, the `sy.launch_duet` is giving a connection TimeoutError. Could you please update with the correct link?

My code- 
```
duet = sy.launch_duet(network_url=""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000/"")
```

notebook link - [here](https://github.com/OpenMined/courses/blob/foundations-of-private-computation/federated-learning/duet_basics/Duet_Basics_Data_Owner.ipynb)

Error Message-
```
ConnectionError: HTTPConnectionPool(host='ec2-18-216-8-163.us-east-2.compute.amazonaws.com', port=5000): Max retries exceeded with url: //metadata (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f04988c9b20>: Failed to establish a new connection: [Errno 110] Connection timed out'))
```


I have made opened an issue here as well - [here](https://github.com/OpenMined/courses/issues/402)Building a local Duet server can help you. #5991 @VIGNESHinZONE it was fixed recently: https://github.com/OpenMined/PySyft/issues/6286",2,2022-02-11 13:19:58,2022-06-08 06:12:18,2022-06-08 06:12:18
https://github.com/OpenMined/PySyft/issues/6286,['bug '],Not able to start the duet connection,"Not able to start the duet connection## Description
Starting from a fresh installation of pysyft with pyenv, the very first time a data owner can launch a duet connection with
`import syft as sy;
duet = sy.duet(loopback=True)`

but the next times, it stucks in the following:

`ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Starting Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹

â™«â™«â™« > DISCLAIMER: Duet is an experimental feature currently in beta.
â™«â™«â™« > Use at your own risk.


    > â¤ï¸ Love Duet? Please consider supporting our community!
    > [https://github.com/sponsors/OpenMined]()`

without going further. Obviously, a data scientist cannot establish any connection with the data owner with `duet = sy.join_duet(loopback=True)`

After the cell is running for almost 4 minutes, this is the error popping up:

```
Exception                                 Traceback (most recent call last)
/var/folders/f5/1fpy821d4cv783czwrb2m2fr0000gp/T/ipykernel_6819/4282418770.py in <module>
      1 import syft as sy
----> 2 duet = sy.duet(loopback=True)

~/.pyenv/versions/3.7.4/envs/openmined-pysyft/lib/python3.7/site-packages/syft/grid/duet/__init__.py in duet(target_id, logging, network_url, loopback, db_path)
    163     else:
    164         return launch_duet(
--> 165             logging=logging, network_url=network_url, loopback=loopback, db_path=db_path
    166         )
    167 

~/.pyenv/versions/3.7.4/envs/openmined-pysyft/lib/python3.7/site-packages/syft/grid/duet/__init__.py in launch_duet(logging, network_url, loopback, credential_exchanger, db_path)
    198 
    199     if not network_url:
--> 200         network_url = get_available_network()
    201     info(""â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:"", print=True)
    202     info(""â™«â™«â™« > "" + str(network_url), print=True)

~/.pyenv/versions/3.7.4/envs/openmined-pysyft/lib/python3.7/site-packages/syft/grid/duet/__init__.py in get_available_network()
     60             error(f""Failed request addr: {e}"")
     61             continue
---> 62     traceback_and_raise(Exception(""Couldn't find any available network.""))
     63 
     64 

~/.pyenv/versions/3.7.4/envs/openmined-pysyft/lib/python3.7/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
     59     if not issubclass(type(e), Exception):
     60         e = Exception(e)
---> 61     raise e
     62 
     63 

Exception: Couldn't find any available network.
```

## How to Reproduce
1. Install pysyft==0.5.0 in pyenv
2. open a new notebook in vscode and run a cell with `import syft as sy; duet = sy.duet(loopback=True)`
3. restart the kernel and repeat step 2
4. duet is not totally initiated

## Expected Behavior
It should listen for connection and connect when a data scientist joins the duet.

## System Information
 - OS: MacOS Big Sur 
 - OS Version: 11.6
 - Language Version: Python 3.7.4
 - Package Manager Version: pyenv 1.2.21
 - PySyft Version: 0.5.0
 - DevTool: Version: 1.62.3
Commit: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247
Date: 2021-11-17T07:59:13.865Z
Electron: 13.5.2
Chrome: 91.0.4472.164
Node.js: 14.16.0
V8: 9.1.269.39-electron.0
OS: Darwin x64 20.6.0 

## Additional Context
Uninstalling and reinstalling the new virtualenv the behaviour is the same.Hi! Have you figured out how to solve this? I also met this problem.Unfortunately not. It works running the same code on colab though (just removing loopback=True).Thanks! Actually, I tried one day later the same code and the error was gone lol...We had some small issue and the Signalling server was rebooted and it is now working again. There is also a maintenance release of syft 0.5 which allows newer Torch which should fix issues with Apple Silicon.",4,2022-02-08 10:39:31,2022-06-08 06:10:58,2022-06-08 06:10:57
https://github.com/OpenMined/PySyft/issues/6215,['bug '],hagrid launch gets stuck at some point,"hagrid launch gets stuck at some point## Description
After running `hagrid launch d0 domain` with `hagrid==0.1.8` the console gets filled with all kind of docker and other outputs. After a few minutes it gets stuck at the output below and does not continue for at least one hour, without giving any error.

What confuses me is that setting up a domain already worked and then all of sudden it stops half way through. Is a RabbitMQ and PostgreSQL container missing (see below docker output at Additional Context)?

```
backend_stream_1  | 
backend_stream_1  | INFO:     Started server process [82]
backend_stream_1  | INFO:     Waiting for application startup.
backend_stream_1  | 2021-12-01 08:57:32 | DEBUG    | grid.logger.handler:init_logger:77: Logging to /var/log/pygrid/grid.log
backend_stream_1  | 2021-12-01 08:57:32 | INFO     | uvicorn.lifespan.on:startup:59: Application startup complete.
```

## How to Reproduce
1. Remove all docker containers and images with `docker system prune -a` (optional)
2. Activate Python virtual environment with `syft==0.6.0` and `hagrid==0.1.8`
3. `hagrid launch d0 domain`

## Expected Behavior
Starting a domain node with hagrid on the default port 8081 with default user `info@openmined.org` and password `changethis` to which I then connect via a Jupyter notebook.

## System Information
 - OS: Ubuntu
 - OS Version: 20.04.3 LTS
 - Language Version: Python 3.8.10
 - Package Manager Version: Virtual Environment

## Additional Context
Checking if the port 8081 is used with `sudo netstat -tulpn | grep 8081` does not yield any results.

The command `docker ps -a` yields the following container:
```
CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                                                                                                                                                   NAMES
696482faa828   dc941fe98248   ""waitforit -address=â€¦""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_backend_stream_1
2fecca4e56c6   dc941fe98248   ""/start-reload.sh""       3 minutes ago   Up 3 minutes                                                                                                                                                           d0_backend_1
39271b233da6   dc941fe98248   ""waitforit -address=â€¦""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_celeryworker_1
1c5381d1aa7a   7c399a4425a5   ""/entrypoint.sh --prâ€¦""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_proxy_1
8b3158d72e52   9bcdabb7d998   ""sh -c '/tailscale/tâ€¦""   3 minutes ago   Up 3 minutes   0.0.0.0:80->81/tcp, :::80->81/tcp, 0.0.0.0:49172->4000/tcp, :::49172->4000/tcp, 0.0.0.0:49157->41641/udp, :::49157->41641/udp                           d0_tailscale_1
12e3c96d1752   c91dff94df48   ""docker-entrypoint.sâ€¦""   3 minutes ago   Up 3 minutes   4369/tcp, 5671/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:49170->5672/tcp, :::49170->5672/tcp, 0.0.0.0:49169->15672/tcp, :::49169->15672/tcp   d0_queue_1
d20260cc79c6   5cdca5bce5c5   ""docker-entrypoint.sâ€¦""   3 minutes ago   Up 3 minutes                                                                                                                                                           d0_frontend_1
381190bbf1a2   41283533d505   ""docker-entrypoint.sâ€¦""   3 minutes ago   Up 3 minutes   0.0.0.0:49171->5432/tcp, :::49171->5432/tcp                                                                                                             d0_db_1
b1bf9ba18e96   1a573a6da0e1   ""/entrypoint.sh""         3 minutes ago   Up 3 minutes                                                                                                                                                           d0_docker-host_1
```

When trying to connect to the domain node over the Jupyter notebook with 
```
domain = sy.login(email=""info@openmined.org"",
                      password=""changethis"",
                      port=8081)
``` 
I get the following error: 
```
Connecting to http://localhost:8081...HTTPConnectionPool(host='localhost', port=8081): Max retries exceeded with url: /api/v1/login (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26283bb8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
````hagrid==0.1.9` seems to have fixed the issue. Even though it is not yet working on ARM architectures.",1,2021-12-01 11:37:34,2021-12-03 16:45:08,2021-12-03 16:45:08
https://github.com/OpenMined/PySyft/issues/6205,[],Give PySyft and PyGrid version for every tutorial,"Give PySyft and PyGrid version for every tutorialFor me it is hard to follow the pace of changes in PySyft and PyGrid. There are plenty tutorials and blog posts available, however the majority does not work with v0.5.0 and it seems some already use v0.6.0.

Therefore, I propose to make it mandatory for every tutorial, jupyter notebook or blog post to give at least the version of PySyft, PyGrid/Hagrid and PyTorch. Also, every data set used should be directly connected to the tutorial so it is easy to find.

For example, with v0.5.0 the `sy.login(email=""info@openmined.org"", password=""changethis"", port=8081)` returns `TypeError: login() got an unexpected keyword argument 'port'`. So I assume the tutorial [here](https://github.com/OpenMined/PySyft/blob/dev/notebooks/course3/L2_Demo.ipynb) uses v0.6.0, but it is not given anywhere. Also, when starting hagrid and then connecting to it via the web browser briefly shows that v0.6.0alpha is used, but this information is either well hidden or not given at all. 

So please make it easier for others to use your framework without the hustle to dig into the source code to understand what I am doing wrong.
True , the blogposts and tutorials does not point to the exact version for which it was created, some are pretty old.It might be hard to work with them. 

In the future blog posts we would  pin the exact version for which it was created.

Currently at this point, the best starting point to learn more about syft ecosystem , would  be start at our new course.
**Remote Data Science** : https://courses.openmined.org/courses/introduction-to-remote-data-science.
which covers most of the new API,
Feel  free to post any questions.

Closing the issue for now, reopen if necessary.",1,2021-11-29 15:07:13,2022-01-10 06:34:12,2022-01-10 06:33:31
https://github.com/OpenMined/PySyft/issues/5991,['bug '],Error when executing syft-network,"Error when executing syft-network## Description
I have created a conda environment (called `test_syft`) and installed PySyft 0.5.0 (using `pip install pip install syft==0.5.0`). After activating the conda environment, I execute `syft-network` to create a network using localhost in order to test the Duet functionality, without having to redirect traffic through the 3rd party duet AWS endpoint (e.g. http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000). 

I am getting the following error:

```
Traceback (most recent call last):
  File ""...../anaconda3/envs/test_syft/bin/syft-network"", line 5, in <module>
    from syft.grid.example_nodes.network import run
ImportError: cannot import name 'run' from 'syft.grid.example_nodes.network' (...../anaconda3/envs/test_syft/lib/python3.8/site-packages/syft/grid/example_nodes/network.py)
```

## How to Reproduce
1. Create a conda environment.
2. Install PySyft 0.5.0 using pip.
3. Execute in a terminal, in which the conda environment is activated, the command `syft-network`.
4. See error.

## Expected Behavior
I was expecting that a network in my localhost would be initiated that could be used by Duet. (Although I am not sure, because I didn't find any documentation describing the expected behaviour of the command).

## System Information
 - OS: Ubuntu
 - OS Version: 20.04
 - Language Version: Python 3.8.11
 - Package Manager Version: conda 4.10.3, pip 21.0.1

Thank you in advance!I have also tried this, same error am i getting.hi , I am getting same error . tried with different python versions and os.
`ImportError: cannot import name 'run' from 'syft.grid.example_nodes.network' (....\anaconda3\envs\syft\lib\site-packages\syft\grid\example_nodes\network.py)   `With `syft==0.6.0a0` I get a similar error after running `syft-network` in a terminal with the respective virtual environment active:

```
Traceback (most recent call last):
  File ""/home/karsten/Dokumente/venvs/fl60/bin/syft-network"", line 5, in <module>
    from syft.grid.example_nodes.network import run
ModuleNotFoundError: No module named 'syft.grid.example_nodes'
```

## System Information
 - OS: Ubuntu
 - OS Version: 20.04.3 LTS
 - Language Version: Python 3.8.10
 - Package Manager Version: Virtual Environment, Pip 20.0.2Same error for me.
I use pyenv with a python version 3.7.4 end pysyft 0.5.0.
I'm not sure, but I think it happened when I updated the pyOpenSSL lib to the 22.0.0 version.If you launch version 0.5.0, the code below can play the same function as `syft-network` to start a Flask,
```
import syft.grid.example_nodes.network as network
network.signaling_server()
```",5,2021-09-20 17:25:07,2022-06-08 06:02:20,2022-06-08 06:02:20
https://github.com/OpenMined/PySyft/issues/5909,['bug '],Not able to install PySyft on Anaconda,"Not able to install PySyft on AnacondaAs mentioned in the openmined website, I tried to install PySyft using the following commands:
$ conda create -n pysyft python=3.9

$ conda activate pysyft

$ conda install jupyter notebook

$ pip install syft
I had also installed Microsoft Build Tools prior to making the installations



![Screenshot (7)](https://user-images.githubusercontent.com/80323298/129441485-8911a73c-3a10-4bd1-84b8-7fce2e307083.png)


System Information
 - OS: windows
 - OS Version: 20H2
 - Language Version:  Python 3.7
 - Package Manager Version: Anaconda3
 


Hi there @anaghasimha are you trying to run tutorials from the private AI series? if yes, try following the guide [here](https://github.com/OpenMined/pysyft/tree/syft_0.5.0)  and if it's for pysyft 0.2.x you can reference this branch [here](https://github.com/OpenMined/PySyft/tree/syft_0.2.x)Hello. Yes, I am trying to install PySyft on my Anaconda prompt. Tried the
link that you have mentioned. Got the following error:
ERROR: Cannot install syft[udacity]==0.2.3, syft[udacity]==0.2.4,
syft[udacity]==0.2.5, syft[udacity]==0.2.6, syft[udacity]==0.2.7,
syft[udacity]==0.2.8, syft[udacity]==0.2.9, syft[udacity]==0.3.0 and
syft[udacity]==0.5.0 because these package versions have conflicting
dependencies.

The conflict is caused by:
    syft[udacity] 0.5.0 depends on torchvision<=0.9.1 and >=0.5
    syft[udacity] 0.3.0 depends on torch>=1.5
    syft[udacity] 0.2.9 depends on torch~=1.4.0
    syft[udacity] 0.2.8 depends on torch~=1.4.0
    syft[udacity] 0.2.7 depends on torch~=1.4.0
    syft[udacity] 0.2.6 depends on torchvision~=0.5.0
    syft[udacity] 0.2.5 depends on torch~=1.4.0
    syft[udacity] 0.2.4 depends on torch~=1.4.0
    syft[udacity] 0.2.3 depends on torch~=1.4.0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency
conflict

ERROR: ResolutionImpossible: for help visit
https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies

On Sat, Aug 14, 2021 at 4:21 PM Ogundeyi Boluwatife <
***@***.***> wrote:

> Hi there @anaghasimha <https://github.com/anaghasimha> are you trying to
> run tutorials from the private AI series? if yes, try following the guide
> here <https://github.com/OpenMined/pysyft/tree/syft_0.5.0> and if it's
> for pysyft 0.2.x you can reference this branch here
> <https://github.com/OpenMined/PySyft/tree/syft_0.2.x>
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5909#issuecomment-898878678>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ATE2FYSWCDIM2BD3DUT3SM3T4ZDDLANCNFSM5CE5MVQQ>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>
> .
>",2,2021-08-14 09:32:47,2022-06-08 05:57:18,2022-06-08 05:57:18
https://github.com/OpenMined/PySyft/issues/5908,['bug '],ValueError: Request to access data length rejected with duet,"ValueError: Request to access data length rejected with duet## Description
`ValueError: Request to access data length rejected` error occurs when trying to run the duet example notebook

## How to Reproduce
1. Go to kaggle.com
2. Upload the Actor Critic Data Scientist notebook
3. Add the `pip install -U syft` line first so that pysyft gets installed
4. Run the notebook with a GPU accelerator
5. Meanwhile, launch the Actor Critic Data Owner notebook locally or elsewhere
6. See error in the last cell (the one with `# run inifinitely many episodes`)

## Expected Behavior
All requests being accepted


## System Information
 - OS:  Ubuntu 20.04 and some kaggle system (presumably Ubuntu on a Docker)
 - Language Version: python 3.8 locally and python 3.7 in kaggle
 - Package Manager Version: pip and conda, respectively


## Additional Context
The complete error output is:
```
[2021-08-13T09:29:03.571799+0000][CRITICAL][logger]][43] Request to access data length rejected.
[2021-08-13T09:29:03.573171+0000][CRITICAL][logger]][43] Request to access data length rejected.
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/syft/ast/klass.py in __len__(self)
    368                 if data_len is None:
--> 369                     raise Exception
    370 

Exception: 

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/syft/ast/klass.py in __iter__(self)
    306             try:
--> 307                 data_len = self.__len__()
    308             except Exception:

/opt/conda/lib/python3.7/site-packages/syft/ast/klass.py in __len__(self)
    373                 traceback_and_raise(
--> 374                     ValueError(""Request to access data length rejected."")
    375                 )

/opt/conda/lib/python3.7/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
     60         e = Exception(e)
---> 61     raise e
     62 

ValueError: Request to access data length rejected.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-15-9a2012a1643d> in <module>
     15 
     16         # take the action
---> 17         state, reward, done, _ = remote_env.step(action)
     18 
     19         buffer_rewards.append(reward)

/opt/conda/lib/python3.7/site-packages/syft/ast/klass.py in __iter__(self)
    308             except Exception:
    309                 traceback_and_raise(
--> 310                     ValueError(""Request to access data length rejected."")
    311                 )
    312 

/opt/conda/lib/python3.7/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
     59     if not issubclass(type(e), Exception):
     60         e = Exception(e)
---> 61     raise e
     62 
     63 

ValueError: Request to access data length rejected.
```



My idea is that explicit checks for data length should be added to the code (they're in place in the DCGAN notebooks, if I remember correctly), but ideally  it should just work or fail gracefully with suggestions about the source of the problem. 
HI Team and @StrangeTcy , 

Any update on this bug ? I am also getting the same bug while following Adam's video Multi-Limb SplitNN on MNISTThe same thing happens to me when running the Multi-Limb SplitNN on MNIST example.Length is considered private.",4,2021-08-13 09:37:17,2022-06-08 05:56:58,2022-06-08 05:56:58
https://github.com/OpenMined/PySyft/issues/5824,"['bug ', '0.5']",The error of example of remote MPC?,"The error of example of remote MPC?I want to run a remote example of MPC, but when I run the PySyft/packages/syft/examples/secure-multi-party-computation/Duet/1-DS-1-DO, there's a bug ""The session *** could not be found"". I also run some local example of MPC, but I don't kown how to write a remote example according to local example. I want to get a help of remote example. Now, I have two choices, one is that if I want to run remote example 1-DS-1-DO without bugs, which version of syft and sympc I should install ? the other is that how to write a remote example according to local example without bugs , anyone can give help? thanks!!!Hi @jiyanxin , 
At that time  we had SyMPC  in another repo, https://github.com/OpenMined/SyMPC , PySyft did not have full fledged SyMPC
Currently we have some example notebooks in https://github.com/OpenMined/PySyft/tree/dev/notebooks/smpc/Training%20Demo
For Initial Training Part, 

Creating Good SMPC Example notebook is at top of my TODO list, Within maybe one or two weeks, I will create good SMPC notebook example.To work with examples, you would need to launch Domain Nodes through hagrid , 
The syft documentation,would help you with the initial setup and deployment
https://openmined.github.io/PySyft/I am closing this issue, as this was for the old notebooks,
For any question feel free to DM me on OM slack
My handle `Rasswanth`
Joining LInk : [OM Slack](https://slack.openmined.org)",3,2021-07-21 06:05:01,2022-06-10 06:40:00,2022-06-10 06:39:59
https://github.com/OpenMined/PySyft/issues/5797,['bug '],PyGrid PyDP example broken,"PyGrid PyDP example broken## Description
PyDP [example](https://github.com/OpenMined/PySyft/blob/dev/packages/syft/examples/pygrid/tutorials/PyDP.ipynb) doesn't work with PyGrid. It crashes every time at .get() with ""Unknown private Exception"".

## Expected Behavior
Approximate value of the float pointer should be displayed as a result of private_mean function.

## Screenshots
![image (2)](https://user-images.githubusercontent.com/52822004/126120503-fbb023fa-d1ac-4540-b1b4-7648db817aa6.png)
![image (3)](https://user-images.githubusercontent.com/52822004/126120529-36f18849-0a41-45a2-b5eb-fe0368c97278.png)

## System Information
 - OS: Windows 10, Ubuntu 20.04, iOS
 - Language Version: Python 3.8@szczepanTopolski I believe this is an issue with PyDP. Check the latest versions here: https://github.com/OpenMined/PyDP/",1,2021-07-19 07:34:19,2022-06-08 05:51:45,2022-06-08 05:51:45
https://github.com/OpenMined/PySyft/issues/5782,['bug '],Lint Errors (0.6 alpha branch),"Lint Errors (0.6 alpha branch)## Description
Tox lint errors (generally styling) need to be resolved.

## How to Reproduce
1. Checkout PySyft branch: `demo_strike_team_branch_4`
2. Run `tox -e lint`

## Expected Behavior
No lint errors!

## Screenshots
`Check python ast.........................................................Failed
- hook id: check-ast
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py: failed parsing with CPython 3.9.5:

    Traceback (most recent call last):
      File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/check_ast.py"", line 20, in main
        ast.parse(f.read(), filename=filename)
      File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
        return compile(source, filename, mode, flags,
      File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py"", line 318
        False=False,
        ^
    SyntaxError: invalid syntax
    
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py: failed parsing with CPython 3.9.5:

    Traceback (most recent call last):
      File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/check_ast.py"", line 20, in main
        ast.parse(f.read(), filename=filename)
      File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
        return compile(source, filename, mode, flags,
      File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py"", line 163
        (s, end),
        ^
    SyntaxError: invalid syntax

Trim Trailing Whitespace.................................................Passed
Check docstring is first.................................................Failed
- hook id: check-docstring-first
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/transport_config.py:33 Module docstring appears after code (code seen on line 30).
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_get_stack.py:33 Module docstring appears after code (code seen on line 30).

Check JSON...............................................................Passed
Check for added large files..............................................Passed
Check Yaml...............................................................Passed
Check for merge conflicts................................................Passed
Check that executables have shebangs.....................................Failed
- hook id: check-executables-have-shebangs
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_free.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_free.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_kubectl.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_kubectl.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/tasks/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/tasks/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/tasks/containers.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/tasks/containers.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/mixins.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/mixins.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/setns.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/setns.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/core.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/core.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/handlers/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/handlers/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/tasks/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/tasks/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/parent.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/parent.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/utils.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/utils.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_local.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_local.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/loaders.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/loaders.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/connection.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/connection.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/jail.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/jail.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/target.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/target.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/services.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/services.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/docker-compose.override.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/docker-compose.override.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_get_stack.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_get_stack.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/unix.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/unix.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible.cfg: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible.cfg`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_machinectl.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_machinectl.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/su.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/su.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/profiler.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/profiler.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/fork.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/fork.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/buildah.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/buildah.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/select.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/select.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/planner.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/planner.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/minify.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/minify.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/strategy_plugins/mitogen_linear.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/strategy_plugins/mitogen_linear.py`
  If it is supposed to be executable, double-check its shebang.
README.md: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x README.md`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/fakessh.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/fakessh.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/tasks/docker.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/tasks/docker.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_sudo.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_sudo.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_fetch.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/action/mitogen_fetch.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_ssh.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_ssh.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/module_finder.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/module_finder.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/kubectl.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/kubectl.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/docker-compose.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/docker-compose.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/docker.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/docker.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_buildah.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_buildah.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/group_vars/all/vars.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/group_vars/all/vars.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/logging.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/logging.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/ssh.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/ssh.py`
  If it is supposed to be executable, double-check its shebang.
.gitignore: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x .gitignore`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/debug.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/debug.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/site.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/site.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/master.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/master.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_doas.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_doas.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/os_fork.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/os_fork.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_jail.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_jail.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/Vagrantfile: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/Vagrantfile`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_su.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_su.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/affinity.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/affinity.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/strategy.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/strategy.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxd.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxd.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/compat/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/compat/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_linear.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_linear.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/transport_config.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/transport_config.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/__init__.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/__init__.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/runner.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/runner.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/compat/pkgutil.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/compat/pkgutil.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_setns.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_setns.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/doas.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/doas.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/scanner.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/scanner.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/compat/tokenize.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/compat/tokenize.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/handlers/main.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/handlers/main.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/parsing.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/parsing.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/service.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/service.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxc.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_lxc.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/lxd.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/lxd.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/node/tasks/system.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/node/tasks/system.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/process.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/process.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_host_pinned.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/strategy/mitogen_host_pinned.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_docker.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/ansible_mitogen/plugins/connection/mitogen_docker.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/roles/containers/tasks/hagrid.yml: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/roles/containers/tasks/hagrid.yml`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/lxc.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/lxc.py`
  If it is supposed to be executable, double-check its shebang.
packages/grid/ansible/mitogen/mitogen/sudo.py: marked executable but has no (or invalid) shebang!
  If it isn't supposed to be executable, try: `chmod -x packages/grid/ansible/mitogen/mitogen/sudo.py`
  If it is supposed to be executable, double-check its shebang.

Debug Statements (Python)................................................Failed
- hook id: debug-statements
- exit code: 1

packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py - Could not parse ast

        Traceback (most recent call last):
          File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/debug_statement_hook.py"", line 55, in check_file
            ast_obj = ast.parse(f.read(), filename=filename)
          File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
            return compile(source, filename, mode, flags,
          File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/encoder.py"", line 318
            False=False,
            ^
        SyntaxError: invalid syntax


packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py - Could not parse ast

        Traceback (most recent call last):
          File ""/Users/dhrebenach/.cache/pre-commit/repodgmp_4en/py_env-python3.9/lib/python3.9/site-packages/pre_commit_hooks/debug_statement_hook.py"", line 55, in check_file
            ast_obj = ast.parse(f.read(), filename=filename)
          File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ast.py"", line 50, in parse
            return compile(source, filename, mode, flags,
          File ""packages/grid/ansible/mitogen/ansible_mitogen/compat/simplejson/decoder.py"", line 163
            (s, end),
            ^
        SyntaxError: invalid syntax

Tests should end in _test.py.............................................Passed
Fix requirements.txt.....................................................Passed
isort (python)...........................................................Passed
black....................................................................Passed`

## System Information
 - OS: iOS
 - OS Version: 11.4
 - Language Version: Python 3.9.5, Node v14.17.3
 - Package Manager Version: Conda 4.10.1
 - Browser (if applicable): Not Applicable
 - Browser Version (if applicable): Not Applicable

## Additional Context
Thank you sir!",1,2021-07-14 19:28:30,2021-07-28 01:46:51,2021-07-28 01:46:51
https://github.com/OpenMined/PySyft/issues/5772,['bug '],AttributeError: 'NoneType' object has no attribute 'serialize',"AttributeError: 'NoneType' object has no attribute 'serialize'## When I execute part02 in the example, I use Python file to execute it directly, prompting an error


ERROR is :AttributeError: 'NoneType' object has no attribute 'serialize'

![æˆªå±2021-07-13 ä¸Šåˆ9 06 06](https://user-images.githubusercontent.com/49719634/125374805-5b4b0f00-e3ba-11eb-83fe-50c5ceb2dc72.png)

## System Information
 - OS: Ubuntu 20.04.1 LTS
 - OS Version: 5.4.0-77-generic
 - Language Version:python3.8.5
 -syft Version:2.9.0

## Additional Context
Add any other context about the problem here.
syft 0.2 is deprecated",1,2021-07-13 01:12:14,2022-06-08 05:48:10,2022-06-08 05:48:09
https://github.com/OpenMined/PySyft/issues/5752,"['bug ', 'pygrid']",Error returns 200 code,"Error returns 200 code## Description
[This line ](https://github.com/OpenMined/PySyft/blob/4f276a97fef6b779822437fa7d54e21ff4d8dd1a/packages/grid/apps/worker/src/main/core/services/tensor_service.py#L156) describes an error response, which gives a 200 HTTP code. Should this be `success=False`?.
@IonesioJunior can you help?The same behavior happens for `create` and `update` routes.

I can have a go.

@IonesioJuniorHello @gkaissis, glad to see you! :smiley: 

Initially, the idea of â€‹â€‹returning rest codes in PyGrid messages was something in our development plan. Over time, due to planning changes and the possibility of the Syft library working with different protocols, this lost some of its semantic meaning. Currently, `status_code=200` is returned by default on all messages (unless an internal error has occurred) just to not break things.

We intend to remove this field in the next versions in order to delegate the responsibility to the frameworks of an external layer (without creating a dependency between the Syft library and the communication protocol used).

In the future, services will be developed following [this pattern](https://github.com/OpenMined/PySyft/blob/785fd8a29e6f8db20ac7b3b159b5842b4c1a8509/packages/syft/src/syft/core/node/common/node_service/dataset_manager/dataset_manager_service.py#L95)

In case of an HTTP request, the code returned will be managed by an external layer, responsible exclusively for handling messages using this protocol.

My apologies for the mistake created.",3,2021-07-02 12:58:27,2022-06-08 05:46:01,2022-06-08 05:46:01
https://github.com/OpenMined/PySyft/issues/5751,['bug '],AttributeError: 'Tensor' object has no attribute 'locations',"AttributeError: 'Tensor' object has no attribute 'locations'
I want to use the securenn module in pysyft, but I get an error when I use the relu and maxpool functions.
Refer to Tutorial 12-2 for training and the version of syft is 0.2.9

class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        self.conv1 = nn.Conv2d(1,16,5,1)
        self.conv2 = nn.Conv2d(16,16,5,1)
        self.fc1 = nn.Linear(256,100)
        self.fc2 =nn.Linear(100,10)
    def forward(self, x):
       # print(x.get())
        x = maxpool(relu(self.conv1(x)),2,2)
        x = maxpool(relu(self.conv2(x)),2,2)
        x = x.view(-1,256)
        x = relu(self.fc1(x))
        x = self.fc2(x)

        return nn.Softmax(x)The syft framework uses the protocol in Securenn to implement some functions in AdditivesharingTensor",1,2021-07-02 08:03:23,2021-07-02 12:45:37,2021-07-02 12:43:54
https://github.com/OpenMined/PySyft/issues/5747,[],Broken. New API changes have broken the ModelCentricFLClient in the FL examples of model centric and possibly others. Please advise or fix.,"Broken. New API changes have broken the ModelCentricFLClient in the FL examples of model centric and possibly others. Please advise or fix.Broken. New API changes have broken the ModelCentricFLClient in the FL examples of model centric and possibly others. Please advise or fix.

_Originally posted by @algarecu in https://github.com/OpenMined/PySyft/issues/5410#issuecomment-870802970_

The code is out of date, and cannot be used with latest examples of pygrid as far as it was tested. There must be another way to host the federated training plan with the new API  of v0.5.0 but undocumented or code of model_centric_fl_client.py in in the syft package is actually broken.@algarecu the MCFL tests are still passing in the `0.5.0` branch here: https://github.com/OpenMined/PySyft/blob/syft_0.5.0/packages/syft/tests/syft/core/fl/model-centric/mcfl_create_execute_plan_test.py

All code from `0.5.0` is public on PyPI, dockerhub and available in the `syft_0.5.0` branch.
The PyGrid repo is `deprecated` and the latest stable version is in the branch above.

`dev` is undergoing lots of changes at the moment so please use the above branch for `0.5.0` stability.Already using package syft 0.5.0, however using branch `main` (e.g., as the file version seems equal there), which seemingly had integrated latest stable commits I see coming up yes. However, I still see not all integration tests were passed in that file I mention above over the branch `main`, yet it was committed 1 month ago approx. Will check back a conda deployment on 0.5.0 to see if anything changes but I suspect it won't if they model centric example contains any deprecated methods for hosting the training plan on a grid domain of pygrid as it gets stucked just at the end there.This works for the connect part only,
```
from syft.grid.client.client import connect  # Method used to connect with the node.
from syft.grid.client.grid_connection import GridHTTPConnection

domain = connect(
     url=""http://localhost:5000"",  # Domain Address
     conn_type=GridHTTPConnection,
 )  # HTTP Connection Protocol
 print(domain)
```
Result:
<GridClient: <UID: 66bc7c48b36044e285a3448d43fcff20>>
Process finished with exit code 0

===============================================================================================

However, old code does result in a 404 Handshake Error, which does not seem right as said and relates to not finding the server of the app in the server. 
```
grid_address = ""localhost:5000""
grid = ModelCentricFLClient(address=grid_address, secure=False)
grid.connect()
```
Result:
```
Traceback (most recent call last):
  File ""/home/algarecu/Documents/github/PySyft/packages/syft/examples/federated-learning/model-centric/mcfl_create_plan_mobile.py"", line 285, in <module>
    grid.connect()
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/federated/model_centric_fl_base.py"", line 52, in connect
    self.ws = websocket.create_connection(**args_)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_core.py"", line 595, in create_connection
    websock.connect(url, **options)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_core.py"", line 252, in connect
    self.handshake_response = handshake(self.sock, *addrs, **options)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_handshake.py"", line 59, in handshake
    status, resp = _get_resp_headers(sock)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_handshake.py"", line 145, in _get_resp_headers
    raise WebSocketBadStatusException(""Handshake status %d %s"", status, status_message, resp_headers)
websocket._exceptions.WebSocketBadStatusException: Handshake status 404 NOT FOUND

Process finished with exit code 1
```
===============================================================================================
Server itself runs in development mode as follows, as well as database which I see it is created using also the next command correctly.

```
./run.sh --name bob --port 5000 --start_local_db 'postgresql+psycopg2://postgres:@localhost:5432/localdb'
[2021-06-30 11:40:48]: 22009 INFO domain version: 0.5.0 in Dev is Ready
```
===============================================================================================

Does any of this ring any bells @madhavajay ?  I also want to try the same in the dockerized env rather than local, but these results make me think it is not a matter of local environment setup but a network problem with websockets or the pygrid api itself.0.5 is deprecated. I did release a new version today but only to fix issues with installing syft on Apple Silicon.",4,2021-06-29 18:05:57,2022-06-08 05:45:06,2022-06-08 05:45:05
https://github.com/OpenMined/PySyft/issues/5745,['bug '],`docker build` fails becasue of `No matching distribution found for torch==1.8.1+cpu`,"`docker build` fails becasue of `No matching distribution found for torch==1.8.1+cpu`## Description

I failed to build [syft.Dockerfile](https://github.com/OpenMined/PySyft/blob/dev/docker/syft.Dockerfile) because `pip` couldn't have resolved `torch==1.8.1+cpu`
```
$ docker build  -f docker/syft.Dockerfile .
[+] Building 18.3s (14/15)
 => [internal] load build definition from syft.Dockerfile                                                                                                        0.0s
 => => transferring dockerfile: 1.78kB                                                                                                                           0.0s
 => [internal] load .dockerignore                                                                                                                                0.0s
 => => transferring context: 262B                                                                                                                                0.0s
 => [internal] load metadata for docker.io/library/python:3.9-slim                                                                                               2.3s
 => [stage-0  1/11] FROM docker.io/library/python:3.9-slim@sha256:8c7df74df97eeccf174b966f190c059b2671a0e617e11edb856114c8fbd5b748                               0.0s
 => => resolve docker.io/library/python:3.9-slim@sha256:8c7df74df97eeccf174b966f190c059b2671a0e617e11edb856114c8fbd5b748                                         0.0s
 => [internal] load build context                                                                                                                                0.6s
 => => transferring context: 9.99MB                                                                                                                              0.6s
 => CACHED [stage-0  2/11] RUN echo 'deb http://deb.debian.org/debian testing main' >> /etc/apt/sources.list                                                     0.0s
 => CACHED [stage-0  3/11] RUN --mount=type=cache,target=/var/cache/apt     apt-get update &&     apt-get install -yqq     gcc gcc-9 g++-9 libc6 git python3-de  0.0s
 => CACHED [stage-0  4/11] RUN --mount=type=cache,target=/root/.cache python3 -m pip install --upgrade pip                                                       0.0s
 => CACHED [stage-0  5/11] RUN --mount=type=cache,target=/root/.cache python3 -m pip install packaging                                                           0.0s
 => CACHED [stage-0  6/11] RUN mkdir -p /syft                                                                                                                    0.0s
 => [stage-0  7/11] COPY ./packages/syft /syft                                                                                                                   0.2s
 => [stage-0  8/11] RUN if [ ""false"" = ""true"" ]; then python /syft/scripts/adjust_torch_versions.py /syft/setup.cfg 1.8.1 gpu; fi                                0.3s
 => [stage-0  9/11] RUN if [ ""false"" = ""false"" ]; then python /syft/scripts/adjust_torch_versions.py /syft/setup.cfg 1.8.1; fi                                   0.3s
 => ERROR [stage-0 10/11] RUN --mount=type=cache,target=/root/.cache cd syft && pip install -e .[all] -f https://download.pytorch.org/whl/torch_stable.html     14.5s
------
 > [stage-0 10/11] RUN --mount=type=cache,target=/root/.cache cd syft && pip install -e .[all] -f https://download.pytorch.org/whl/torch_stable.html:
#14 0.462 Looking in links: https://download.pytorch.org/whl/torch_stable.html
#14 0.462 Obtaining file:///syft
#14 0.528   Installing build dependencies: started
#14 7.262   Installing build dependencies: finished with status 'done'
#14 7.265   Getting requirements to build wheel: started
#14 7.489   Getting requirements to build wheel: finished with status 'done'
#14 7.491     Preparing wheel metadata: started
#14 7.686     Preparing wheel metadata: finished with status 'done'
#14 9.551 Collecting names
#14 10.000   Downloading names-0.3.0.tar.gz (789 kB)
#14 11.55 Collecting requests-toolbelt
#14 11.59   Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)
#14 13.00 Collecting protobuf
#14 13.00   Using cached protobuf-3.17.3-cp39-cp39-manylinux2014_aarch64.whl (923 kB)
#14 14.39 ERROR: Could not find a version that satisfies the requirement torch==1.8.1+cpu (from syft[all]) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 1.8.0, 1.8.1, 1.9.0)
#14 14.39 ERROR: No matching distribution found for torch==1.8.1+cpu
------
executor failed running [/bin/sh -c cd syft && pip install -e .[all] -f https://download.pytorch.org/whl/torch_stable.html]: exit code: 1
```

## How to Reproduce
1. Clone this repository (commit: 4f276a97fef6b779822437fa7d54e21ff4d8dd1a)
2. Run `docker build  -f docker/syft.Dockerfile .` at the root directory of this project.

## Expected Behavior

A docker image is created without any problem.

## System Information
 - OS: macOS
 - OS Version: 11.4 (BigSur)
 - Language Version: Docker version 20.10.7, build f0df350,  Python 3.9 (in Dockerfile)
 - Package Manager Version: pip 21.1.3 (in Dockerfile)

## Additional Context
noneThat's probably because I use an M1 mac. I close this issue because it's not an issue of pysyft.",1,2021-06-29 04:22:59,2021-06-29 04:29:34,2021-06-29 04:29:34
https://github.com/OpenMined/PySyft/issues/5743,['bug '],This page cannot be opened ,"This page cannot be opened https://github.com/OpenMined/PySyft/blob/pygrid_demo/examples/pygrid/model_inference/Model%20Inference%20PyGrid%20%2B%20SyMPC.ipynb

![image](https://user-images.githubusercontent.com/10841478/123604199-350b6800-d82d-11eb-8b35-ab52fa3d5e73.png)

These are out of date. Our docs are undergoing an update.These are out of date. Our docs are undergoing an update.",2,2021-06-28 08:24:30,2022-06-08 05:43:32,2022-06-08 05:43:27
https://github.com/OpenMined/PySyft/issues/5738,['bug '],AttributeError: type object 'Tensor' has no attribute 'fft' ,"AttributeError: type object 'Tensor' has no attribute 'fft' ## Description
Cannot import syft without receiving ""AttributeError: type object 'Tensor' has no attribute 'fft' "" using recommended environment and installation procedures.

## How to Reproduce
1. Install Anaconda.
2. Open Anaconda Prompt
3. Run these commands as recommended:

```
conda create -n pysyft python=3.9
conda activate pysyft
conda install jupyter notebook
```
4. Install PySyft:

```
pip install syft
```

5. Create Python file called test.py containing:

```python
import syft
```

6. Run the python program using:

```
python test.py
```

## Expected Behavior
syft should import correctly and not throw any errors.

## System Information
 - OS: Windows 10
 - Language Version: Python 3.9.5
 - Package Manager Version: Conda 4.10.1

## Additional Context
See #4999.

If this is an issue with torch, then the README needs to be updated with a workaround.
Solved by installing `syft==0.5.0rc1` which I think uses a different version of PyTorch. I will leave this open because the recommended installation procedure does not work.",1,2021-06-27 10:04:59,2022-06-08 05:42:23,2022-06-08 05:42:23
https://github.com/OpenMined/PySyft/issues/5724,['bug '],Install error: AttributeError: type object 'Tensor' has no attribute 'fft',"Install error: AttributeError: type object 'Tensor' has no attribute 'fft'## Description
!pip install syft on google colab, and it gets installed without any errors.
import syft as sy
error: type object 'Tensor' has no attribute 'fft'
same error when I use conda to install as instruction:
`$ conda create -n pysyft python=3.9
$ conda activate pysyft
$ conda install jupyter notebook
$ pip install syft`

## System Information
-OS: windows 10
-Language Version:Python 3.9.5
-Package Manager Version: syft 0.3.0, torch1.8.0,  torchvision 0.9.0

It works with the latest version of syft",1,2021-06-23 09:47:25,2021-06-25 14:56:18,2021-06-25 14:56:18
https://github.com/OpenMined/PySyft/issues/5701,['bug '], AttributeError: 'FSS' object has no attribute '__name__',"AttributeError: 'FSS' object has no attribute '__name__'Error with ""`SessionManager.setup_mpc(session)`"" 

I followed the steps mentioned in example 
![image](https://user-images.githubusercontent.com/30037676/122711673-2e568100-d280-11eb-88b2-82e34bfbf8df.png)

Everything works well till step 2.2 where it tries to send the session to all the parties. Then it throws the attribute error related to FSS object.
```
`AttributeError                            Traceback (most recent call last)
<ipython-input-8-43b115104f2d> in <module>
----> 1 SessionManager.setup_mpc(session)

E:\PySMC\lib\site-packages\sympc\session\session_manager.py in setup_mpc(session)
     53             session_party.uuid = uuid4()
     54             uuids[rank] = session_party.uuid
---> 55             session.session_ptrs.append(session_party.send(party))  # type: ignore
     56 
     57         session.uuid = uuid4()

E:\PySMC\lib\site-packages\syft\ast\klass.py in send(self, client, pointable, description, tags, searchable)
    455 
    456             # Step 3: send message
--> 457             client.send_immediate_msg_without_reply(msg=obj_msg)
    458 
    459             # Step 4: return pointer

E:\PySMC\lib\site-packages\syft\core\node\common\client.py in send_immediate_msg_without_reply(self, msg, route_index)
    259             )
    260             debug(output)
--> 261             msg = msg.sign(signing_key=self.signing_key)
    262         debug(f""> Sending {msg.pprint} {self.pprint} âž¡ï¸  {msg.address.pprint}"")
    263         self.routes[route_index].send_immediate_msg_without_reply(msg=msg)

E:\PySMC\lib\site-packages\syft\core\common\message.py in sign(self, signing_key)
     89         """"""
     90         debug(f""> Signing with {self.address.key_emoji(key=signing_key.verify_key)}"")
---> 91         signed_message = signing_key.sign(serialize(self, to_bytes=True))
     92 
     93         # signed_type will be the final subclass callee's closest parent signed_type

E:\PySMC\lib\site-packages\syft\core\common\serde\serialize.py in _serialize(obj, to_proto, to_bytes)
     63         # indent=None means no white space or \n in the serialized version
     64         # this is compatible with json.dumps(x, indent=None)
---> 65         serialized_data = is_serializable._object2proto().SerializeToString()
     66         blob: Message = DataMessage(
     67             obj_type=get_fully_qualified_name(obj=is_serializable),

E:\PySMC\lib\site-packages\syft\core\node\common\action\save_object_action.py in _object2proto(self)
     51 
     52     def _object2proto(self) -> SaveObjectAction_PB:
---> 53         obj = self.obj._object2proto()
     54         addr = serialize(self.address)
     55         return SaveObjectAction_PB(obj=obj, address=addr)

E:\PySMC\lib\site-packages\syft\core\store\storeable_object.py in _object2proto(self)
    131 
    132         # Step 3: Serialize data to protobuf and pack into proto
--> 133         data = self._data._object2proto()
    134 
    135         proto.data.Pack(data)

E:\PySMC\lib\site-packages\syft\generate_wrapper.py in _object2proto(self)
     32 
     33         def _object2proto(self) -> Any:
---> 34             return type_object2proto(self.obj)
     35 
     36         @staticmethod

E:\PySMC\lib\site-packages\syft\lib\sympc\session.py in object2proto(obj)
     12 
     13 def object2proto(obj: object) -> MPCSession_PB:
---> 14     proto = protobuf_session_serializer(obj)
     15     return proto
     16 

E:\PySMC\lib\site-packages\syft\lib\sympc\session_util.py in protobuf_session_serializer(session)
     27     )
     28 
---> 29     protocol = session.protocol.__name__
     30     protocol_serialized = str.encode(protocol)
     31 

AttributeError: 'FSS' object has no attribute '__name__'`
```


Running this on Windows 10 with the below installed packages
- pip install syft==0.5.0rc2
- pip install git+https://github.com/OpenMined/SyMPC@main
- pip install torchcsprng==0.2.1+cpu -f https://download.pytorch.org/whl/torch_stable.html
We modified the functionalities, the error is due to the old version of PySyft , you could remove the current version and install the latest one.`pip uninstall syft`.
`pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft`Tried it in a new virtual env `pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft`.

But getting the below error. 
![image](https://user-images.githubusercontent.com/30037676/122729893-44237080-d297-11eb-84e8-2f7d9885006a.png)

Are there any dependencies?ok , I made a typo this would work `pip install -e  ""git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft""`",3,2021-06-21 05:38:04,2021-06-21 09:35:32,2021-06-21 09:35:32
https://github.com/OpenMined/PySyft/issues/5678,"['bug ', 'pygrid']",poetry install at `PyGrid/apps/domain` does not work... ,"poetry install at `PyGrid/apps/domain` does not work... ## Description
I would like to try this tutorial ( https://github.com/OpenMined/PySyft/blob/0.5.0rc2/packages/syft/examples/federated-learning/model-centric/mcfl_create_plan.ipynb ).

but poetry install at `PyGrid/apps/domain` does not work... 

## How to Reproduce

```
PyGrid/apps/domain  dev âœ—                                                                 3d âš‘ â—’
â–¶ poetry install
Installing dependencies from lock file

Package operations: 1 install, 32 updates, 0 removals

  â€¢ Updating markupsafe (2.0.1 -> 1.1.1)
  â€¢ Updating six (1.16.0 -> 1.15.0)
  â€¢ Updating click (8.0.1 -> 7.1.2)
  â€¢ Updating greenlet (1.1.0 -> 1.0.0)
  â€¢ Updating itsdangerous (2.0.1 -> 1.1.0)
  â€¢ Updating jinja2 (3.0.1 -> 2.11.3)
  â€¢ Updating netifaces (0.11.0 -> 0.10.9)
  â€¢ Updating numpy (1.20.3 -> 1.20.2)
  â€¢ Updating typing-extensions (3.10.0.0 -> 3.7.4.3)
  â€¢ Updating urllib3 (1.26.5 -> 1.26.4)
  â€¢ Updating werkzeug (2.0.1 -> 1.0.1)
  â€¢ Updating botocore (1.20.88 -> 1.20.57)
  â€¢ Updating certifi (2021.5.30 -> 2020.12.5)
  â€¢ Updating distlib (0.3.2 -> 0.3.1)
  â€¢ Updating protobuf (3.17.2 -> 3.15.8)
  â€¢ Updating sqlalchemy (1.4.17 -> 1.4.11)
  â€¢ Updating alembic (1.6.5 -> 1.5.8)
  â€¢ Updating attrs (21.2.0 -> 20.3.0)
  â€¢ Updating cfgv (3.3.0 -> 3.2.0)
  â€¢ Updating flake8 (3.9.2 -> 3.9.1)
  â€¢ Updating identify (2.2.9 -> 2.2.4)
  â€¢ Updating more-itertools (8.8.0 -> 8.7.0)
  â€¢ Updating pygments (2.9.0 -> 2.8.1)
  â€¢ Updating typeguard (2.12.1 -> 2.12.0)
  â€¢ Updating virtualenv (20.4.7 -> 20.4.4)
  â€¢ Updating websocket-client (1.0.1 -> 0.58.0)
  â€¢ Updating boto3 (1.17.88 -> 1.17.57)
  â€¢ Updating flake8-comprehensions (3.5.0 -> 3.4.0)
  â€¢ Updating pre-commit (2.13.0 -> 2.12.1)
  â€¢ Installing python-dp (1.0.2): Failed

  RuntimeError

  Unable to find installation candidates for python-dp (1.0.2)

  at ~/.pyenv/versions/3.8.8/lib/python3.8/site-packages/poetry/installation/chooser.py:72 in choose_for
       68â”‚
       69â”‚             links.append(link)
       70â”‚
       71â”‚         if not links:
    â†’  72â”‚             raise RuntimeError(
       73â”‚                 ""Unable to find installation candidates for {}"".format(package)
       74â”‚             )
       75â”‚
       76â”‚         # Get the best link

  â€¢ Updating sqlalchemy-mixins (1.4 -> 1.3)
  â€¢ Updating syft (0.3.0.post0.dev1522+geb46f1d90 -> 0.3.0.post0.dev1315+gfc8dd76ec fc8dd76)
  â€¢ Updating tenseal (0.3.4 -> 0.3.2)

```

## System Information
 - OS: Big Sur
 - OS Version: 11.4ï¼ˆ20F71ï¼‰
 - Language Version:  Python 3.8,8
 - Package Manager Version: Poetry version 1.1.6

moved from [PyGrid issues](https://github.com/OpenMined/PyGrid/issues/868)HI @IonesioJunior,
Were you able to find a solution to this issue?Has there been any solution to this issue?",3,2021-06-21 03:35:24,2022-06-08 05:39:14,2022-06-08 05:39:14
https://github.com/OpenMined/PySyft/issues/5671,['bug '], Unable to load package support for: sympc. No module named 'sympc',"Unable to load package support for: sympc. No module named 'sympc'Trying out examples for SMC with PySyft, but I am getting errors on loading ""sympc""

```
import torch  
import syft as sy  

sy.load(""sympc"") 
sy.logger.add(sink=""./example.log"")
```

![image](https://user-images.githubusercontent.com/30037676/122505490-141b6980-d01a-11eb-9cdb-2d20bbd68a15.png)




## System Information
 - OS: Windows 10
 - Language Version: Python 3.7
 - Pysyft version : 0.5.0rc2@spnzig  ,did you try installing sympc ,`pip install git+https://github.com/OpenMined/SyMPC@dev` and checking it again.@rasswanth-s yes I tried that. It still didn't work. 
![image](https://user-images.githubusercontent.com/30037676/122707524-cbf98280-d277-11eb-8f1e-70bdb636c037.png)
Sorry ,I interchanged in pysyft we `dev` for SyMPC we use `main` , this would work `pip install git+https://github.com/OpenMined/SyMPC@main`@rasswanth-s  its gives the below error. 
![image](https://user-images.githubusercontent.com/30037676/122707664-1844c280-d278-11eb-965b-fb632a223732.png)



I think `sy.load`  is deprecated now,remove `sy.load` could you try `import sympc` in a separate cell,that should work.Oh, I see.
@rasswanth-s that doesn't seem to work for me either . 
![image](https://user-images.githubusercontent.com/30037676/122706601-f0545f80-d275-11eb-8b0f-50154a7eb127.png)

Are there any updated document with details about the installation steps and examples? 
I am trying out the examples for SyMPC under PySyft. 
![image](https://user-images.githubusercontent.com/30037676/122706822-5c36c800-d276-11eb-9e87-153e9cf7cd44.png)
Yeah , that is due to gpu build issue,I think you must have installed `torchcsprng==0.2.1`.
Firtst  you  could uninstall it `pip uninstall torchcsprng`.
Then install the cpu build from torch repo `pip install torchcsprng==0.2.1+cpu -f https://download.pytorch.org/whl/torch_stable.html`
Then you could import sympc and check.Thank you. I will try that out. 
I have installed PySyft with this command ` pip install syft==0.5.0rc2` and haven't installed any other package explicitly to try out the examples for SMC with PySyft.
Would this have any dependency issues for running other examples under Homomorphic encryption or differential privacy? It is due to the PyPI problem, now it should work. I think there  wont be any dependency issue with other libraries ,you could open a issue , if there are any.Thanks @rasswanth-s . That worked. But I am not sure if the library is fully functional. I get errors when I try out the code.
![image](https://user-images.githubusercontent.com/30037676/122738589-c0ba4d00-d29f-11eb-9c21-e81cff60b2b4.png)

The error is below
```
`[2021-06-21T14:49:49.943489+0530][CRITICAL][logger]][10676] UnknownPrivateException has been triggered.
---------------------------------------------------------------------------
UnknownPrivateException                   Traceback (most recent call last)
<ipython-input-13-b434b26d9c89> in <module>
----> 1 print(""X + Y ="", (x + y).reconstruct())

E:\SMC\lib\site-packages\sympc\tensor\mpc_tensor.py in reconstruct(self, decode, get_shares)
    375             self.share_ptrs,
    376             get_shares=get_shares,
--> 377             security_type=self.session.protocol.security_type,
    378         )
    379 

E:\SMC\lib\site-packages\sympc\tensor\share_tensor.py in reconstruct(share_ptrs, get_shares, security_type)
    525 
    526         args = [[share] for share in share_ptrs]
--> 527         local_shares = request_wrap(args)
    528 
    529         shares = [share.tensor for share in local_shares]

E:\SMC\lib\site-packages\sympc\utils\utils.py in wrapper(args, kwargs)
    122                 futures.append(executor.submit(funcs[i], *_args, **_kwargs))
    123 
--> 124         local_shares = [f.result() for f in futures]
    125 
    126         return local_shares

E:\SMC\lib\site-packages\sympc\utils\utils.py in <listcomp>(.0)
    122                 futures.append(executor.submit(funcs[i], *_args, **_kwargs))
    123 
--> 124         local_shares = [f.result() for f in futures]
    125 
    126         return local_shares

C:\ProgramData\Anaconda3\lib\concurrent\futures\_base.py in result(self, timeout)
    423                 raise CancelledError()
    424             elif self._state == FINISHED:
--> 425                 return self.__get_result()
    426 
    427             self._condition.wait(timeout)

C:\ProgramData\Anaconda3\lib\concurrent\futures\_base.py in __get_result(self)
    382     def __get_result(self):
    383         if self._exception:
--> 384             raise self._exception
    385         else:
    386             return self._result

C:\ProgramData\Anaconda3\lib\concurrent\futures\thread.py in run(self)
     55 
     56         try:
---> 57             result = self.fn(*self.args, **self.kwargs)
     58         except BaseException as exc:
     59             self.future.set_exception(exc)

E:\SMC\lib\site-packages\sympc\tensor\share_tensor.py in _request_and_get(share_ptr)
    518             if not islocal(share_ptr):
    519                 share_ptr.request(block=True)
--> 520             res = share_ptr.get_copy()
    521             return res
    522 

e:\smc\src\syft\packages\syft\src\syft\core\pointer\pointer.py in get_copy(self, request_block, timeout_secs, reason, verbose)
    202             reason=reason,
    203             delete_obj=False,
--> 204             verbose=verbose,
    205         )
    206 

e:\smc\src\syft\packages\syft\src\syft\core\pointer\pointer.py in get(self, request_block, timeout_secs, reason, delete_obj, verbose)
    267 
    268         if not request_block:
--> 269             result = self._get(delete_obj=delete_obj, verbose=verbose)
    270         else:
    271             response_status = self.request(

e:\smc\src\syft\packages\syft\src\syft\core\pointer\pointer.py in _get(self, delete_obj, verbose)
    177         )
    178 
--> 179         obj = self.client.send_immediate_msg_with_reply(msg=obj_msg).data
    180         if self.is_enum:
    181             enum_class = self.client.lib_ast.query(self.path_and_name).object_ref

e:\smc\src\syft\packages\syft\src\syft\core\node\common\client.py in send_immediate_msg_with_reply(self, msg, route_index)
    234                 exception = exception_msg.exception_type(exception_msg.exception_msg)
    235                 error(str(exception))
--> 236                 traceback_and_raise(exception)
    237             else:
    238                 return response.message

e:\smc\src\syft\packages\syft\src\syft\logger.py in traceback_and_raise(e, verbose)
     59     if not issubclass(type(e), Exception):
     60         e = Exception(e)
---> 61     raise e
     62 
     63 

UnknownPrivateException: UnknownPrivateException has been triggered.`
```I think we did not update the examples to the current sympc framework in pysyft, I would look at it and get back to you regarding this.@rasswanth-s Thanks for your time. That would be really helpful.@rasswanth-s any suggestion on how to go ahead with the MPC examples? I still seem to be stuck with an Unknown private exception when I try basic operations (sum, subtract, multiply) on tensors.
![image](https://user-images.githubusercontent.com/30037676/124871533-c7f09300-dfe1-11eb-91f7-451d5b9779b1.png)
The MPC Examples in PySyft are not updated, you could try the MPC examples in SyMPC repo,(https://github.com/OpenMined/SyMPC/tree/main/examples) ,until PySyft examples are fixed.@spnzig We have a new code architecture in dev which will be released as `0.7.0` soon with a much better working SMPC implementation built into the core.",15,2021-06-18 04:19:15,2022-06-08 05:39:10,2022-06-08 05:39:09
https://github.com/OpenMined/PySyft/issues/5668,['bug '],module 'syft' has no attribute 'load',"module 'syft' has no attribute 'load'I run the  notebook Tutorial_0_TenSEAL_Syft_Data_Owner   . I get following error.  

AttributeError                            Traceback (most recent call last)
<ipython-input-1-a81a3ddffd44> in <module>
      3 import pytest
      4 
----> 5 sy.load(""tenseal"")

AttributeError: module 'syft' has no attribute 'load'

![image](https://user-images.githubusercontent.com/20768904/122392510-fbad3f80-cf84-11eb-8519-1f2f15397a91.png)
I was initially facing a similar issue. Which version of PySyft are you using? Could you share in some environment details too.I am using pysft version 0.3.0. I am running it on ubuntu machine python version 3.6.9. 
>>> import syft
>>> syft.__version__
'0.3.0'



Can you update to the latest version of Syft? (`0.5.0rc2`)root@ip-172-31-26-203:~# pip3 install syft==0.5.0rc2
ERROR: Could not find a version that satisfies the requirement syft==0.5.0rc2 (from versions: 0.1.0a1, 0.1.1a2, 0.1.2a1, 0.1.3a1, 0.1.4a1, 0.1.4a2, 0.1.5a1, 0.1.6a1, 0.1.7a1, 0.1.8a1, 0.1.9a1, 0.1.10a1, 0.1.10a2, 0.1.10a4, 0.1.11a1, 0.1.12a1, 0.1.13a1, 0.1.14a1, 0.1.15a1, 0.1.16a1, 0.1.19a1, 0.1.20a1, 0.1.21a1, 0.1.22a1, 0.1.23a1, 0.1.24a1, 0.1.25a1, 0.1.26a1, 0.1.27a1, 0.1.28a1, 0.1.29a1, 0.2.0a1, 0.2.0a2, 0.2.1a1, 0.2.2a1, 0.2.3a1, 0.2.3a2, 0.2.3a3, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.2.8, 0.2.9, 0.3.0, 0.5.0rc1)
ERROR: No matching distribution found for syft==0.5.0rc2


I tried with version ""0.5.0rc1"" but it has thrown another error as below:
ERROR: syft-proto 0.5.3 has requirement protobuf>=3.12.2, but you'll have protobuf 3.12.0 which is incompatible.

Then I tried updating probut. It results in further error:
root@ip-172-31-26-203:~# pip3 install protobuf==3.12.2
Collecting protobuf==3.12.2
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.12.2) (51.3.3)
Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf==3.12.2) (1.15.0)
ERROR: tensorflow 1.15.5 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.
ERROR: coremltools 2.0 has requirement six==1.10.0, but you'll have six 1.15.0 which is incompatible.
ERROR: autokeras 1.0.11 has requirement tensorflow>=2.3.0, but you'll have tensorflow 1.15.5 which is incompatible.
Installing collected packages: protobuf
  Attempting uninstall: protobuf
    Found existing installation: protobuf 3.12.0
    Uninstalling protobuf-3.12.0:
      Successfully uninstalled protobuf-3.12.0
Successfully installed protobuf-3.12.2",4,2021-06-17 11:59:59,2022-06-08 05:38:21,2022-06-08 05:38:21
https://github.com/OpenMined/PySyft/issues/5663,['bug '],Bugs on multi party secure computation,"Bugs on multi party secure computation## Description
The new pysyft, SyMPC. We can't let MPCTensor divide by a  constant or minus by a constant. In the 2.9.* version, it does not have such problem. Also, when we share the neural network to session, the model.parameters() return empty list because the model contains two sub-neural networks. But it shouldn't be the case. It should return all the parameters.


## How to Reproduce
1. Go to '...'
2. Click on '...'
3. Scroll down to '...'
4. See error

## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
@fu1001hao  ,maybe could you post a screenshot of the error , when you do operations of  MPCTensor with a constant,also syft version> @fu1001hao ,maybe could you post a screenshot of the error , when you do operations of MPCTensor with a constant,also syft version

<img width=""817"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122649242-f2de7a00-d0fa-11eb-89b3-ed2fae625d11.png"">

The version is ""0.5.0rc2.post1.dev25+ge7fa7629f.d20210520""

There are other issues. For example, if a network structure (model) contains two subnetworks (model1, model2), the MPC will return an empty list of parameters, when calling model.parameters(). You have to use model1.parameters()+model2.paramters() to call the parameters. Also, the MPCTensor cannot be divided by constant, it will return None type data.@fu1001hao I will take a look at it. could you also post the whole code, where you get None value from MPCTensor, when doing operations with constant.> @fu1001hao I will take a look at it. could you also post the whole code, where you get None value from MPCTensor, when doing operations with constant.

<img width=""438"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122649823-cd06a480-d0fd-11eb-8d38-28348dfcc621.png"">

You set ""batchs"" to be any constant number, you get None type. I also attach the whole code.

import syft as sy
import torch
import torch.optim as optim
from sympc.session import Session
from sympc.session import SessionManager
from sympc.module import nn
from sympc.optim import SGD
from sympc.tensor import MPCTensor
import time

start = time.time()
sy.load(""sympc"")
sy.logger.add(sink=""./example.log"")

alice = sy.VirtualMachine(name=""alice"")
bob = sy.VirtualMachine(name=""bob"")

alice_client = alice.get_client()
bob_client = bob.get_client()

session = Session(parties=[alice_client, bob_client])
session.autograd_active = True
SessionManager.setup_mpc(session)

x, y = torch.load('data/train.pt')
xt, yt = torch.load('data/test.pt')

def one_hot(y):

    tmp = torch.zeros((len(y),10))
    for i in range(len(y)):
        tmp[i, y[i]] = 1
    return tmp

def split(x, y):

    party0, party1 = [], []
    for i in range(10):
        indices = (y==i).nonzero()[:,0]
        l = len(indices) // 2
        party0.append(indices[:l])
        party1.append(indices[l:])
    party0, party1 = torch.cat(party0, 0), torch.cat(party1, 0)
    return (x[party0], y[party0]), (x[party1], y[party1])

party0, party1 = split(x, y)

class Net(sy.Module):

    def __init__(self, torch_ref):
        super(Net, self).__init__(torch_ref = torch_ref)
        self.fc1 = torch_ref.nn.Linear(28*28, 128)
        self.fc2 = torch_ref.nn.Linear(128, 64)
        self.fc3 = torch_ref.nn.Linear(64, 10)

    def forward(self, x):
        x = self.torch_ref.nn.functional.relu(self.fc1(x))
        x = self.torch_ref.nn.functional.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x

def share(party, pct = 0.01):

    x, y = party
    shared = []
    for i in range(10):
        indices = (y==i).nonzero()[:,0]
        l = int(len(indices)*pct)
        shared.append(indices[:l])
    shared = torch.cat(shared, 0)
    return x[shared], y[shared]


model = Net(torch_ref = torch)
private = True

x0, y0 = party0
xs, ys = share(party1)
x0, xs = x0.reshape(-1, 28*28), xs.reshape(-1, 28*28)
print(x0.shape, xs.shape)

ys = one_hot(ys)
y0 = one_hot(y0)
lr = 1e-2
epoch = 500
device = 'cpu'

batch0, batchs = y0.shape[0], ys.shape[0]
x0, y0 = x0.to(device), y0.to(device)
xs, ys = xs.to(device), ys.to(device)

shapexs, shapeys = xs.shape, ys.shape

if private:

    xs = xs.share(session = session)
    ys = ys.share(session = session)

for i in range(epoch):

    print(i)
    for j in range(2):

        if (j==0):

            if i!=0 and private:

                model = model.reconstruct()

            optimizer = optim.SGD(model.parameters(), lr = lr)
            optimizer.zero_grad()
            output = model(x0)
            loss = ((output - y0)**2).mean()
            loss.backward()
            optimizer.step()
            print(loss.item())

        elif (j==1):

            if private:

                model = model.share(session)
                optimizer = SGD(model.parameters(), lr = lr)
            else:

                optimizer = optim.SGD(model.parameters(), lr = lr)
                
            optimizer.zero_grad()
            output = model(xs)
            loss = ((output - ys)**2).sum()/batchs
            loss.backward()
            optimizer.step()
            if private:

                print(loss.reconstruct())

            else:

                print(loss.item())

xt = xt.reshape(-1, 28*28)
xt, yt = xt.to(device), yt.to(device)
if private:

    model = model.reconstruct()
output = model(xt)
pred = output.argmax(dim=1)
total = pred.eq(yt).sum().item()
print(total*1.0/len(pred), total, len(pred))

print(time.time() - start)If you take the latest version of SyMPC - from the dev branch - do you have the same problem?
It might be that at the point of releasing there was no support for division?> If you take the latest version of SyMPC - from the dev branch - do you have the same problem?
> It might be that at the point of releasing there was no support for division?

 I downloaded via this link: https://github.com/OpenMined/SyMPC/tree/main/src/sympc. Is this the latest one?You could install the latest version by `pip install git+https://github.com/OpenMined/SyMPC@dev` , it would install latest one.> You could install the latest version by `pip install git+https://github.com/OpenMined/SyMPC@dev` , it would install latest one.

<img width=""762"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122684666-b97a3d00-d1d4-11eb-85e2-1f9d75858ce7.png"">

It doesn't work.Sorry ,I interchanged in pysyft we `dev` for SyMPC we use `main` , this would work `pip install git+https://github.com/OpenMined/SyMPC@main`> Sorry ,I interchanged in pysyft we `dev` for SyMPC we use `main` , this would work `pip install git+https://github.com/OpenMined/SyMPC@main`

I got a totally different error. Before update I could at least run the code by not using dividing, now I can't even run the code.

<img width=""920"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122811106-12fa6e80-d29e-11eb-939c-00ce0f17a742.png"">

I even ran the 'introduction.ipynb' on your SyMPC GitHub. It gave me the same error.
Yeah,I answered the issue for a similar error ,could you follow these issues https://github.com/OpenMined/PySyft/issues/5701 and https://github.com/OpenMined/PySyft/issues/5671> Yeah,I answered the issue for a similar error ,could you follow these issues #5701 and #5671

Not work for me. I run

pip uninstall syft
pip uninstall sympc

then run

pip install -e ""git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft""
pip install git+https://github.com/OpenMined/SyMPC@main

And it shows successful install but still when I run the code I got the same error.@fu1001hao ,Could you do it in a new virtual env?I did, but the problem was not solved.

The error is:
<img width=""672"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122942535-47c10100-d344-11eb-8a04-fd261aa6e041.png"">
because I did division in my code:
<img width=""563"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122942648-5e675800-d344-11eb-83b7-6f05c093f985.png"">

If I remove the division, it has no error. So overall, even the latest version does not support division.
The latest version , supports division, @gmuraru  is it because of spdz issue with division(2 parties),?The division works for the moment with a number of two parties (we are working towards adding support for more)> The division works for the moment with a number of two parties (we are working towards adding support for more)

I uninstalled pysyft and sympc, then reinstalled. It shows the same error. From my test,  only the MPCTensor that are processed by neural network will become NoneType by division (which is weird). If I just simply divide an MPCTensor by a constant, it works well (I have checked that). So I think it is from the sy.Module or MPC version of the network that causes the issue.@fu1001hao we are getting close to releasing `0.7.0` and there is a completely new architecture and smpc implementation there. You can see it in dev.",18,2021-06-15 18:10:48,2022-06-08 05:38:00,2022-06-08 05:38:00
https://github.com/OpenMined/PySyft/issues/5641,['bug '],Attribute error with Syft,"Attribute error with SyftI have installed Pysyft version 0.3.0 on my windows machine and imported it in jupyter. When I try to run the commands from the examples (PySyft/packages/syft/examples/homomorphic-encryption/Tutorial_0_TenSEAL_Syft_Data_Owner.ipynb) , it gives attribute errors.

```
import syft as sy
import tenseal as ts
import pytest 
sy.load(tenseal)

```
Here it throws an attribute error.


![image](https://user-images.githubusercontent.com/30037676/120957947-49030300-c774-11eb-9384-f5090b723d8f.png)


## System Information
 - Vitual env on a Windows 10 OS
 - Python                   3.7.1
 - pip                         21.1.2
 - torch                      1.7.1+cpu
 - torchaudio             0.7.2
 - torchvision             0.8.2+cpu
 - tenseal                   0.3.4

Two issues, one your version is likely very out of date, we will be doing an official release as soon as we merge the monorepo until then the latest release candidate is available here:
```
$ pip install syft==0.5.0rc2
```

Second issue, sy.load takes a string:
```
import syft as sy
import tenseal as ts
import pytest 
sy.load(""tenseal"")
```",1,2021-06-07 04:28:59,2021-06-07 08:28:51,2021-06-07 05:15:28
https://github.com/OpenMined/PySyft/issues/5638,['bug '],Retrieval from duet store loading endlessly,"Retrieval from duet store loading endlessly## Description
After exploring some issue with loading pointers from the duet store I found the size of the objects in the duet store to be the problem. When the objects in the duet store are over a certain size threshold (for me that threshold is somewhat consistent between a tensor of size 9.000.000 an 11.000.000) then the DS on the other side canÂ´t load the pointer. The program will just get stuck in an endless loop, however if the tensor in the store is below the threshold the pointer will load instantly.

## How to Reproduce
See screenshots.

## Expected Behavior
The pointer to the data should not take any significant amount of time to load.

## Screenshots
![image](https://user-images.githubusercontent.com/36222794/120785655-9fcacb80-c52d-11eb-8f5c-bdc5172b7577.png)
Run this then load on the DS side. With 9.000.000 it should run instantly, with 11.000.000 the data_ptr = duet.store[0] instruction gets stuck in endless loop on DS side.

## System Information
 - OS: Windows 10
 - OS Version: 20H2 (Build 19042.985)
 - Language Version: Python 3.9.4 / syft 0.5.0rc1 / pytorch 1.8.0 / jupyterlab 3.0.14
 - Package Manager Version: Conda 4.10.1Hey @AdrianGlauben!

Could you install the latest from the dev branch to see if you can replicate the error anymore? Thank you!",1,2021-06-04 10:24:25,2022-06-08 05:36:51,2022-06-08 05:36:51
https://github.com/OpenMined/PySyft/issues/5627,['bug '],Large nested SyModules exceed maximum protobuf size,"Large nested SyModules exceed maximum protobuf size## Description
When nesting SyModules with many parameters, protobuf size gets too large (>2gb) and will throw a `ValueError` as a result.

## How to Reproduce

1. Make a very large SyModule (50+ million parameters, BERT sized)
2. Nest it in another SyModule
3. Execute a train plan and call `.get()` on the updated model

Minimal example:

```
import torch
from torch import nn
import syft as sy
from syft import VirtualMachine
from syft.core.plan.plan_builder import make_plan, ROOT_CLIENT
from syft import SySequential, SyModule

class MLP(SyModule):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.layers = SySequential(*[nn.Linear(2048, 2048) for _ in range(20)], input_size=(1, 2048))
        
    def forward(self, x):
        return self.layers(x=x)[0]

model = MLP(input_size=(1, 2048))
print('num_params:', sum(p.numel() for p in model.parameters())) 
# ~84 million parameters

@make_plan
def train(model=model, x=torch.randn(1, 2048)):
    opt = ROOT_CLIENT.torch.optim.SGD(model.parameters(), lr=1e-3)
    out = model(x=x)[0]
    loss = out.mean()
    loss.backward()
    opt.step()
    return [model]

# Send plan, train iteration
alice_client = sy.VirtualMachine(name=""alice"").get_client()
train_ptr = train.send(alice_client)
model_ptr = train_ptr(model=model, x=torch.randn(1, 2048))

# Issue happens here
updated_model = model_ptr.get()
```
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-909fe9935eac> in <module>
     35 
     36 # Issue happens here
---> 37 updated_model = model_ptr.get()

[...]

~/projects/PySyft/packages/syft/src/syft/lib/python/list.py in <listcomp>(.0)
    151         id_ = serialize(obj=self.id)
    152         downcasted = [downcast(value=element) for element in self.data]
--> 153         data = [serialize(obj=element, to_bytes=True) for element in downcasted]
    154         return List_PB(id=id_, data=data)
    155 

~/projects/PySyft/packages/syft/src/syft/core/common/serde/serialize.py in _serialize(obj, to_proto, to_bytes)
     63         # indent=None means no white space or \n in the serialized version
     64         # this is compatible with json.dumps(x, indent=None)
---> 65         serialized_data = is_serializable._object2proto().SerializeToString()
     66         blob: Message = DataMessage(
     67             obj_type=get_fully_qualified_name(obj=is_serializable),

ValueError: Message syft.lib.torch.Module exceeds maximum protobuf size of 2GB: 2685748983
```

Note that using a non-nested SyModule does not have the same issue here. I've not been able to make a model too large to throw a `ValueError` in a non-nested setup, my PC runs out of memory first. To test this, replace line 16 with:

```
model = SySequential(*[nn.Linear(2048, 2048) for _ in range(20)], input_size=(1, 2048))
```

## Expected Behavior
I expect the above model to be serializable.

## Screenshots


## System Information
 - OS: Ubuntu
 - OS Version: 21.04
 - Language Version: Python 3.9.5
 - Package Manager Version: conda 4.10.1
 - Browser (if applicable): -
 - Browser Version (if applicable): -

## Additional Context
Elaborating this issue a bit for #5634. A script that measures what happens to proto size when nesting SyModules:
```
from torch import nn
from syft import  SySequential, SyModule, serialize
import matplotlib.pyplot as plt
from syft import logger
logger.remove()

class Wrapper(SyModule):
    def __init__(self, module, input_size=(1, 10)):
        super().__init__(input_size=input_size)
        self.module = module
        
    def forward(self, x):
        return self.module(x=x)[0]

bytesizes = []
for n in range(10):
    model = SySequential(nn.Linear(10, 10), input_size=(1, 10))
    # Nest model in an empty SyModule n times
    for _ in range(n):
        model = Wrapper(model)
    proto = serialize(model)
    bytesizes.append(proto.ByteSize())
    
plt.plot(bytesizes)
plt.show()
```


Which shows that the protobuf size doubles every time you nest:

![14147894](https://user-images.githubusercontent.com/7243409/120592688-8e56c600-c43e-11eb-8a22-4b3d980636f0.png)",1,2021-06-01 15:14:16,2022-06-08 05:36:30,2022-06-08 05:36:30
https://github.com/OpenMined/PySyft/issues/5679,"['bug ', 'pygrid']",`pyinquirer` package conflict,"`pyinquirer` package conflict## Description
I run PyGird domain in dir `/PyGrid/apps/domain` and I got the error:`ModuleNotFoundError: No module named 'PyInquirer'`

Then i install the package by command `pip install PyInquirer`

but this package is conflict with `ipython` and `jupyter-console`whick is dependent on Jupyter.

because:
`jupyter-console 6.4.0 requires prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0, but you have prompt-toolkit 1.0.14 which is incompatible.`
`ipython 7.22.0 requires prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0, but you have prompt-toolkit 1.0.14 which is incompatible.
`
but 
`pyinquirer 1.0.3 requires prompt-toolkit==1.0.14, but you have prompt-toolkit 3.0.18 which is incompatible.`

I can never satisfy the dependencies of both packages

Is there any way to deal with this problem?
I've already solved this problem by creating 2 env:
`conda create -n env1` and install  `syft-0.5.0rc1` /run jupyter notebook
`conda create -n env2` and run `pygrid_0.4.0`

by the way ,there are too many branches/tags/version in PyGrid/PySfyt, It would be even better if there was a recommended matching version of PyGrid and PySyft 

thanksï¼
Hello @LuanJia!  

Yeah, we need to use different prompt-toolkit versions due to some dependencies (hopefully we'll be fixing it in the next weeks).

Regarding the branches/tags/version, we're actually in the middle of a huge task that will merge PySyft/PyGrid at the same repository in order to sync their development/issues. This will probably solve all this confusion and make the development process clean and easy for both repositories.",2,2021-06-01 03:13:04,2022-06-08 05:35:58,2022-06-08 05:35:58
https://github.com/OpenMined/PySyft/issues/5617,['bug '],Get objects from Duet's store not working properly (even with added handler and request submitted),"Get objects from Duet's store not working properly (even with added handler and request submitted)## Description
In Duet, the Data Scientist is not able to get an object from the duet store immediately, even if handlers have been added and requested have been submitted. However, when running the code to get the object a second time, everything works fine (even though errors keep getting printed on the Data Owner side.

## How to Reproduce
Example with OpenMined's PSI Lbrary: 

Data Owner's side (assuming Duet is setup):
```
fpr=1e-6 
duet.requests.add_handler(
    action=""accept"", 
    tags=[""fpr""]
)
sy_fpr = sy.lib.python.Float(fpr)
sy_fpr_ptr = sy_fpr.send(duet, pointable=True, tags=[""fpr""], description=""false positive rate"")
```

Data Scientist's side:

```
#get False Positive Rate
fpr_ptr = duet.store[""fpr""]
fpr_ptr.request(reason=""I want to know the fpr"", timeout_secs=-1)
fpr = fpr_ptr.get()
```


## Expected Behavior
When running ` fpr_ptr.get()`  I expect to get the variable immediately, as the request has been submitted and the handler has been added. This does not always happen (see description above).


## Screenshot
I attach a screenshot of what happens on the Data Owner's side when the problem described above happens. Even after re-running the `.get()` function the second time (and after actually getting the object then), the print out of the error message in the screenshot keeps occurring.
![doside](https://user-images.githubusercontent.com/15127774/120234184-be904000-c257-11eb-9bc2-816a72c1fd5d.png)
Hey @daler3 !

Using the latest release of syft and python 3.9 with a fresh install I couldn't replicate this issue. Could you try again (if it still replicates, could you give me OS info)",1,2021-05-31 19:33:09,2022-06-08 05:30:59,2022-06-08 05:30:59
https://github.com/OpenMined/PySyft/issues/5612,['bug '],duet cannot be searialized,"duet cannot be searialized## Description
Trying to run duet MNIST example leads to the following error:
>UserWarning: The following variables cannot be serialized: duet

## How to Reproduce
1. Clone the PySyft repository
2. Install syft==0.5.0rc1
3. Go to the `duet` folder and then to the MNIST folder.
4. Run Data Owner and Data Scientist notebooks on different machines
5. See error

## Expected Behavior
Errorless processing of remote dataset

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: Ubuntu
 - OS Version: 20.04
 - Language Version: Python 3.8
 - Package Manager Version pip


## Additional Context
Both notebooks were run in Yandex.DataSphere on c1.4 machines. It's possible to use machines with GPUs if this is the cause of the problem (which seems unlikely)
Hi @StrangeTcy,

With the latest release/dev branch, I can't reproduce the error (python 3.8, torch 1.7.1, Ubuntu OS).

Could you give me more info/could you test with the latest branch of dev to see if you can still reproduce it?

Thank you!Hello. 

@tudorcebere , as far as I can recall, I'm using torch 1.8, which might be one of the reason for the error.

Anyway, test results on the latest dev are to follow.@tudorcebere 

Ok, so far the results have revealed the following: the problem persists if I try to install `syft==0.5.0rc1` from pip, and it doesn't arise if I `pip install syft==0.3.0`, but in the latter case syft.util has no `get_root_data_path`

ETA: in a fresh install of syft from source (cloning and `pip install -e .`) the problem seemingly persists.",3,2021-05-30 11:09:47,2022-06-08 05:32:07,2022-06-08 05:32:07
https://github.com/OpenMined/PySyft/issues/5608,['bug '],AttributeError: module 'torch._C' has no attribute 'native__has_torch_function_unary',"AttributeError: module 'torch._C' has no attribute 'native__has_torch_function_unary'## Description

When I repeat the experiment following the blog [ã€ŠENCRYPTED DEEP LEARNING CLASSIFICATION WITH PYTORCH & PYSYFTã€‹](https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/),  I I encountered the following error:

![Screen Shot 2021-05-27 at 8 58 29 PM](https://user-images.githubusercontent.com/38783332/119829929-56c3b780-bf2e-11eb-93ef-897b8f9c1afe.png)

```
---------------------------------------------------------------------------
PureFrameworkTensorFoundError             Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    286     def send_(self, *location):
--> 287         """"""
    288         Calls send() with inplace option, but only with a single location

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in unwrap_args_from_function(attr, args, kwargs, return_args_type)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(x)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in tuple_one_fold(lambdas, args)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(i)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)

PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-99-5bcf8df4cadf> in <module>
      2 optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment
      3 for epoch in range(1, args.epochs + 1):
----> 4     train(args, model, device, federated_train_loader, optimizer, epoch)
      5     test(args, model, device, test_loader)

<ipython-input-97-9b8111af22ce> in train(args, model, device, train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
    887         """"""
    888         for name, module in self.named_children():
--> 889             yield module
    890 
    891     def named_children(self):

<ipython-input-96-ceb0955942ca> in forward(self, x)
      8 
      9     def forward(self, x):
---> 10         x = F.relu(self.conv1(x))
     11         x = F.max_pool2d(x, 2, 2)
     12         x = F.relu(self.conv2(x))

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    295         return self.send(*location, inplace=True)
    296 
--> 297     def create_pointer(
    298         self,
    299         location: BaseWorker = None,

/usr/local/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py in handle_func_command(cls, command)

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    485 
    486         Example:
--> 487             >>> import syft as sy
    488             >>> hook = sy.TorchHook(verbose=False)
    489             >>> me = hook.local_worker

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    256         :return: a pointer to the result
    257         """"""
--> 258 
    259         command, _self, args = message
    260 

/usr/local/lib/python3.7/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      5     def _send_msg(self, message, location):
      6         return location._recv_msg(message)
----> 7 
      8     def _recv_msg(self, message):
      9         return self.recv_msg(message)

/usr/local/lib/python3.7/site-packages/syft/workers/virtual.py in _recv_msg(self, message)
      8     def _recv_msg(self, message):
      9         return self.recv_msg(message)

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in recv_msg(self, bin_message)
    290             # TODO: Handle when the response is not simply a tensor
    291             # don't re-register tensors if the operation was inline
--> 292             # not only would this be inefficient, but it can cause
    293             # serious issues later on
    294             # if(_self is not None):

/usr/local/lib/python3.7/site-packages/syft/workers/base.py in execute_command(self, message)
    430 
    431     # SECTION: convenience methods for constructing frequently used messages
--> 432 
    433     def send_obj(self, obj, location):
    434         """"""Send a torch object to a worker.

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    319                 to another worker so you can pre-initialize the location
    320                 attribute of the pointer to some other worker, but this is a
--> 321                 rare exception.
    322             id_at_location: A string or integer id of the tensor being pointed
    323                 to. Similar to location, this parameter is almost always

/usr/local/lib/python3.7/site-packages/torch/nn/functional.py in relu(input, inplace)
   1199     Sample from Gumbel(0, 1)
   1200 
-> 1201     based on
   1202     https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,
   1203     (MIT license)

/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    319                 to another worker so you can pre-initialize the location
    320                 attribute of the pointer to some other worker, but this is a
--> 321                 rare exception.
    322             id_at_location: A string or integer id of the tensor being pointed
    323                 to. Similar to location, this parameter is almost always

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in <module>

AttributeError: module 'torch._C' has no attribute 'native__has_torch_function_unary'
```


## System Information
 - OS:  macos 
 - Language Version:  Python 3.7
 - syft: 0.1.29a1 
 - pytorch: 1.1.0

Hi @napoay !

Thank you for your interest in Syft! Sadly, everything that is lower than `0.3.0` hit EOL and it's no longer supported. Checkout the latest releases, maybe it will suit your needs!",1,2021-05-27 12:59:37,2021-05-28 09:32:25,2021-05-28 09:32:25
https://github.com/OpenMined/PySyft/issues/5559,['bug '],Range test broken in Nightlies,"Range test broken in Nightlies## Description
Nightlies are broken: https://github.com/OpenMined/PySyft/runs/2570729351?check_suite_focus=true
Possibly due to this Range PR: https://github.com/OpenMined/PySyft/pull/5452 

My guess is that the tests were copied from python 3.9 CPython repo. Two things:
1) These always break across different versions because they are designed to fix regressions in older python where as we support all those versions
2) we need to add a reference to these in our LICENSE file.

See: LICENSE:
```

The following files are copied from CPython and are under the PSF license.
See here for more: https://github.com/python/cpython/blob/master/LICENSE

tests/syft/lib/python/collections/ordered_dict/ordered_dict_sanity_test.py
tests/syft/lib/python/complex/complex_test.py
tests/syft/lib/python/dict/dict_test.py
tests/syft/lib/python/float/float_test.py
tests/syft/lib/python/list/list_test.py
tests/syft/lib/python/string/string_utils_test.py
```

```
2021-05-12T22:09:09.0419344Z __________ ERROR collecting tests/syft/lib/python/range/range_test.py __________
2021-05-12T22:09:09.0421077Z ImportError while importing test module '/home/runner/work/PySyft/PySyft/tests/syft/lib/python/range/range_test.py'.
2021-05-12T22:09:09.0422155Z Hint: make sure your test modules/packages have valid Python names.
2021-05-12T22:09:09.0422873Z Traceback:
2021-05-12T22:09:09.0423672Z /opt/hostedtoolcache/Python/3.6.13/x64/lib/python3.6/importlib/__init__.py:126: in import_module
2021-05-12T22:09:09.0424842Z     return _bootstrap._gcd_import(name[level:], package, level)
2021-05-12T22:09:09.0425699Z tests/syft/lib/python/range/range_test.py:7: in <module>
2021-05-12T22:09:09.0426436Z     from test.support import ALWAYS_EQ
2021-05-12T22:09:09.0427366Z E   ImportError: cannot import name 'ALWAYS_EQ'
```

Working on fixing it, will create a PR.This is fixed.",2,2021-05-13 03:28:40,2021-06-01 07:07:43,2021-06-01 07:07:43
https://github.com/OpenMined/PySyft/issues/5536,['bug '],XGBoost Segfault,"XGBoost Segfault## Description
XGBoost is Segfaulting in the test and it happens in any code example as long as Syft is imported before xgboost.

## How to Reproduce

This works:
```python
import numpy as np
import xgboost as xgb
import syft as sy

X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
y = np.array([0, 0, 1, 1])
D_train = xgb.DMatrix(X, label=y)
```

This does not:
```python
import numpy as np
import syft as sy
import xgboost as xgb

X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
y = np.array([0, 0, 1, 1])
D_train = xgb.DMatrix(X, label=y)

```

## System Information
 - OS: MacOS 10.15.7
 - Python 3.8
 - `dev` branch

## Additional Context
I can't seem to figure out why this is the case but its easy to replicate.The original PR actually never ran the tests on MacOS:
https://pipelines.actions.githubusercontent.com/tPFNPqeRbvWdN0L3FU84cUvH4mGjAPQ3yYz8CFZWN08ePzUDwG/_apis/pipelines/1/runs/11244/signedlogcontent/30?urlExpires=2021-05-05T03%3A32%3A49.3947978Z&urlSigningMethod=HMACV1&urlSignature=gtsKxvjjm%2FUo6ouATDjvfN20dsfg6M3RGaO%2FUaFPw8M%3D

```
2021-04-20T08:50:44.4358540Z Failed to load xgboost. XGBoost Library (libxgboost.dylib) could not be loaded.
2021-04-20T08:50:44.4359540Z Likely causes:
2021-04-20T08:50:44.4362060Z   * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.
2021-04-20T08:50:44.4365050Z   * You are running 32-bit Python on a 64-bit OS
2021-04-20T08:50:44.4367390Z Error message(s): ['dlopen(/Users/runner/hostedtoolcache/Python/3.6.13/x64/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/runner/hostedtoolcache/Python/3.6.13/x64/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib\n  Reason: image not found']
```

The reason why these tests skip is for instances where there are mismatches or issues installing especially across different python versions etc so its important to actually check they ran.",1,2021-05-05 03:19:04,2022-06-08 05:34:34,2022-06-08 05:34:34
https://github.com/OpenMined/PySyft/issues/5530,"['bug ', '0.2.x']",AttributeError: module 'syft' has no attribute 'FederatedDataset' and AttributeError: module 'syft' has no attribute 'FederatedDataLoader',"AttributeError: module 'syft' has no attribute 'FederatedDataset' and AttributeError: module 'syft' has no attribute 'FederatedDataLoader'```

federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])
federated_test_dataset = sy.FederatedDataset([bob_test_dataset, anne_test_dataset])

federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, 
                                                shuffle=True, batch_size=BATCH_SIZE)
federated_test_loader = sy.FederatedDataLoader(federated_test_dataset, 
                                               shuffle=False, batch_size=BATCH_SIZE)

```

I trying to implement this but a have error :  
AttributeError: module 'syft' has no attribute 'FederatedDataset'

AttributeError: module 'syft' has no attribute 'FederatedDataLoader'Hi! `0.2.x` hit EOL 2 months ago, we are no longer support it.

Thank you and take a look maybe syft `0.5.0` suits your needs already!",1,2021-05-02 13:14:48,2021-06-01 11:01:44,2021-06-01 11:01:43
https://github.com/OpenMined/PySyft/issues/5509,['bug '],MNIST GPU training is failed,"MNIST GPU training is failed## Description
Try to run MNIST GPU training example from https://github.com/OpenMined/PySyft/tree/dev/examples/duet/mnist but failed. However, CPU training works fine.

## How to Reproduce
1. Open Data owner and Data Scientist notebook based on https://github.com/OpenMined/PySyft/tree/dev/examples/duet/mnist
2. Run Data Owner Code Part 1 to launch duet
3. Run Data Scientist Code Part 1 to join duet
4. Run Data Owner Code Part 2 to add handler
5. Run Data Scientist Code Part 2 to do training
6. Error log show both on Data Scientist training cell and Data Owner handler cell. 

## Expected Behavior
No error happened

## Screenshots
- Data Scientist
> Code
```
import time

args[""dry_run""] = True  # comment to do a full train
print(""Starting Training"")
for epoch in range(1, args[""epochs""] + 1):
    epoch_start = time.time()
    print(f""Epoch: {epoch}"")
    # remote training on model with remote_torch
    train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)
    # local testing on model with local torch
    test_local(model, torch, test_loader, test_data_length)
    scheduler.step()
    epoch_end = time.time()
    print(f""Epoch time: {int(epoch_end - epoch_start)} seconds"")
    if args[""dry_run""]:
        break
print(""Finished Training"")
```
> Error
![image](https://user-images.githubusercontent.com/3213161/115989749-72b40080-a5f2-11eb-9df7-bbcb14e43b14.png)

- Data Owner
![image](https://user-images.githubusercontent.com/3213161/115989784-9e36eb00-a5f2-11eb-9620-021fbe7431b3.png)

## System Information
 - OS: ubuntu Server
 - OS Version: LTS 18.04
 - Language Version: Python 3.6.9
 - Package Manager Version: syft = 0.5.0rc1, torch=1.8.0, torchcsprng=0.2, torchvision=0.9.0
 - Browser (if applicable): Google Chrome
 - Browser Version (if applicable):  90.0.4430.85
 
## Additional Context
Found some explanation on https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte, but failed to send data to cuda  for data_ptr and and target_ptr for the following pySyft training def.
```

def train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length):
    # + 0.5 lets us math.ceil without the import
    train_batches = round((train_data_length / args[""batch_size""]) + 0.5)
    print(f""> Running train in {train_batches} batches"")
    if model.is_local:
        print(""Training requires remote model"")
        return

    model.train()

    for batch_idx, data in enumerate(train_loader):
        data_ptr, target_ptr = data[0], data[1]
        optimizer.zero_grad()
        output = model(data_ptr)
        loss = torch_ref.nn.functional.nll_loss(output, target_ptr)
        loss.backward()
        optimizer.step()
        loss_item = loss.item()
        train_loss = loss_item.resolve_pointer_type()
        if batch_idx % args[""log_interval""] == 0:
            local_loss = None
            local_loss = train_loss.get(
                reason=""To evaluate training progress"",
                request_block=True,
                timeout_secs=5
            )
            if local_loss is not None:
                print(""Train Epoch: {} {} {:.4}"".format(epoch, batch_idx, local_loss))
            else:
                print(""Train Epoch: {} {} ?"".format(epoch, batch_idx))
        if batch_idx >= train_batches - 1:
            print(""batch_idx >= train_batches, breaking"")
            break
        if args[""dry_run""]:
            break
```
Has the problem been solved?I didn't test it for the moment so I close it.",2,2021-04-25 10:23:36,2021-07-25 23:28:57,2021-07-25 23:28:57
https://github.com/OpenMined/PySyft/issues/5507,['bug '],AttributeError: module 'syft' has no attribute 'TensorFlowHook',"AttributeError: module 'syft' has no attribute 'TensorFlowHook'https://stackoverflow.com/questions/67248373/attributeerror-module-syft-has-no-attribute-tensorflowhook

Which version of Syft are you using? If it is 0.2.x, switch to 0.5. PySyft has been completed revamped after 0.2 and there is no use of hooks anymore. Also, support for tensorflow was discontinued.here is my syft version from pip list
syft 0.3.0.post0.dev1298+g30278611f
syft-proto 0.5.3
syft-tensorflow 0.1.0@JozefKondas seems like you are running the wrong code for this version. Support for hooks is deprecated in `0.3.0` .  Try running the below code to create a vm and have a root user. 
```python
import syft as sy
bob_vm = sy.VirtualMachine(name=""bob"")
bob_root = bob_vm.get_root_client()
ptr = bob_root.torch.Tensor([1,2,3])
ptr = ptr.get()
print(ptr)
```
Also, syft no longer supports Tensorflow.I will use torch, thanks for help@avinsit123  could you please share me the link for syft updated documentation?",5,2021-04-24 23:38:20,2021-09-06 20:34:57,2021-05-02 13:19:00
https://github.com/OpenMined/PySyft/issues/5475,['bug '],PyGrid Association Request Example Not Working,"PyGrid Association Request Example Not Working## Description
I'm currently trying out some PyGrid APIs provided in Jupyter notebook in the `/examples/pygrid/association_requests` folder of the repo. 

I just create a new Jupyter Notebook on my own laptop and copy some code from the notebook instead of downloading the notebook directly.

I quickly encountered an issue in the second cell when setting up a domain in my local machine using the following piece of code:

```
domain_node = connect(
    url=""http://localhost:5000"", # Domain Address
    credentials={""email"":""admin@email.com"", ""password"":""pwd123""},
    conn_type= GridHTTPConnection, # HTTP Connection Protocol
)
```

The issue I encountered is the following:

```
---------------------------------------------------------------------------
ConnectionRefusedError                    Traceback (most recent call last)
/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connection.py in _new_conn(self)
    168         try:
--> 169             conn = connection.create_connection(
    170                 (self._dns_host, self.port), self.timeout, **extra_kw

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/util/connection.py in create_connection(address, timeout, source_address, socket_options)
     95     if err is not None:
---> 96         raise err
     97 

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/util/connection.py in create_connection(address, timeout, source_address, socket_options)
     85                 sock.bind(source_address)
---> 86             sock.connect(sa)
     87             return sock

ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

NewConnectionError                        Traceback (most recent call last)
/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    698             # Make the request on the httplib connection object.
--> 699             httplib_response = self._make_request(
    700                 conn,

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)
    393             else:
--> 394                 conn.request(method, url, **httplib_request_kw)
    395 

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connection.py in request(self, method, url, body, headers)
    233             headers[""User-Agent""] = _get_default_user_agent()
--> 234         super(HTTPConnection, self).request(method, url, body=body, headers=headers)
    235 

/usr/lib/python3.8/http/client.py in request(self, method, url, body, headers, encode_chunked)
   1254         """"""Send a complete request to the server.""""""
-> 1255         self._send_request(method, url, body, headers, encode_chunked)
   1256 

/usr/lib/python3.8/http/client.py in _send_request(self, method, url, body, headers, encode_chunked)
   1300             body = _encode(body, 'body')
-> 1301         self.endheaders(body, encode_chunked=encode_chunked)
   1302 

/usr/lib/python3.8/http/client.py in endheaders(self, message_body, encode_chunked)
   1249             raise CannotSendHeader()
-> 1250         self._send_output(message_body, encode_chunked=encode_chunked)
   1251 

/usr/lib/python3.8/http/client.py in _send_output(self, message_body, encode_chunked)
   1009         del self._buffer[:]
-> 1010         self.send(msg)
   1011 

/usr/lib/python3.8/http/client.py in send(self, data)
    949             if self.auto_open:
--> 950                 self.connect()
    951             else:

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connection.py in connect(self)
    199     def connect(self):
--> 200         conn = self._new_conn()
    201         self._prepare_conn(conn)

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connection.py in _new_conn(self)
    180         except SocketError as e:
--> 181             raise NewConnectionError(
    182                 self, ""Failed to establish a new connection: %s"" % e

NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fddc1b96e20>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

MaxRetryError                             Traceback (most recent call last)
/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)
    438             if not chunked:
--> 439                 resp = conn.urlopen(
    440                     method=request.method,

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    754 
--> 755             retries = retries.increment(
    756                 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/urllib3/util/retry.py in increment(self, method, url, response, error, _pool, _stacktrace)
    572         if new_retry.is_exhausted():
--> 573             raise MaxRetryError(_pool, url, error or ResponseError(cause))
    574 

MaxRetryError: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /users/login (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fddc1b96e20>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

ConnectionError                           Traceback (most recent call last)
<ipython-input-2-9ac90a88235f> in <module>
----> 1 domain_node = connect(
      2     url=""http://localhost:5000"", # Domain Address
      3     credentials={""email"":""admin@email.com"", ""password"":""pwd123""},
      4     conn_type= GridHTTPConnection, # HTTP Connection Protocol
      5 )

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/syft/grid/client/client.py in connect(url, conn_type, credentials, user_key)
    202                 raise Exception(response.content[""error""])  # type: ignore
    203 
--> 204     return GridClient(
    205         credentials=credentials, url=url, conn_type=conn_type, client_type=DomainClient
    206     )

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/syft/grid/client/client.py in __init__(self, credentials, url, conn_type, client_type)
     62 
     63             if credentials:
---> 64                 metadata, _user_key = self.conn.login(credentials=credentials)  # type: ignore
     65                 _user_key = SigningKey(_user_key.encode(""utf-8""), encoder=HexEncoder)
     66             else:

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/syft/grid/client/grid_connection.py in login(self, credentials)
     53     def login(self, credentials: Dict) -> Tuple:
     54         # Login request
---> 55         response = requests.post(
     56             url=self.base_url + GridHTTPConnection.LOGIN_ROUTE, json=credentials
     57         )

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/requests/api.py in post(url, data, json, **kwargs)
    117     """"""
    118 
--> 119     return request('post', url, data=data, json=json, **kwargs)
    120 
    121 

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/requests/api.py in request(method, url, **kwargs)
     59     # cases, and look like a memory leak in others.
     60     with sessions.Session() as session:
---> 61         return session.request(method=method, url=url, **kwargs)
     62 
     63 

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/requests/sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)
    540         }
    541         send_kwargs.update(settings)
--> 542         resp = self.send(prep, **send_kwargs)
    543 
    544         return resp

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/requests/sessions.py in send(self, request, **kwargs)
    653 
    654         # Send the request
--> 655         r = adapter.send(request, **kwargs)
    656 
    657         # Total elapsed time of the request (approximately)

/mnt/c/Users/Gilang R Ilhami/Desktop/personal_projects/playground/env/lib/python3.8/site-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)
    514                 raise SSLError(e, request=request)
    515 
--> 516             raise ConnectionError(e, request=request)
    517 
    518         except ClosedPoolError as e:

ConnectionError: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /users/login (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fddc1b96e20>: Failed to establish a new connection: [Errno 111] Connection refused'))
```

I'm not sure what happened here since this is only the beginning of the Jupyter notebook and I see no further description of additional setup steps I had to do. Could I be missing something? Some additional setup perhaps? 

## How to Reproduce
When installing `syft`, I'd suggest installing from the GitHub repo as such:
`pip install git+https://github.com/OpenMined/PySyft.git`

If i install `syft` with `pip install syft`, I was not able to import `connect` from `syft.grid.client.client` due to the following error:

`No module named 'syft.grid.client.client'`

When you got `syft` installed, create your own Jupyter Notebook on your local machine and start copying the code from the Jupytre Notebook in  `/examples/pygrid/association_requests`.

## Expected Behavior
The example notebook didn't show anything if the issue did not occur, so I'm not sure how it would look like if it's successful.

## Screenshots
<img width=""772"" alt=""Cuplikan layar 2021-04-15 162155"" src=""https://user-images.githubusercontent.com/25741803/114846316-c5c5d080-9e06-11eb-8ba3-633f98fd9749.png"">

## System Information
 - OS: Ubuntu Linux 
 - OS Version: 18.04
 - Language Version: Python 3.8 (venv)
 - Package Manager Version: PIP 20.2.4 

I was able to sort this one out.  This is because I was using a URL for the `url` parameter that does not refer to any service using port `5000` in my local machine. Note that the value for `url` has to be a URL that is used by a PyGrid Domain service, which if anybody wants to know how to set up can refer to the [PyGird repo](https://github.com/OpenMined/PyGrid).

I ended up hosting a PyGrid Domain service on a remote server and then passing the URL of that service as the `url` parameter, and now it's working just fine.",1,2021-04-15 09:24:48,2021-04-20 17:51:04,2021-04-20 17:51:04
https://github.com/OpenMined/PySyft/issues/5470,[],Integrate NumPy into PySyft,"Integrate NumPy into PySyft## Feature Description
This issue will eventually integrate NumPy into PySyft.

## Is your feature request related to a problem?
No, it is due to a lack of current support. 

## What alternatives have you considered?
There are presently no alternatives.

## Are you interested in working on this yourself?
Yes.

## Additional Context
The checklist will be added soon.

Is this available to work on?
This is being worked on.",2,2021-04-13 17:34:34,2021-04-21 08:49:34,2021-04-21 08:49:33
https://github.com/OpenMined/PySyft/issues/5464,['bug '],Broken install?,"Broken install?## Description
My syft installation doesn't seem to work as intented as I cannot run the duet MNIST example.

## How to Reproduce
I essentially followed the `CONTRIBUTING.md` installation process, as the current examples somewhat rely on it.
1. git clone the repo
2. create 3.9.0 venv (I've tested both pyenv-virtualenv and pipenv)
3. install dev requirements and jupyter
4. install syft from `pip install -e .`
5. run notebooks, with corresponding kernel

## Error
The training part raises : 
```---------------------------------------------------------------------------
UnknownPrivateException                   Traceback (most recent call last)
<ipython-input-22-653de4faaab9> in <module>
      7     print(f""Epoch: {epoch}"")
      8     # remote training on model with remote_torch
----> 9     train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)
     10     # local testing on model with local torch
     11     test_local(model, torch, test_loader, test_data_length)

<ipython-input-18-c6153a198b5b> in train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length)
     17         optimizer.step()
     18         loss_item = loss.item()
---> 19         train_loss = loss_item.resolve_pointer_type()
     20         if batch_idx % args[""log_interval""] == 0:
     21             local_loss = None

~/projects/PySyft/src/syft/ast/klass.py in _resolve_pointer_type(self)
     64 
     65     # the path to the underlying type. It has to live in the AST
---> 66     real_type_path = self.client.send_immediate_msg_with_reply(msg=cmd).type_path
     67     new_pointer = self.client.lib_ast.query(real_type_path).pointer_type(
     68         client=self.client, id_at_location=id_at_location

~/projects/PySyft/src/syft/core/node/common/client.py in send_immediate_msg_with_reply(self, msg, route_index)
    229                 exception = exception_msg.exception_type(exception_msg.exception_msg)
    230                 error(str(exception))
--> 231                 traceback_and_raise(exception)
    232             else:
    233                 return response.message

~/projects/PySyft/src/syft/logger.py in traceback_and_raise(e, verbose)
     59     if not issubclass(type(e), Exception):
     60         e = Exception(e)
---> 61     raise e
     62 
     63 

UnknownPrivateException: UnknownPrivateException has been triggered.
```

## System Information
 - OS: Ubuntu
 - OS Version: 20.04.2
 - Language Version: Python 3.9
 - Package Manager Version: pip
 
## Additional info
pr tests run fine for the corresponding commit
pip show syft output : 
```
Name: syft
Version: 0.3.0.post0.dev1286+gc08237685
Summary: PySyft is a Python library for secure and private Deep Learning, allowing you to compute on data you do not own and cannot see
Home-page: https://github.com/OpenMined/PySyft
Author: OpenMined
Author-email: info@openmined.org
License: Apache-2.0
Location: /home/marcalph/test/pyenv/PySyft/src
Requires: aiortc, dataclasses, dpcontracts, flask, forbiddenfruit, loguru, nest-asyncio, packaging, pandas, protobuf, PyJWT, PyNaCl, requests, sqlitedict, syft-proto, torch, torchvision, typeguard, typing-extensions, websocket-client
```
@marcalph  Is this bug resolved? I am facing the same issue.",1,2021-04-12 10:39:37,2021-04-30 04:04:08,2021-04-13 19:08:26
https://github.com/OpenMined/PySyft/issues/5460,['bug '],ValueError: bytes is not a 16-char string,"ValueError: bytes is not a 16-char string## Description

The return statement `return deserialize(pb)` in function `get_model(grid_address, worker_id, request_key, model_id)` utilise in the Federated Learning model-centric example `PySyft/examples/federated-learning/model-centric/mcfl_create_plan.ipynb` gives an error `ValueError: bytes is not a 16-char string`

## Software Versions
Pygrid (latest dev branch)
Syft (0.5.0rc1)
Torch (1.8.0)
Torchvision (0.8.2)
Python - (3.7.6)

## How to Reproduce
1. Start Pygrid domain server using command `./run.sh --host localhost  --port 7000 --start_local_db`
2. Execute the NoteBook `PySyft/examples/federated-learning/model-centric/mcfl_create_plan.ipynb`
3. The following error occurs
```
 # Model 
model_params_downloaded = get_model(grid_address, worker_id, request_key, model_id) 
print(""Params shapes:"", [p.shape for p in model_params_downloaded])                                                                                            
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-22-14a183e0aa75> in <module>
      1 # Model
----> 2 model_params_downloaded = get_model(grid_address, worker_id, request_key, model_id)
      3 print(""Params shapes:"", [p.shape for p in model_params_downloaded])

<ipython-input-21-43c3f622395f> in get_model(grid_address, worker_id, request_key, model_id)
      6     pb = ListPB()
      7     pb.ParseFromString(req.content)
----> 8     return deserialize(pb)
      9 

~/anaconda3/lib/python3.7/site-packages/syft/core/common/serde/deserialize.py in _deserialize(blob, from_proto, from_bytes)
     87         traceback_and_raise(deserialization_error)
     88 
---> 89     res = _proto2object(proto=blob)
     90     return res

~/anaconda3/lib/python3.7/site-packages/syft/lib/python/list.py in _proto2object(proto)
    156     @staticmethod
    157     def _proto2object(proto: List_PB) -> ""List"":
--> 158         id_: UID = deserialize(blob=proto.id)
    159         value = []
    160         # list comprehension doesn't work since it results in a

~/anaconda3/lib/python3.7/site-packages/syft/core/common/serde/deserialize.py in _deserialize(blob, from_proto, from_bytes)
     87         traceback_and_raise(deserialization_error)
     88 
---> 89     res = _proto2object(proto=blob)
     90     return res

~/anaconda3/lib/python3.7/site-packages/syft/core/common/uid.py in _proto2object(proto)
    189             if you wish to deserialize an object.
    190         """"""
--> 191         return UID(value=uuid.UUID(bytes=proto.value))
    192 
    193     @staticmethod

~/anaconda3/lib/python3.7/uuid.py in __init__(self, hex, bytes, bytes_le, fields, int, version, is_safe)
    167         if bytes is not None:
    168             if len(bytes) != 16:
--> 169                 raise ValueError('bytes is not a 16-char string')
    170             assert isinstance(bytes, bytes_), repr(bytes)
    171             int = int_.from_bytes(bytes, byteorder='big')

ValueError: bytes is not a 16-char string
```

## Expected Behavior
Show the expected model information.

## Screenshots
If applicable, add screenshots to help explain your problem.

<img width=""933"" alt=""11"" src=""https://user-images.githubusercontent.com/12051191/114309870-0365e900-9ae9-11eb-95a7-43794d75335d.png"">

## System Information
 - OS: [ubuntu]
 - OS Version: [18.04]
 - Language Version: [Python 3.7.6]
Having a similar issue at the same point in the notebook

Any solutions yet ? @YasirArfat32@mnshmnu not yetHave you tried the same with an alternate version of PySyft?

like 0.3.0dev etc..?

@YasirArfat32Fixed in https://github.com/OpenMined/PySyft/pull/5520
Note: this error doesn't affect FL model from being hosted or later execution of training plan (in execute plan notenook).
It's just the part of notebook that demonstrates low-level interaction with pygrid and it had outdated code of how model is serialized.Please reopen as this is not yet fixed in 0.5.0 (latest release) or dev branch. The changes in #5520 still work if applied manually but currently that branch can't be merged to dev due to conflicts.",5,2021-04-11 15:21:57,2021-07-15 14:43:41,2021-05-04 06:12:06
https://github.com/OpenMined/PySyft/issues/5341,['bug '],DictPointer.items() can't be iterated,"DictPointer.items() can't be iterated## Description
I got error when trying to iterate on `DictPointer.items()`, (while I can iterate on `ListPointer`).
## How to Reproduce
```python
# on DO side
duet.requests.add_handler(action=""accept"")

# on DS side
d = sy.lib.python.Dict({""1"":1,""2"":2})
dptr = d.send(duet)
itemsptr = dptr.items() # you get a ListPointer
itemsptr.__len__() # got error
for e in itemsptr: # got error too
    print(e)
```


## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
@tudorcebere Did we end up supporting Dicts in the `Iterator`? Seems like you can get `.len()` on the `dptr` but not on the `itemsptr` interestingly.@madhavajay Awkward, I remember solving this at some point. @xutongye fixed and added tests to be sure to not have a regression again.",2,2021-03-23 02:39:19,2021-03-23 20:07:18,2021-03-23 20:07:18
https://github.com/OpenMined/PySyft/issues/5334,['bug '],ImportError: cannot import name 'get_root_data_path',"ImportError: cannot import name 'get_root_data_path'## Description
ImportError when executing `from syft.util import get_root_data_path`


## How to Reproduce
1. Go to 'PySyft/examples/duet/dcgan/DCGAN_Syft_Data_Owner.ipynb'
2. Execute second cell.
4. See **ImportError: cannot import name 'get_root_data_path'**

## Screenshots
![Screenshot from 2021-03-21 18-09-30](https://user-images.githubusercontent.com/59893283/111905455-b48cdc80-8a71-11eb-8631-3901acadec20.png)
****

## System Information
 - OS: Ubuntu 18.04 LTS
 - Language Version: Python 3.6.9

Hi @yashmaurya01 since many of the notebooks, including this one in particular are run in our integration tests in CI, your error probably means you don't have the right version of Syft installed.

Until the next release it's advised to install directly from the `dev` branch.
```
$  pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft
```This should be fixed.Hello @madhavajay !

I have the same problem with this function, but when I tried to install PySyft from the dev branch, an error raised. How can this can be fixed?

Thank you!


![image](https://user-images.githubusercontent.com/2991063/121261791-8f965180-c889-11eb-905d-112cc944d4af.png)",3,2021-03-21 12:47:53,2021-06-08 21:47:50,2021-03-23 23:58:07
https://github.com/OpenMined/PySyft/issues/5311,['bug '],Installation in Colab,"Installation in Colab## Description
import  shows error

## How to Reproduce
1. Open a colab notebook
2. 
```bash
!pip install syft
import syft as sy
```
## Expected Behavior
No error

## Screenshots
![image](https://user-images.githubusercontent.com/19462637/111311632-73b55200-8684-11eb-8a30-219e54960c9e.png)
![image](https://user-images.githubusercontent.com/19462637/111311692-8465c800-8684-11eb-971c-b1e6bbcd5c0b.png)


## System Information
 - Environment - colab.research.google.com
@abhi1nandy2 could you try to install ```torch == 1.7.1``` after installing syft.
The issue might be because ```torch1.8``` is out and syft was not released (YET!) with torch1.8 support.@gmuraru I tried this out the other day but to no avail. You still get the same error!Sadly - this is a known issue. The latest version of PySyft is not compatible with some of the ways Colab is locked down - pip install locally (using conda) and we'll address colab integration in a later version.

CC: @madhavajay to confirm.We can install in Colab, but there are issues running in Colab after the connection is established which relates to networking between Colab and another system which we are investigating.

To install in colab do this:
```python
%%capture
# This only runs in colab and clones the code sets it up and fixes a few issues, 
# you can skip this if you are running Jupyter Notebooks
import sys
if ""google.colab"" in sys.modules:
    branch = ""dev""    # change to the branch you want
    ! git clone --single-branch --branch $branch https://github.com/OpenMined/PySyft.git
    ! cd PySyft && ./scripts/colab.sh      # fixes some colab python issues
    sys.path.append(""/content/PySyft/src"") # prevents needing restart
```

You can see more about whats going on in the script `scripts/colab.sh`.

Additionally if you are reading this ticket because you are trying to use Syft for the Privacy Course on your local Jupyter until the next PyPI release you will need to install via git:
```
pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft
```Thanks a lot!",5,2021-03-16 12:52:15,2021-04-21 08:28:40,2021-04-21 08:28:40
https://github.com/OpenMined/PySyft/issues/5271,[],TypeError: send() got an unexpected keyword argument 'tags',"TypeError: send() got an unexpected keyword argument 'tags'Î—ello and greetings from greece
I am trying to execute the following example but i cant run this line of code
`data_pointer = data.send(duet, tags=[""dataset""], description=""simple binary dataset"", pointable=True)`
because send does not have those attributes

 [the link of the example](https://colab.research.google.com/github/OpenMined/PySyft/blob/dev/examples/vertical-learning/basic_splitnn/DS_local_data.ipynb#scrollTo=lWz6sCuf9oZN)

is there any version of syft that can execute this example or another way to solve this issue
thank you in advanceThe API is under flux and all the working examples in CI are off `dev`. Its possible you are using `0.3.0` from PyPI. Try installing the `dev` branch directly and play with the examples which are in the examples folder as most of them are tested with CI against the `dev` directly.",1,2021-03-08 13:31:02,2021-03-12 07:11:53,2021-03-12 07:11:53
https://github.com/OpenMined/PySyft/issues/5234,['bug '],conftest.py file is erroneous,"conftest.py file is erroneous## Description
I use ``pipenv shell`` for all the PySyft work. I was testing my ``slice`` branch from ``dev`` branch and ran ``pytest -m fast`` and got an exception.

## How to Reproduce
1. Go to PySyft repo
2. Type in ``pytest -m fast`` or ``pytest -m slow`` or ``pytest -m all`` or ``pytest -m vendor``
3. See error

## Expected Behavior
Run all the tests

## System Information
 - OS: Ubuntu 20.04 LTS
 - Language Version: Python 3.8
 - Package Manager Version: Conda latest
 
## Additional Context
The error is as follows : 
```
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest -m fast -n auto
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ cd src/syft/lib/python
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib/python$ nano bool.py
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib/python$ nano slice.py
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib/python$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/lib$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src$ cd ..
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest -m fast
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ pytest -m fast -n auto
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
tests/conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
(nabanita07) (base) nabanita07@nabanita07:~/PySyft$ cd tests
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/tests$ nano conftest.py
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/tests$ pytest -m all
ImportError while loading conftest '/home/nabanita07/PySyft/tests/conftest.py'.
conftest.py:19: in <module>
    from syft.lib import VendorLibraryImportException
E   ImportError: cannot import name 'VendorLibraryImportException' from 'syft.lib' (/home/nabanita07/anaconda3/lib/python3.8/site-packages/syft/lib/__init__.py)
```
@dnabanita7 we use those commands in CI, so it's possible this is related to your current branch.
Are you in a particular branch you can share to test this?
Do you have a circular import or other issue in your branch?My bad! it works fine now.
What is a circular import?",2,2021-03-02 06:14:31,2021-03-02 13:32:01,2021-03-02 13:32:00
https://github.com/OpenMined/PySyft/issues/5208,"['bug ', 'priority: 2 - high :cold_sweat:', '0.5']",Handler Serde,"Handler Serde## Description
The `duet.requests.handler` return value is broken currently due to serialization errors.

```
TypeError: You tried to deserialize an unsupported type. This can be caused by several reasons. Either you are actively writing Syft code and forgot to create one, or you are trying to deserialize an object which was serialized using a different version of Syft and the object you tried to deserialize is not supported in this version.
```

## How to Reproduce
Run: `duet.requests.handler`

## Expected Behavior
No error

## Additional Context
We will be refactoring this anyway.want to work on this",1,2021-02-23 07:01:31,2021-03-04 13:08:56,2021-03-04 13:08:56
https://github.com/OpenMined/PySyft/issues/5150,['bug '],[Core Security Audit] security vulnerabilities found with safety check,"[Core Security Audit] security vulnerabilities found with safety check## Description
As part of the security audit I ran [free-tier safety](https://pyup.io/safety/) check on PySyft and found multiple libraries with known vulnerabilities

## How to Reproduce
1. make Python 3.8.2 virtual environment using virtualenv 
2. activate virtual environment
3. `$ pip install safety`
4. `$ pip install syft`
5. `$ safety check`

## Expected Behavior
Fewer or no libraries found with known vulnerabilities

## Screenshots
n/a see attached safety check report 
[safety-check.log](https://github.com/OpenMined/PySyft/files/5972727/safety-check.log)

## System Information
 - OS: Kali Linux
 - OS Version: 2020.2a
 - Language Version: Python 3.8.2
 - Package Manager Version: virtualenv

## Additional Context
See attached report for affected libraries
@socd06 are you sure you are scanning syft?

None of these packages are in our requirements or installed in my virtualenv? Perhaps you are running `safety check` with your main system site-packages in the path.


If I run the same safety check I get the following:
```
safety report
checked 160 packages, using free DB (updated once a month)
---
-> tornado, installed 6.1, affected <=6.1, id 39462
```

Additionally looking into this:
```
$ pip install pipdeptree
$ pipdeptree -r -p tornado
tornado==6.1
  - jupyter-client==6.1.11 [requires: tornado>=4.1]
    - nbclient==0.5.2 [requires: jupyter-client>=6.1.5]
      - nbconvert==6.0.7 [requires: nbclient>=0.5.0,<0.6.0]
```

It appears tornado is only being used by Jupyter.

Looking at the CVE:
```json
""tornado"": [
    {
        ""advisory"": ""All versions of package tornado are vulnerable to Web Cache Poisoning by using a vector called parameter cloaking. When the attacker can separate query parameters using a semicolon (;), they can cause a difference in the interpretation of the request between the proxy (running with default configuration) and the server. This can result in malicious requests being cached as completely safe ones, as the proxy would usually not see the semicolon as a separator, and therefore would not include it in a cache key of an unkeyed parameter. See CVE-2020-28476."",
        ""cve"": null,
        ""id"": ""pyup.io-39462"",
        ""specs"": [
            ""<=6.1""
        ],
        ""v"": ""<=6.1""
    }
],
```

https://vuldb.com/?id.168074
https://snyk.io/vuln/SNYK-PYTHON-TORNADO-1017109

Based on that it's not clear that Jupyter itself would be vulnerable but the Jupyter server would need to be accessible to the attacker. Syft does not use Jupyter for communication itself, instead it operates over a WebRTC connection established in Python, so I would imagine this likely does not apply.

What are your thoughts on this?
Yes it seems I wrote the issue poorly. Just edited the steps to reproduce. Let me double check on Ubuntu 18.04 LTS and anaconda, might have to do with it being on kali and virtualenvOK just did the same thing on Ubuntu + Conda and got the same result as you. 
Steps:
1. `$ conda create -n pysyft python=3.8`
2. `$ conda activate pysyft`
3. `$ conda install jupyter notebook`
4. `$ pip install syft`
5. `$ pip install safety`
6. `$ safety check`

Closing since it's not clear if Jupyter is vulnerable. My original report probably had to do with Kali + Virtualenv or just a mistake on my end. @socd06 You could report a bug with Kali saying their packages are vulnerable. Who's watching the watchers? ðŸ˜‚",4,2021-02-12 15:33:12,2021-02-23 04:54:27,2021-02-16 18:31:24
https://github.com/OpenMined/PySyft/issues/5134,"['bug ', '0.2.x']",I get syft.frameworks isn't a module error,"I get syft.frameworks isn't a module error## Description
I have downloaded syft 3.0, 0.2.9 and 0.2.8. syft 3.0 shows this error. While syft 0.2.9 and syft 0.2.8 shows mismatched torch version. I use the latest version of pytorch.

```
Collecting syft==0.2.8
  Downloading syft-0.2.8-py3-none-any.whl (415 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415 kB 71 kB/s  eta 0:00:01
Requirement already satisfied: websockets~=8.1.0 in /home/nabanita07/anaconda3/envs/pysyft/lib/python3.9/site-packages (from syft==0.2.8) (8.1)
ERROR: Could not find a version that satisfies the requirement torch~=1.4.0 (from syft)
ERROR: No matching distribution found for torch~=1.4.0
```

## How to Reproduce
1. !pip install syft==0.2.9 or lower versions
2. See the error

## Expected Behaviour
0.2 versions and lower of syft doesn't support PyTorch's latest version. Syft 3.0 doesn't support the latest versions of frameworks package. Shall I have to downgrade PyTorch's version?

## System Information
 - OS: [e.g. Ubuntu Linux]
 - Language Version: [e.g. Python 3.8]
 - Package Manager Version: [e.g. Conda latest]
 - Browser (if applicable): [e.g. Google Chrome latest]
Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",1,2021-02-10 05:34:48,2021-04-21 09:21:51,2021-04-21 09:21:50
https://github.com/OpenMined/PySyft/issues/5132,"['bug ', '0.2.x']",RuntimeError: set_storage is not allowed on Tensor created from .data or .detach(),"RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()windows 10
python 3.7.3
pytorch=1.1.0
pysyft=0.1.15a1


```
def plot_federated_graphs(diagnosis_title, losses, accuracies):
    for i in range(n_hospitals):
        plt.plot(losses[i], label=f'Hospital {i}')
    legend = plt.legend(loc='upper right', shadow=True)
    plt.title(f""{diagnosis_title} - Training Loss"")
    plt.xlabel(""Iterations"")
    plt.ylabel(""Training Loss"")
    plt.show()
    for i in range(n_hospitals):
        plt.plot(accuracies[i], label=f'Hospital {i}')
    legend = plt.legend(loc='lower right', shadow=True)
    plt.title(f""{diagnosis_title} - Training Accuracy"")
    plt.xlabel(""Iterations"")
    plt.ylabel(""Training Accuracy (Percent %)"")
    plt.show()
    
def compute_federated_accuracy(model, input, output):
    prediction = model(input)
    n_samples = prediction.shape[0]
    s = 0.
    for i in range(n_samples):
        p = 1. if prediction[i] >= 0.5 else 0.
        e = 1. if p == output[i] else 0.
        s += e
    return 100. * s / n_samples

iterations = 1000 #2000
worker_iterations = 5

def federated_learning(diagnosis_title, hospital_features, hospital_targets, test_input, test_output):
    model = LogisticRegression()
    criterion = torch.nn.BCELoss(size_average=True)
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  
    losses = [[] for i in range(n_hospitals)]
    accuracies = [[] for i in range(n_hospitals)]
    for iteration in range(iterations):
        models = [model.copy().send(hospitals[i]) for i in range(n_hospitals)]
        optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_hospitals)]
        for worker_iteration in range(worker_iterations):
            last_losses = []
            for i in range(n_hospitals):
                optimizers[i].zero_grad()
                prediction = models[i](hospital_features[i])
                loss = criterion(prediction, hospital_targets[i])
                loss.backward()
                optimizers[i].step()
                loss = loss.get().data.item()
                last_losses.append(loss)
        for i in range(n_hospitals):
            losses[i].append(last_losses[i])
            train_acc = compute_federated_accuracy(models[i], hospital_features[i], hospital_targets[i])
            accuracies[i].append(train_acc)
            models[i].move(secure_worker)
        with th.no_grad():
            avg_weight = sum([models[i].linear.weight.data for i in range(n_hospitals)]) / n_hospitals
            model.linear.weight.set_(avg_weight.get())
            avg_bias = sum([models[i].linear.bias.data for i in range(n_hospitals)]) / n_hospitals
            model.linear.bias.set_(avg_bias.get())
        if iteration % 100 == 0:
            losses_str = ['{:.4f}'.format(losses[i][-1]) for i in range(n_hospitals)]
            accuracies_str = [to_percent(accuracies[i][-1]) for i in range(n_hospitals)]
            print('Iteration={}, losses={}, accuracies={}'.format(iteration, losses_str, accuracies_str))
    plot_federated_graphs(diagnosis_title, losses, accuracies)
    test_acc = compute_accuracy(model, test_input, test_output)
    print('\nTesting Accuracy = {}'.format(to_percent(test_acc)))
    return model
model = federated_learning(diagnosis_title1, hospital_features, hospital_targets1, test_input, test_output1)
```


```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-20-f697b3c5e29b> in <module>
----> 1 model = federated_learning(diagnosis_title1, hospital_features, hospital_targets1, test_input, test_output1)

<ipython-input-19-4e11088f598e> in federated_learning(diagnosis_title, hospital_features, hospital_targets, test_input, test_output)
     35     accuracies = [[] for i in range(n_hospitals)]
     36     for iteration in range(iterations):
---> 37         models = [model.copy().send(hospitals[i]) for i in range(n_hospitals)]
     38         optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_hospitals)]
     39         for worker_iteration in range(worker_iterations):

<ipython-input-19-4e11088f598e> in <listcomp>(.0)
     35     accuracies = [[] for i in range(n_hospitals)]
     36     for iteration in range(iterations):
---> 37         models = [model.copy().send(hospitals[i]) for i in range(n_hospitals)]
     38         optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_hospitals)]
     39         for worker_iteration in range(worker_iterations):

/opt/conda/lib/python3.7/site-packages/syft/frameworks/torch/hook.py in module_send_(nn_self, dest)

/opt/conda/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in send_(self, *location)
    329             for loc in location:
    330                 children.append(self.clone().send(loc))
--> 331 
    332             output = syft.frameworks.torch.tensors.interpreters.MultiPointerTensor(
    333                 children=children

/opt/conda/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in send(self, inplace, *location)
    278                     ptr_ = self.ptr()
    279                     if ptr_ is not None:
--> 280                         ptr_.garbage_collect_data = False
    281 
    282             # we need to cache this weak reference to the pointer so that

RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()
```Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",1,2021-02-09 15:47:25,2021-04-21 09:21:39,2021-04-21 09:21:39
https://github.com/OpenMined/PySyft/issues/5080,"['bug ', '0.5']",Duet: send a model in the store for debugging purposes.,"Duet: send a model in the store for debugging purposes.## Description
For the TenSEAL training/inference scenarios, I want to compare the encrypted results with the plain results.
More specifically, I want to evaluate N ciphertexts with a model and get their accuracy.
Then, I want to test the N underlining plaintexts with the same model and get the plain accuracy.

Then, I want to show a comparison between the plain accuracy and the encrypted accuracy. 
But for the second step, I have to share the model with the DO instance.

The model inherits sy.Module, but I cannot add tags on Duet send.

model.send(duet, tags=[""model""])
results in the error
```
TypeError: send() got an unexpected keyword argument 'tags'
```
I cannot retrieve the model_ptr otherwise

## System Information
 - Language Version: Python 3.8
@bcebere We also need something similar for Opacus so we can remotely attach the PrivacyEngine to the model. The way the SyModule currently works is its a thin veneer over the submodule layers. Perhaps we can simply create a real torch module on either side inside the SyModule to help attach all of the layers to thus providing a very real normal model to get a pointer to. The main issue is that `send` requires serialization so if we want to send the whole model we need to support sending everything the model supports where as currently we just invoke the creation of the same modules remotely. I would love some input on the best way to tackle this one.@bcebere this is resolved now that torch.nn.module is serializable properly.",2,2021-02-01 07:03:54,2021-04-21 07:51:47,2021-04-21 07:51:47
https://github.com/OpenMined/PySyft/issues/5073,"['bug ', '0.5', 'rescope']",tenseal: Performance Issues,"tenseal: Performance Issues## Description
Consider the following stress test using TenSEAL:
``` 
@pytest.fixture(scope=""function"")
def context() -> Any:
    context = ts.context(
        ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.global_scale = pow(2, 40)
    context.generate_galois_keys()
    return context
  
@pytest.fixture(scope=""function"")
def duet() -> Any:
    return sy.VirtualMachine().get_root_client()

@pytest.mark.vendor(lib=""tenseal"")
 def test_tenseal_ckkstensor_stress_imul(context: Any, duet: sy.VirtualMachine) -> None:
     v1 = [0, 1, 2, 3, 4]
     v2 = [4, 3, 2, 1, 0]
     expected = [v1 * v2 for v1, v2 in zip(v1, v2)]
 
     for i in range(20):
         enc_v1 = ts.ckks_tensor(context, v1)
 
         ctx_ptr = context.send(duet, searchable=True)
         enc_v1_ptr = enc_v1.send(duet, searchable=True)
 
         enc_v1_ptr.link_context(ctx_ptr)
 
         # imul
         result_enc_ptr = enc_v1_ptr * v2
 
         result = decrypt(context, result_enc_ptr)
         _almost_equal(result, expected)
```

This test takes **116.19s**. Removing the `generate_galois_keys` call reduces the duration to **34s**.

Simulating the same test using just the TenSEAL library
```
 def test_stress_imul(context):
     v1 = [0, 1, 2, 3, 4]
     v2 = [4, 3, 2, 1, 0]
     expected = [v1 * v2 for v1, v2 in zip(v1, v2)]
 
     for i in range(20):
         buf = context.serialize(save_secret_key=True)
         newctx = ts.context_from(buf)
 
         tensor = ts.ckks_tensor(newctx, v1)
 
         res = tensor * v2
 
         plain_ts = res.decrypt()
         decrypted_result = plain_ts.tolist()
 
         _almost_equal(decrypted_result, expected), ""Product is incorrect.""
```
This test takes **6.12s**. Removing the `generate_galois_keys` call reduces the duration to **2.45s**.

Profiling the Duet code using cProfile returns
```
   Ordered by: cumulative time
   List reduced from 8996 to 100 due to restriction <100>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   2171/1    0.148    0.000  104.937  104.937 {built-in method builtins.exec}
        1    0.000    0.000  104.937  104.937 <string>:1(<module>)
        1    0.000    0.000  104.937  104.937 runpy.py:197(run_module)
        1    0.000    0.000  104.803  104.803 runpy.py:64(_run_code)
        1    0.000    0.000  104.803  104.803 __main__.py:1(<module>)
        1    0.000    0.000  104.803  104.803 __init__.py:178(console_main)
        1    0.000    0.000  104.802  104.802 __init__.py:130(main)
   654/55    0.000    0.000  104.782    1.905 manager.py:90(_hookexec)
   654/55    0.001    0.000  104.782    1.905 manager.py:84(<lambda>)
   654/55    0.009    0.000  104.782    1.905 callers.py:157(_multicall)
    269/2    0.001    0.000  104.780   52.390 hooks.py:272(__call__)
        1    0.000    0.000  101.890  101.890 main.py:315(pytest_cmdline_main)
        1    0.000    0.000  101.890  101.890 main.py:256(wrap_session)
        1    0.000    0.000  101.728  101.728 main.py:319(_main)
       10    0.000    0.000   99.848    9.985 runner.py:298(from_call)
        1    0.000    0.000   99.736   99.736 main.py:336(pytest_runtestloop)
        1    0.000    0.000   99.705   99.705 runner.py:106(pytest_runtest_protocol)
        1    0.000    0.000   99.705   99.705 runner.py:114(runtestprotocol)
        3    0.000    0.000   99.705   33.235 runner.py:212(call_and_report)
        3    0.000    0.000   99.704   33.235 runner.py:240(call_runtest_hook)
        3    0.000    0.000   99.704   33.235 runner.py:255(<lambda>)
        1    0.000    0.000   95.425   95.425 runner.py:153(pytest_runtest_call)
        1    0.000    0.000   95.425   95.425 python.py:1639(runtest)
        1    0.000    0.000   95.425   95.425 python.py:176(pytest_pyfunc_call)
        1    0.001    0.001   95.425   95.425 tenseal_ckkstensor_test.py:228(test_tenseal_ckkstensor_stress_imul)
29891/2243    0.035    0.000   81.579    0.036 syft_decorator_impl.py:29(wrapper)
29891/2243    0.095    0.000   81.576    0.036 typecheck.py:116(decorator)
29891/2243    0.218    0.000   81.510    0.036 __init__.py:888(wrapper)
      100    0.032    0.000   78.250    0.782 client.py:252(send_immediate_msg_without_reply)
       60    0.002    0.000   70.730    1.179 klass.py:276(send)
  200/182    0.065    0.000   51.134    0.281 message.py:75(sign)
 2040/182    0.404    0.000   44.336    0.244 serializable.py:231(serialize)
   180/80    0.005    0.000   41.932    0.524 storeable_object.py:103(_object2proto)
       60    0.001    0.000   41.666    0.694 save_object_action.py:71(_object2proto)
       60    0.000    0.000   41.591    0.693 klass.py:355(serialize)
   320/80    0.002    0.000   41.584    0.520 serialize.py:13(_serialize)
       20    0.367    0.018   38.684    1.934 context.py:31(_data_object2proto)
       20   38.315    1.916   38.315    1.916 enc_context.py:172(serialize)
      100    0.001    0.000   28.221    0.282 route.py:164(send_immediate_msg_without_reply)
      100    0.000    0.000   28.218    0.282 virtual.py:74(send_immediate_msg_without_reply)
      100    0.000    0.000   28.205    0.282 virtual.py:40(recv_immediate_msg_without_reply)
      100    0.001    0.000   28.192    0.282 node.py:392(recv_immediate_msg_without_reply)
      820    0.001    0.000   18.304    0.022 message.py:138(message)
 2040/200    0.410    0.000   18.260    0.091 deserialize.py:15(_deserialize)
       60    0.001    0.000   16.268    0.271 save_object_action.py:93(_proto2object)
   180/80    0.036    0.000   16.090    0.201 storeable_object.py:146(_proto2object)
       20    0.395    0.020   15.017    0.751 context.py:40(_data_proto2object)
       20    0.000    0.000   14.620    0.731 __init__.py:68(context_from)
       20    0.000    0.000   14.620    0.731 enc_context.py:157(load)
       20   14.620    0.731   14.620    0.731 {built-in method _tenseal_cpp.deserialize}
       80   11.171    0.140   11.172    0.140 ckkstensor.py:10(__init__)
       20    0.000    0.000   11.172    0.559 __init__.py:116(ckks_tensor)
      180    0.032    0.000   10.845    0.060 node.py:455(process_message)
       40    0.001    0.000    8.551    0.214 klass.py:43(run_class_method)
       39    0.003    0.000    6.962    0.179 __init__.py:2(<module>)
      100    0.000    0.000    6.576    0.066 obj_action_service.py:21(process)
       40    0.002    0.000    6.542    0.164 run_class_method_action.py:81(execute_action)
      200    0.376    0.002    6.454    0.032 signing.py:190(sign)
      200    0.349    0.002    5.732    0.029 crypto_sign.py:77(crypto_sign)
       20    0.000    0.000    5.630    0.282 abstract_tensor.py:115(__mul__)
       20    5.546    0.277    5.630    0.281 ckkstensor.py:65(mul)
      200    5.380    0.027    5.380    0.027 {built-in method _sodium.crypto_sign}
       20    0.000    0.000    5.225    0.261 utils_test.py:6(decrypt)
        1    0.000    0.000    4.277    4.277 runner.py:148(pytest_runtest_setup)
        1    0.000    0.000    4.277    4.277 runner.py:436(prepare)
        1    0.000    0.000    4.277    4.277 python.py:1643(setup)
        1    0.000    0.000    4.277    4.277 fixtures.py:563(_fillfixtures)
        2    0.000    0.000    4.277    2.138 fixtures.py:570(getfixturevalue)
        2    0.000    0.000    4.277    2.138 fixtures.py:585(_get_active_fixturedef)
        2    0.000    0.000    4.277    2.138 fixtures.py:617(_compute_fixture_value)
        2    0.000    0.000    4.277    2.138 fixtures.py:1044(execute)
        2    0.000    0.000    4.276    2.138 fixtures.py:1111(pytest_fixture_setup)
        2    0.000    0.000    4.276    2.138 fixtures.py:916(call_fixture_func)
        1    0.000    0.000    3.700    3.700 tenseal_ckkstensor_test.py:27(context)
      200    0.030    0.000    3.615    0.018 message.py:146(is_valid)
      200    0.380    0.002    3.585    0.018 signing.py:90(verify)
        1    3.415    3.415    3.415    3.415 enc_context.py:227(generate_galois_keys)
        5    0.000    0.000    3.407    0.681 client.py:2(<module>)
      200    0.347    0.002    3.205    0.016 crypto_sign.py:97(crypto_sign_open)
       20    0.001    0.000    3.170    0.158 ckkstensor.py:51(decrypt)
       20    3.167    0.158    3.167    0.158 abstract_tensor.py:81(_decrypt)
 2087/221    0.012    0.000    2.922    0.013 <frozen importlib._bootstrap>:986(_find_and_load)
 2076/219    0.011    0.000    2.916    0.013 <frozen importlib._bootstrap>:956(_find_and_load_unlocked)
        1    0.000    0.000    2.912    2.912 __init__.py:297(_prepareconfig)
  1770/53    0.010    0.000    2.902    0.055 <frozen importlib._bootstrap>:650(_load_unlocked)
        1    0.000    0.000    2.889    2.889 __init__.py:999(pytest_cmdline_parse)
        1    0.000    0.000    2.889    2.889 __init__.py:1275(parse)
        1    0.000    0.000    2.883    2.883 __init__.py:1149(_preparse)
      200    2.855    0.014    2.855    0.014 {built-in method _sodium.crypto_sign_open}
  2220/53    0.002    0.000    2.822    0.053 <frozen importlib._bootstrap>:211(_call_with_frames_removed)
  1524/50    0.005    0.000    2.785    0.056 <frozen importlib._bootstrap_external>:777(exec_module)
    32/16    0.000    0.000    2.755    0.172 __init__.py:109(import_module)
    44/16    0.000    0.000    2.755    0.172 <frozen importlib._bootstrap>:1002(_gcd_import)
    70/25    0.001    0.000    2.747    0.110 rewrite.py:130(exec_module)
        7    0.000    0.000    2.645    0.378 pathlib.py:458(import_path)
       60    2.617    0.044    2.617    0.044 abstract_tensor.py:72(serialize)
       17    0.000    0.000    2.551    0.150 __init__.py:515(_getconftestmodules)
       15    0.000    0.000    2.547    0.170 __init__.py:552(_importconftest)
        1    0.000    0.000    2.546    2.546 __init__.py:1068(pytest_load_initial_conftests)
        1    0.000    0.000    2.546    2.546 __init__.py:474(_set_initial_conftests)
```


## System Information
 - OS: Linux Mint 20
 - Python 3.8.0Full cProfile dump.

Decompress first. Can be visualized with 
```
pyprof2calltree -i profile -k
```

[profile.tar.gz](https://github.com/OpenMined/PySyft/files/5897630/profile.tar.gz)
Full profiling script

```
import os
import pytest
from time import time
import tenseal as ts

import syft as sy
from typing import Any

import pstats
import cProfile

profile = cProfile.Profile()

sy.logger.remove()
LOOPS = 50


def duet_ctx() -> Any:
    return sy.VirtualMachine().get_root_client()


def context():
    context = ts.context(
        ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.global_scale = pow(2, 40)
    context.generate_galois_keys()
    return context


def test_stress_imul_duet() -> None:
    sy.load_lib(""tenseal"")

    v1 = [0, 1, 2, 3, 4]
    v2 = [4, 3, 2, 1, 0]
    expected = [v1 * v2 for v1, v2 in zip(v1, v2)]

    duet = duet_ctx()
    ctx = context()

    ctx_ptr = ctx.send(duet, searchable=True)

    for i in range(LOOPS):
        enc_v1 = ts.ckks_tensor(ctx, v1)
        enc_v1_ptr = enc_v1.send(duet, searchable=True)
        enc_v1_ptr.link_context(ctx_ptr)
        enc_v1_ptr.link_context(ctx_ptr)

        result_enc_ptr = enc_v1_ptr * v2
        result_enc = result_enc_ptr.get()


start = time()

profile.runcall(test_stress_imul_duet)

total = time() - start
op_results = total / LOOPS
print(f""AVG Duet imul duration: {op_results} sec. total {total} sec"")

ps = pstats.Stats(profile)
ps.sort_stats(""tottime"")

ps.print_stats()
```Some lessons:
 - Duet should have the concept of session. The TenSEAL context needs to sent only once. That reduces the running time of the above script from 80sec to 15 sec. This is still 13 sec slower than the native version.
 - It looks like some crypto signing operations and typeguarding are taking a lot of time.

The top calls in the profiler are
```
         15783679 function calls (15178813 primitive calls) in 15.337 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    1.290    0.006    1.293    0.006 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/ckkstensor.py:10(__init__)
      550    1.201    0.002    1.201    0.002 {built-in method _sodium.crypto_sign}
      150    1.085    0.007    1.085    0.007 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/abstract_tensor.py:72(serialize)
      550    0.659    0.001    0.659    0.001 {built-in method _sodium.crypto_sign_open}
75506/72986    0.626    0.000    1.122    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2889(_bind)
245244/145684    0.603    0.000    1.767    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:601(check_type)
       50    0.549    0.011    0.689    0.014 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/ckkstensor.py:65(mul)
    75506    0.537    0.000    1.330    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2112(_signature_from_function)
        1    0.418    0.418    0.418    0.418 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/enc_context.py:172(serialize)
1423757/1419919    0.345    0.000    0.353    0.000 {built-in method builtins.getattr}
    75506    0.344    0.000    1.171    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:842(typechecked)
75506/72902    0.330    0.000    3.844    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:100(__init__)
2744871/2740634    0.318    0.000    0.320    0.000 {built-in method builtins.isinstance}
75506/2432    0.310    0.000   13.694    0.006 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:888(wrapper)
75506/75422    0.295    0.000    1.824    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2206(_signature_from_callable)
      100    0.264    0.003    0.264    0.003 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/abstract_tensor.py:31(link_context)
   167319    0.236    0.000    0.412    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2477(__init__)
        1    0.235    0.235    0.235    0.235 {built-in method _tenseal_cpp.deserialize}
        1    0.216    0.216    0.216    0.216 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/enc_context.py:227(generate_galois_keys)
    75506    0.200    0.000    0.357    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/functools.py:34(update_wrapper)
   151012    0.197    0.000    0.361    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:171(_has_code_flag)
```@bcebere The typecheck is gone and we have an idea about building a client side cache, do you think that would help improve this scenario?Yes, that helps.

Still, the big impact comes from the signing logic.
So, 
 1. Do we need to sign the already encrypted data too?
 2. If yes, do we need to re-serialize the deserialized object for that? if storable object can keep a hash for the signing logic directly, that could speed-up things.@bcebere Totally open to suggestions for improvement. I assume we will need to hash it at least once, and surely at the time of signing to make sure it isn't changed? We could use something else to hash the message, perhaps an interface allowing a custom hash implementation on any given message and a fallback to the hash of the bytes after serialization?",6,2021-01-30 08:36:27,2022-06-08 05:13:48,2022-06-08 05:13:48
https://github.com/OpenMined/PySyft/issues/5069,"['bug ', 'help wanted :wave:', '0.5', 'rescope']",Accepting requests on objects from an iterable,"Accepting requests on objects from an iterable## Description
We would like to be able to do on the DS side:
```
torch_ptr = duet.torch.Tensor([1, 2, 3])
torch_ptr[0].request(reason=""some reason"")
```
And on the DO side:
```
duet.requests[0].accept()
```
Currently, the execution fails due to unknown UID of torch_ptr[0] in the store.

## Expected Behavior
We would like to be able to get the described object.

## Additional Context
The issue will be assigned after a PR will be opened. The PR has to have the base branch the `0.4` one.Hi, I think there is a bigger bug in the functionality provided here,

When we execute the following statement from the DS side:

```
torch_ptr = duet.torch.Tensor([1, 2, 3])
```

It adds the data in the store of the Data Owner beforehand (even before administering the request itself). The Data Scientist can flood the data store of the data owner via this, an example

```
>>> duet.store.pandas
                                        ID Tags Description             object_type
0  <UID: cd63b75dfa55405eaabe28546e7b9717>  [x]      xasdad  <class 'torch.Tensor'>
1  <UID: e50520210b4244ca87eb274c4659f997>   []              <class 'torch.Tensor'>
2  <UID: 4ca9b63f45534f7a8e53bee1bec5bb96>   []              <class 'torch.Tensor'>
3  <UID: 01a56e5218884d90b0b396869959001b>   []              <class 'torch.Tensor'>
4  <UID: 38560424aacf44af834daf73b6236927>   []              <class 'torch.Tensor'>

>>> duet.store[1].get()
tensor([1., 2., 3.])
```",1,2021-01-28 10:26:52,2022-06-08 05:13:44,2022-06-08 05:13:44
https://github.com/OpenMined/PySyft/issues/5043,"['bug ', '0.5', 'rescope']",Duet: sending an object twice with the same tag results in duplicate objects,"Duet: sending an object twice with the same tag results in duplicate objects## Description
Duet: sending an object twice with the same tag results in duplicate objects, and the DS cannot retrieve it anymore.

Reproduced with the TenSEAL  notebook.

Sending the context once is fine and the DS can retrieve it
```
ctx_ptr = context.send(duet, searchable=True, tags=[""context""])
duet.store.pandas

	ID	Tags	Description
0	<UID: 5061f0db8a824e4f90c8295cc745cd0d>	[context]	
```

Running the cell again and sending the context results in a duplicate tag in the store
```
ctx_ptr = context.send(duet, searchable=True, tags=[""context""])
duet.store.pandas

	ID	Tags	Description
0	<UID: 5061f0db8a824e4f90c8295cc745cd0d>	[context]	
1	<UID: 16557f39c8cc413aacd640d50e5995af>	[context]	
```
Now the DS instance fails to get the context with
```
[2021-01-20T18:32:20.696733+0200][CRITICAL][logger] 'More than one item with tag:context'
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-10-cad91c8e2dae> in <module>
      1 # STEP 1 Get pointers to the two encrypted vectors
----> 2 ctx_ptr = duet.store[""context""]
      3 enc_v1_ptr = duet.store[""enc_v1""]
      4 enc_v2_ptr = duet.store[""enc_v2""]

~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/core/node/common/client.py in __getitem__(self, key)
    430                 return match_obj
    431             elif matches > 1:
--> 432                 traceback_and_raise(KeyError(""More than one item with tag:"" + str(key)))
    433 
    434             traceback_and_raise(KeyError(""No such request found for id:"" + str(key)))

~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
     57     except BaseException as ex:
     58         logger.debug(""failed to print exception"", ex)
---> 59     raise e
     60 
     61 

KeyError: 'More than one item with tag:context'
```


## System Information
 - OS: Ubuntu 20.04
 -  Python 3.8.5
I have some thoughts about this issue.
1. The problem is not that ""duet.store has multiple elements with same tags"". I think it's okay and reasonable.
2. And ""we can't call `duet.store['context']` when there are multiple elements with tags=['context']"" is also not the real problem. Because it's natural that syft can't figure out  which one to return when there are mutiple ones match. The right way in this case is to use `duet.store[""5061f0db8a824e4f90c8295cc745cd0d""]# use id` or `duet.store[0] # use index`.
3. But it is truly a problem that ""multiple ptrs in duet.store pointing to the same object, if we send a same object multiple times."" This is a bug we want to fix. And I have one optional solution in mind:
    1. The method `SaveObjectAction.execute_action` is where we put an object into `node.store`.
    2. In this method, before we do anything, we should first check if there already exists an object with the same id.
    3. If so, we just do nothing. Becuase the object we want to put into store is already there.
    4. Else, we do what should be done normally.@xutongye also perhaps rather than rely on ID we could look at a hash since we use that already for signing.I think we should be able to fix this with a client side registry which tracks duplicates and introduce the unique shared network `var_name`. See notion: https://www.notion.so/openmined/2021-02-10-0-5-API-Refactor-f636ae0ff25f4921a84505ac7bd97ac7",3,2021-01-20 16:33:41,2022-06-08 05:13:32,2022-06-08 05:13:32
https://github.com/OpenMined/PySyft/issues/5041,"['bug ', '0.5', 'rescope']",Transforming a StorableObject to proto and back doesn't work ,"Transforming a StorableObject to proto and back doesn't work ## Description
Using `_object2proto` on a StorableObject to create a proto, and then using `_proto2object` on the result to create a StorableObject does not work

## How to Reproduce
1. Create a StorableObject
2. Execute `StorableObject._object2proto` on it to create a proto object
3. Execute `StorableObject._proto2object` on the proto object 
4. See error

## Expected Behavior
At the end we should see a valid StorableObject

## Screenshots
```python
storable
<Storable: <UID: 7ceb6fe14a094ed7b85addfcf9de4068>>
(Pdb) proto_storable = StorableObject._object2proto(storable)
(Pdb) proto_storable
id {
  value: ""\265\264\007\253\337>D\276\260]+`G\271\025~""
}
obj_type: ""syft.core.store.storeable_object.StorableObject""
data {
  type_url: ""type.googleapis.com/syft.core.common.UID""
  value: ""\n\020|\353o\341J\tN\327\270Z\335\374\371\336@h""
}
description: ""This is a dummy id""
tags: ""dummy""
tags: ""test""
type(proto_storable)
<class 'proto.core.store.store_object_pb2.StorableObject'>
StorableObject._proto2object(proto=proto_storable)
*** ValueError: bytes is not a 16-char string
```

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.8.5
 - Package Manager Version: pip 20.0.2
 @Benardi how does this look with the new https://github.com/OpenMined/PySyft/pull/5104 changes?Since we have completely overhauled the `StorableObject` code im going to assume this isn't an issue anymore.
There",2,2021-01-20 11:44:37,2021-02-22 06:41:27,2021-02-22 06:41:27
https://github.com/OpenMined/PySyft/issues/5024,"['bug ', 'help wanted :wave:']",Flaky Duet Test,"Flaky Duet Test## Description
The test in tests/syft/grid/duet/duet_test.py can fail due to a race conditional/already used port, etc.

## How to Reproduce
Remove the `@pytest.mark.skip` decorator from the test and run it multiple times.

## Expected Behavior
The test must pass.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
I can work on this one.",1,2021-01-19 21:09:23,2021-02-08 11:56:48,2021-02-08 11:56:48
https://github.com/OpenMined/PySyft/issues/5015,"['bug ', 'help wanted :wave:', 'good first issue :mortar_board:', '0.5']",Autoapprove requests made by root clients,"Autoapprove requests made by root clients## Description
Requests made by root clients in the `VirtualMachine` context should be automatically accepted.

## How to Reproduce
```
import syft as sy
alice = sy.VirtualMachine(name=""alice"")
alice_client = alice.get_root_client()

alice_client.torch.Tensor([1, 2, 3]).get(
    request_block=True,
    name=""Test""
)
```

## Expected Behavior
To receive the requested object.Hey, I want to work on this issue, can you help from where to get started?Can I work on this?@tudorcebere I am getting the following error(in screenshot) when I run your code snippet. I am not able to understand the purpose of `request_block = True` as when I use a normal `Tensor([1,2,3]).get()` I am able to retrieve the tensor from alice_client . Do you want the .get() function to still return if the `request_block` is set to `True` .
![Screenshot 2021-01-19 at 12 22 20 PM](https://user-images.githubusercontent.com/33565881/104998712-af031e00-5a51-11eb-8809-c2123344fc62.png)
Hi all!

An issue will be assigned after a PR is opened to tackle the progress/give feedback.

Open a PR and ping me where you get stuck, thank you for your interest in syft!",4,2021-01-14 14:25:49,2021-03-10 08:15:18,2021-03-10 08:15:18
https://github.com/OpenMined/PySyft/issues/5010,"['bug ', '0.2.x']",AttributeError: module 'torchvision.datasets' has no attribute 'VisionDataset',"AttributeError: module 'torchvision.datasets' has no attribute 'VisionDataset'## Description
I tried to import syft package to run a federated leaning code using MNIST dataset. I am now stuck with an attribute error after importing the packages.

## Code

import pickle
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import TensorDataset,DataLoader
import time
import copy
import numpy as np
import syft as sy
from syft.frameworks.torch.federated import utils
from syft.workers.websocket_client import WebsocketClientWorker

## Screenshots
![e1](https://user-images.githubusercontent.com/14846379/104409313-0144ca80-558c-11eb-9f31-a3cc3c52fa40.PNG)
![e2](https://user-images.githubusercontent.com/14846379/104409318-0275f780-558c-11eb-8211-49b2f37cbfb3.PNG)


## System Information
 - OS: Windows 10
 - Language Version: Python 3.8.0
 - Package Manager Version: Conda 4.8.2,it looks like torchvision is not installed install torchvision or update torchvisioncan you please mention a stable version of torchvision


On Thu, Jan 14, 2021 at 5:56 PM Leo3967 <notifications@github.com> wrote:

> install torchvision or update torchvision
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5010#issuecomment-760164796>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADRITK3IADUT4MU55IIDVCLSZ3PH7ANCNFSM4WAHRZ5Q>
> .
>
will torch vision package automatically add with syft?

On Sat, Jan 16, 2021 at 9:46 PM Harikrishnan K H <
harikrishnankh1996@gmail.com> wrote:

> can you please mention a stable version of torchvision
>
>
> On Thu, Jan 14, 2021 at 5:56 PM Leo3967 <notifications@github.com> wrote:
>
>> install torchvision or update torchvision
>>
>> â€”
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/OpenMined/PySyft/issues/5010#issuecomment-760164796>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ADRITK3IADUT4MU55IIDVCLSZ3PH7ANCNFSM4WAHRZ5Q>
>> .
>>
>
in requirements.txt you can see clearly that it is installing torch>=1.5 and the version of torch vision which is compatible with that 
if you want stable pysyft i say go with pi install syft=0.=2.9Thanks, I'll check it out.

On Sun, 17 Jan, 2021, 7:58 pm RAHUL Danu, <notifications@github.com> wrote:

> in requirements.txt you can see clearly that it is installing torch>=1.5
> and the version of torch vision which is compatible with that
> if you want stable pysyft i say go with pi install syft=0.=2.9
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5010#issuecomment-761821288>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADRITK2DQ6VEL6VPUMCIH6TS2LX2PANCNFSM4WAHRZ5Q>
> .
>
I tried installing syft 0.2.9 but I got the error:"" Could not find a version that satisfies the requirement torch~=1.4.0 (from syft)""
I tried installing pytorch 1.4,0 manually, but got the same error@harikrishnankh what python version are you using? Python 3.9 is not supported by syft==0.2.9 or any version of syft currently.Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",9,2021-01-13 05:12:27,2021-04-21 09:21:18,2021-04-21 09:21:17
https://github.com/OpenMined/PySyft/issues/5009,['bug '],installation not working,"installation not workingI used the command **pip install syft** but it is showing an error, Cannot build wheel for av. I tried installing microsoft visual c++ build tools. Still the issue persist.
![error syft](https://user-images.githubusercontent.com/14846379/104362284-a3879280-5539-11eb-8814-a34aa2612ba5.PNG)
@harikrishnankh Please provide all of the relevant details required to debug such an error.
- OS version
- Python version
- Instructions followed
- Command ran
- Errors Outputtedfollow this blog post https://blog.openmined.org/how-to-setup-pysyft-on-windows-10/@harikrishnankh I can see mention of 3.9 in the output above, are you using Python 3.9? It's still not supported yet, so I would suggest using something lower like 3.8 if you can. Can you confirm the output of this command:
```
where python3
python3 --version
```@madhavajay  I am using windows 10. I am running this on anaconda. My python version is 3.9.1. I will try to install python 3.8, Can you please recommend an exact version of python.@madhavajay 
Successfully installed syft  after changing python version to 3.8.0
Thank you for your help!

But a new issue raised. An Attribute error while importing syft. torchvision.datasets has no attribute visiondataset. Please check the attachment for more details

I tried importing syft module alone, but the issue still persists.

## Screenshots
![e1](https://user-images.githubusercontent.com/14846379/104411930-5df6b400-5591-11eb-8f13-a116292b0264.PNG)
![e2](https://user-images.githubusercontent.com/14846379/104411936-5f27e100-5591-11eb-8790-cb6581b069d3.PNG)

@harikrishnankh the Torch Vision API hasn't been completely added yet. This would probably be a pretty easy fix. If you would like to open a PR that would be greatly appreciated. See `src/syft/lib/torchvision/allowlist.py`Closing this for now. https://github.com/OpenMined/PySyft/issues/5186",7,2021-01-12 19:22:53,2021-02-18 09:04:25,2021-02-18 09:04:25
https://github.com/OpenMined/PySyft/issues/5002,"['bug ', 'help wanted :wave:', 'priority: 2 - high :cold_sweat:']",Model parameters not preserving .grad property,"Model parameters not preserving .grad property## Description
`.grad` property is not preserved on a model parameters when it's downloaded locally.

## How to Reproduce

```
import syft as sy
import torch

alice = sy.VirtualMachine(name=""alice"")
alice_client = alice.get_root_client()
remote_torch = alice_client.torch

class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.fc1 = self.torch_ref.nn.Linear(100, 10)

    def forward(self, x):
        return self.fc1(x)

model = SyNet(torch)
data = torch.randn(size=(1, 100))
result = model(data)
labels = torch.randn(size=(1, 10))
loss_func = torch.nn.L1Loss()
loss = loss_func(result, labels)
loss.backward()

print(model.parameters()[-1].grad) # exists


model_ptr = model.send(alice_client)
data_ptr = data.send(alice_client)
labels_ptr = labels.send(alice_client)
results_ptr = model_ptr(data_ptr)
remote_loss_func = alice_client.torch.nn.L1Loss()
remote_loss = remote_loss_func(results_ptr, labels_ptr)
remote_loss.backward()

print(model_ptr.parameters().get()[-1].grad) # exists
print(model_ptr.get().parameters()[-1].grad) # does not exist anymore
```

## Expected Behavior
The `.grad` attribute should be present when we download the remote model.I can work on this one. Please assign it to me.PyTorch's load_state_dict breaks the computational graph, so on get(), there won't be any gradients to retrieve.

The gradients will have to be retrieved via the model_ptr.parameters().get() call.",2,2021-01-10 18:19:39,2021-01-18 10:13:55,2021-01-18 10:13:55
https://github.com/OpenMined/PySyft/issues/4961,['bug '],Upcast for List is not recursive,"Upcast for List is not recursivehttps://github.com/OpenMined/PySyft/blob/65ba3ebe83eecc26528f1b451746ede7f6a43fc0/src/syft/lib/python/list.py#L59

```
obj = lib.python.util.downcast({1 : [None, 1, 2, 3]})
obj
```
`{1: [<syft.lib.python._SyNone object at 0x7f073b9de438>, 1, 2, 3]}`


```
lib.python.util.upcast(obj)
```
`{1: [<syft.lib.python._SyNone object at 0x7f073b9de438>, 1, 2, 3]}
`
This will be a problem if we use `{1 : [None, 1, 2, 3]} ` as function argument@NProkoptsev There is some asymmetry in upcasting and downcasting at the moment because `generate_primitive` doesn't pass through anything non primitives but instead terminates in a SyNone. Do you have an example of this actually causing an issue yet?The main problem is that
`lib.python.util.downcast(None) is None` returns `False`, so some functions may not work correctly@NProkoptsev totally understand, we battled with that for a while but since the `is` comparison relates to the actual memory address and `None` is a singleton it's impossible to provide `SyNone is None`. The recursive `upcasting` and `downcasting` on both sides can be done but we will need to go through the code and just double check we aren't relying on the current functionality. If you have already had this issue with a particular bit of code, I would be interested in seeing an example.@NProkoptsev we have a related issue which might make more sense: https://github.com/OpenMined/PySyft/issues/4854@madhavajay I don't think that this issue is relevant
Let me provide a more clear example
`type(upcast(downcast([1,2,3]))[0])` gives `syft.lib.python.Int` while it should be just `int`
I got the idea that `upcast` should be inverse of `downcast`

Here is the example with pytorch optimizer, that can use the list param_groups as an argument

This code runs successfully
```
class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.lin = nn.Linear(1,1)

    def forward(self, x):
        return self.lin(x)
    
model = SyNet(torch)

parameters = [{'params': model.parameters()[0], 'lr':0.1},
        {'params': model.parameters()[1], 'lr' : 0.01 }]

optimizer = torch.optim.Adadelta(parameters)
```

This one returns error 
```
class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.lin = nn.Linear(1,1)

    def forward(self, x):
        return self.lin(x)
    
model = SyNet(torch)
model.send(client)

parameters = [{'params': model.parameters()[0], 'lr':0.1},
        {'params': model.parameters()[1], 'lr' : 0.01 }]

optimizer = client.torch.optim.Adadelta(parameters)
```
Stacktrace:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-187-6514aa276e26> in <module>
     13         {'params': model.parameters()[1], 'lr' : 0.01 }]
     14 
---> 15 optimizer = client.torch.optim.Adadelta(parameters)
     16 
     17 

/opt/conda/lib/python3.8/site-packages/syft/ast/callable.py in __call__(self, *args, **kwargs)
     96                 )
     97 
---> 98                 self.client.send_immediate_msg_without_reply(msg=msg)
     99 
    100                 inherit_tags(

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/client.py in send_immediate_msg_without_reply(self, msg, route_index)
    256             msg = msg.sign(signing_key=self.signing_key)
    257         debug(f""> Sending {msg.pprint} {self.pprint} âž¡ï¸  {msg.address.pprint}"")
--> 258         self.routes[route_index].send_immediate_msg_without_reply(msg=msg)
    259 
    260     def send_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/route.py in send_immediate_msg_without_reply(self, msg)
    165     ) -> None:
    166         debug(f""> Routing {msg.pprint} via {self.pprint}"")
--> 167         self.connection.send_immediate_msg_without_reply(msg=msg)
    168 
    169     def send_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/virtual.py in send_immediate_msg_without_reply(self, msg)
     68         self, msg: SignedImmediateSyftMessageWithoutReply
     69     ) -> None:
---> 70         self.server.recv_immediate_msg_without_reply(msg=msg)
     71 
     72     def send_immediate_msg_with_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/virtual.py in recv_immediate_msg_without_reply(self, msg)
     38         self, msg: SignedImmediateSyftMessageWithoutReply
     39     ) -> None:
---> 40         self.node.recv_immediate_msg_without_reply(msg=msg)
     41 
     42     def recv_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/node.py in recv_immediate_msg_without_reply(self, msg)
    395         )
    396 
--> 397         self.process_message(msg=msg, router=self.immediate_msg_without_reply_router)
    398         try:
    399             pass

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/node.py in process_message(self, msg, router)
    477                 traceback_and_raise(KeyError(log))
    478 
--> 479             result = service.process(
    480                 node=self,
    481                 msg=msg.message,

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/service/obj_action_service.py in process(node, msg, verify_key)
     25         verify_key: Optional[VerifyKey] = None,
     26     ) -> None:
---> 27         msg.execute_action(node=node, verify_key=verify_key)
     28 
     29     @staticmethod

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/action/function_or_constructor_action.py in execute_action(self, node, verify_key)
    124 
    125         # execute the method with the newly upcasted args and kwargs
--> 126         result = method(*upcasted_args, **upcasted_kwargs)
    127 
    128         # to avoid circular imports

/opt/conda/lib/python3.8/site-packages/torch/optim/adadelta.py in __init__(self, params, lr, rho, eps, weight_decay)
     34 
     35         defaults = dict(lr=lr, rho=rho, eps=eps, weight_decay=weight_decay)
---> 36         super(Adadelta, self).__init__(params, defaults)
     37 
     38     @torch.no_grad()

/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py in __init__(self, params, defaults)
     50 
     51         for param_group in param_groups:
---> 52             self.add_param_group(param_group)
     53 
     54     def __getstate__(self):

/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py in add_param_group(self, param_group)
    228         for param in param_group['params']:
    229             if not isinstance(param, torch.Tensor):
--> 230                 raise TypeError(""optimizer can only optimize Tensors, ""
    231                                 ""but one of the params is "" + torch.typename(param))
    232             if not param.is_leaf:

TypeError: optimizer can only optimize Tensors, but one of the params is syft.lib.python.Dict
```

This happens because in
https://github.com/pytorch/pytorch/blob/95d2318510371523b3406ae1d4818f8f0607bbc6/torch/optim/optimizer.py#L50
param_groups[0] is `syft.lib.python.Dict` instead of `dict`

`param_groups = [{'params': param_groups}]` makes optimizer crash later with given stacktraceIt seems that it is fixed in https://github.com/OpenMined/PySyft/commit/04bd42c7ae71576f5896a9808346aa5fb533346d",6,2020-12-29 19:42:59,2021-04-07 18:40:30,2021-04-07 18:40:29
https://github.com/OpenMined/PySyft/issues/4917,"['bug ', '0.2.x']",Opacus won't work with Syft 0.2.9,"Opacus won't work with Syft 0.2.9## Description
Existing Ticket on PriMIA: https://github.com/gkaissis/PriMIA/issues/47
This still does not work, when i try to run https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/
How were they able to run both together at that time? i tried pysyft 0.2.8 + opacus 0.9.x also can not.
Any ideas on what versions of both library can work together?
@madhavajay 
Same issue here. Any tutorial for 0.2.x or 0.3.x to work with privacy engine in Opacus is really helpful. I have been waiting for 2 months so far.I have the same problem. I tried pysyft 0.2.8 + opacus 0.9.x and  pysyft 0.2.9 + opacus 0.9.x , but it still doesn't work.@bigmoumou and @cherrytora 
The current example is here:
https://github.com/OpenMined/PySyft/tree/dev/examples/differential-privacy/opacus

Its still a work in progress but you can remotely train MNIST with opacus.Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",5,2020-12-16 04:11:59,2021-04-21 09:21:09,2021-04-21 09:21:09
https://github.com/OpenMined/PySyft/issues/4916,"['bug ', '0.2.x']",Bug in torch.square for additive shared tensor,"Bug in torch.square for additive shared tensor## Description
torch.square(t) currently fails  with encrypted-shared tensors

## How to Reproduce


`import syft as sy`
`import torch`

`hook = sy.TorchHook(torch)`

`alice = sy.VirtualWorker(hook, id=""alice"")`
`bob = sy.VirtualWorker(hook, id=""bob"")`
`crypto_provider = sy.VirtualWorker(hook, id=""crypto_provider"")`
`t = torch.tensor([1.5, 2.5])`
`t_encrypt = t.fix_precision().share(alice, bob, crypto_provider=crypto_provider, protocol=""fss"")`
`print(t_encrypt)`

Computing the mean and centering the tensor works just fine:

`t_mean = torch.mean(t_encrypt)`
`new_t = t_encrypt - t_mean `
`new_t.get().float_precision()`     # returns the correct output tensor = [-0.5, 0.5]

What if we want to square the tensor after centering:

`t_mean = torch.mean(t_encrypt) `
`new_t = t_encrypt - t_mean`
`new_t_square = torch.square(new_t)`
`new_t_square.get().float_precision()`   # returns the wrong output tensor = [-7.3e+15, -7e+15]*. 

*Tensor values vary with relative magnitude on the order of ~ e+15

The desired output tensor can be calculated as:

`new_t_square = torch.square(t - torch.mean(t))`    # returns the desired output tensor = [0.25, 0.25]

## System Information
 - OS: macOS 
 - OS Version: 10.15.6
 - Language Version: Python 3.7.9
 - Package Manager Version: Conda 4.8.4
 - Syft version: 0.2.9
 Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",1,2020-12-15 21:01:46,2021-04-21 09:21:06,2021-04-21 09:21:06
https://github.com/OpenMined/PySyft/issues/4914,['bug '],Duet loop issue,"Duet loop issue## Description
When I try and run the simple duet example at the top of the Duet README file it throws an error. It seems to be to do with how the event loop is initialised. Can someone let me know if this is a bug, or an issue on my end?

## How to Reproduce
1. go to the duet main README page and copy out the example.

## Expected Behavior
on the data science side I should be able to run 'duet.store.pandas' and get the table of whats in the store as a tensor has been sent to the duet from the data owner side.

## Screenshots
![Screenshot 2020-12-15 at 16 54 29](https://user-images.githubusercontent.com/51291404/102246045-365eee00-3ef6-11eb-9b20-478a7d9dda57.png)
![Screenshot 2020-12-15 at 16 54 49](https://user-images.githubusercontent.com/51291404/102246076-41198300-3ef6-11eb-8510-c879d70d038e.png)

## System Information
 - OS: macOS
 - OS Version: 10.15.5
 - Language Version: Python 3.7

## Additional Context
Add any other context about the problem here.
Same problem for me when running https://github.com/OpenMined/PySyft/tree/dev/examples/duet/mnist
- mac OS 11.0.1
- Python 3.7Ok apparently this is because we have an old version of jupyter notebook!
`pip install --upgrade notebook`  should fix this!@LaRiffle Thank you, this has solved the issue for me!",3,2020-12-15 16:56:28,2020-12-15 18:28:03,2020-12-15 18:28:03
https://github.com/OpenMined/PySyft/issues/4904,"['bug ', 'rescope']",Syft logger generates error stack due to Unicode Emojis,"Syft logger generates error stack due to Unicode Emojis## Description
While testing the Duet MNIST tutorials with latest version of syft (dev branch) I ran into the following error:

```
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=207266), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating âœ‰ï¸  (RunFunctionOrConstructorAction) <UID:ðŸšðŸšƒ>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 68042, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=208269), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 256, 'message': '> ðŸ“¡ [ðŸ°] Launcher Client (Duet)@<UID:ðŸš‰ðŸšˆ> Signing âœ‰ï¸  (RunFunctionOrConstructorAction) with ðŸ”', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 69045, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4e1' in position 107: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=209268), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'sign', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 87, 'message': '> Signing with ðŸ”', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 70044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f754' in position 87: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=212265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating Signed âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithoutReply) <UID:ðŸšðŸšƒ>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 73041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 95-96: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=213268), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 258, 'message': '> Sending âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithoutReply) ðŸ“¡ [ðŸ°] Launcher Client (Duet)@<UID:ðŸš‰ðŸšˆ> âž¡ï¸  ðŸ’  [ðŸ°] Launcher Client (Address)', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 74044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 115-116: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=213268), 'exception': None, 'extra': {}, 'file': (name='route.py', path='e:\\repos\\pysyft\\src\\syft\\core\\io\\route.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 166, 'message': '> Routing âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithoutReply) via ðŸ›£ï¸  (SoloRoute)', 'module': 'route', 'name': 'syft.core.io.route', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 74044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 105-106: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=215267), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating âœ‰ï¸  (RequestMessage) <UID:ðŸ™¾ðŸœ>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 76043, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=216267), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 256, 'message': '> ðŸ“¡ [ðŸ°] Launcher Client (Duet)@<UID:ðŸš‰ðŸšˆ> Signing âœ‰ï¸  (RequestMessage) with ðŸ”', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 77043, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4e1' in position 107: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=217267), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'sign', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 87, 'message': '> Signing with ðŸ”', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 78043, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f754' in position 87: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=225268), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating Signed âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithoutReply) <UID:ðŸ™¾ðŸœ>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 86044, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 95-96: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=228265), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 258, 'message': '> Sending âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithoutReply) ðŸ“¡ [ðŸ°] Launcher Client (Duet)@<UID:ðŸš‰ðŸšˆ> âž¡ï¸  ðŸ’  [ðŸ°] Launcher Client (Address)', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 89041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 115-116: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=228265), 'exception': None, 'extra': {}, 'file': (name='route.py', path='e:\\repos\\pysyft\\src\\syft\\core\\io\\route.py'), 'function': 'send_immediate_msg_without_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 166, 'message': '> Routing âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithoutReply) via ðŸ›£ï¸  (SoloRoute)', 'module': 'route', 'name': 'syft.core.io.route', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 89041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 105-106: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=344265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating âœ‰ï¸  (RequestAnswerMessage) <UID:ðŸš±ðŸ™”>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 205041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=345265), 'exception': None, 'extra': {}, 'file': (name='client.py', path='e:\\repos\\pysyft\\src\\syft\\core\\node\\common\\client.py'), 'function': 'send_immediate_msg_with_reply', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 221, 'message': '> ðŸ“¡ [ðŸ°] Launcher Client (Duet)@<UID:ðŸš‰ðŸšˆ> Signing âœ‰ï¸  (RequestAnswerMessage) with ðŸ”', 'module': 'client', 'name': 'syft.core.node.common.client', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 206041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4e1' in position 104: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=345265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'sign', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 87, 'message': '> Signing with ðŸ”', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 206041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f754' in position 87: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=349264), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating Signed âœ‰ï¸ ðŸ” (SignedImmediateSyftMessageWithReply) <UID:ðŸš±ðŸ™”>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 210040, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 95-96: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=354262), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': 'post_init', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 53, 'message': '> Creating âœ‰ï¸  (RequestAnswerMessage) <UID:ðŸš²ðŸ™–>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 215038, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 88-89: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=357264), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': '_object2proto', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 158, 'message': '> âœ‰ï¸ ðŸ” -> Proto ðŸ”¢ <UID: af8d7977a5014f1c80c2cfdfd18460e4>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 218040, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 84-85: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=361265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': '_object2proto', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 158, 'message': '> âœ‰ï¸ ðŸ” -> Proto ðŸ”¢ <UID: fbefe4e6d0904fd881c439e3afbd02e5>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 222041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 84-85: character maps to <undefined>
--- End of logging error ---
--- Logging error in Loguru Handler #1 ---
Record was: {'elapsed': datetime.timedelta(seconds=135, microseconds=364265), 'exception': None, 'extra': {}, 'file': (name='message.py', path='e:\\repos\\pysyft\\src\\syft\\core\\common\\message.py'), 'function': '_object2proto', 'level': (name='DEBUG', no=10, icon='ðŸž'), 'line': 158, 'message': '> âœ‰ï¸ ðŸ” -> Proto ðŸ”¢ <UID: 03f3d92ec8754f9896940b581539c15f>', 'module': 'message', 'name': 'syft.core.common.message', 'process': (id=24716, name='MainProcess'), 'thread': (id=11756, name='MainThread'), 'time': datetime(2020, 12, 11, 15, 38, 53, 225041, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800), 'India Standard Time'))}
Traceback (most recent call last):
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_handler.py"", line 287, in _queued_writer
    self._sink.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\site-packages\loguru\_file_sink.py"", line 176, in write
    self._file.write(message)
  File ""C:\Users\test\.conda\envs\pysyft\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 84-85: character maps to <undefined>
--- End of logging error ---
```

### âš ï¸ Note - The error (obviously) goes away if `sy.logging(file_path=""./syft_do.log"")` is commented out. 

I am taking a wild guess here but it seems the logger cannot handle some emojis.

## How to Reproduce
1. Run the MNIST example notebooks


## System Information
 - OS: Windows 10
 - Language Version: Python 3.8.5,
 - Syft Version - Syft Dev 0.3.0.post0.dev34+ga9a7874a

@jaintj95, this looks like its converting UTF-8 into cp1252 on windows and failing. Are you able to find the exact char sequence which fails and dump it do we can turn this into a test for all platforms and fix the issue?This should be fixed.",2,2020-12-11 10:54:01,2021-04-20 07:28:02,2021-04-20 07:28:02
https://github.com/OpenMined/PySyft/issues/4903,"['bug ', '0.5']",ptr.__len__() returns None in syft 0.3.0 dev,"ptr.__len__() returns None in syft 0.3.0 dev## Description
While testing the Duet MNIST tutorials with latest version of syft (dev branch) I ran into the following error
![len](https://user-images.githubusercontent.com/36858630/101894253-e74e4b80-3bcb-11eb-98d1-fef7594c0cb2.png)


## How to Reproduce
1. Run the MNIST example notebooks
2. The error occurs on `def get_train_length(train_data_ptr)` cell in Data Scientist notebook

Also the `try-except` block seems redundant here. 

## System Information
 - OS: Windows 10
 - Language Version: Python 3.8.5, 
 - Syft Version - Syft Dev 0.3.0.post0.dev34+ga9a7874a@jaintj95. Good spot, this is most likely in the dev branch which is not 100% stable. We recently added a new __len__ getter mechanism for iterators, so this code will need to change but the API hasn't been fully worked out yet.

You can see in these cells that there is an automatically generated request in the background.
<img width=""1083"" alt=""Screen Shot 2020-12-14 at 10 25 41 am"" src=""https://user-images.githubusercontent.com/2882739/102028621-e4836e80-3df6-11eb-98c1-210e33f1d46d.png"">


<img width=""793"" alt=""Screen Shot 2020-12-14 at 10 26 00 am"" src=""https://user-images.githubusercontent.com/2882739/102028619-e0efe780-3df6-11eb-81b2-bd2397f9f2b2.png"">

I will make sure we get this example updated once we get the Iterators / Len stuff sorted.
I believe this is related to the scenario in which the request is made:
https://github.com/OpenMined/PySyft/issues/5170

This does need to be fixed.This has been solved by #5275.",3,2020-12-11 10:48:27,2021-03-10 08:05:07,2021-03-10 08:05:07
https://github.com/OpenMined/PySyft/issues/4894,"['bug ', 'testing ']",Error when installing via `pip install syft`,"Error when installing via `pip install syft`## Description
When installing using `pip install syft`, I'm getting the error: 
```
$ pip install syft
Collecting syft
  Using cached syft-0.3.0-py2.py3-none-any.whl (289 kB)
  Using cached syft-0.2.9-py3-none-any.whl (433 kB)
  Using cached syft-0.2.8-py3-none-any.whl (415 kB)
  Using cached syft-0.2.7-py3-none-any.whl (394 kB)
  Using cached syft-0.2.6-py3-none-any.whl (377 kB)
  Using cached syft-0.2.5-py3-none-any.whl (369 kB)
  Using cached syft-0.2.4-py3-none-any.whl (341 kB)
  Using cached syft-0.2.3-py3-none-any.whl (331 kB)
ERROR: Cannot install syft==0.2.3, syft==0.2.4, syft==0.2.5, syft==0.2.6, syft==0.2.7, syft==0.2.8, syft==0.2.9 and syft==0.3.0 because these package versions have conflicting dependencies.

The conflict is caused by:
    syft 0.3.0 depends on torch>=1.5
    syft 0.2.9 depends on torch~=1.4.0
    syft 0.2.8 depends on torch~=1.4.0
    syft 0.2.7 depends on torch~=1.4.0
    syft 0.2.6 depends on torchvision~=0.5.0
    syft 0.2.5 depends on torchvision~=0.5.0
    syft 0.2.4 depends on torchvision~=0.5.0
    syft 0.2.3 depends on torchvision~=0.5.0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies
```

## How to Reproduce
Type `pip install syft`

## System Information
 - OS: MacOS 
 - OS Version: 11.0.1
 - Language Version: Python 3.9.0
 - Package Manager Version: Conda 4.9.2Facing the exact same issue on Windows 10.

@Wilann As a temporary resolution, you can try these steps.
1) pip install syft==0.3.0
2) If 1 fails, install pytorch
3) Try 1 again@jaintj95 Worked perfectly - thanks a lot! Unfortunately, PyTorch does not support Python 3.9 yet so we are unable to support it either.
I would suggest using a tool like pyenv so you can install multiple versions of Python 3 on MacOS now that brew is upgrading the current python 3 to 3.9.0.@madhavajay I had the same issue with Python 3.8.x
Hi @jaintj95, Do you have an existing installation of torch? Are you able to show some steps to re-produce your 3.8.x error?The issue arises due to conflicting dependencies of different versions for syft. 
As, @madhavajay suggested, you should consider using `virtualenvs` if you seek to work with multiple versions. Or consider uninstalling previous versions, if you currently don't have dependendents off them.
On a side note, we recent brought major changes in recent releases for pysyft(v0.3.x), and it is recommended to switch to current versions to recieve all the cool new changes. ðŸš€Torch 1.4.0 is installed in Conda base package but I created a separated conda environment for syft.

Steps:
```
$ conda create -n pysyft python=3.8
$ conda activate pysyft
$ conda install jupyter notebook
$ pip install syft
```
@jaintj95 We can add some Conda tests to our CI to see whats happening and make sure this isnt an issue.",8,2020-12-09 11:46:49,2021-02-22 06:23:21,2020-12-09 17:16:54
https://github.com/OpenMined/PySyft/issues/4887,"['bug ', '0.2.x']",Error in PySyft Autograd for Convolution,"Error in PySyft Autograd for Convolution## Description
It looks like convolution are not handle by the PySyft 0.2.9 Custom Autograd system, resulting in poor performance for training CNN in fixed precision or in a fully private way

## How to Reproduce
Take any small CNN and train it in fixed precision over MNIST. If you observe the convolution parameters during training, they don't change.

## System Information
 - PySyft 0.2.9
Hey!
I notice the same issue on my end, and was wondering if you found any solution to this? 
I am currently using PySyft 0.2.9 (the same as you mentioned in the post). Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",2,2020-12-03 09:29:08,2021-04-21 09:20:58,2021-04-21 09:20:57
https://github.com/OpenMined/PySyft/issues/4875,"['bug ', '0.2.x']",Module 'syft' has no attribute 'KerasHook',"Module 'syft' has no attribute 'KerasHook'I am using syft version 0.2.9. I have installed tensorflow-privacy and tensorflow-encrypted in my environment as per the discussion [here](https://github.com/OpenMined/PySyft/issues/2859). The error is still there.

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-85-b7865538fc26> in <module>
      5 
      6 import syft as sy
----> 7 hook = sy.KerasHook(tf.keras)

AttributeError: module 'syft' has no attribute 'KerasHook'


````sy.KerasHook` is only added if `tf_encrypted` is installed.
```
$ pip install tf_encrypted
```",1,2020-11-30 14:21:45,2021-02-18 08:40:45,2021-02-18 08:40:45
https://github.com/OpenMined/PySyft/issues/4809,"['bug ', '0.2.x']",DataCentricFLClient. serve_model does not have correct path for PyGrid,"DataCentricFLClient. serve_model does not have correct path for PyGrid## Description
[The path set in DataCentricFLClient.serve_model](https://github.com/OpenMined/PySyft/blob/e1933a4a3c439964b8a92a158f6777819a1fcc34/syft/grid/clients/data_centric_fl_client.py#L230) is `/data_centric/serve-model/`, but the actual path is `/data-centric/serve-model/`.

## How to Reproduce

```
hook = sy.TorchHook(torch)
model_reg = DataCentricFLClient(hook, ""http://modelregistry:5005"") 

# code for building your model Plan
....

success = model_reg.serve_model(model, model_id = ""test"")
```

## Expected Behavior
Return a bool indicating of post was a success.
Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",1,2020-11-11 23:35:33,2020-11-19 13:40:48,2020-11-19 13:40:47
https://github.com/OpenMined/PySyft/issues/4802,"['bug ', '0.2.x']",[WinError 10061] No connection could be made because the target machine actively refused it,"[WinError 10061] No connection could be made because the target machine actively refused it## Description
The WebsocketClientWorker refuses to connect to the mentioned port.

## How to Reproduce
1. Convert both the notebooks WebsocketServerWorker.ipynb and WebsocketClientWorker.ipynb as python files
1. Run file WebsocketServerWorker.py
2. Run file WebsocketClientWorker.py
4. See error: [WinError 10061] No connection could be made because the target machine actively refused it

## Expected Behavior
A successful connection of client to the server and exchange of data

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.7
 - Package Manager Version: pip 20.2.4
Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",1,2020-11-10 12:42:26,2020-11-19 13:40:33,2020-11-19 13:40:33
https://github.com/OpenMined/PySyft/issues/4791,"['bug ', 'syft 0.3']",Retrieving StorableObject from bytes leads to loss of data/tag/description,"Retrieving StorableObject from bytes leads to loss of data/tag/description## Description
A `StorableObject` instance made into bytes using  `StorableObject.to_bytes()` and retrieved using `syft.core.common.serde._deserialize` loses the values of its fields data/tag/description.

The problem occurred using branch  **syft_0.3.0**

## How to Reproduce
1. Go to branch `syft_0.3.0`
2.  Install syft locally via `pip install -e .`
    2.1 Install  packages missing from requirements : `pip install loguru sqlitedict packaging`
3. Run the code below to see the error:

```python
import torch as th
from syft.core.common.uid import UID
from syft.core.common.serde import _deserialize
from syft.core.store.storeable_object import StorableObject

storable = StorableObject(
  id = UID(),
  data=th.Tensor([1, 2, 3, 4]),
  description=""Dummy tensor"",
  tags=[""dummy"", ""tensor""]
)

print(""Original StorableObject"")

print(""\nRetrieved StorableObject"")
print(""ID: {}"".format(storable.id))
print(""DATA: {}"".format(storable.data))
print(""DESCRIPTION: {}"".format(storable.description))
print(""TAGS: {}"".format(storable.tags))

the_bytes= storable.to_bytes()
retrieved = _deserialize(blob=the_bytes, from_bytes=True)

print(""\nRetrieved StorableObject"")
print(""ID: {}"".format(retrieved.id))
print(""DATA: {}"".format(retrieved.data))
print(""DESCRIPTION: {}"".format(retrieved.description))
print(""TAGS: {}"".format(retrieved.tags))

```

## Expected Behavior
Once made again into an instance of StorableObject the object should contain the same fields and values it displayed before 

## Screenshots
Output of python code above:
 
![image](https://user-images.githubusercontent.com/9937551/98472402-ad0b1c00-21d1-11eb-9b14-a14fd3c4724d.png)

## System Information
 - OS: Debian
 - OS Version: 10
 - Language Version: Python 3.7.5, Torch 1.7.0
 - Package Manager Version: pip 19.2.3I want to work on it.",1,2020-11-08 17:55:41,2020-11-25 14:05:11,2020-11-25 14:05:11
https://github.com/OpenMined/PySyft/issues/4786,"['bug ', '0.2.x']",comparison between FPT and AST is broken for SNN protocol,"comparison between FPT and AST is broken for SNN protocol## Description
Comparison operations mainly <, >, ==, <=, >= are broken for SNN protocol when we use it for FPT and AST.

## How to Reproduce
![Screenshot 2020-11-06 at 1 01 54 PM](https://user-images.githubusercontent.com/28955148/98338478-41d61400-2030-11eb-81be-6cac8899dfb7.png)

## Expected Behavior
it should be working as same as its working for FSS protocol
![Screenshot 2020-11-06 at 1 02 59 PM](https://user-images.githubusercontent.com/28955148/98338590-68944a80-2030-11eb-9615-7533da639108.png)
I am new to this project and wish to contribute to it I have gone through all the tutorials. Can give a try to this issueYes @ayush12gupta go ahead!@ayush12gupta updates?I read the about the implementation of snn through its paper and not trying to understand the code structureHello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",5,2020-11-06 07:35:00,2020-11-19 13:40:10,2020-11-19 13:40:10
https://github.com/OpenMined/PySyft/issues/4784,"['bug ', '0.2.x']",TenSEAL framework missing for CKKS encryption,"TenSEAL framework missing for CKKS encryption## Description
Trying to run the homomorphic encryption via CKKS in the OpenMined tutorial. The syft.frameworks.tenseal is missing.

## How to Reproduce
1. Go to https://blog.openmined.org/what-is-homomorphic-encryption/
2. Run the CKKS tutorial
4. See error

## Expected Behavior
Tutorial should run

## Screenshots
![Screenshot 2020-11-05 at 14 11 20](https://user-images.githubusercontent.com/51291404/98251580-c8c3b780-1f70-11eb-8b65-52c8858f9de7.png)

## System Information
 - OS: macOS Catalina
 - OS Version: 10.15.5
 - Language Version: Python 3.7
 - Package Manager Version: Venv

## Additional Context
Looking at https://github.com/OpenMined/TenSEAL/issues/19 it seems like if you want to use syft.frameworks.tenseal you have to use the [tenseal/ckksvector](https://github.com/OpenMined/PySyft/tree/tenseal/ckksvector) branch. But it seems like adding CKKSTensor won't be merged into master anytime soon due to the technical challenges faced.

I also tried running the tutorial but after using [tenseal/ckksvector](https://github.com/OpenMined/PySyft/tree/tenseal/ckksvector)  I got the following error even though the import succeeded:

![image](https://user-images.githubusercontent.com/12242041/98362780-ba83a300-2025-11eb-8635-1c515eb774a8.png)
As @boris-vasilev explained, the use of ckks isn't yet fully supported in PySyft. We are working hard on TenSEAL to make the integration as soon as possible.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",3,2020-11-05 14:13:25,2020-11-19 13:39:53,2020-11-19 13:39:53
https://github.com/OpenMined/PySyft/issues/4745,"['bug ', 'syft 0.3']",KeyError / Fix the FQN issue on print(duet.store),"KeyError / Fix the FQN issue on print(duet.store)## Description

Sending a searchable SyPrimitive type seems to cause an exception when printing the store.
```
l = sy.lib.python.List()
l.send(duet, searchable=True)
print(duet.store)
```

## Definition of Done
Fixed.
This is happening with any and all classes where the fqn changes depending on import context, so we need something more permanently corrective.Still happens on classes like:
```
>>> torch.nn.modules.Sequential
<class 'torch.nn.modules.container.Sequential'>
>>> torch.nn.Sequential
<class 'torch.nn.modules.container.Sequential'>
```This also happens inside the new sy.module:
```
# module.py
def __setattr__(self, name: str, value: Union[Any, ""Module""]) -> None:
        # bug where torch.nn.modules isnt the full name on some imports
        # TODO: fix this properly
        if ""torch.nn"" in full_name_with_qualname(klass=type(value)):
            modules = self.__dict__.get(""_modules"")
            if modules is not None:
                modules[name] = value
        else:
            object.__setattr__(self, name, value)

```",3,2020-10-28 20:59:09,2021-01-22 05:39:45,2021-01-22 05:39:45
https://github.com/OpenMined/PySyft/issues/4742,"['bug ', '0.5']",Duet Network Exception,"Duet Network Exception## Description
This sometimes happens when using the MNIST notebooks, but doesn't seem to cause any issue. I guess there is a problem with the internal state sometimes and this exception isn't being caught.
```
Exception in callback Transaction.__retry()
handle: <TimerHandle when=156.343500133 Transaction.__retry()>
Traceback (most recent call last):
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/nest_asyncio.py"", line 198, in run
    ctx.run(self._callback, *self._args)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aioice/stun.py"", line 299, in __retry
    self.__future.set_exception(TransactionTimeout())
  File ""/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/futures.py"", line 246, in set_exception
    raise exceptions.InvalidStateError(f'{self._state}: {self!r}')
asyncio.exceptions.InvalidStateError: FINISHED: <Future finished result=(Message(messa...\x8c\xe8\xd1'), ('192.168.176.153', 64677))>
```

## Definition of Done
Figure out how to repeat and setup exception handling to prevent this from displaying in the notebook.
Another similar one:
```
Task exception was never retrieved
future: <Task finished name='Task-47763' coro=<RTCSctpTransport._transmit() done, defined at /Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py:1505> exception=ConnectionError('Cannot send encrypted data, not connected')>
Traceback (most recent call last):
  File ""/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/tasks.py"", line 280, in __step
    result = coro.send(None)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py"", line 1539, in _transmit
    await self._send_chunk(chunk)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py"", line 1339, in _send_chunk
    await self.__transport._send_data(
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py"", line 655, in _send_data
    raise ConnectionError(""Cannot send encrypted data, not connected"")
ConnectionError: Cannot send encrypted data, not connected
```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-10-28 09:33:18,2022-06-08 05:02:26,2022-06-08 05:02:26
https://github.com/OpenMined/PySyft/issues/4735,"['bug ', 'syft 0.3']",Replicate and Document Issue on Ubuntu with GPU during Training,"Replicate and Document Issue on Ubuntu with GPU during Training## Description
There seems to be some bug / exception happening, but I need to detail and replicate it better.
It occurs on my VM on GCE with Ubuntu and a GPU during the MNIST duet notebooks, but not on CPU on my Macbook.

## Definition of Done
Figure out what this bug is and document how to re-produce / solve it.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Last check worked, so we can close this until the GPU CI tests.",2,2020-10-28 00:38:44,2021-02-18 08:20:31,2021-02-18 08:20:31
https://github.com/OpenMined/PySyft/issues/4734,"['bug ', 'good first issue :mortar_board:']",Duplicate Request after .get() is successful causes Issue,"Duplicate Request after .get() is successful causes Issue## Description
When you keep a local reference to a pointer, then fetch the item and then make a request again you can get into a bad state.

DO:

```
x = sy.lib.python.Int(1)
x.send(duet, searchable=True)
duet.requests.add_handler(
    action=""accept""
)
```

DS:

```
x = duet.store[0]
x.request()
y = x.get()
...
x.request() <---- this ID doesnt exist so this request causes a looping exception on the DO
```

Prevent `.request()` working on a deleted obj, just like garbage collection when disabled.

## Definition of Done
This should not cause any major issues to the state of the notebook and a test should be written to ensure the correct behaviour occurs.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This should be handled by the client registry.Hi @madhavajay, I'm new to the community and I'd like to be assigned to this issue if possible :)Hey @madhavajay! Just wanted to confirm, is it the case that this issue is no longer open to new contributors?",5,2020-10-28 00:36:43,2022-06-08 05:02:18,2022-06-08 05:02:18
https://github.com/OpenMined/PySyft/issues/4706,"['bug ', '0.2.x']",ERROR installing syft with pip install syft on linux,"ERROR installing syft with pip install syft on linux## Description
i tried installing syft via pip with 'pip install syft' command and ""pip install 'syft[udacity]' ""

## How to Reproduce
1. I followed the steps on the pre-installation section of  the pysyft repo
2. pytorch version ==1.4.0
3. after running pip install syft i got these error in the screenshots

## Screenshots
![Screenshot 2020-10-24 at 11 39 32 PM](https://user-images.githubusercontent.com/39227096/97095153-debda800-1653-11eb-9845-2d906f2de773.png)
![Screenshot 2020-10-24 at 11 39 13 PM](https://user-images.githubusercontent.com/39227096/97095156-e1b89880-1653-11eb-9729-a4b94b6303e2.png)


## System Information
 - OS: Linux(chromebook)
 - Language Version: [e.g. Python 3.8.5,]
 - Package Manager Version: [e.g. Conda 4.6.1]

## Additional Context
error log:
Running setup.py install for netifaces ... error
    ERROR: Command errored out with exit status 1:
     command: /home/tifeasypeasy/opt/miniconda3/envs/my_syft/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-8f4hbpb4/netifaces/setup.py'""'""'; __file__='""'""'/tmp/pip-install-8f4hbpb4/netifaces/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-ffuxctmc/install-record.txt --single-version-externally-managed --compile --install-headers /home/tifeasypeasy/opt/miniconda3/envs/my_syft/include/python3.8/netifaces
Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",1,2020-10-24 22:55:54,2020-11-19 13:37:51,2020-11-19 13:37:51
https://github.com/OpenMined/PySyft/issues/4676,"['bug ', 'priority: 2 - high :cold_sweat:', 'severity: 1 - critical :fire:']",torch ops not working with smpc,"torch ops not working with smpc## Description
torch ops like relu and argmax etc are not working during encrypted training on encrypted data (using smpc)

these are working if we pass protocol = `fss` during encryption but earlier it used to work with default protocols
## How to Reproduce
used below model with oygrid nodes

```
class Classifier(sy.Plan):
    def __init__(self, in_features, out_features):
        super(Classifier, self).__init__()
        self.fc = torch.nn.Linear(in_features, out_features)
    def forward(self, x):
        logits = self.fc(x)
        probs =F.relu(logits)
        return probs, logits                                                                    
# Create the classifer 
classifier = Classifier(in_features = 300, out_features = 2)
# Apply SMPC encryption
classifier = classifier.fix_precision()\
                       .share(bob, alice, 
                              crypto_provider = james,
                              requires_grad = True,
                             )

```


## Screenshots
```
KeyError                                  Traceback (most recent call last)
<ipython-input-55-c062504472ad> in <module>
     10 
     11         # Predict sentiment probabilities
---> 12         probs, logits = classifier(vectors)
     13 
     14         # Compute loss and accuracy
~/Anton/OpenMined/PySyft/syft/execution/plan.py in __call__(self, *args)
    376             if self.include_state:
    377                 args = (*args, self.state)
--> 378             return self.forward(*args)
    379         else:
    380             if self.validate_input_types:
<ipython-input-52-1607ff94b4a2> in forward(self, x)
     17         logits = self.fc(x)
     18 
---> 19         probs =F.relu(logits)
     20 
     21         return probs, logits
~/Anton/OpenMined/PySyft/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)
    344                 handle_func_command = syft.framework.Tensor.handle_func_command
    345 
--> 346             response = handle_func_command(command)
    347 
    348             return response
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    439             # Send it to the appropriate class and get the response
    440             try:
--> 441                 response = new_type.handle_func_command(new_command)
    442             except RuntimeError:
    443                 # Change the library path to avoid errors on layers like AvgPooling
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py in handle_func_command(cls, command)
    292 
    293         if cmd is not None:
--> 294             return cmd(*args_, **kwargs_)
    295 
    296         # Replace all AutogradTensor with their child attribute
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py in relu(tensor, **kwargs)
    257 
    258                 def relu(tensor, **kwargs):
--> 259                     return tensor.relu()
    260 
    261                 module.relu = relu
~/Anton/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py in method_with_grad(*args, **kwargs)
    161                 )
    162 
--> 163                 result = getattr(new_self, name)(*new_args, **new_kwargs)
    164 
    165                 # Put back SyftTensor on the tensors found in the response
~/Anton/OpenMined/PySyft/syft/generic/frameworks/hook/hook.py in overloaded_syft_method(self, *args, **kwargs)
    110 
    111             # Send it to the appropriate class and get the response
--> 112             response = getattr(new_self, attr)(*new_args, **new_kwargs)
    113 
    114             # For inplace methods, just directly return self
~/Anton/OpenMined/PySyft/syft/frameworks/torch/mpc/__init__.py in method(self, *args, **kwargs)
     32 
     33         def method(self, *args, **kwargs):
---> 34             f = protocol_store[(name, self.protocol)]
     35             return f(self, *args, **kwargs)
     36 
KeyError: ('AdditiveSharingTensor.relu', None)

```

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: latest master branch of Pysyft (0.2.9_
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
Hi @Nilanshrajput I just tried this on my machine and its working and as discussed with you we can close this issue :) Yup closing it, thanks.",2,2020-10-19 13:04:40,2020-11-06 08:40:15,2020-11-06 08:40:15
https://github.com/OpenMined/PySyft/issues/4673,['bug '],Tutorial Part 11 - Secure Deep Learning Classification runs into a EmptyCryptoPrimitiveStoreError,"Tutorial Part 11 - Secure Deep Learning Classification runs into a EmptyCryptoPrimitiveStoreError ## Description
Tutorial [Part 11 - Secure Deep Learning Classification](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2011%20-%20Secure%20Deep%20Learning%20Classification.ipynb) runs into an EmptyCryptoPrimitiveStoreError.

## How to Reproduce
Just running the tutorial as it is produces this error.


## Screenshots
If applicable, add screenshots to help explain your problem.
![image](https://user-images.githubusercontent.com/51778760/96413765-bd9b2880-1209-11eb-9677-b89f99f0ac59.png)


## System Information
syft version 0.2.5
torch version 1.4.0




Thank you for opening this!Hi @Bhuvan-21 just checked this notebook, runs perfectly on my machine. Please upgrade to the latest syft master, I am sure it will no longer throw this error. @Bhuvan-21 is this problem still showing up?Closing! Unable to get output from the author.",4,2020-10-19 07:23:01,2020-11-12 18:32:50,2020-11-12 18:32:50
https://github.com/OpenMined/PySyft/issues/4671,"['bug ', 'good first issue :mortar_board:', 'severity: 1 - critical :fire:', 'syft 0.3']",Fix broken float tests,"Fix broken float tests## Description
There are two tests marked `@pytest.mark.xfail` in id_test.py which need to be fixed.

## How to Reproduce
Remove the annotations marked `@pytest.mark.xfail` then run the fast tests:
```
$ pytest -m fast
```

## Expected Behavior
Tests should pass

## Definition of Done
PR should be posted with passing test suite and `@pytest.mark.xfail` annotations removed.
If there is a good reason these tests cannot pass that should be documented and then explained here.
Can I work on this? @madhavajay Sure @rajathpatel23. Assigned it to you :+1: It is the ```syft_0.3.0``` branchThank you @gmuraru @rajathpatel23 Yes, this is for 0.3 but contributions are welcome. If you checkout syft_0.3.0 and then branch from there and make this change that would be amazing. Just a note, the ""slow"" tests are currently failing on the 0.3.0 branch which i am fixing now in another PR, so don't be surprised if that happens. This task only applies to the fast tests.

Also this might not be the easiest task for starting on the 0.3 code base, so sorry if I labelled it that way, its hard to know if the work has been done yet or it's just still left off. Feel free to try or if you don't want to thats also okay. ðŸ˜Š

If you have any questions just write them here or ping me on slack and I can try to help.@madhavajay , cool I would like to give it a try for next couple of days, if I do not make progress we can handover it to someone, does that work ?@madhavajay I was not able to make progress on this, we can assign it somone.",7,2020-10-18 23:15:06,2020-11-02 06:03:02,2020-11-02 06:03:02
https://github.com/OpenMined/PySyft/issues/4657,['bug '],Unable to host model for Model Centric FL when using manually started grid network,"Unable to host model for Model Centric FL when using manually started grid network## Description
I have manually started PyGrid network using:
`./run.sh --port 7000 --start_local_db`

I am also using Part 01 - Create Plan.ipynb notebook and I am unable to send model to the network for hosting when I execute the following:
```
response = grid.host_federated_training(
    model=model_params_state,
    client_plans={'training_plan': training_plan},
    client_protocols={},
    server_averaging_plan=avg_plan,
    client_config=client_config,
    server_config=server_config
)
print(""Host response:"", response) 
```

The error that I get in the notebook states:
`Host response: {'status': 'error', 'message': 'Invalid request format!'}
`
However, on the server running grid network, I get 
`Message:  {'type': 'model-centric/host-training', 'data': {'model': 'XXXX`, 'plans': {'training_plan': 'XXXX'},  'protocols': {}, 'averaging_plan': 'XXXX', 'client_config': {'name': 'mnist', 'version': '1.0.0', 'batch_size': 64, 'lr': 0.005, 'max_updates': 100}, 'server_config': {'min_workers': 5, 'max_workers': 5, 'pool_selection': 'random', 'do_not_reuse_workers_until_cycle': 6, 'cycle_length': 28800, 'num_cycles': 5, 'max_diffs': 1, 'minimum_upload_speed': 0, 'minimum_download_speed': 0, 'iterative_plan': True}}}

##### I have replaced the long strings for model, plans and averaging_plan with 'XXXX'

## How to Reproduce
1. Start the Grid network manually using `./run.sh --port 7000 --start_local_db`
2. Run 'Part - 01 - Create Plan.ipynb' inside model centric tutorials
3. Error will occur in code cell 17 containing:
```
response = grid.host_federated_training(
    model=model_params_state,
    client_plans={'training_plan': training_plan},
    client_protocols={},
    server_averaging_plan=avg_plan,
    client_config=client_config,
    server_config=server_config
)
print(""Host response:"", response) 
```
4. See error - Host response: {'status': 'error', 'message': 'Invalid request format!'}

## Expected Behavior
Status : success  

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.7
 - Package Manager Version: Conda 4.8.3, Poetry 1.1.3
 - Browser (if applicable): Firefox
 - Browser Version (if applicable): 81.0.2

## Additional Context
It does not matter if the grid network is running on a different system or on the same system running Jupyter notebook, same thing happens.@IonesioJunior ^^ if you have any ideaGot it to work, I was using Network instead of Node app from PyGrid. Thanks @gmuraru anyway! Great!",3,2020-10-18 02:29:57,2020-10-19 07:47:02,2020-10-18 20:42:28
https://github.com/OpenMined/PySyft/issues/4656,"['bug ', '0.2.x']","Federated Learning examples give ""RuntimeError: Websocket connection closed and creation of new connection failed."" error when using Websocket client workers.","Federated Learning examples give ""RuntimeError: Websocket connection closed and creation of new connection failed."" error when using Websocket client workers.## Description

I am following PySyft tutorials and I keep getting ""RuntimeError: Websocket connection closed and creation of new connection failed."" error when I use remote workers through websockets instead of VirtualWorkers. I have 2 vms running which act as Websocket client worker and a third vm where I run jupyter notebooks. I start the websocket server on the vms using run_websocket_server.py. Whenever I try to train a model in a notebook for Federated learning, for e.g. Federated learning with websockets and federated averaging.ipynb or Federated Recurrent Neural Network.ipynb, I get ""RuntimeError: Websocket connection closed and creation of new connection failed."" error. The full error in the notebook is as follows:
 ```
RuntimeError                              Traceback (most recent call last)
<ipython-input-17-dec9889208dd> in <module>
      1 for epoch in range(1, args.epochs + 1):
      2     print(""Starting epoch {}/{}"".format(epoch, args.epochs))
----> 3     model = rwc.train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)
      4     rwc.test(model, device, test_loader)
~/PySyft/examples/tutorials/advanced/websockets_mnist/run_websocket_client.py in train(model, device, federated_train_loader, lr, federate_after_n_batches, abort_after_one)
    134             if curr_batches:
    135                 models[worker], loss_values[worker] = train_on_batches(
--> 136                     worker, curr_batches, model, device, lr
    137                 )
    138             else:
~/PySyft/examples/tutorials/advanced/websockets_mnist/run_websocket_client.py in train_on_batches(worker, batches, model_in, device, lr)
     68         optimizer.step()
     69         if batch_idx % LOG_INTERVAL == 0:
---> 70             loss = loss.get()  # <-- NEW: get the loss back
     71             loss_local = True
     72             logger.debug(
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    646             tensor = self.child.get(*args, **kwargs)
    647         else:  # Remote tensor/chain
--> 648             tensor = self.child.get(*args, user=user, reason=reason, **kwargs)
    649 
    650         # Clean the wrapper
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in get(self, user, reason, deregister_ptr)
    324             object used to point to #on a remote machine.
    325         """"""
--> 326         tensor = ObjectPointer.get(self, user=user, reason=reason, deregister_ptr=deregister_ptr)
    327 
    328         # TODO: remove these 3 lines
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py in get(self, user, reason, deregister_ptr)
    267         else:
    268             # get tensor from location
--> 269             obj = self.owner.request_obj(self.id_at_location, self.location, user, reason)
    270 
    271         # Remove this pointer by default
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in request_obj(self, obj_id, location, user, reason)
    603             A torch Tensor or Variable object.
    604         """"""
--> 605         obj = self.send_msg(ObjectRequestMessage(obj_id, user, reason), location)
    606         return obj
    607 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    314 
    315         # Step 2: send the message and wait for a response
--> 316         bin_response = self._send_msg(bin_message, location)
    317 
    318         # Step 3: deserialize the response
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
     10         """"""send message to worker location""""""
     11 
---> 12         return location._recv_msg(message)
     13 
     14     def _recv_msg(self, message: bin) -> bin:
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py in _recv_msg(self, message)
    115             if not self.ws.connected:
    116                 raise RuntimeError(
--> 117                     ""Websocket connection closed and creation of new connection failed.""
    118                 )
    119         return response
RuntimeError: Websocket connection closed and creation of new connection failed.
```


The trace on one of the worker vm is below:
```
2020-10-16 13:44:20,707 ERROR base_events.py(l:1619, p:2157) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/sug/PySyft/syft/workers/websocket_server.py:93> exception=IndexError('tuple index out of range')>
Traceback (most recent call last):
  File ""/home/sug/PySyft/syft/workers/websocket_server.py"", line 111, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/sug/PySyft/syft/workers/websocket_server.py"", line 122, in _recv_msg
    return self.recv_msg(message)
  File ""/home/sug/PySyft/syft/workers/base.py"", line 338, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/home/sug/PySyft/syft/serde/serde.py"", line 78, in deserialize
    return strategy(binary, worker)
  File ""/home/sug/PySyft/syft/serde/msgpack/serde.py"", line 383, in deserialize
    return _deserialize_msgpack_simple(simple_objects, worker)
  File ""/home/sug/PySyft/syft/serde/msgpack/serde.py"", line 374, in _deserialize_msgpack_simple
    return _detail(worker, simple_objects)
  File ""/home/sug/PySyft/syft/serde/msgpack/serde.py"", line 517, in _detail
    val = msgpack_global_state.detailers[obj[0]](worker, obj[1], **kwargs)
  File ""/home/sug/PySyft/syft/messaging/message.py"", line 385, in detail
    sy.serde.msgpack.serde._detail(worker, msg_tuple[3]),
IndexError: tuple index out of range
2020-10-16 13:44:20,941 ERROR base_events.py(l:1619, p:2157) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/sug/PySyft/syft/workers/websocket_server.py:93> exception=IndexError('tuple index out of range')>
Traceback (most recent call last):
  File ""/home/sug/PySyft/syft/workers/websocket_server.py"", line 111, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/sug/PySyft/syft/workers/websocket_server.py"", line 122, in _recv_msg
    return self.recv_msg(message)
  File ""/home/sug/PySyft/syft/workers/base.py"", line 338, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/home/sug/PySyft/syft/serde/serde.py"", line 78, in deserialize
    return strategy(binary, worker)
  File ""/home/sug/PySyft/syft/serde/msgpack/serde.py"", line 383, in deserialize
    return _deserialize_msgpack_simple(simple_objects, worker)
  File ""/home/sug/PySyft/syft/serde/msgpack/serde.py"", line 374, in _deserialize_msgpack_simple
    return _detail(worker, simple_objects)
  File ""/home/sug/PySyft/syft/serde/msgpack/serde.py"", line 517, in _detail
    val = msgpack_global_state.detailers[obj[0]](worker, obj[1], **kwargs)
  File ""/home/sug/PySyft/syft/messaging/message.py"", line 385, in detail
    sy.serde.msgpack.serde._detail(worker, msg_tuple[3]),
IndexError: tuple index out of range
```

I have found some old issues here from folks had similar problem but the issues are either stale now or no solution has been posted yet!

Any help is really appreciated!

Thanks!  

## How to Reproduce
1. Create 3 systems/vms with access to each other.
2. Follow the instructions on PySyfts gtihub page to install pySyft, pyTorch on all three systems:
```
conda create -n pysyft python=3.7
conda activate pysyft # some older version of conda require ""source activate pysyft"" instead.
conda install jupyter notebook==5.7.8 tornado==4.5
conda activate pysyft
pip install 'syft[udacity]'
```
3. Clone PySyft github repo on all 3 systems
4. On the 2 systems acting as websocket workers, execute:
cd PySyft; python3 run_websocket_server.py --host ""host-ip"" --port ""port-number"" --id ""replace-with-name""
5. 
    a) On the 3rd system, change directories to go to the tutorial subdir inside PySyft.
    b) Run jupyter notebook 
    c) Open Federated Recurrent Neural Network.ipynb or  Federated learning with websockets and federated averaging.ipynb 
    d) Replace the following lines
```
              hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra
              alice = sy.VirtualWorker(hook, id=""alice"")  
              bob = sy.VirtualWorker(hook, id=""bob"")  
              # charlie = sy.VirtualWorker(hook, id=""charlie"") 
              workers_virtual = [alice, bob]
``` 
         with these and execute the notebook:
 
```
             hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra
             kwargs_websocket_alice = {""host"": ""ip_alice"", ""hook"": hook}
             alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
             kwargs_websocket_bob = {""host"": ""ip_bob"", ""hook"": hook}
             bob = WebsocketClientWorker(id=""bob"", port=8778, **kwargs_websocket_bob)
             workers_virtual = [alice, bob] 
```


 
## Expected Behavior
The notebook should run without giving any errors.


## System Information
 - OS: Ubuntu 
 - OS Version: 18.04
 - Language Version: Python 3.7
 - Package Manager Version:  Conda 4.8.3
 - Browser (if applicable): Firefox for jupyter notebook
 - Browser Version (if applicable): 81.02

## Additional Context
I have also tried to run the above scenario with python-3.6.7 but I still get the same error.
@IonesioJunior any idea?Hi, just wondering: do you get this error also when replacing the Web Workers with local ""dummy"" Virtual Workers? 


FYI: The PySyft version I was using in the tutorial linked https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/, was v0.1.19A1Hi @DanyEle, no, with virtualworkers most of the stuff runs as expected. The problem starts to occur when PySyft is being used in a pseudo realistic/realistic setup.> Hi @DanyEle, no, with virtualworkers most of the stuff runs as expected. The problem starts to occur when PySyft is being used in a pseudo realistic/realistic setup.

Yeah, that's indeed the problem I noticed as well... I will try to see if I managed replicate the problem on my end with this example. Are you sure you're using exactly the same PySyft build version on both web workers? Did you try not to use conda, and building PySyft from source instead?> Yeah, that's indeed the problem I noticed as well... I will try to see if I managed replicate the problem on my end with this example. Are you sure you're using exactly the same PySyft build version on both web workers? Did you try not to use conda, and building PySyft from source instead?

I am not using v1.19a1 or rather I can't. When I search for tagged releases, I get results from hydrogen and onwards, there is no v1.19a1. I did use hydrogen release though and made sure that all my systems were using the same version but that did not help either. I did not try to build it from source. I might give that a shot!Yeah, between August 2019 and 2017 there  don't seem to be any versions tracked. The most similar version could be: 0.1.23a though https://github.com/OpenMined/PySyft/releases/tag/0.1.23a dating back to August 2019. From what I remember, this version was working with my exampleAh okay, I dont think I tried that version. I will try and see if it works. But I guess folks over at slack are recommending to use grid now.So, I just cloned the latest version of PySyft and ran it all locally on an Ubuntu Virtual Machine from my local Windows. I then proceeded to start the websockets locally, and ran the example ""Federated Recurrent Neural Network"".

The only thing I changed was removed any reference to ""device"", which in my case led to a lot of problems, as I don't have CUDA installed. So I made the following changes:

```
#device = torch.device(""cuda"" if args.use_cuda else ""cpu"")
model = RNN(n_letters, n_hidden, n_categories)#.to(device)
```

And from:
```
    line_reshaped, category_single = line_reshaped.to(device), category_single.to(device)
```

to:

```
line_reshaped, category_single = line_reshaped, category_single
```

Then, everything went well, and the training went just fine. I suppose the problem you mentioned may arise when working with distributed machines instead of local ones? That's kinda weird though: from my experience, if something worked on local websockets, it worked on remote websockets just as well. 



![image](https://user-images.githubusercontent.com/4907418/96837052-1b1bb900-1446-11eb-941d-16480933e3d7.png)
I'm going to open a Pull Request with the new changes shortly> I suppose the problem you mentioned may arise when working with distributed machines instead of local ones?

Yeah, I believe so as well. With virtual workers things are working pretty much as expected.Once PR #4697 gets approved and merged, could you please try and see if the issue got resolved for websockets as well? Sure!Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.same questions",14,2020-10-16 14:59:37,2021-04-28 02:26:56,2020-11-19 13:37:36
https://github.com/OpenMined/PySyft/issues/4651,['bug '],ERROR ImportError while loading conftest,"ERROR ImportError while loading conftest## Description
A clear and concise description of the bug.
When i follow the INSTALLATION.md in pycharm of win10, i wanna to run python setup.py test in CMD.
But always occur this ERROR.
How to fix it?Lots of thx!!!!!!!!
.
.
.
.
.
.
.
.

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\pathspec-0
.8.0-py3.7.egg
Searching for regex>=2020.1.8
Best match: regex 2020.10.11
Processing regex-2020.10.11-py3.7-win-amd64.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\regex-2020
.10.11-py3.7-win-amd64.egg
Searching for typed-ast>=1.4.0
Best match: typed-ast 1.4.1
Processing typed_ast-1.4.1-py3.7-win-amd64.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\typed_ast-
1.4.1-py3.7-win-amd64.egg
Searching for appdirs
Best match: appdirs 1.4.4
Processing appdirs-1.4.4-py3.7.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\appdirs-1.
4.4-py3.7.egg
Searching for textwrap3>=0.9.2
Best match: textwrap3 0.9.2
Processing textwrap3-0.9.2-py3.7.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\textwrap3-
0.9.2-py3.7.egg
Searching for pyflakes<2.3.0,>=2.2.0
Best match: pyflakes 2.2.0
Processing pyflakes-2.2.0-py3.7.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\pyflakes-2
.2.0-py3.7.egg
Searching for pycodestyle<2.7.0,>=2.6.0a1
Best match: pycodestyle 2.6.0
Processing pycodestyle-2.6.0-py3.7.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\pycodestyl
e-2.6.0-py3.7.egg
Searching for mccabe<0.7.0,>=0.6.0
Best match: mccabe 0.6.1
Processing mccabe-0.6.1-py3.7.egg

Using d:\program files (x86)\onedrive - mail.dhu.edu.cn\dhu\lab\self-talk\ex\just for fun\pysyft-master\.eggs\mccabe-0.6
.1-py3.7.egg
running egg_info
writing syft.egg-info\PKG-INFO
writing dependency_links to syft.egg-info\dependency_links.txt
writing requirements to syft.egg-info\requires.txt
writing top-level names to syft.egg-info\top_level.txt
reading manifest file 'syft.egg-info\SOURCES.txt'
reading manifest template 'MANIFEST.in'
writing manifest file 'syft.egg-info\SOURCES.txt'
running build_ext
Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorF
low. Fix this by compiling custom ops. Missing file was 'D:\Anaconda3\envs\pysyft\lib\site-packages\tf_encrypted/operati
ons/secure_random/secure_random_module_tf_1.15.4.so'
WARNING:tensorflow:From D:\Anaconda3\envs\pysyft\lib\site-packages\tf_encrypted\session.py:24: The name tf.Session is de
precated. Please use tf.compat.v1.Session instead.

**ImportError while loading conftest 'D:\Program Files (x86)\OneDrive - mail.dhu.edu.cn\DHU\lab\self-talk\Ex\just for fun\
PySyft-master\test\conftest.py'.**
D:\Anaconda3\envs\pysyft\lib\importlib\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary
incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)
D:\Anaconda3\envs\pysyft\lib\importlib\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary
incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)
D:\Anaconda3\envs\pysyft\lib\importlib\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary
incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)
D:\Anaconda3\envs\pysyft\lib\importlib\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary
incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)
test\conftest.py:12: in <module>
    import syft
syft\__init__.py:14: in <module>
    import syft.frameworks.torch.hook.hook_args
syft\frameworks\torch\hook\hook_args.py:4: in <module>
    from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
syft\frameworks\torch\tensors\interpreters\native.py:6: in <module>
    from syft.frameworks.torch.tensors.interpreters.precision import FixedPrecisionTensor
syft\frameworks\torch\tensors\interpreters\precision.py:5: in <module>
    from syft.frameworks.torch.tensors.interpreters.replicated_shared import ReplicatedSharingTensor
syft\frameworks\torch\tensors\interpreters\replicated_shared.py:3: in <module>
    from syft.generic.frameworks.hook import hook_args
syft\generic\frameworks\__init__.py:1: in <module>
    from syft.generic.frameworks.types import framework_packages  # noqa: F401
syft\generic\frameworks\types.py:39: in <module>
    import crypten
D:\Anaconda3\envs\pysyft\lib\site-packages\crypten\__init__.py:8: in <module>
    import crypten.communicator as comm
D:\Anaconda3\envs\pysyft\lib\site-packages\crypten\communicator\__init__.py:9: in <module>
    from .distributed_communicator import DistributedCommunicator
D:\Anaconda3\envs\pysyft\lib\site-packages\crypten\communicator\distributed_communicator.py:15: in <module>
    from torch.distributed import ReduceOp
D:\Anaconda3\envs\pysyft\lib\site-packages\crypten\communicator\distributed_communicator.py:15: in <module>
    from torch.distributed import ReduceOp
**E   ImportError: cannot import name 'ReduceOp' from 'torch.distributed' (D:\Anaconda3\envs\pysyft\lib\site-packages\tor
ch\distributed\__init__.py)**


Python 3.7Hey ! this is a crypten error
Maybe related to https://github.com/SsnL/dataset-distillation/issues/12
please check the crypten repo for more details :) 
https://github.com/facebookresearch/CrypTenThe issue I think is that CrypTen is not supported on Windows. You might get away with it by removing crypten from the requirements file.",3,2020-10-14 13:21:40,2020-10-14 14:41:20,2020-10-14 14:09:37
https://github.com/OpenMined/PySyft/issues/4628,"['bug ', '0.2.x']",Error while installing PySyft,"Error while installing PySyft## Description
The Error pops up while `pip install syft` in anaconda prompt.

ERROR: Could not find a version that satisfies the requirement torch~=1.4.0 (from syft) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2) ERROR: No matching distribution found for torch~=1.4.0 (from syft)

## Expected Behavior
Installation of the package. All the steps have been followed and worked with progress in order. Only in installation, it showed error.

## System Information
 - OS: [e.g. iOS] Windows 
 - OS Version: [e.g. 22] 10
 - Language Version: [e.g. Python 3.7, Node 10.18.1] Python 3.7
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1] pip
 - Browser (if applicable): [e.g. Google Chrome] Google Chrome
 - Browser Version (if applicable): [e.g. 81.0.4044.138]@dA505819 Are you sure you have pytorch installed on your machine? The error indicates you haven't installed pytorch yet. 

Head over here https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md and follow the instructions and you should be good to goOr probably your pytorch version is lower than 1.4 . Try upgrading pytorch if that's the case@Boluwatifeh Yes, PyTorch is installed in the system. @Boluwatifeh Can you help me in upgrading the PyTorch by sharing a valuable article or video?Follow the instructions here https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md@dA505819 have you resolved the issue? @Boluwatifeh I will be working on it in 6 hours. 
Will be updating soon.@Boluwatifeh I have installed a new version of PyTorch. It gives an error after running this code:
`python setup.py install udacity`

Error is:
```
usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: setup.py --help [cmd1 cmd2 ...]
   or: setup.py --help-commands
   or: setup.py cmd --help

error: invalid command 'udacity
```

Run this command instead

 python setup.py install
Trying with it now.
@Boluwatifeh 
python setup.py install

`error: Could not find suitable distribution for Requirement.parse('websockets~=8.1.0')`Following all the procedures, still the error.if you try to install websockets with pip install what version it installs?@dA505819 ping! :D@gmuraru I have to check. Please give a day! @gmuraru It installs websockets version 8.1

I am sorry for the late reply.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",17,2020-10-05 21:33:56,2020-11-19 13:36:33,2020-11-19 13:36:33
https://github.com/OpenMined/PySyft/issues/4624,"['bug ', '0.2.x']",'IndexError: list index out of range' occurs whenever I try to do websocket connection.,"'IndexError: list index out of range' occurs whenever I try to do websocket connection.## Description
Hi, I'm attempting to do federated learing tutorial using websocket communication. I used 2 Raspberry Pi 4 to do this. 

I followed the instructions written in here; https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis,
but It threw an error. 

## How to Reproduce
I was using Docker env(arm32v7/python:3.7-slim) on Raspberry Pi 4s running **run_websocket_server.py** and central coordinator runs this notebook : https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/Federated%20Recurrent%20Neural%20Network.ipynb

First time, I used 
**python 3.7**
**run_websocket_server.py from branch 0.2.3a**(https://github.com/OpenMined/PySyft/blob/0.1.23a/examples/tutorials/advanced/websockets-example-MNIST/run_websocket_server.py)
**syft 0.1.13a**
**torch 1.0.0**
**torchvision 0.2.2.post3**

and this kind of error happened.

```2020-10-01 09:56:21,437 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
2020-10-01 09:56:21,674 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
2020-10-01 10:15:40,288 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
2020-10-01 10:15:40,513 ERROR base_events.py(l:1619, p:26) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('list index out of range')>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 285, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 351, in deserialize
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 543, in _detail
    return detailers[obj[0]](worker, obj[1])
IndexError: list index out of range
```

Then second time, I used
**python 3.7**
**run_websocket_server.py from master branch**
**syft 0.2.3**
**torch 1.4.0**
**torchvision 0.5.0**

and similar error happened.
```
2020-10-05 04:29:26,743 ERROR base_events.py(l:1619, p:12) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=KeyError(53)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 309, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 69, in deserialize
    return strategy(binary, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 369, in deserialize
    return _deserialize_msgpack_simple(simple_objects, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 360, in _deserialize_msgpack_simple
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 460, in _detail
    return detailers[obj[0]](worker, obj[1], **kwargs)
KeyError: 53
2020-10-05 04:29:26,972 ERROR base_events.py(l:1619, p:12) - Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=KeyError(53)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/usr/local/lib/python3.7/site-packages/syft/workers/base.py"", line 309, in recv_msg
    msg = sy.serde.deserialize(bin_message, worker=self)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/serde.py"", line 69, in deserialize
    return strategy(binary, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 369, in deserialize
    return _deserialize_msgpack_simple(simple_objects, worker)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 360, in _deserialize_msgpack_simple
    return _detail(worker, simple_objects)
  File ""/usr/local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 460, in _detail
    return detailers[obj[0]](worker, obj[1], **kwargs)
KeyError: 53
```

Error occurs right after the worker devices(RPi) receive a message from central device. Can you give me some advice about this situation?

+)
Error at the centeral deveice is like below
```
2020-10-05 16:01:10,413 WARNING websocket_client.py(l:107) - Websocket connection closed (worker: alice)
2020-10-05 16:01:10,537 WARNING websocket_client.py(l:112) - Created new websocket connection
Traceback (most recent call last):
  File ""<file path...>/run_websocket_client(0.2.3).py"", line 280, in <module>
    main()
  File ""<file path...>/run_websocket_client(0.2.3).py"", line 218, in main
    alice = WebsocketClientWorker(id=""alice"", port=10002, **a_kwargs_websocket)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 66, in __init__
    self.connect()
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 79, in connect
    self._log_msgs_remote(self.log_msgs)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 145, in _log_msgs_remote
    return self._send_msg_and_deserialize(""_log_msgs"", value=value)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 126, in _send_msg_and_deserialize
    response = self._send_msg(serialized_message)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 93, in _send_msg
    return self._recv_msg(message)
  File ""<virtual-env path...>\lib\site-packages\syft\workers\websocket_client.py"", line 117, in _recv_msg
    ""Websocket connection closed and creation of new connection failed.""
RuntimeError: Websocket connection closed and creation of new connection failed.

Process finished with exit code 1
```

## Expected Behavior
When I tested it in local environment(without using RPis) It worked perfectly. 

## System Information
 - OS: Devian (Docker : https://hub.docker.com/r/arm32v7/python/)
 - Language Version:  Python 3.7
 - Package Manager Version: Written above

## Additional Context

I was filled with hope that it would be succesful, but after got this thing my heart's broken.... plz help me....

@IonesioJunior do you have any idea?Is it open to fix then I want to give a trySure! Assigned it to you @sparkingdark Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.Okay I will inform you soon... @cereallarceny and btw I am not on slack,can you send me a invite",5,2020-10-01 14:26:23,2020-12-01 14:00:56,2020-11-19 13:36:23
https://github.com/OpenMined/PySyft/issues/4623,"['bug ', 'good first issue :mortar_board:', 'hacktoberfest']","Sending private tensors throws and error when only one user is listed in ""allowed_users"" ","Sending private tensors throws and error when only one user is listed in ""allowed_users"" ## Description
After creating a private tensor, I get a `SendNotPermittedError` when trying to send the data to the node if only one user is listed in allowed_users.

## How to Reproduce
`private_dataset = th.tensor([1, 3.5, 47.3]).private_tensor(allowed_users = (""Alice""))
private_dataset = private_dataset.tag('#my_data')
data_pointer = private_dataset.send(site, user='Alice')`

## Expected Behavior
Possibility to define only one allowed user.

## Additional Context
To overcome this issue I am currently listing the same user twice. For instance, `allowed_users = (""Alice"", ""Alice"")`
Thank you for reporting this :+1: I will take this one.:raised_hands: actually this not a bug, private tensor expects a list of users, `private_tensor(allowed_users = (""Alice"")) ` and here you are passing a string basically which converts to 5 users ['A', 'l' ....], 

either pass a list or tuple. for tuple with single element you need to use this format `(""Alice"",)` ,   `(""Alice"")` this is just a string
`private_tensor(allowed_users = (""Alice"",)) ` this will work
or better `private_tensor(allowed_users = [""Alice""]) `Thank you for looking into this. I think we can close it!@gmuraru  should i add a method to convert string to list explicitly?
so you can pass a string also, and passing string for single user looks betterNope, I think it is fine because the parameter name ```allowed_users``` allude to a list/tuple of user namescool np",8,2020-10-01 08:15:58,2020-10-01 14:27:49,2020-10-01 14:24:56
https://github.com/OpenMined/PySyft/issues/4621,"['bug ', '0.2.x']",error when 'import syft'  (syft==0.2.9),"error when 'import syft'  (syft==0.2.9)## Description
After I update my syft to 0.2.9,I'm not allowed to import syft

Here is the traceback:

```
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-4-7df2e9ff92ca> in <module>
----> 1 import syft as sy  # import the Pysyft library
      2 hook = sy.TorchHook(torch)  # hook PyTorch to add extra functionalities like Federated and Encrypted Learning
      3 
      4 # simulation functions
      5 def connect_to_workers(n_workers):

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\__init__.py in <module>
     12 # This import statement is strictly here to trigger registration of syft
     13 # tensor types inside hook_args.py.
---> 14 import syft.frameworks.torch.hook.hook_args
     15 
     16 import logging

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\frameworks\torch\hook\hook_args.py in <module>
      2 
      3 from syft import dependency_check
----> 4 from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
      5 from syft.generic.frameworks.hook.hook_args import (
      6     register_ambiguous_method,

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\frameworks\torch\tensors\interpreters\native.py in <module>
     14 from syft.generic.abstract.hookable import hookable
     15 from syft.generic.pointers.pointer_tensor import PointerTensor
---> 16 from syft.generic.utils import memorize
     17 from syft.workers.base import BaseWorker
     18 

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\generic\utils.py in <module>
----> 1 from syft.generic.frameworks.attributes import allowed_commands
      2 import syft as sy
      3 
      4 
      5 class memorize(dict):

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\generic\frameworks\attributes.py in <module>
      6 from typing import Any
      7 
----> 8 from syft.generic.frameworks.hook.hook import FrameworkHook
      9 
     10 allowed_commands = set()

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\generic\frameworks\hook\hook.py in <module>
      9 from syft.generic.frameworks.hook import hook_args
     10 from syft.generic.pointers.pointer_tensor import PointerTensor
---> 11 from syft.generic.frameworks.hook.pointers import PointerHook
     12 from syft.generic.frameworks.hook.string import StringHook
     13 from syft.generic.frameworks.hook.tensors import TensorHook

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\generic\frameworks\hook\pointers.py in <module>
      6 from syft.exceptions import TensorsNotCollocatedException
      7 from syft.generic.frameworks.hook import hook_args
----> 8 from syft.generic.pointers.multi_pointer import MultiPointerTensor
      9 from syft.generic.pointers.object_pointer import ObjectPointer
     10 from syft.generic.pointers.pointer_tensor import PointerTensor

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\generic\pointers\multi_pointer.py in <module>
      9 from syft.generic.abstract.tensor import AbstractTensor
     10 from syft.workers.abstract import AbstractWorker
---> 11 from syft.workers.base import BaseWorker
     12 
     13 

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\workers\base.py in <module>
     10 import syft as sy
     11 from syft import codes
---> 12 from syft.execution.plan import Plan
     13 from syft.frameworks.torch.mpc.primitives import PrimitiveStorage
     14 

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\execution\plan.py in <module>
     19 from syft.execution.translation.default import PlanTranslatorDefault
     20 from syft.execution.translation.torchscript import PlanTranslatorTorchscript
---> 21 from syft.execution.translation.threepio import PlanTranslatorTfjs
     22 from syft.execution.translation import TranslationTarget
     23 from syft.generic.frameworks import framework_packages

~\AppData\Local\Continuum\anaconda3\envs\pytorch\lib\site-packages\syft\execution\translation\threepio.py in <module>
      1 from typing import List
      2 import pythreepio
----> 3 from pythreepio.threepio import Threepio
      4 from pythreepio.command import Command
      5 from syft.execution.computation import ComputationAction

ModuleNotFoundError: No module named 'pythreepio.threepio'

```Hi!
Very strange that it didn't install `pythreepio`...
You can install manually
`pip install openmined.threepio==0.2.0`
Please let me know if this fixes the pbAny update @Doodlera?> Any update @Doodlera?

It didn't work.
I install manually by _pip install openmined.threepio==0.2.0_.It have been installed as follow:
![image](https://user-images.githubusercontent.com/32300708/95530037-57472680-0a0f-11eb-9ef6-269e44ba239a.png)
But I still have the problem:
    _ModuleNotFoundError: No module named 'pythreepio.threepio'_
> Any update @Doodlera?

By the way,I used to find the same problem in 0.2.7. I change the release to 0.2.6 and avoid it.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",6,2020-09-30 07:36:12,2020-11-19 13:36:15,2020-11-19 13:36:15
https://github.com/OpenMined/PySyft/issues/4616,"['bug ', 'status: available :wave:', 'hacktoberfest', '0.2.x']",SVD is returning 4 pointers instead of 3,"SVD is returning 4 pointers instead of 3## Description
When sending a tensor to a worker and performing SVD, returns four pointers instead of three. Also, the third one is not gettable. By experimentation, I have had to solve the issue using `U, s, _, V = x.svd()`.

## How to Reproduce
```python
import torch
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id='bob')

x = torch.rand(250, 84).send(bob)  # Synthetic tensor
x.svd()

# Output:
# ((Wrapper)>[PointerTensor | me:88822589827 -> bob:10423896311],
#  (Wrapper)>[PointerTensor | me:22528885369 -> bob:34285527022],
#  (Wrapper)>[PointerTensor | me:46709676193 -> bob:67244907535],
#  (Wrapper)>[PointerTensor | me:235847656 -> bob:15738446586])
```

## Expected Behavior
Should return **three** pointers: `U, s, V = x.svd()`

## System Information
 - Official released Docker container
 - Same for pip package:
   - Ubuntu 18.04.5 LTS (Bionic Beaver)
   - Python 3.6.9this is pretty weird I run this code in debug mode, stepped into every function, the things seemed correct while computing the response (3 tensors were returned),  and in the end got this error : (which shows things were correct 3 tensor returned as expected)
```
Exception has occurred: ValueError
not enough values to unpack (expected 4, got 3)
  File ""/home/nilansh/Anton/OpenMined/PySyft/debug.py"", line 8, in <module>
    U, s, _, V = x.svd()

```

but returns 4 values when run as normal python code.

@LaRiffle  want to work on it.@sssilvar could you test this? It should be solved on on the 0.2.x branchHello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, Iâ€™ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and Iâ€™ll reopen the issue.",4,2020-09-28 14:38:42,2020-11-19 13:36:07,2020-11-19 13:36:07
https://github.com/OpenMined/PySyft/issues/4585,"['bug ', 'priority: 4 - low :sunglasses:', '0.2.x']",Protobuf serialization mode seems broken,"Protobuf serialization mode seems broken## Description
Have any of you used the protobuf serialization mode instead of the msgpack one?
I know we have one, but I switch to this mode by doing in `syft/serde/serde.py`
```
from syft.serde.msgpack import serialize as msgpack_serialize
from syft.serde.msgpack import deserialize as msgpack_deserialize
```
-> 
```
from syft.serde.protobuf import serialize as msgpack_serialize
from syft.serde.protobuf import deserialize as msgpack_deserialize
```

## How to Reproduce
I have tons of weird errors on the simple example:
```
message = th.tensor([[1., 2], [3, 4]])
message.send(alice).get()
```

This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",2,2020-09-22 14:53:25,2020-11-19 13:31:08,2020-11-19 13:31:08
https://github.com/OpenMined/PySyft/issues/4579,['bug '],"I got problems while I'm executing ""examples/tutorials/advanced/websockets_mnist/""","I got problems while I'm executing ""examples/tutorials/advanced/websockets_mnist/""Hi, there.

While I was following the tutorial ""examples/tutorials/advanced/websockets_mnist/"", I got some problems and I'm here to ask one of those.

_Question is_ 
whenever I execute ""start_websocket_servers.py"" I get **""TypeError: argument of type 'WindowsPath' is not iterable""**
Is this related with FILE_PATH object?

For your convinience, I attached the codes and error messages below

```
import subprocess
import sys
from pathlib import Path

python = Path(sys.executable).name

FILE_PATH = Path(__file__).resolve().parent.joinpath(""run_websocket_server.py"")

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]

call_bob = [python, FILE_PATH, ""--port"", ""8778"", ""--id"", ""bob""]

call_charlie = [python, FILE_PATH, ""--port"", ""8779"", ""--id"", ""charlie""]


print(""Starting server for Alice"")
subprocess.Popen(call_alice)

print(""Starting server for Bob"")
subprocess.Popen(call_bob)

print(""Starting server for Charlie"")
subprocess.Popen(call_charlie)

```

```
Traceback (most recent call last):
  File ""C:/Users/Lee/Documents/GitHub/FED/websockets_mnist/start_websocket_servers.py"", line 18, in <module>
    subprocess.Popen(call_alice)
  File ""C:\Users\Lee\anaconda3\envs\websockets_mnist\lib\subprocess.py"", line 800, in __init__
    restore_signals, start_new_session)
  File ""C:\Users\Lee\anaconda3\envs\websockets_mnist\lib\subprocess.py"", line 1148, in _execute_child
    args = list2cmdline(args)
  File ""C:\Users\Lee\anaconda3\envs\websockets_mnist\lib\subprocess.py"", line 555, in list2cmdline
    needquote = ("" "" in arg) or (""\t"" in arg) or not arg
TypeError: argument of type 'WindowsPath' is not iterable
```

and honestly... I don't know where the ""run_websocket_server.py"" at ""FILE_PATH"" came from. I couldn't find it anywhere in this tutorial. Do I have to make this file on my own?


There are many other questions but that's the main one anyway. I guess I can do the rest myself after solving this one.

Thank you in advance!
I solved this problem by wrapping FILE_PATH with str() like below.
`FILE_PATH = str(Path(__file__).resolve().parent.joinpath(""run_websocket_server.py""))`

I think it's not that elaborate way, but anyway it works for my case.",1,2020-09-21 11:18:12,2020-09-22 06:50:48,2020-09-22 06:50:48
https://github.com/OpenMined/PySyft/issues/4568,"['bug ', 'hacktoberfest', '0.2.x']", model.get() causes RuntimeError if the code is running on GPU with resnet model,"model.get() causes RuntimeError if the code is running on GPU with resnet model## Description
After I train the model locally by a worker, I do model.get() to retrieve it and I have the following runtime error: ""Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_"".
I am training on GPU (same code runs perfectly if I use CPU) and I am using resnet50 model.

## How to Reproduce
```
optimizer = optim.Adam(model.parameters(), lr=lr) 
criterion = nn.CrossEntropyLoss()

model.train()
model.send(worker)
for batch_idx, (data, target) in enumerate(batches):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        loss = loss.get()
        model.get()  # <-- This get causes the error
```

## System Information
 - syft: 0.2.9Hey, thanks for reporting!
can you alors provide your stack trace please? :) Hi @Hjeljeli @LaRiffle, I encountered the same problem a few months ago, please refer to the comments in #3848 for further explanation.@LaRiffle 
Hi Theo, please find my stack trace. Merci pour ton aide!

```
<ipython-input-16-1a450dc3c5d4> in <module>
      3 logging.basicConfig(format=FORMAT, level=LOG_LEVEL)
      4 
----> 5 main()

<ipython-input-15-443eb06bbc7c> in main()
    208     for epoch in range(1, epochs + 1):
    209         logger.warning(""Starting epoch %s/%s"", epoch, epochs)
--> 210         model = train(model, device, federated_train_loader, test_loader, lr, federate_after_n_batches)
    211         test(model, device, test_loader)

<ipython-input-15-443eb06bbc7c> in train(model, device, federated_train_loader, test_loader, lr, federate_after_n_batches, abort_after_one)
    112             curr_batches = batches[worker]
    113             if curr_batches:
--> 114                 local_models[worker] = train_on_batches(worker, curr_batches, model, device, test_loader, lr)
    115 
    116             else:

<ipython-input-15-443eb06bbc7c> in train_on_batches(worker, batches, model_in, device, test_loader, lr)
     42             t1 = time.time()
     43             # We measure accurancy of worker's model
---> 44             model.get()
     45             accuracy = test(model, device, test_loader)
     46             accuracies[worker].append(accuracy)

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
    673             if isinstance(nn_self.forward, Plan):

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in get_(self, *args, **kwargs)
    685         Calls get() with inplace option set to True
    686         """"""
--> 687         return self.get(*args, inplace=True, **kwargs)
    688 
    689     def allow(self, user=None) -> bool:

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    672 
    673         if inplace:
--> 674             self.set_(tensor)
    675             if hasattr(tensor, ""child""):
    676                 self.child = tensor.child

RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_
```+1, I also run into this issue with very similar code to the above, except using mobilenet instead of resnet. RuntimeError message is the same. The issue disappears when I use a neural net I specify for myself, so I think it could be interop with the torch model zoo models?

(for reference I had this same issue back in ~May on syft ~0.2.4 but didn't report- unfortunately some other projects pulled me away from this one)Thank you for reporting it! It might be a problem that the tensors should be sent to the ```device``` (in this case GPU) before using ```set_```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.> This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.

Updating so this issue is active.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.is this issue fixed in 0.3.x? @Hjeljeli. Currently stuck with this bug in 0.2.9 :(.@naveenggmu Hi Naveen, I could not test on 0.3.x as you know the releases 0.3.x do not support all the privacy-preserving techniques that 0.2.x used to support, for me I am using PySyft for Federated Learning.",10,2020-09-18 09:40:30,2020-12-28 00:54:47,2020-11-19 13:30:59
https://github.com/OpenMined/PySyft/issues/4555,['bug '],utils.federated_avg() gives ar error with resnet models on pysyft-0.2.9,"utils.federated_avg() gives ar error with resnet models on pysyft-0.2.9## Description
When I call utils.federated_avg() on resnet models, I have the following error: init() missing 2 required positional arguments: 'block' and 'layers'. Any idea how to fix this?

## System Information
Pysyft Version: 0.2.9

## Code Snippet 
import torch
from torchvision import datasets, transforms, models

import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.frameworks.torch.fl import utils
hook = sy.TorchHook(torch)

alice = VirtualWorker(id=""alice"", hook=hook)
bob = VirtualWorker(id=""bob"", hook=hook)
carol = VirtualWorker(id=""carol"", hook=hook)
workers = [alice, bob, carol]

model_in = models.resnet50(pretrained=True)

local_models = {}
for worker in workers:
local_models[worker]= model_in.copy()

model_out = utils.federated_avg(local_models)

## Error
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/hamza/PySyft-0.2.9/syft/frameworks/torch/fl/utils.py"", line 85, in federated_avg
    model = type(model_list[0])()
TypeError: __init__() missing 2 required positional arguments: 'block' and 'layers'Closing this issue as it is a duplicate of #4481",1,2020-09-15 02:08:16,2020-09-15 15:00:05,2020-09-15 15:00:04
https://github.com/OpenMined/PySyft/issues/4551,"['bug ', '0.2.x']","Hi, I am getting import error ' from crc32c import crc32' when i am trying to run WebsocketServerWorker on GCP ,Please suggest to fix this","Hi, I am getting import error ' from crc32c import crc32' when i am trying to run WebsocketServerWorker on GCP ,Please suggest to fix this ## Description
A clear and concise description of the bug.
I installed the dependecies using !pip install syft[udacity,notebooks] using Google cloud Notebook . 
but getting this error.


---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/aiortc/rtcsctptransport.py in <module>
     32 try:
---> 33     from crc32c import crc32
     34 except ImportError:  # pragma: no cover

ImportError: cannot import name 'crc32' from 'crc32c' (/opt/conda/lib/python3.7/site-packages/crc32c/__init__.py)

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-0df61b862dcd> in <module>
      1 import torch
----> 2 import syft as sy
      3 
      4 hook = sy.TorchHook(torch)
      5 


## How to Reproduce
Please run this script to reproduce 

import torch
import syft as sy

hook = sy.TorchHook(torch)

from syft.workers.websocket_server import WebsocketServerWorker

local_worker = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8183)

local_worker.start()



## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome] -
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",2,2020-09-13 12:06:22,2020-11-19 13:30:34,2020-11-19 13:30:33
https://github.com/OpenMined/PySyft/issues/4545,['bug '],Error importing PySyft on MacOS after pip install,"Error importing PySyft on MacOS after pip install## Description
Import syft results in error on Mac

## How to Reproduce
Follow instructions on installation on MacOS here:
https://github.com/OpenMined/PySyft/blob/master/INSTALLATION.md

## Expected Behavior
import syft to succeed.

## Error message
If applicable, add screenshots to help explain your problem.

>>> import syft
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/eliotpbrenner/Projects/PySyft/syft/__init__.py"", line 43, in <module>
    from syft.grid.private_grid import PrivateGridNetwork  # noqa: E402,F401
  File ""/Users/eliotpbrenner/Projects/PySyft/syft/grid/__init__.py"", line 4, in <module>
    from syft.grid.rtc.network import Network
  File ""/Users/eliotpbrenner/Projects/PySyft/syft/grid/rtc/network.py"", line 6, in <module>
    from syft.grid.rtc.nodes_manager import WebRTCManager
  File ""/Users/eliotpbrenner/Projects/PySyft/syft/grid/rtc/nodes_manager.py"", line 1, in <module>
    from syft.grid.rtc.webrtc_connection import WebRTCConnection
  File ""/Users/eliotpbrenner/Projects/PySyft/syft/grid/rtc/webrtc_connection.py"", line 6, in <module>
    from aiortc import RTCPeerConnection, RTCSessionDescription
  File ""/opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/__init__.py"", line 20, in <module>
    from .rtcpeerconnection import RTCPeerConnection
  File ""/opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/rtcpeerconnection.py"", line 10, in <module>
    from .codecs import CODECS, HEADER_EXTENSIONS, is_rtx
  File ""/opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/codecs/__init__.py"", line 15, in <module>
    from .opus import OpusDecoder, OpusEncoder
  File ""/opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/codecs/opus.py"", line 9, in <module>
    from ._opus import ffi, lib
ImportError: dlopen(/opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/codecs/_opus.abi3.so, 2): Symbol not found: ____chkstk_darwin
  Referenced from: /opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/codecs/_opus.abi3.so
  Expected in: /usr/lib/libSystem.B.dylib
 in /opt/miniconda3/envs/375/lib/python3.7/site-packages/aiortc/codecs/_opus.abi3.so


## System Information
 - OS: MacOS
 - OS Version: 10.11.5
 - Language Version: Python 3.7.5
 - Package Manager Version: pip 20.2.1
Hi!
I guess it must be linked to https://github.com/huggingface/tokenizers/issues/321#issuecomment-659969197
You're using macOS El Capitan from 2016, if you can upgrade to a newer version it will be fixed.
We should update `MACOSX_DEPLOYMENT_TARGET` as they suggest, but I don't know how to do this, contribution welcome  :) @eliotpbrenner did @LaRiffle solved your issue?I trust that it'll work, but I didn't upgrade my MacOS.  I just decided to use PySyft on Unix.",3,2020-09-09 16:06:19,2020-10-01 12:43:28,2020-10-01 12:43:28
https://github.com/OpenMined/PySyft/issues/4530,['bug '],"## Under contributors guidelines to pysft, deploying workers guide returns a 404 page","## Under contributors guidelines to pysft, deploying workers guide returns a 404 page## Description
A clear and concise description of the bug.

## How to Reproduce
1. Go to '...'
2. Click on '...'
3. Scroll down to '...'
4. See error

## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS]
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1]
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
Hey can you please precise what the bug is? Thanks ðŸ˜„ 
Hey there @LaRiffle i was reading through the contribution.md page and under the deploying workers section, the example link on how to deploy workers returns a 404 page. Here's the link https://github.com/OpenMined/PySyft/blob/master/examples/deploy_workers/deploy-and-connect.ipynbI guess it has been moved here: https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/tutorial-websocket/deploy_workers/deploy-and-connect.ipynb
Will fix this, thanks!",3,2020-09-03 23:08:13,2020-09-15 16:31:46,2020-09-15 16:31:46
https://github.com/OpenMined/PySyft/issues/4514,"['bug ', '0.2.x']",Sending requests to the pygrid using os.path.join,"Sending requests to the pygrid using os.path.join## Description
I have just noticed a limitation of PySyft/PyGrid when relying on `os.path.join` to interface with the network. More specifically, nothing happens when I try to add a node to the network using `.\apps\node\run.sh --id Alice --port 5001 --host localhost --network http://localhost:7000 --start_local_db`. I manually checked this behavior as shown below. This is due to the fact that `os.path.join` uses back slashes instead of forward slashes. I temporally solved this using `.replace(""\\"",""/"")` after `os.path.join`.

## How to Reproduce
1. Create a grid via `.\apps\network>run.sh --port 7000 --start_local_db`
2. In a Jupyter notebook run


> import requests
> import os
> import json
> 
> node_id = 'Alice'
> port = '5001'
> GRID_NETWORK_PORT = '7000'
> 
> res = requests.post(
>      #  Expected path ""http://localhost:7000//join""
>      # Actual path ""http://localhost:7000\\join""
>      os.path.join(""http://localhost:"" + GRID_NETWORK_PORT, ""join""),
>      data=json.dumps(
>          {""node-id"": node_id, ""node-address"": ""http://localhost:"" + port}
>      ),
> )

3. Check response via `res.text`
4. Response: `'<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 3.2 Final//EN"">\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n'`

## Expected Behavior
The path should be ""http://localhost:7000//join"" (now ""http://localhost:7000\\join"").

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.7.3 (running on virtualenv)
 - Browser (if applicable): Google Chrome
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",2,2020-09-01 07:40:48,2020-11-19 13:30:22,2020-11-19 13:30:22
https://github.com/OpenMined/PySyft/issues/4507,['bug '],"Error when saving model with torch.save() trained with SMPC - ""Can't pickle module objects""","Error when saving model with torch.save() trained with SMPC - ""Can't pickle module objects""## Description
Trained a model using the tutorial example for encrypted training on MNIST. The training works fine. When doing torch.save(model.state_dict(), PATH), it gives the following error - 
 _""... pickler.dump(obj)
TypeError: can't pickle module objects""_

## How to Reproduce
1. Run tutorial example - Encrypted training on MNIST.ipynb
2. Execute - torch.save(model.state_dict(), ""private_MNIST.pt"")

## System Information
 - OS: Ubuntu 18.04.5
 - Language Version:  Python 3.7.7
-  syft 0.2.8
-  syft-proto 0.5.2
 - Package Manager Version:  Conda 4.8.4

Resolved. The solution turned out to be simple. Just reconstruct the model and convert it back to floating point using model.get().float_precision(). Then use torch.save(model, PATH).",1,2020-08-31 15:12:48,2020-08-31 18:23:13,2020-08-31 18:23:12
https://github.com/OpenMined/PySyft/issues/4502,['bug '],Unable to execute PySyft/examples/tutorials/model-centric-fl/Part 01 - Create Plan.ipynb,"Unable to execute PySyft/examples/tutorials/model-centric-fl/Part 01 - Create Plan.ipynb## Description

Hi PySyft team,

I encountered these errors when running the mentioned notebook. 
 
The error below happens with syft==0.2.7.
```
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-3-22da4773ebd0> in <module>
      6 from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB
      7 from syft_proto.execution.v1.state_pb2 import State as StatePB
----> 8 from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient
      9 from syft.execution.state import State
     10 from syft.execution.placeholder import PlaceHolder

ModuleNotFoundError: No module named 'syft.grid.clients.model_centric_fl_client'
```

While another error below happens with syft==0.2.8.

```
KeyError                                  Traceback (most recent call last)
<ipython-input-17-8a945e035458> in <module>
     12     server_averaging_plan=avg_plan,
     13     client_config=client_config,
---> 14     server_config=server_config
     15 )
     16 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/clients/model_centric_fl_client.py in host_federated_training(self, model, client_plans, client_protocols, client_config, server_averaging_plan, server_config)
    119         }
    120 
--> 121         return self._send_msg(message)
    122 
    123     def get_model(self, name, version, checkpoint=""latest""):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/clients/model_centric_fl_client.py in _send_msg(self, message)
     49         json_response = json.loads(self.ws.recv())
     50 
---> 51         error = json_response[""data""].get(""error"", None)
     52         if error is not None:
     53             raise GridError(error, None)

KeyError: 'data'
```
Please share the list of dependencies that work with the examples. Thanks
@chihan461 How did you fix this? I am having the same error for syft==0.2.8",1,2020-08-29 18:12:02,2020-09-10 14:28:11,2020-08-30 07:30:20
https://github.com/OpenMined/PySyft/issues/4495,"['bug ', '0.2.x']",RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.,"RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.Hi PySyft-Team,

I have updated the PySyft version from v0.2.1.a1 to 0.2.4.

Now I get the following error message when I run my program on the client (here a WebsocketServerWorker is running):

```
Serving. Press CTRL-C to stop.
Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/jetson/PySyft/syft/workers/websocket_server.py:95> exception=RuntimeError('a leaf Variable that requires grad is being used in an in-place operation.',)>
Traceback (most recent call last):
  File ""/home/jetson/PySyft/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/jetson/PySyft/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/home/jetson/PySyft/syft/workers/base.py"", line 320, in recv_msg
    response = self._message_router[type(msg)](msg)
  File ""/home/jetson/PySyft/syft/workers/base.py"", line 434, in execute_tensor_command
    return self.execute_computation_action(cmd.action)
  File ""/home/jetson/PySyft/syft/workers/base.py"", line 464, in execute_computation_action
    getattr(_self, op_name)(*args, **kwargs)
  File ""/home/jetson/PySyft/syft/generic/frameworks/hook/trace.py"", line 83, in trace_wrapper
    response = func(*args, **kwargs)
  File ""/home/jetson/PySyft/syft/generic/frameworks/hook/hook.py"", line 419, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""/home/jetson/PySyft/syft/generic/frameworks/hook/hook.py"", line 415, in overloaded_native_method
    response = method(*args, **kwargs)
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
```

This is done by executing the following command on the server (has the client mounted as WebsocketClientWorker):

`optimizer.step()`

The data is loaded to the client (on the client before the websocket server is started) as follows:

```
remote_worker = WebsocketServerWorker(...)
...
data = data.to(DEVICE) 
target = target.to(DEVICE)

data_ptr = th.tensor(data, requires_grad=True).tag(TRAIN_DATA_TAG).send(remote_worker)  
target_ptr = th.tensor(target, requires_grad=False).tag(TRAIN_TARGET_TAG).send(remote_worker)

remote_worker.start()
```

Does anyone have an idea?
Many thanks in advance
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",2,2020-08-28 08:57:33,2020-11-19 13:30:13,2020-11-19 13:30:13
https://github.com/OpenMined/PySyft/issues/4492,"['bug ', '0.2.x']",test() causes error at Part 11 Tutorial Notebook,"test() causes error at Part 11 Tutorial Notebook## Description

In the last cell of the notebook: 
`test(args, model, private_test_loader)`
I am getting this error:

> AssertionError: Searching for #fss_comp_plan_1 on alice. /!\ 0 found

I am new to the Pysyft library, although I tried to find the reason of this error, I couldn't find it.

Full text of error:

```
`---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-37-d96a4baef877> in <module>()
----> 1 test(args, model, private_test_loader)

22 frames
<ipython-input-36-22b4a92d84ce> in test(args, model, test_loader)
      5     with torch.no_grad():
      6         for data, target in test_loader[:n_test_batches]:
----> 7             output = model(data)
      8             pred = output.argmax(dim=1)
      9             n_correct_priv += pred.eq(target.view_as(pred)).sum()

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-30-6d8ab0cff85f> in forward(self, x)
      8         x = x.view(-1, 784)
      9         x = self.fc1(x)
---> 10         x = F.relu(x)
     11         x = self.fc2(x)
     12         return x

/usr/local/lib/python3.6/dist-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)
    338                 handle_func_command = syft.framework.Tensor.handle_func_command
    339 
--> 340             response = handle_func_command(command)
    341 
    342             return response

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    358             # Send it to the appropriate class and get the response
    359             try:
--> 360                 response = new_type.handle_func_command(new_command)
    361             except RuntimeError:
    362                 # Change the library path to avoid errors on layers like AvgPooling

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/precision.py in handle_func_command(cls, command)
    810 
    811         # Send it to the appropriate class and get the response
--> 812         response = new_type.handle_func_command(new_command)
    813 
    814         # Put back FixedPrecisionTensor on the tensors found in the response

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in handle_func_command(cls, command)
   1119 
   1120         if cmd is not None:
-> 1121             return cmd(*args_, **kwargs_)
   1122 
   1123         tensor = args_[0] if not isinstance(args_[0], (tuple, list)) else args_[0][0]

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in relu(tensor_shares, inplace)
    928             def functional(module):
    929                 def relu(tensor_shares, inplace=False):
--> 930                     return tensor_shares.relu()
    931 
    932                 module.relu = relu

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/mpc/__init__.py in method(self, *args, **kwargs)
     32         def method(self, *args, **kwargs):
     33             f = protocol_store[(name, self.protocol)]
---> 34             return f(self, *args, **kwargs)
     35 
     36         return method

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in relu(self)
    954     def relu(self):
    955         zero = self - self
--> 956         return self * (self >= zero)
    957 
    958     def positive(self):

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/mpc/__init__.py in method(self, *args, **kwargs)
     32         def method(self, *args, **kwargs):
     33             f = protocol_store[(name, self.protocol)]
---> 34             return f(self, *args, **kwargs)
     35 
     36         return method

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in __ge__(self, other)
    981     @crypto_protocol(""fss"")
    982     def __ge__(self, other):
--> 983         return fss.le(other, self)
    984 
    985     def lt(self, other):

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/mpc/fss.py in le(x1, x2)
    190 
    191 def le(x1, x2):
--> 192     return fss_op(x1, x2, ""comp"")
    193 
    194 

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/mpc/fss.py in fss_op(x1, x2, type_op)
    101         args = (x1.child[location.id], x2.child[location.id])
    102         share = request_run_plan(
--> 103             me, f""#fss_{type_op}_plan_1"", location, return_value=True, args=args
    104         )
    105         shares.append(share)

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/mpc/fss.py in request_run_plan(worker, plan_tag, location, return_value, args, kwargs)
     73         return_value=return_value,
     74         kwargs_=kwargs,
---> 75         args_=args,
     76     )
     77     return response

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    514                 cmd_name, target, args_, kwargs_, return_ids, return_value
    515             )
--> 516             ret_val = self.send_msg(message, location=recipient)
    517         except ResponseSignatureError as e:
    518             ret_val = None

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_msg(self, message, location)
    315 
    316         # Step 2: send the message and wait for a response
--> 317         bin_response = self._send_msg(bin_message, location)
    318 
    319         # Step 3: deserialize the response

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _send_msg(self, message, location)
     14             sleep(self.message_pending_time)
     15 
---> 16         return location._recv_msg(message)
     17 
     18     def _recv_msg(self, message: bin) -> bin:

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _recv_msg(self, message)
     18     def _recv_msg(self, message: bin) -> bin:
     19         """"""receive message""""""
---> 20         return self.recv_msg(message)
     21 
     22     # For backwards compatibility with Udacity course

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in recv_msg(self, bin_message)
    355         for handler in self.message_handlers:
    356             if handler.supports(msg):
--> 357                 response = handler.handle(msg)
    358                 break
    359         # TODO(karlhigley): Raise an exception if no handler is found

/usr/local/lib/python3.6/dist-packages/syft/generic/abstract/message_handler.py in handle(self, msg)
     18 
     19     def handle(self, msg):
---> 20         return self.routing_table[type(msg)](msg)

/usr/local/lib/python3.6/dist-packages/syft/workers/message_handler.py in execute_tensor_command(self, cmd)
     53     def execute_tensor_command(self, cmd: TensorCommandMessage) -> PointerTensor:
     54         if isinstance(cmd.action, ComputationAction):
---> 55             return self.execute_computation_action(cmd.action)
     56         else:
     57             return self.execute_communication_action(cmd.action)

/usr/local/lib/python3.6/dist-packages/syft/workers/message_handler.py in execute_computation_action(self, action)
     86                     assert (
     87                         len(res) == 1
---> 88                     ), f""Searching for {_self} on {self.worker.id}. /!\\ {len(res)} found""
     89                     _self = res[0]
     90             if sy.framework.is_inplace_method(op_name):

AssertionError: Searching for #fss_comp_plan_1 on alice. /!\ 0 found`
```

## System Information
 - run on Colab with GPU


## Additional Context
Add any other context about the problem here.
Hello, have you tried building from sources? This error might have been solved in the latest version that is not released yet.@teo-milea when were the sources updated at last?The sources are updating (I think) at least once in every 3-4 days
https://github.com/OpenMined/PySyft/issues/4473 <-- could you run the steps posted by @teo-milea @gmuraru the issue doesn't get resolved by following those steps.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",6,2020-08-26 21:41:44,2020-11-19 13:30:03,2020-11-19 13:30:02
https://github.com/OpenMined/PySyft/issues/4491,"['bug ', '0.2.x']",PureFrameworkTensorFoundError AttributeError: 'Tensor' object has no attribute 'child',"PureFrameworkTensorFoundError AttributeError: 'Tensor' object has no attribute 'child'After using the .get() function on each tensor in the list of features produced by an UXception encoder model which resides at the client worker(virtual worker on same machine), I pass this list of features through a decoder model. This is when I get the error as stated below.

---------------------------------------------------------------------------
PureFrameworkTensorFoundError             Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    340             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
--> 341                 cmd, args_, kwargs_, return_args_type=True
    342             )

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in unwrap_args_from_function(attr, args_, kwargs_, return_args_type)
    156         # Try running it
--> 157         new_args = hook_args(args_)
    158 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(x)
    355 
--> 356     return lambda x: f(lambdas, x)
    357 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in tuple_one_fold(lambdas, args_)
    522     def tuple_one_fold(lambdas, args_):
--> 523         return (lambdas[0](args_[0], **kwargs),)
    524 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py in <lambda>(i)
    330         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 331         else lambda i: forward_func[type(i)](i)
    332         for a, r in zip(args_, rules)  # And do this for all the args / rules provided

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     23     if hasattr(i, ""child"")
---> 24     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     25     torch.nn.Parameter: lambda i: i.child

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     23     if hasattr(i, ""child"")
---> 24     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     25     torch.nn.Parameter: lambda i: i.child

PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    383             try:
--> 384                 response = cls._get_response(cmd, args_, kwargs_)
    385             except AttributeError:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in _get_response(cmd, args_, kwargs_)
    417         if isinstance(args_, tuple):
--> 418             response = command_method(*args_, **kwargs_)
    419         else:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/functional.py in interpolate(input, size, scale_factor, mode, align_corners)
   2508 
-> 2509     if input.dim() == 3 and mode == 'nearest':
   2510         return torch._C._nn.upsample_nearest1d(input, _output_size(1))

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    173                     # we can make some errors more descriptive with this method
--> 174                     raise route_method_exception(e, self, args, kwargs)
    175 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    169                 try:
--> 170                     response = method(*args, **kwargs)
    171 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py in dim(self)
    106         def dim(self):
--> 107             return len(self.shape)
    108 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in shape(self)
    136         if self.is_wrapper:
--> 137             return self.child.shape
    138         else:

AttributeError: 'Tensor' object has no attribute 'child'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-29-2ce8f7bfa4e9> in <module>
     56 
     57     #4) make prediction on next model using recieved signal
---> 58     output = server_model(server_a)
     59     break
     60 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-12-df1dc6dd3ba5> in forward(self, features)
     47         """"""Sequentially pass `x` trough model`s encoder, decoder and heads""""""
     48         #features = self.encoder(x)
---> 49         decoder_output = self.decoder(*features)
     50 
     51         masks = self.segmentation_head(decoder_output)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-6-821c73a4e911> in forward(self, *features)
    110         for i, decoder_block in enumerate(self.blocks):
    111             skip = skips[i] if i < len(skips) else None
--> 112             x = decoder_block(x, skip)
    113 
    114         return x

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

<ipython-input-6-821c73a4e911> in forward(self, x, skip)
     27 
     28     def forward(self, x, skip=None):
---> 29         x = F.interpolate(x, scale_factor=2, mode=""nearest"")
     30         if skip is not None:
     31             x = torch.cat([x, skip], dim=1)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_func(*args, **kwargs)
    338                 handle_func_command = syft.framework.Tensor.handle_func_command
    339 
--> 340             response = handle_func_command(command)
    341 
    342             return response

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    386                 # Change the library path to avoid errors on layers like AvgPooling
    387                 cmd = cls._fix_torch_library(cmd)
--> 388                 response = cls._get_response(cmd, args_, kwargs_)
    389 
    390         return response

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in _get_response(cmd, args_, kwargs_)
    416 
    417         if isinstance(args_, tuple):
--> 418             response = command_method(*args_, **kwargs_)
    419         else:
    420             response = command_method(args_, **kwargs_)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/functional.py in interpolate(input, size, scale_factor, mode, align_corners)
   2507             align_corners = False
   2508 
-> 2509     if input.dim() == 3 and mode == 'nearest':
   2510         return torch._C._nn.upsample_nearest1d(input, _output_size(1))
   2511     elif input.dim() == 4 and mode == 'nearest':

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    172                 except BaseException as e:
    173                     # we can make some errors more descriptive with this method
--> 174                     raise route_method_exception(e, self, args, kwargs)
    175 
    176             else:  # means that there is a wrapper to remove

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    168 
    169                 try:
--> 170                     response = method(*args, **kwargs)
    171 
    172                 except BaseException as e:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py in dim(self)
    105 
    106         def dim(self):
--> 107             return len(self.shape)
    108 
    109         tensor_type.dim = dim

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in shape(self)
    135     def shape(self):
    136         if self.is_wrapper:
--> 137             return self.child.shape
    138         else:
    139             return self.native_shape

AttributeError: 'Tensor' object has no attribute 'child'
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.but the problem is that version 0.3.x does not support torchhook. If it's supported please share an example.",3,2020-08-26 17:54:50,2022-02-07 15:36:33,2020-11-19 13:29:57
https://github.com/OpenMined/PySyft/issues/4481,"['bug ', '0.2.x']",utils.federated_avg() gives ar error with resnet models,"utils.federated_avg() gives ar error with resnet models## Description
When I call **utils.federated_avg()** on **resnet** models, I have the following error: __init__() missing 2 required positional arguments: 'block' and 'layers'. Any idea how to fix this?

## System Information
 - Pysyft Version: 0.2.9

## Code snippet
```
import torch
from torchvision import datasets, transforms, models

import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.frameworks.torch.fl import utils
hook = sy.TorchHook(torch)

alice = VirtualWorker(id=""alice"", hook=hook)
bob = VirtualWorker(id=""bob"", hook=hook)
carol = VirtualWorker(id=""carol"", hook=hook)
workers = [alice, bob, carol]

model_in = models.resnet50(pretrained=True)

local_models = {}
for worker in workers:
    local_models[worker]= model_in.copy()
    
# Average the models
model_out = utils.federated_avg(local_models)
```@Hjeljeli  Could you also provide a code snippet to reproduce the error. Thanks
@steph-en-m Sure. I added a code snippet to the description. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.> This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.

Updating so this issue is active.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",5,2020-08-26 00:53:41,2020-11-19 13:29:44,2020-11-19 13:29:43
https://github.com/OpenMined/PySyft/issues/4477,"['bug ', '0.2.x']",Duplicated method name in base.py,"Duplicated method name in base.py`syft/workers/base.py` contains two identically named `register_obj` methods:

https://github.com/OpenMined/PySyft/blob/99190dfa85d86b1d6542a7ee0454b2758c289605/syft/workers/base.py#L189

and 

https://github.com/OpenMined/PySyft/blob/99190dfa85d86b1d6542a7ee0454b2758c289605/syft/workers/base.py#L553


In best python tradition, only the latter one actually gets called, but we should fix that. 

@gkaissis ..I would like to give this a shot..how would you like me to approach this bug?Could you please see to the failing tests and perhaps @cereallarceny or @gmuraru have a look? This was a subject of discussion recently owing to the issues we had with websocket trainingThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",4,2020-08-25 14:56:27,2020-11-19 13:27:31,2020-11-19 13:27:31
https://github.com/OpenMined/PySyft/issues/4473,"['bug ', '0.2.x']",AssertionError: Searching for #fss_comp_plan_1 on worker1. /!\ 0 found,"AssertionError: Searching for #fss_comp_plan_1 on worker1. /!\ 0 foundDescription:
AssertionError: Searching for #fss_comp_plan_1 on worker1. /!\ 0 found



## Screenshots
![Untitled](https://user-images.githubusercontent.com/63416489/91140892-57e76000-e6e2-11ea-83f9-0293be1e5a9c.png)
Hello, could you provide a method to reproduce this bug? At a first glance it seems the computation command didn't find a worker, but I need a snippet to recreate the bug and help you further.Hi,thank you for your help.Actually, I don't know how i made this bug.Maybe I provide the code with you first and to see whether is there a bug on your side.


[Federated learning with MNIST.zip](https://github.com/OpenMined/PySyft/files/5122356/Federated.learning.with.MNIST.zip)
You need to build from repo with these steps:
-  `git clone https://github.com/OpenMined/PySyft.git`
-  `cd PySyft`
-  `pip install -r pip-dep/requirements.txt` (and possibly other files from pip-dep or other dependencies to ensure the compatibility of your venv with syft)
-  `pip install -e .`  

There will be another issue to update the version from pip to the latest release.
If there is any other problem let me know!
@superxii did what @teo-milea mentioned solved your problemIt solved thanks!!! But It appeared another error with the program

Is that something i missed to install?
![Untitled](https://user-images.githubusercontent.com/63416489/91243206-ff64a100-e77b-11ea-833e-c0484b6e099c.png)
Are you running on Windows?Yes, I was like running on Windows first before I run on AzureCould you try to run on Linux and check if the issue is still there?I may need some time to fix other errors regarding to tensor flow on Linux.

Meanwhile,in tutorial two, I followed the example code but comes out with 
![Untitled](https://user-images.githubusercontent.com/63416489/91823544-f25c1c00-ec6b-11ea-9250-85b13c85950e.png)

ImportError: cannot import name 'ReduceOp' from 'torch.distributed' (C:\Users\user\anaconda3\envs\pysyft\lib\site-packages\torch\distributed\__init__.py)

I have do some search and found that the distributed processing seems not to support windows yet,but I can ran the code in serveral weeks ago before I install with other package or libray.How can I fix this?Could you do a ```pip uninstall crypten```? CrypTen is supported only in Linux.Thanks, I will comeback later on for the first bug to see whether it appears on linux or not.@superxii any update?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",14,2020-08-25 06:50:45,2020-11-19 13:27:26,2020-11-19 13:27:26
https://github.com/OpenMined/PySyft/issues/4464,['bug '],Import syft after installing latest version (0.2.8),"Import syft after installing latest version (0.2.8)## Description
After upgrading my PySyft from 0.2.7 to 0.2.8 I am not able to import syft anymore. Now I get _ImportError: cannot import name 'ReduceOp' from 'torch.distributed'_.

## How to Reproduce
1. After installing PySyft 0.2.8
2. I import syft
3. As a consequence, I get _ImportError: cannot import name 'ReduceOp' from 'torch.distributed'_

## Expected Behavior
Import syft without errors.

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.8.3
Use Python 3.6-3.7 and see if the error persists!> Use Python 3.6-3.7 and see if the error persists!

Hi @addy369, with 3.7 it worked! :)
Thank you so much for the precious help!You can close the issue now",3,2020-08-23 13:24:07,2020-08-25 20:22:43,2020-08-25 20:22:43
https://github.com/OpenMined/PySyft/issues/4048,"['bug ', 'good first issue :mortar_board:']",Reciprocal test enchantment negative numbers,"Reciprocal test enchantment negative numbers## Description
Test the ```reciprocal``` method from precision using negative numbers

## Expected Behavior
All tests are passing

## Screenshots
If applicable, add screenshots to help explain your problem.

## Additional Context
It might require changes to the reciprocal methodI guess the Log and NR method are a problem. Division works fine.. Will look into the issueAdding you :)> I guess the Log and NR method are a problem. Division works fine.. Will look into the issue

Also, there might be worth checking out how [CrypTen](https://github.com/facebookresearch/CrypTen) is doing - if they take into consideration negative values.

If not, one idea (it might not be the greatest) is to use symmetry.hey could you review my PR?
https://github.com/OpenMined/PySyft/pull/4065",4,2020-08-20 06:13:18,2020-08-23 10:50:12,2020-08-23 10:50:12
https://github.com/OpenMined/PySyft/issues/4037,"['bug ', '0.2.x']",Installation of PySyft with Python3.6 on MacOS,"Installation of PySyft with Python3.6 on MacOS## Description
So when I am trying to build with source there is an issue while running the tests..
After cloning https://github.com/OpenMined/PySyft.git and running python setup.py install,I try running setup.py test. There is first a issue i.e . No module named 'crypten'. 
I install it manually but it says it supports python 3.7 and upwards only.(This is the problem probably)
So my question is whether people are able to use python3.6 for installation? I keep getting this error  ""cannot import name 'onnx_converter' "" while running setup.py test. Any workaround??
## Additional Context
Add any other context about the problem here.
Currently, there is supported only ```Python >= 3.7```Actually it isn't working with python 3.7 too
Can you please follow these steps
Create a virtual environment with Python 3.7
Install torch 1.4 and vison 0.5.0
Clone pysyft
Cd into directory
Run python setup.py
Run python setup.py test I keep getting this error ""cannot import name 'onnx_converter'  from crypten.nn and that makes sense because there is no onnx_converter defined thereI got the same error on Linux with Python 3.7.7.

**Problem:** Apparently, when you install **crypten** using ""python -m pip install crypten"" it doesn't create the same structure as here: https://github.com/facebookresearch/CrypTen/tree/master/crypten/nn

The only release is from Feb 5, before the commit (https://github.com/facebookresearch/CrypTen/commit/1aa8cedced113806e3b35f653bcd03f2cf364d6b#diff-901387c8cb64f231ab7b5bb4cad43497) which creates the file causing the error (onnx_converter.py): https://pypi.org/project/crypten/#history

**Solution:** I just hacked it by copying everything from here [1] to [2]. It works now, but we should modify the documentation, I guess.
[1]: https://github.com/facebookresearch/CrypTen/tree/master/crypten
[2]: ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/crypten/

Let me know if you have any idea on how to automatically fix this issue instead of hacking it like I did above.@gmuraru so the installation instructions are a bit outdated...I have also confirmed @radusqrt is right. Pip install crypten has a different structure than when cloning from the repo https://github.com/facebookresearch/CrypTen/tree/master/crypten. I can update the installation readme
@radusqrt thank you, your solution works!  
And I think, just as mentioned by @addy369 , this issue should be fixed as soon as possible.@addy369 Hi, I also meet the same error as you mentioned about the ""cannot import name 'onnx_converter' from crypten.nn. So have you solved it?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",9,2020-08-18 19:58:31,2020-11-19 13:27:08,2020-11-19 13:27:08
https://github.com/OpenMined/PySyft/issues/4036,"['bug ', 'good first issue :mortar_board:', '0.2.x']",Flaky exp test,"Flaky exp test## Description
The tolerance for the ```exp``` needs to be increased since it is failing randomly (because of the random order in which we run the tests).

## How to Reproduce
```
____________________ test_torch_sigmoid_approx[exp-3-0.065] ____________________

method = 'exp', prec_frac = 3, tolerance = 0.065
workers = {'alice': <VirtualWorker id:alice #objects:1>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:0>, ...}

    @pytest.mark.parametrize(
        ""method, prec_frac, tolerance"",
        [
            (""chebyshev"", 3, 6 / 100),
            (""chebyshev"", 4, 1 / 1000),
            (""exp"", 3, 6.5 / 100),
            (""exp"", 4, 1 / 100),
            (""maclaurin"", 3, 7 / 100),
            (""maclaurin"", 4, 15 / 100),
        ],
    )
    def test_torch_sigmoid_approx(method, prec_frac, tolerance, workers):
        """"""
        Test the approximate sigmoid with different tolerance depending on
        the precision_fractional considered
        """"""
        alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
        t = torch.tensor(range(-10, 10)) * 0.5
        t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
        r_sh = t_sh.sigmoid(method=method)
        r = r_sh.get().float_prec()
        t = t.sigmoid()
        diff = (r - t).abs().max()
        norm = (r + t).abs().max() / 2
    
>       assert (diff / (tolerance * norm)) < 1
E       assert (tensor(1.2798e+13) / (0.065 * tensor(6.3991e+12))) < 1
```

## Expected Behavior
The test should be passing

## Screenshots
If applicable, add screenshots to help explain your problem.
Hey @gmuraru would want to work on this!Assigned it to you! But I think this will require more research since it seems that the value is pretty high and probably we do something behind the scenes which brokes the ```exp```. A simple increase in the tolerance would not do the job.The issue is related to the method we use for ```sigmoid``` when computing ```reciprocal```.
Could you make a PR where you can simply add ```method=""division""``` to the reciprocal.So multiple things. Firstly, should'nt we get a value >1 and not <1 as the assert suggests! Also the reciprocal method is tested.Passing method=""division  is just a default parameter and anyway tests with all methods(divison,log,nr) are getting passed. Tell me if I am missing somethingI merged yesterday a PR for [this](https://github.com/OpenMined/PySyft/pull/4044).
Yep - you are correct. The tests are passing, but there is a scenario that we do not take care of. Opened a new issue for this - [here](https://github.com/OpenMined/PySyft/issues/4048)This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hey, I want to work on this issue, Can you assign me on this issue?Sure :D@gmuraru is this issue still valid?It can be closed - we would deal with it in SyMPC when the time would come",10,2020-08-18 13:04:10,2021-02-18 13:31:12,2021-02-18 13:31:12
https://github.com/OpenMined/PySyft/issues/4025,"['bug ', 'good first issue :mortar_board:', 'status: stale :bread:', '0.2.x']",Check dependency CrypTen tests,"Check dependency CrypTen tests## Description
Currently, CrypTen is available only on Linux and Mac, but if someone installs the PySyft repo and run the tests we also have some CrypTen related tests.
Those should be taken into consideration only if we have ```dependency_check.crypten```.

## How to Reproduce
Run the tests on Windows

## Expected Behavior
All the tests should pass - maybe skip the tests for CrypTen.
Hi, it's Sagnik from Slack, may I handle this issue?Sure! :DThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2020-08-17 06:45:10,2020-12-27 00:18:51,2020-12-27 00:18:51
https://github.com/OpenMined/PySyft/issues/4017,"['bug ', 'priority: 1 - immediate :fire:', 'severity: 1 - critical :fire:']",Most recent version of the codebase is broken,"Most recent version of the codebase is broken## Description
I merged the master branch of pysyft to my fork of pysyft and now everything is broken, what I discovered so far is the .send() and .share() functions 
## How to Reproduce
1. Clone pysyft to your machine or pull the last version of the repo
2. run jupyter notebook or python shell from inside pysyft folder (to use the cloned code, not the installed one)
3. run torch.tensor(0).send(bob) or .share or anything else
4. AttributeError: type object 'EmptyCryptoPrimitiveStoreError' has no attribute 'get_msgpack_code'

Hmm...did you try upgrading ```syft-proto```?@gmuraru that worked ðŸ˜…",2,2020-08-14 21:57:15,2020-08-15 11:35:53,2020-08-15 11:35:53
https://github.com/OpenMined/PySyft/issues/4013,"['bug ', '0.2.x']",Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. ,"Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. ## Description
Trying to run first tutorial: The Basic Tools of Private Deep Learning

## How to Reproduce
1. Following this guide https://github.com/OpenMined/PySyft/blob/master/INSTALLATION.md
2. Running script: 
```
# Run this cell to see if things work
import sys

import torch
from torch.nn import Parameter
import torch.nn as nn
import torch.nn.functional as F

import syft as sy
hook = sy.TorchHook(torch)

torch.tensor([1,2,3,4,5])
```
3. See error:
```
Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/taras/anaconda3/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'
WARNING:tensorflow:From /home/taras/anaconda3/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
```


## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: Ubuntu 20 LTS
 - Language Version:Python 3.7
 - Pip list:
```
Package                            Version            
---------------------------------- -------------------
absl-py                            0.9.0              
aioice                             0.6.18             
aiortc                             0.9.28             
alabaster                          0.7.12             
anaconda-client                    1.7.2              
anaconda-navigator                 1.9.12             
anaconda-project                   0.8.3              
argh                               0.26.2             
asn1crypto                         1.3.0              
astor                              0.8.1              
astroid                            2.3.3              
astropy                            4.0                
atomicwrites                       1.3.0              
attrs                              19.3.0             
autopep8                           1.4.4              
av                                 8.0.2              
Babel                              2.8.0              
backcall                           0.1.0              
backports.functools-lru-cache      1.6.1              
backports.shutil-get-terminal-size 1.0.0              
backports.tempfile                 1.0                
backports.weakref                  1.0.post1          
beautifulsoup4                     4.8.2              
bitarray                           1.2.1              
bkcharts                           0.2                
bleach                             3.1.0              
bokeh                              1.4.0              
boto                               2.49.0             
Bottleneck                         1.3.2              
certifi                            2019.11.28         
cffi                               1.14.0             
chardet                            3.0.4              
Click                              7.0                
cloudpickle                        1.3.0              
clyent                             1.2.2              
colorama                           0.4.3              
conda                              4.8.2              
conda-build                        3.18.11            
conda-package-handling             1.6.0              
conda-verify                       3.4.2              
contextlib2                        0.6.0.post1        
crc32c                             2.0.1              
cryptography                       2.8                
cycler                             0.10.0             
Cython                             0.29.15            
cytoolz                            0.10.1             
dask                               2.11.0             
decorator                          4.4.1              
defusedxml                         0.6.0              
diff-match-patch                   20181111           
dill                               0.3.2              
distributed                        2.11.0             
docutils                           0.16               
entrypoints                        0.3                
et-xmlfile                         1.0.1              
fastcache                          1.1.0              
filelock                           3.0.12             
flake8                             3.7.9              
Flask                              1.1.1              
Flask-SocketIO                     4.2.1              
fsspec                             0.6.2              
future                             0.18.2             
gast                               0.2.2              
gevent                             1.4.0              
glob2                              0.7                
gmpy2                              2.0.8              
google-pasta                       0.2.0              
greenlet                           0.4.15             
grpcio                             1.31.0             
h5py                               2.10.0             
HeapDict                           1.0.1              
html5lib                           1.0.1              
hypothesis                         5.5.4              
idna                               2.8                
imageio                            2.6.1              
imagesize                          1.2.0              
importlib-metadata                 1.5.0              
importlib-resources                1.5.0              
intervaltree                       3.0.2              
ipykernel                          5.1.4              
ipython                            7.12.0             
ipython-genutils                   0.2.0              
ipywidgets                         7.5.1              
isort                              4.3.21             
itsdangerous                       1.1.0              
jdcal                              1.4.1              
jedi                               0.14.1             
jeepney                            0.4.2              
Jinja2                             2.11.1             
joblib                             0.14.1             
json5                              0.9.1              
jsonschema                         3.2.0              
jupyter                            1.0.0              
jupyter-client                     5.3.4              
jupyter-console                    6.1.0              
jupyter-core                       4.6.1              
jupyterlab                         1.2.6              
jupyterlab-server                  1.0.6              
Keras-Applications                 1.0.8              
Keras-Preprocessing                1.1.2              
keyring                            21.1.0             
kiwisolver                         1.1.0              
lazy-object-proxy                  1.4.3              
libarchive-c                       2.8                
lief                               0.9.0              
llvmlite                           0.31.0             
locket                             0.2.0              
lxml                               4.5.0              
lz4                                3.0.2              
Markdown                           3.2.2              
MarkupSafe                         1.1.1              
matplotlib                         3.1.3              
mccabe                             0.6.1              
mistune                            0.8.4              
mkl-fft                            1.0.15             
mkl-random                         1.1.0              
mkl-service                        2.3.0              
mock                               4.0.1              
more-itertools                     8.2.0              
mpmath                             1.1.0              
msgpack                            1.0.0              
multipledispatch                   0.6.0              
navigator-updater                  0.2.1              
nbconvert                          5.6.1              
nbformat                           5.0.4              
netifaces                          0.10.9             
networkx                           2.4                
nltk                               3.4.5              
nose                               1.3.7              
notebook                           5.7.8              
numba                              0.48.0             
numexpr                            2.7.1              
numpy                              1.18.1             
numpydoc                           0.9.2              
olefile                            0.46               
openmined.threepio                 0.2.0              
openpyxl                           3.0.3              
opt-einsum                         3.3.0              
packaging                          20.1               
pandas                             1.0.1              
pandocfilters                      1.4.2              
parso                              0.5.2              
partd                              1.1.0              
path                               13.1.0             
pathlib2                           2.3.5              
pathtools                          0.1.2              
patsy                              0.5.1              
pep8                               1.7.1              
pexpect                            4.8.0              
phe                                1.4.0              
pickleshare                        0.7.5              
Pillow                             7.2.0              
pip                                20.0.2             
pkginfo                            1.5.0.1            
pluggy                             0.13.1             
ply                                3.11               
prometheus-client                  0.7.1              
prompt-toolkit                     3.0.3              
protobuf                           4.0.0rc2           
psutil                             5.7.0              
ptyprocess                         0.6.0              
py                                 1.8.1              
pycodestyle                        2.5.0              
pycosat                            0.6.3              
pycparser                          2.19               
pycrypto                           2.6.1              
pycurl                             7.43.0.5           
pydocstyle                         4.0.1              
pyee                               7.0.2              
pyflakes                           2.1.1              
Pygments                           2.5.2              
pylibsrtp                          0.6.6              
pylint                             2.4.4              
pyodbc                             4.0.0-unsupported  
pyOpenSSL                          19.1.0             
pyparsing                          2.4.6              
pyrsistent                         0.15.7             
PySocks                            1.7.1              
pytest                             5.3.5              
pytest-arraydiff                   0.3                
pytest-astropy                     0.8.0              
pytest-astropy-header              0.1.2              
pytest-doctestplus                 0.5.0              
pytest-openfiles                   0.4.0              
pytest-remotedata                  0.3.2              
python-dateutil                    2.8.1              
python-engineio                    3.13.1             
python-jsonrpc-server              0.3.4              
python-language-server             0.31.7             
python-socketio                    4.6.0              
pytz                               2019.3             
PyWavelets                         1.1.1              
pyxdg                              0.26               
PyYAML                             5.3                
pyzmq                              18.1.1             
QDarkStyle                         2.8                
QtAwesome                          0.6.1              
qtconsole                          4.6.0              
QtPy                               1.9.0              
requests                           2.22.0             
requests-toolbelt                  0.9.1              
RestrictedPython                   5.0                
rope                               0.16.0             
Rtree                              0.9.3              
ruamel-yaml                        0.15.87            
scikit-image                       0.16.2             
scikit-learn                       0.22.1             
scipy                              1.4.1              
seaborn                            0.10.0             
SecretStorage                      3.1.2              
Send2Trash                         1.5.0              
setuptools                         45.2.0.post20200210
shaloop                            0.2.1a11           
simplegeneric                      0.8.1              
singledispatch                     3.4.0.3            
six                                1.14.0             
snowballstemmer                    2.0.0              
sortedcollections                  1.1.2              
sortedcontainers                   2.1.0              
soupsieve                          1.9.5              
Sphinx                             2.4.0              
sphinxcontrib-applehelp            1.0.1              
sphinxcontrib-devhelp              1.0.1              
sphinxcontrib-htmlhelp             1.0.2              
sphinxcontrib-jsmath               1.0.1              
sphinxcontrib-qthelp               1.0.2              
sphinxcontrib-serializinghtml      1.1.3              
sphinxcontrib-websupport           1.2.0              
spyder                             4.0.1              
spyder-kernels                     1.8.1              
SQLAlchemy                         1.3.13             
statsmodels                        0.11.0             
syft                               0.2.8              
syft-proto                         0.5.1              
sympy                              1.5.1              
tables                             3.6.1              
tblib                              1.6.0              
tensorboard                        1.15.0             
tensorflow                         1.15.3             
tensorflow-estimator               1.15.1             
termcolor                          1.1.0              
terminado                          0.8.3              
testpath                           0.4.4              
tf-encrypted                       0.5.9              
toolz                              0.10.0             
torch                              1.4.0              
torchvision                        0.5.0              
tornado                            4.5.3              
tqdm                               4.42.1             
traitlets                          4.3.3              
ujson                              1.35               
unicodecsv                         0.14.1             
urllib3                            1.25.8             
watchdog                           0.10.2             
wcwidth                            0.1.8              
webencodings                       0.5.1              
websocket-client                   0.57.0             
websockets                         8.1                
Werkzeug                           1.0.0              
wheel                              0.34.2             
widgetsnbextension                 3.5.1              
wrapt                              1.11.2             
wurlitzer                          2.0.0              
xlrd                               1.2.0              
XlsxWriter                         1.2.7              
xlwt                               1.3.0              
xmltodict                          0.12.0             
yapf                               0.28.0             
zict                               1.0.0              
zipp                               2.2.0
```
quick fix: just reinstall chardet moduleThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",3,2020-08-14 11:54:10,2020-11-19 13:26:40,2020-11-19 13:26:40
https://github.com/OpenMined/PySyft/issues/3994,"['bug ', '0.2.x']",AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset',"AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'Hi everyone,
I am trying to connect 4 virtual machines (3 as clients and one as server) as federated learning with websocket.
I installed python3.7 and pysyft on a virtual environment as following:

conda create -n <env_name> python=3.7
conda activate <env_name>
sudo apt install gcc
pip install syft[udacity]

and I got this error from client side:

``` AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset' ```

in addition, I did exactly previous steps for python3.6 and I got the following:

``` AttributeError: module 'asyncio' has no attribute 'run' ```

I am new in this subject, could you please give me a hint?Hi, I have the same problem, have you solved it?Same here using PySyft 0.2.8


```
import pandas as pd
import numpy as np
import torch
import syft as sy

[...]

if __name__ == ""__main__"":
    
    # init PySyft
    hook = sy.TorchHook(torch)
        
    # load data
    data = pd.read_csv(""worker-train.csv"")

    # split data into sequences by using sliding window technique
    X, y = get_train_data_and_labels(data)
    
    # create syft dataset 
    dataset = sy.BaseDataset(data=X, targets=y)
    
    # setup server
    websocket_server = sy.WebsocketServerWorker(hook=hook, id=""worker-0"", host=""0.0.0.0"", port=""9999"")
    websocket_server.add_dataset(dataset, key=""some-key"")
```

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-80-c62cd3dd5cb7> in <module>
     18     # setup server
     19     websocket_server = WebsocketServerWorker(hook=hook, id=""worker-0"", host=""0.0.0.0"", port=""9999"")
---> 20     websocket_server.add_dataset(dataset)
     21 
     22 

AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'
```I tested PySyft versions 0.2.2 to 0.2.6 with the code above. Up to version 0.2.5 the `add_dataset()` method is working. In 0.2.6 it is broken.

Best regards!
d

ps: thanks for this great libraryThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",5,2020-08-12 13:49:00,2020-11-19 13:26:21,2020-11-19 13:26:21
https://github.com/OpenMined/PySyft/issues/3986,"['bug ', '0.2.x']",'sy.TorchHook(torch)' cause error,"'sy.TorchHook(torch)' cause errorI use Pysyft to train the network, which involves the following operations:

```python
import torch
import numpy as np
import syft as sy

hook = sy.TorchHook(torch)
data = torch.rand(3, 2).to(""cuda"")
index1 = np.array([2,1,0,0,1,1,0,2,2,1,0,0,1,1,0,2,2,1,0,0,1,1,0,2,2,1,0,0,1,1,0,2])
index1 = torch.from_numpy(index1).long().to(""cuda"")
index2 = np.array([2,1,0,0,1,1,0,2])
index2 = torch.from_numpy(index2).long().to(""cuda"")
print(data[index1])
print(data[index2])
```

When `print(data[index2])` is executed, it causes the error â€œtoo many indices for tensor of dimension 2â€. But when `hook = sy.TorchHook(torch)
` was commented out, the code runs successfully. Why is this happening? 

My environment:
pytorch: 1.4.0
syft: 0.25Hmmm..if you remove the ```to(""cuda"")``` it works?I removed the `to(""cuda"")`,  and it still doesn't work.Yep - there is an issue. If you try to directly use ```index2``` without converting it to a tensor it works.
Thank you for signaling it :DYes. If `index2` is a numpy array, it works. Will the issue be resolved?We will start looking into this.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue should be reopened, I had the exact same problem because of the hook:
![image](https://user-images.githubusercontent.com/26694607/106267656-a28d7b00-6232-11eb-8e28-64bdc4ae7063.png)
If I comment out the hook part (hook = sy.TorchHook(torch)) it works
Also worked when I moved into numpy to do the operations and back to torch. As of `Jan 2022`, this error still remains , 
![image](https://user-images.githubusercontent.com/52364337/151281193-3eda6fad-de71-451b-a965-382fd9b236ef.png)",9,2020-08-11 11:03:21,2022-01-27 02:31:15,2020-12-21 00:15:48
https://github.com/OpenMined/PySyft/issues/3982,"['bug ', 'good first issue :mortar_board:']",Return invalid dtype when MPC is applied to Other Dtype Tensor,"Return invalid dtype when MPC is applied to Other Dtype Tensor## Description

When MPC is applied to the int tensor, it must be int but float return.

## How to Reproduce

```python
x = torch.tensor([1, 2, 3])
print(x.dtype) # torch.int64

x = share(bob, alice, crypto_provider=theo)
print(x.dtype) # torch.float32 # should be torch.int64

print(x.get().dtype) # torch.int64
```

## Expected Behavior

should be `torch.int64`

## Screenshots

![image](https://user-images.githubusercontent.com/39186433/89849067-a9f89380-dbc2-11ea-84aa-6bf791a46b78.png)


## System Information
 - OS: MAC
 - OS Version: Catalina
 - Language Version: Python3.7
 - Package Manager Version: Conda 4.8.3
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context


Hi @gmuraru can I take this?Sure :D",2,2020-08-11 02:07:13,2020-08-22 05:34:34,2020-08-22 05:34:34
https://github.com/OpenMined/PySyft/issues/3980,"['bug ', 'status: stale :bread:']",AutogradTensor.backward() in sy.Plan does not propagate to the entire NN model,"AutogradTensor.backward() in sy.Plan does not propagate to the entire NN model## Description

I'm trying to use the example code from [Part 01 - Create Plan.ipynb](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/model-centric-fl/Part%2001%20-%20Create%20Plan.ipynb) to create a Plan for an LSTM model that I built using a modular approach. However, when executing the `loss.backward()` the gradient error does not propagate back to all layers (& model parameters) in the model besides the ones defined in the last subclass/module

## How to Reproduce
1. Here's my LSTM implementation https://gist.github.com/santteegt/55ec836b00493ded4479c1cefa9f5c8a
2. Execute using a dev PySyft environment
3. You'll get an error `TypeError: mul(): argument 'other' (position 1) must be Tensor, not NoneType` in the `naive_sgd` function due to a `param.grad` is None

## Expected Behavior
All model parameters should have a grad != None
I have the same problem but with a convolutional network, mainly with a Conv2d layer. I think that the problem is related to issue #3509 and this one  #3550. I want to contribute for solve the problem and make .grad of this layer different from None. I tried to use the Conv2d from syft/frameworks/torch/nn/conv, but I'm still without success. The same occurs when a modified the autograd.py to support conv2d on backward pass. Based on the related issues I think, if available, that @iamtrask @karlhigley  and @vvmnnnkv can give us a start guide or tips to make these layers work in this example. I really want to contribute guys :+1: .This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.the same question",3,2020-08-10 23:08:49,2021-02-13 16:40:52,2020-11-29 00:11:25
https://github.com/OpenMined/PySyft/issues/3975,['bug '],EmptyCryptoPrimitiveStoreError has no attribute 'get_msgpack_code' in BaseDataset.send,"EmptyCryptoPrimitiveStoreError has no attribute 'get_msgpack_code' in BaseDataset.send## Description
I'm getting the following exception when trying to send some data to a worker using the BaseDataset wrapper

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-455832041bc0> in <module>
     11 
     12 # Sending toy datasets to virtual workers
---> 13 bob_train_dataset = sy.BaseDataset(train_inputs[:train_idx], train_labels[:train_idx]).send(bob)
     14 anne_train_dataset = sy.BaseDataset(train_inputs[train_idx:], train_labels[train_idx:]).send(anne)
     15 bob_test_dataset = sy.BaseDataset(test_inputs[:test_idx], test_labels[:test_idx]).send(bob)

~/openmined/PySyft/syft/frameworks/torch/fl/dataset.py in send(self, location)
     74 
     75     def send(self, location: BaseWorker):
---> 76         ptr = self.owner.send(self, workers=location)
     77         return ptr
     78 

~/openmined/PySyft/syft/workers/base.py in send(self, obj, workers, ptr_id, garbage_collect_data, requires_grad, create_pointer, **kwargs)
    431 
    432         # Send the object
--> 433         self.send_obj(obj, worker)
    434 
    435         if requires_grad:

~/openmined/PySyft/syft/workers/base.py in send_obj(self, obj, location)
    589                 receive the object.
    590         """"""
--> 591         return self.send_msg(ObjectMessage(obj), location)
    592 
    593     def request_obj(

~/openmined/PySyft/syft/workers/base.py in send_msg(self, message, location)
    313 
    314         # Step 1: serialize the message to a binary
--> 315         bin_message = sy.serde.serialize(message, worker=self)
    316 
    317         # Step 2: send the message and wait for a response

~/openmined/PySyft/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
     45         strategy = msgpack_serialize
     46 
---> 47     return strategy(obj, worker, simplified, force_full_simplification)
     48 
     49 

~/openmined/PySyft/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
    339         worker = syft.framework.hook.local_worker
    340 
--> 341     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
    342     return _serialize_msgpack_binary(simple_objects)
    343 

~/openmined/PySyft/syft/serde/msgpack/serde.py in _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
    279             simple_objects = _force_full_simplify(worker, obj)
    280         else:
--> 281             simple_objects = _simplify(worker, obj)
    282     else:
    283         simple_objects = obj

~/openmined/PySyft/syft/serde/msgpack/serde.py in _simplify(worker, obj, **kwargs)
    422     current_type, obj = _simplify_field(obj)
    423 
--> 424     if current_type in msgpack_global_state.simplifiers:
    425         result = (
    426             msgpack_global_state.simplifiers[current_type][0],

~/openmined/PySyft/syft/serde/msgpack/serde.py in wrapper(self)
     68         @property
     69         def wrapper(self):
---> 70             self = self.update()
     71             return wrapped_func.__get__(self, type(self))
     72 

~/openmined/PySyft/syft/serde/msgpack/serde.py in update(self)
    187         ):
    188             simplifier, detailer = syft_type.simplify, syft_type.detail
--> 189             _add_simplifier_and_detailer(syft_type, simplifier, detailer)
    190         #
    191         # # Register syft objects with custom force_simplify and force_detail methods

~/openmined/PySyft/syft/serde/msgpack/serde.py in _add_simplifier_and_detailer(curr_type, simplifier, detailer, forced)
    170 
    171         def _add_simplifier_and_detailer(curr_type, simplifier, detailer, forced=False):
--> 172             type_info = proto_type_info(curr_type)
    173             if forced:
    174                 self._forced_full_simplifiers[curr_type] = (type_info.forced_code, simplifier)

~/openmined/PySyft/syft/serde/msgpack/proto.py in proto_type_info(cls)
     71     if type_name in proto_info[""TYPES""]:
     72         return TypeInfo(name=type_name, obj=proto_info[""TYPES""][type_name])
---> 73     elif cls.get_msgpack_code.__qualname__.startswith(cls.__name__):
     74         return TypeInfo(name=type_name, obj=cls.get_msgpack_code())
     75     else:

AttributeError: type object 'EmptyCryptoPrimitiveStoreError' has no attribute 'get_msgpack_code'
```

## How to Reproduce
1. Use the latest changes in the PySyft master branch
2. Open the [examples/tutorials/advanced/federated_sms_spam_prediction/Federated SMS Spam prediction.ipynb](Federated SMS Spam prediction.ipynb) tutorial
3. Execute until the 8th cell 
4. See the error begin thrown

## Expected Behavior
BaseDataset object is sent to the corresponding worker
Please follow the command below. :smile: 

`pip install --upgrade syft-proto`",1,2020-08-10 03:00:24,2020-08-10 06:50:18,2020-08-10 06:50:18
https://github.com/OpenMined/PySyft/issues/3950,"['bug ', 'good first issue :mortar_board:', 'status: stale :bread:', '0.2.x']",Fixed precision tensor: linear operations with torch tensor are broken,"Fixed precision tensor: linear operations with torch tensor are brokenfixed precision tensor is supposed to work correctly given an int or float to be subtracted from or added to, just like a torch tensor.
for example:
torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
this should be the correct behavior of FPT:
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
but instead we get:
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)

multiplication also is broken. 
any fix should be tested against all arithmetic operations (add, sub, mul, div, ..etc)I'd like to take this on :) 

---

Formatting the exit condition and setup for easier checking

```
torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
```

this should be the correct behavior of FPT:

```
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
```

but instead we get:

```
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)
```@IanQS how it goes with this issue. Did you start work on it?Heya @gmuraru ! 

I've started working on it but I'm running into roadblocks. I've solved the 

`torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)` but admittedly my solution isn't pretty and I've not run tests to make sure that my changes don't break anything. 

I'm not too sure about how to solve the first issue (`PureFrameworkTensorFoundError`) I'd love some guidance if you've got any insight into it@gmuraru 

I've linked my PR to this. Let me know if you think I'm going down the wrong path. I'd love to get feedback as I go along. I'm still trying to figure out how to address the `PureFrameworkTensorFoundError`@IanQS you'd wanna look at the operations of the native tensor, since torch.Tensor+FPT calls the __add__ method of the native tensor (torch.Tensor)Got it! I'll look into `syft.frameworks.torch.tensor.interpreters.Tensor` specifically the `add`! I'll get to it this weekend and will try my best to have something up by Monday. @IanQS let's review and merge the first fix and make the second one in a separate PRHey @abogaziah  @gmuraru 

I think it might be better for me to unassign myself. I'm really not sure how to fix the issue or where to put the fixes so it might be better for someone else to try and take it on. I'll close out the PR but leave a reference to itHi @abogaziah I would like to attempt this if still available@duggalsu sure, go-ahead  I would like to fix this if still availableHi @xutongye , I've started to work on this now. Will need a few days. I'll let you know if I cannot finish it.@LaRiffle I know we discussed yesterday about this behavior.

We throw an exception if:
- float_tensor (+|-|*|/) fix_prec_tensor
- fix_prec_tensor (+|-|*|/) float_tensor

This was the conclusion, right?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",14,2020-08-05 20:13:02,2020-12-08 00:12:01,2020-12-08 00:12:01
https://github.com/OpenMined/PySyft/issues/3937,"['bug ', 'priority: 2 - high :cold_sweat:', 'status: stale :bread:']",SMPC for more than 2 parties,"SMPC for more than 2 parties## Description
Currently, we support only SMPC for <= 2 parties. We would like to support ```n``` parties.
See [this](https://github.com/OpenMined/PySyft/pull/3909) for more details.


## Acceptance Criteria
* Add tests where we have multiple workersThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-08-04 08:37:41,2020-11-29 00:11:33,2020-11-29 00:11:33
https://github.com/OpenMined/PySyft/issues/3912,"['bug ', 'status: stale :bread:']",Memory leak problem and worker is not training problem.,"Memory leak problem and worker is not training problem.## Description
### Memory leak problem 
I deployed 10 workers on a server for federated learning, controlled by train_config.  After one training is completed and the average of ten models is collected, the model is assigned to TrainConfig.model and the entire TrainConfig is sent. There is a serious memory leak on the worker side. I inserted objgraph.show_growth into the fit functionin the worker, as shown in Figure 1. It is found that the memory growth is shown in Figure 2.
![å¾®ä¿¡å›¾ç‰‡_20200731105702](https://user-images.githubusercontent.com/18498934/88995295-d8ea4c00-d31c-11ea-8c8c-e7b7adfd98f1.png)





![å¾®ä¿¡å›¾ç‰‡_20200731105654](https://user-images.githubusercontent.com/18498934/88995299-dd166980-d31c-11ea-9f21-784e2499cdbb.png)


Worker is not training problem
Since the sending of train_config will cause memory leaks, I tried to solve the problem by passing only the model, but after sending the model through self.model_ptr, self._model_id = self._wrap_and_send_obj(self.model, location), the training cannot be obtained After the model.


## System Information
 - OS: [ubuntu18.04]
 - OS Version: [ubuntu18.04]
 - Language Version: [Python 3.6]
 - Package Manager Version: [pip]
-sypysyft 0.2.3
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-07-31 03:13:13,2020-12-21 00:15:50,2020-12-21 00:15:50
https://github.com/OpenMined/PySyft/issues/3908,['bug '],#Plan :  That is wrong to use 'model(data)' in plan,"#Plan :  That is wrong to use 'model(data)' in plan## Description
That is wrong to use 'model(data)' in plan.

## How to Reproduce
my demo like this:

import torch
import torch.nn as nn
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision import datasets
from tqdm import tqdm
import time
import syft as sy  # import the Pysyft library
hook = sy.TorchHook(torch)  # hook PyTorch ie add extra functionalities 
hook.local_worker.is_client_worker = False
server = hook.local_worker
x11 = torch.tensor([-1, 2.]).tag('input_data')

@sy.func2plan()
def plan_model(x, model):
    x = model(x)
    return x

model = nn.Linear(2, 1)
build_model = plan_model.build(x11, model)


## Expected Behavior
It should be a (1,2) tensor

## Screenshots
But it gets wrong:
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-98-222ad6d0c80f> in <module>
----> 1 bd_model = plan_model.build(x11,model)

c:\users\fyrong\appdata\local\programs\python\python37\lib\site-packages\syft\execution\plan.py in build(self, trace_autograd, *args)
    267                 framework_kwargs[f_name] = wrap_framework_func(self.role)
    268 
--> 269         results = self.forward(*args, **framework_kwargs)
    270 
    271         # Register inputs in role

<ipython-input-96-42593bc52555> in plan_model(x, model)
      1 @sy.func2plan()
      2 def plan_model(x, model):
----> 3     x = model(x)
      4     return x
      5 

TypeError: 'PlaceHolder' object is not callable



## Additional Context
Does it can't be use model(data)?
if so, how I use this plan to train a model? 
Thanks a lot for your work!!!Hey @fanyaorong. What was the issue here? :D",1,2020-07-30 02:31:20,2020-08-14 10:14:07,2020-08-14 05:59:22
https://github.com/OpenMined/PySyft/issues/3905,"['bug ', 'priority: 3 - medium :unamused:']",Cannot find dataset pointers,"Cannot find dataset pointers## Description
A clear and concise description of the bug.  I tried the tutorial for the federated learning for Mnist, the link is: https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/grid/federated_learning/mnist
but I cannot find the dataset pointer

## How to Reproduce
1. Go to '...'
2. Click on '...'
3. Scroll down to '...'
4. See error

## Expected Behavior
A clear and concise description of what you expected to happen.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: [e.g. iOS] windows 10
 - OS Version: [e.g. 22]
 - Language Version: [e.g. Python 3.7, Node 10.18.1] python 3.7
 - Package Manager Version: [e.g. Conda 4.6.1, NPM 6.14.1]
 - Browser (if applicable): [e.g. Google Chrome]
 - Browser Version (if applicable): [e.g. 81.0.4044.138]

## Additional Context
Add any other context about the problem here.
Here is my code.
import syft as sy
from syft.grid.clients.dynamic_fl_client import DynamicFLClient
import torch
import pickle
import time
import torchvision
from torchvision import datasets, transforms
import tqdm
from syft.grid.public_grid import PublicGridNetwork
from syft.grid.private_grid import PrivateGridNetwork
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def epoch_total_size(data):
    total = 0
    for i in range(len(data)):
        for j in range(len(data[i])):
            total += data[i][j].shape[0]

    return total


def train(epoch, data):
    model.train()
    epoch_total = epoch_total_size(data)
    current_epoch_size = 0
    for i in range(len(data)):
        for j in range(len(data[i])):
            current_epoch_size += len(data[i][j])
            worker = data[i][j].location
            model.send(worker)
            optimizer.zero_grad()
            pred = model(data[i][j])
            loss = criterion(pred, target[i][j])
            loss.backward()
            optimizer.step()
            model.get()
            loss = loss.get()
            print('Train Epoch: {} | With {} data |: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                      epoch, worker.id, current_epoch_size, epoch_total,
                            100. *  current_epoch_size / epoch_total, loss.item()))


hook = sy.TorchHook(torch)

nodes = [""ws://localhost:3001/"", ""ws://localhost:3000/""]

compute_nodes = []
for node in nodes:
    compute_nodes.append(DynamicFLClient(hook, node))

N_SAMPLES = 10000
MNIST_PATH = './dataset'

transform = transforms.Compose([
                              transforms.ToTensor(),
                              transforms.Normalize((0.1307,), (0.3081,)),
                              ])

trainset = datasets.MNIST(MNIST_PATH, download=True, train=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=N_SAMPLES, shuffle=False)

dataiter = iter(trainloader)

images_train_mnist, labels_train_mnist = dataiter.next()

datasets_mnist = torch.split(images_train_mnist, int(len(images_train_mnist) / len(compute_nodes)), dim=0 ) #tuple of chunks (dataset / number of nodes)
labels_mnist = torch.split(labels_train_mnist, int(len(labels_train_mnist) / len(compute_nodes)), dim=0 )  #tuple of chunks (labels / number of nodes)

tag_img = []
tag_label = []


for i in range(len(compute_nodes)):
    tag_img.append(datasets_mnist[i].tag(""#X"", ""#mnist"", ""#dataset"").describe(""The input datapoints to the MNIST dataset.""))
    tag_label.append(labels_mnist[i].tag(""#Y"", ""#mnist"", ""#dataset"").describe(""The input labels to the MNIST dataset.""))


shared_x1 = tag_img[0].send(compute_nodes[0], garbage_collect_data=False) # First chunk of dataset to Bob
shared_x2 = tag_img[1].send(compute_nodes[1], garbage_collect_data=False) # Second chunk of dataset to Alice

shared_y1 = tag_label[0].send(compute_nodes[0], garbage_collect_data=False) # First chunk of labels to Bob
shared_y2 = tag_label[1].send(compute_nodes[1], garbage_collect_data=False) # Second chunk of labels to Alice

# print(""X tensor pointers: "", shared_x1, shared_x2)
# print(""Y tensor pointers: "", shared_y1, shared_y2)

device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")

if (torch.cuda.is_available()):
    torch.set_default_tensor_type(torch.cuda.FloatTensor)

model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

GRID_ADDRESS = 'localhost'
GRID_PORT = '5000'

my_grid = PublicGridNetwork(hook, ""http://"" + GRID_ADDRESS + "":"" + GRID_PORT)

data = my_grid.search(""#X"", ""#mnist"", ""#dataset"")
target = my_grid.search(""#Y"", ""#mnist"", ""#dataset"")

data = data.values()
print(data)

N_EPOCS = 3
SAVE_MODEL = True
SAVE_MODEL_PATH = './models'


for epoch in range(N_EPOCS):
    train(epoch, data)
@IonesioJunior  @junrong1  I have the same problem of not finding the pointer via the grid search. 
Is there a workaround or a solution meanwhile?

Thx in advance!Okay, I've found an docker image with a working pygrid! (development tag)> @IonesioJunior @junrong1 I have the same problem of not finding the pointer via the grid search.
> Is there a workaround or a solution meanwhile?
> 
> Thx in advance!

Ohhhhhh, sorry for late respond, I haven't found the solution, could u tell me ur solution to fix this?@junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.

So, consider the following:

```
docker pull openmined/grid-network:development
docker pull openmined/grid-node:development
```

and then run the mnist federated learning example again.> @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> 
> So, consider the following:
> 
> ```
> docker pull openmined/grid-network:development
> docker pull openmined/grid-node:development
> ```
> 
> and then run the mnist federated learning example again.

I tried to use
`docker pull openmined/pysyft-notebook`
but I cannaot find the link they give me.> > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > So, consider the following:
> > ```
> > docker pull openmined/grid-network:development
> > docker pull openmined/grid-node:development
> > ```
> > 
> > 
> > and then run the mnist federated learning example again.
> 
> I tried to use
> `docker pull openmined/pysyft-notebook`
> but I cannaot find the link they give me.

Is there any tutorials for using network and node on docker?> > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > So, consider the following:
> > > ```
> > > docker pull openmined/grid-network:development
> > > docker pull openmined/grid-node:development
> > > ```
> > > 
> > > 
> > > and then run the mnist federated learning example again.
> > 
> > 
> > I tried to use
> > `docker pull openmined/pysyft-notebook`
> > but I cannaot find the link they give me.
> 
> Is there any tutorials for using network and node on docker?

Hi @junrong1 and @thiessl . The docker images were updated recently (a couple of day ago), actually the images are automatically udpated when a commit to develop or master is pushed.

@junrong1 , is https://hub.docker.com/r/openmined/grid-node the image you are looking for?

Please confirm this is solved in order to close the issue.
For trazability reasons, we reccomend to open this issues directly on PyGrid repo> > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > So, consider the following:
> > > ```
> > > docker pull openmined/grid-network:development
> > > docker pull openmined/grid-node:development
> > > ```
> > > 
> > > 
> > > and then run the mnist federated learning example again.
> > 
> > 
> > I tried to use
> > `docker pull openmined/pysyft-notebook`
> > but I cannaot find the link they give me.
> 
> Is there any tutorials for using network and node on docker?

Create a docker-compose.yml file with the following content:

```
version: '3'
services:
  network:
    image: openmined/grid-network:development
    environment:
      - PORT=5000
      - SECRET_KEY=ineedtoputasecrethere
      - DATABASE_URL=sqlite:///databasenetwork.db
    ports:
      - 5000:5000
  bob:
    image: openmined/grid-node:development
    environment:
      - NODE_ID=Bob
      - ADDRESS=http://bob:3000/
      - PORT=3000
      - NETWORK=http://network:5000
      - DATABASE_URL=sqlite:///databasenode.db

    depends_on:
      - 'network'
    ports:
      - 3000:3000
  alice:
    image: openmined/grid-node:development
    environment:
      - NODE_ID=Alice
      - ADDRESS=http://alice:3001/
      - PORT=3001
      - NETWORK=http://network:5000
      - DATABASE_URL=sqlite:///databasenode.db
    depends_on:
      - 'network'
    ports:
      - 3001:3001
```

and execute

`docker-compose up`

this ensures that alice and bob (grid-nodes) and the grid-network run based on the respective docker image (development tag, as this works with the current commit).

After that you can execute your notebook and connect to your grid-nodes properly.> > > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > > So, consider the following:
> > > > ```
> > > > docker pull openmined/grid-network:development
> > > > docker pull openmined/grid-node:development
> > > > ```
> > > > 
> > > > 
> > > > and then run the mnist federated learning example again.
> > > 
> > > 
> > > I tried to use
> > > `docker pull openmined/pysyft-notebook`
> > > but I cannaot find the link they give me.
> > 
> > 
> > Is there any tutorials for using network and node on docker?
> 
> Create a docker-compose.yml file with the following content:
> 
> ```
> version: '3'
> services:
>   network:
>     image: openmined/grid-network:development
>     environment:
>       - PORT=5000
>       - SECRET_KEY=ineedtoputasecrethere
>       - DATABASE_URL=sqlite:///databasenetwork.db
>     ports:
>       - 5000:5000
>   bob:
>     image: openmined/grid-node:development
>     environment:
>       - NODE_ID=Bob
>       - ADDRESS=http://bob:3000/
>       - PORT=3000
>       - NETWORK=http://network:5000
>       - DATABASE_URL=sqlite:///databasenode.db
> 
>     depends_on:
>       - 'network'
>     ports:
>       - 3000:3000
>   alice:
>     image: openmined/grid-node:development
>     environment:
>       - NODE_ID=Alice
>       - ADDRESS=http://alice:3001/
>       - PORT=3001
>       - NETWORK=http://network:5000
>       - DATABASE_URL=sqlite:///databasenode.db
>     depends_on:
>       - 'network'
>     ports:
>       - 3001:3001
> ```
> 
> and execute
> 
> `docker-compose up`
> 
> this ensures that alice and bob (grid-nodes) and the grid-network run based on the respective docker image (development tag, as this works with the current commit).
> 
> After that you can execute your notebook and connect to your grid-nodes properly.

I have an error with worker failed to boot. Do you know how can I fix this?No. I run this yesterday from the docker compose from the repo without erros> > > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > > So, consider the following:
> > > > ```
> > > > docker pull openmined/grid-network:development
> > > > docker pull openmined/grid-node:development
> > > > ```
> > > > 
> > > > 
> > > > and then run the mnist federated learning example again.
> > > 
> > > 
> > > I tried to use
> > > `docker pull openmined/pysyft-notebook`
> > > but I cannaot find the link they give me.
> > 
> > 
> > Is there any tutorials for using network and node on docker?
> 
> Hi @junrong1 and @thiessl . The docker images were updated recently (a couple of day ago), actually the images are automatically udpated when a commit to develop or master is pushed.
> 
> @junrong1 , is https://hub.docker.com/r/openmined/grid-node the image you are looking for?
> 
> Please confirm this is solved in order to close the issue.
> For trazability reasons, we reccomend to open this issues directly on PyGr

> No. I run this yesterday from the docker compose from the repo without erros",11,2020-07-28 09:33:57,2020-08-13 09:39:11,2020-08-13 09:39:11
https://github.com/OpenMined/PySyft/issues/3902,"['bug ', 'status: stale :bread:']",RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_,"RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_RuntimeError when adding Batchnorm in the tutorial

differ from 
#[2498](https://github.com/OpenMined/PySyft/issues/2498) 
#[2132](https://github.com/OpenMined/PySyft/issues/2132)
I got a new problem:
Traceback (most recent call last):
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/mytest.py"", line 117, in <module>
    train(args, model, device, federated_train_loader, optimizer, epoch)
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/mytest.py"", line 84, in train
    model.get() # <-- NEW: get the model back
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/syft/frameworks/torch/hook/hook.py"", line 671, in module_get_
    p.get_()
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/syft/frameworks/torch/tensors/interpreters/native.py"", line 687, in get_
    return self.get(*args, inplace=True, **kwargs)
  File ""/home/ubuntu/liangenmin/Project/PySyft-master/syft/frameworks/torch/tensors/interpreters/native.py"", line 674, in get
    self.set_(tensor)
RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_

Process finished with exit code 1

Something wrong when model.get(), if I delete ""to(device)"", it works when I use cpu for data and model. It seems that type doesn't change in BN.
Here is my code:

```
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms

import syft as sy  # <-- NEW: import the Pysyft library
epochs = 10

hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob
alice = sy.VirtualWorker(hook, id=""alice"")

class Arguments():
    def __init__(self):
        self.batch_size = 64
        self.test_batch_size = 1000
        self.epochs = epochs
        self.lr = 0.01
        self.momentum = 0.5
        self.no_cuda = False
        self.seed = 1
        self.log_interval = 30
        self.save_model = False

args = Arguments()

use_cuda = not args.no_cuda and torch.cuda.is_available()

torch.manual_seed(args.seed)

device = torch.device(""cuda"" if use_cuda else ""cpu"")

kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)
        self.bn1 = nn.BatchNorm2d(20)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.bn1(x)
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def train(args, model, device, federated_train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
        model.send(data.location) # <-- NEW: send the model to the right location
        data, target = data.to(device), target.to(device)
        # data, target = data.cuda(), target.cuda()
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        model.get() # <-- NEW: get the model back
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # <-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
                100. * batch_idx / len(federated_train_loader), loss.item()))


def test(args, model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss
            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))

model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment

for epoch in range(1, args.epochs + 1):
    train(args, model, device, federated_train_loader, optimizer, epoch)
    test(args, model, device, test_loader)

if (args.save_model):
    torch.save(model.state_dict(), ""mnist_cnn.pt"")
```


python 3.7.7
torch 1.4.0

This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hi, have you find a solution?> Hi, have you find a solution?

Not yet, I have given up PySyftThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.I got the same issue, is there any solution to this?",5,2020-07-27 15:08:33,2021-11-19 14:33:30,2020-12-21 00:15:52
https://github.com/OpenMined/PySyft/issues/3897,"['bug ', 'status: stale :bread:']",split_neural_network tutorial fails at move() method when work with Websocket Workers,"split_neural_network tutorial fails at move() method when work with Websocket Workers## Description
After I changed VirtualWorkers to pairs of WebSocketServerWorker and WebSocketClientWorker. The move method stop working. 
The notebook prints ""RuntimeError: Websocket connection closed and creation of new connection failed.""
The WebSocketServerWorker prints ""Worker alice1 couldn't recognize worker alice2"" and raise an error saying ""AttributeError: 'str' object has no attribute '_recv_msg'""

## How to Reproduce
1. Go to [Tutorial 1 - SplitNN Introduction.ipynb](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb)
2. Modify the VirtualWorkers to WebSocket Workers and those related variables (Bob, Alice => Alice1, Alice2 in screenshot)
3. Make sure the WebSocketServerWorkers are running.
4. Click ""Kernel"" => ""Restart & Run All""
5. See error

## Expected Behavior
Move() method can move objects from one WebSocketServerWorker to another.

## Screenshots
![Screen Shot 2020-07-25 at 5 31 30 PM](https://user-images.githubusercontent.com/34226180/88466687-e62ab500-ce9c-11ea-883c-37b4b9567c2e.png)
![Screen Shot 2020-07-25 at 5 32 14 PM](https://user-images.githubusercontent.com/34226180/88466688-ea56d280-ce9c-11ea-8718-d37d06564167.png)
![Screen Shot 2020-07-25 at 5 31 59 PM](https://user-images.githubusercontent.com/34226180/88466689-ecb92c80-ce9c-11ea-9ed9-72c57c6f3d9a.png)
![Screen Shot 2020-07-25 at 5 12 12 PM](https://user-images.githubusercontent.com/34226180/88466411-fd1bd800-ce99-11ea-8091-17af4ef577d3.png)

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.6.9; Syft 0.2.6
 - Package Manager Version: pip 20.1.1
 - Browser (if applicable): Safari
 - Browser Version (if applicable): Version 13.1.1 (15609.2.9.1.2)


Thank you for your help!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This bug is still present unfortunately.Is there any other way to bypass the problem by using some alternative method than **move()**This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hi,
    Just in case for anyone in the same situation, this is fixed with PyGrid workers.(not supporting PySyft-0.3.0 for now)
    You can check [this slack posting](https://openmined.slack.com/archives/C6EEFN3A8/p1596720041221900?thread_ts=1596661549.217900&cid=C6EEFN3A8) for an example to setup PyGrid workers and then move() should work.

Thanks,",5,2020-07-25 21:36:41,2020-12-14 16:29:52,2020-12-14 16:29:52
https://github.com/OpenMined/PySyft/issues/3887,"['bug ', '0.2.x']",Cannot move traced model to cuda,"Cannot move traced model to cuda## Description
After initializing TorchHook and tracing model you can't move this model to another device (cuda or cpu). This happens because  method `parameters()` of a traced model returns list of torch.Tensor instead of list of nn.Parameter, so we can't move tensors to another device because they don't have setter for .data property
https://github.com/OpenMined/PySyft/blob/5c8e7b78eba693ea29e07eac7476aa7517e5dfef/syft/frameworks/torch/tensors/interpreters/native.py#L141


```
import torch
import syft as sy
hook = sy.TorchHook(torch)
model = torch.nn.Linear(1,1)
model = torch.jit.trace(model,torch.rand(1,1))
model.cpu()
```
This code produces error `AttributeError: can't set attribute`
The traceback:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-54d42a2d39a0> in <module>
----> 1 model.cpu()

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in cpu(self)
    310             Module: self
    311         """"""
--> 312         return self._apply(lambda t: t.cpu())
    313 
    314     def type(self, dst_type):

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in _apply(self, fn)
    224                 should_use_set_data = compute_should_use_set_data(param, param_applied)
    225                 if should_use_set_data:
--> 226                     param.data = param_applied
    227                 else:
    228                     assert isinstance(param, Parameter)

AttributeError: can't set attribute
```

## System Information
 - PySyft 0.2.7
 - Torch 1.4.0
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.@NProkoptsev is there any workaround for this problem? Save model to disk, then
torch.jit.load(f, map_location='cuda') @NProkoptsev thanks, I do so. But it seems saving and loading would break the object pointer so once you use the `get` command to retrieve your model from one of the workers it retrieves the old one (the same model before saving and not the updated one).
```Python
torch.jit.save(model,'model.pt')
model = torch.jit.load('model.pt',map_location='cpu')
```Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",5,2020-07-21 22:38:35,2020-11-19 13:26:11,2020-11-19 13:26:09
https://github.com/OpenMined/PySyft/issues/3886,"['bug ', '0.2.x']",Importing torchvision library is causing problems when using pysyft,"Importing torchvision library is causing problems when using pysyft## Description
I use torchvision to load some datasets while using Pysyft framework, the problem is if I import the libraries after using ""hook = sy.TorchHook(torch)"" I get weird error. The issue disappears when doing import before using hook.

## How to Reproduce
1. Install latest Pysyft
2. write a simple script
3. import syft as sy
4. using torch hook
5. import torchvision

## Expected Behavior
To be able to load the library properly regardless of the order of being imported. I have requirement where I need to load datasets at a later time in a different module.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: Ubuntu
 - OS Version: 16.04
 - Language Version: [e.g. Python 3.7, Node 10.18.1]

## Additional Context
Error trace is as follows:

```
Traceback (most recent call last):
  File ""start_federated_server.py"", line 19, in <module>
    import torchvision.transforms as transforms
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/__init__.py"", line 3, in <module>
    from torchvision import models
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/models/__init__.py"", line 12, in <module>
    from . import detection
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/models/detection/__init__.py"", line 1, in <module>
    from .faster_rcnn import *
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/models/detection/faster_rcnn.py"", line 14, in <module>
    from .roi_heads import RoIHeads
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py"", line 211, in <module>
    @torch.jit.script
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py"", line 1281, in script
    fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj))
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/_recursive.py"", line 555, in try_compile_fn
    return torch.jit.script(fn, _rcb=rcb)
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py"", line 1281, in script
    fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj))
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/_recursive.py"", line 555, in try_compile_fn
    return torch.jit.script(fn, _rcb=rcb)
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py"", line 1278, in script
    ast = get_jit_def(obj)
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/frontend.py"", line 171, in get_jit_def
    return build_def(ctx, py_ast.body[0], type_line, self_name)
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/frontend.py"", line 212, in build_def
    build_stmts(ctx, body))
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/frontend.py"", line 127, in build_stmts
    stmts = [build_stmt(ctx, s) for s in stmts]
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/frontend.py"", line 127, in <listcomp>
    stmts = [build_stmt(ctx, s) for s in stmts]
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/frontend.py"", line 186, in __call__
    raise UnsupportedNodeError(ctx, node)
torch.jit.frontend.UnsupportedNodeError: import statements aren't supported:
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py"", line 2471
    .. include:: cuda_deterministic_backward.rst
    """"""
    from .modules.utils import _ntuple
    ~~~~ <--- HERE

    def _check_size_scale_factor(dim):
'_onnx_heatmaps_to_keypoints' is being compiled since it was called from '_onnx_heatmaps_to_keypoints_loop'
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py"", line 218

    for i in range(int(rois.size(0))):
        xy_preds_i, end_scores_i = _onnx_heatmaps_to_keypoints(maps, maps[i],
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...  <--- HERE
                                                               widths_ceil[i], heights_ceil[i],
                                                               widths[i], heights[i],
```
UPDATE: This error seems to occur only when I try to create plan using the tutorials at: [Creating Plans](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/static-fl/Part%2001%20-%20Create%20Plan.ipynb). After removing any calls to @sy.func2plan() the code seems to work fine. Is this a bug or not? I am confused now even more!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Can confirm this bug exists. I am not using any tutorial. Just created a hook and then tried to import datasets from torchvision and I got the same error.

The hack I am using right now is to do torchvision stuff first and then create a hook.Have this/similar problem too.
After hooking torch, the following code will fail every time:
`pickle.load(pickle_file)`

I also used the workaround of first importing torchvision and then hooking.Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I'll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I'll reopen the issue.",5,2020-07-21 14:18:24,2020-11-19 13:26:05,2020-11-19 13:26:04
https://github.com/OpenMined/PySyft/issues/3885,"['bug ', 'status: stale :bread:']",model.send fails in websocket workers,"model.send fails in websocket workers## Description
I am implementing web-socket workers for my training, but when I try to send the model to respective workers for training I get:

AttributeError: 'AutogradTensor' object has no attribute 'send_'

## How to Reproduce
1. Install latest version of pysyft
2. Create asynchronous routines for worker / server modules
3. Create a torch neural network
4. Send the model to the worker.


## Expected Behavior
To be able to send the model to the websocket workers.

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - OS: Ubuntu
 - OS Version:  16.04
 - Language Version: Python 3.7

## Additional Context
The error trace of the issue is as follows:
```
future: <Task finished coro=<training_handler() done, defined at start_federated_server.py:98> exception=AttributeError(""'AutogradTensor' object has no attribute 'send_'"")>
Traceback (most recent call last):
  File ""start_federated_server.py"", line 130, in training_handler
    for worker in sampled_workers
  File ""start_federated_server.py"", line 82, in fit_model_on_worker
    model_params.send(worker)
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py"", line 629, in module_send_
    p.send_(*dest, **kwargs)
  File ""/home/usama/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 171, in __getattribute__
    return object.__getattribute__(self, name)
AttributeError: 'AutogradTensor' object has no attribute 'send_'
```I have a related question about send() method actually. 
Can anyone point me out where it is implemented? I didn't see it in torch.tensor and sequential module but it seems their instances do have this method. 
And it seems to be the similar question here. The AutogradTensor class don't have this method. So why there is the difference and how to debug this issue?

Thanks,This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",3,2020-07-21 08:55:29,2020-12-21 00:15:54,2020-12-21 00:15:54
https://github.com/OpenMined/PySyft/issues/3879,"['bug ', 'status: stale :bread:']",'Dense' object has no attribute '_constructor_parameters_store',"'Dense' object has no attribute '_constructor_parameters_store'## Description
I am trying to recreate  to recreate [this Keras example](https://keras.io/examples/structured_data/imbalanced_classification/) using PySyft. I am facing the following error : `AttributeError: 'Dense' object has no attribute '_constructor_parameters_store'`
when I run `model.share(cluster)`.

## How to Reproduce
1. `git clone https://github.com/madisonestabrook/imbalanced_classification.git`
2. `cd imbalanced_classification`
3. `conda env create -f pysyft.yml`
4. Download the data from [https://www.kaggle.com/mlg-ulb/creditcardfraud/](https://www.kaggle.com/mlg-ulb/creditcardfraud/) and place in your `imbalanced_classification` folder
5. Open `imbalanced_classification.ipynb` your preferred `.ipynb` editor 
6. Run up to cell 7
7. Notice the error

## Expected Behavior
The code should run without errors.

## Screenshots
![image](https://user-images.githubusercontent.com/29613918/87881340-96447d80-c9c6-11ea-82ae-164277fadd00.png)

## System Information
 - OS: Windows
 - OS Version: 10 Pro (64-bit)
 - Language Version: Python 3.7.7 (64-bit) 
 - Package Manager Version: Anaconda 2020.02
-  `.ipynb` Editor: Visual Studio Code

## Additional Context
I am trying to apply the [tutorials](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials) to non-toy and non-text data. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-07-19 17:58:58,2020-12-21 00:15:55,2020-12-21 00:15:54
https://github.com/OpenMined/PySyft/issues/3871,"['bug ', 'status: stale :bread:']",socket timeout error in deploy_workers example,"socket timeout error in deploy_workers example## Description
When I try out the [deploy_workers example](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/websocket/deploy_workers/deploy-and-connect.ipynb) code after creating workers with the given docker-compose file it is giving me a socket timeout error.

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 66, in __init__
    self.connect()
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 78, in connect
    self.ws = websocket.create_connection(**args_)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_http.py"", line 193, in _open_socket
    raise error
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/websocket/_http.py"", line 176, in _open_socket
    sock.connect(address)
socket.timeout: timed out
``` 

In the example code the host is  127.0.0.1. That code on execution gave me this error,
```
Websocket connection closed (worker: alice)
Created new websocket connection
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 66, in __init__
    self.connect()
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 79, in connect
    self._log_msgs_remote(self.log_msgs)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 145, in _log_msgs_remote
    return self._send_msg_and_deserialize(""_log_msgs"", value=value)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 126, in _send_msg_and_deserialize
    response = self._send_msg(serialized_message)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 93, in _send_msg
    return self._recv_msg(message)
  File ""/opt/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 117, in _recv_msg
    ""Websocket connection closed and creation of new connection failed.""
RuntimeError: Websocket connection closed and creation of new connection failed.
```

So I inspected the container ids and found out docker created those workers in different IPs.
Like ""127.21.0.1"". I tried those IPs and received the first error.

## How to Reproduce
1. docker-compose up this [docker-compose file](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/websocket/deploy_workers/docker-compose.yaml)
2. Try the following code
```python
import torch
import syft
from syft import WebsocketClientWorker
hook = syft.TorchHook(torch)
alice = WebsocketClientWorker(hook=hook, id=""alice"", host=""172.0.0.1"", port=8777)
```

I tried the localhost and the IP address docker compose inspect container provided. Both resulted in corresponding errors I mentioned above

## System Information
 - OS: MacOS Catelina
 - OS Version: 10.15.5
 - Language Version: Python 3.7
 - Package Manager Version: Conda 4.8.3
 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-07-17 21:40:39,2020-08-24 00:10:59,2020-08-24 00:10:59
https://github.com/OpenMined/PySyft/issues/3865,"['bug ', 'priority: 1 - immediate :fire:', 'severity: 1 - critical :fire:']",Serde Can not serialize 'DynamicFLClient' object,"Serde Can not serialize 'DynamicFLClient' objectCannot share tensor from reference pointer

** This issue is critical for SyferText, since it breaks functionality when working with Grid nodes **
## How to Reproduce

Nodes Creation :
`python -m gridnode --id=bob  --host=localhost --port 3001`
`python -m gridnode --id=alice  --host=localhost --port 3002`
`python -m gridnode --id=bill  --host=localhost --port 3003`

```
bob = DynamicFLClient(hook, ""ws://localhost:3001/"")
alice = DynamicFLClient(hook, ""ws://localhost:3002"")
bill = DynamicFLClient(hook, ""ws://localhost:3003"")
my_grid = sy.PrivateGridNetwork(bob,alice, bill)
t = th.Tensor([4,6]).send(alice)
t_shared = t.fix_prec().share(bob, alice, crypto_provider=bill)
t_shared.get()
```

## Expected Behavior

A clear and concise description of what you expected to happen.

## Error

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-4-4e56dcdd7ee1> in <module>
      4 my_grid = sy.PrivateGridNetwork(bob,alice, bill)
      5 t = th.Tensor([4,6]).send(alice)
----> 6 t_shared = t.fix_prec().share(bob, alice, crypto_provider=bill )
      7 t_shared.get()
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
    916                 {""requires_grad"": requires_grad} if isinstance(chain, syft.PointerTensor) else {}
    917             )
--> 918             shared_tensor = chain.share(
    919                 *owners,
    920                 protocol=protocol,
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
    380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
    381 
--> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
    383         return response
    384 
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    486                 cmd_name, target, args_, kwargs_, return_ids, return_value
    487             )
--> 488             ret_val = self.send_msg(message, location=recipient)
    489         except ResponseSignatureError as e:
    490             ret_val = None
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/base.py in send_msg(self, message, location)
    304 
    305         # Step 1: serialize the message to a binary
--> 306         bin_message = sy.serde.serialize(message, worker=self)
    307 
    308         # Step 2: send the message and wait for a response
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
     43         strategy = serialize
     44 
---> 45     return strategy(obj, worker, simplified, force_full_simplification)
     46 
     47 
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
    335 
    336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
--> 337     return _serialize_msgpack_binary(simple_objects)
    338 
    339 
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
    289     # 2) Serialize
    290     # serialize into a binary
--> 291     binary = msgpack_lib.dumps(simple_objects)
    292 
    293     # 3) Compress
~/anaconda3/envs/pysyft/lib/python3.8/site-packages/msgpack/__init__.py in packb(o, **kwargs)
     33     See :class:`Packer` for options.
     34     """"""
---> 35     return Packer(**kwargs).pack(o)
     36 
     37 
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
TypeError: can not serialize 'DynamicFLClient' object
```

## System Information
 - OS: Ubuntu
 - Language Version: Python 3.7
- Pysyft Latest master branch

## Additional Context
Add any other context about the problem here.
Should we open this issue in PySyft @AlanAboudib @Nilanshrajput ?
`DynamicFLClient` is defined in PySyft, here :point_right: https://github.com/OpenMined/PySyft/blob/f692b992fe14fab7fe5c2006d087a683a856d914/syft/grid/clients/dynamic_fl_client.py#L16Done @sachin-101 CC: @IonesioJunior - thoughts on this? Could use your help since it's in the syft.grid package.It seems like #3857 is for a similar issue. cc @IonesioJunior @AlanAboudib Sorry for the delay! It looks like a problem that we [solved ](https://github.com/OpenMined/PyGridNode/pull/7) before. But both PySyft and PyGrid have gone through several refactoring since then, probably something has changed during the process. I will check it when I get some time.",5,2020-07-17 14:32:40,2020-08-20 20:14:33,2020-08-20 20:14:33
https://github.com/OpenMined/PySyft/issues/3863,"['bug ', 'status: stale :bread:']",Averaging method utils.federated_avg(models) returns wrong results and further bug,"Averaging method utils.federated_avg(models) returns wrong results and further bug## Description
The result of the function utils.federated_avg() is not the average of the input models.

## How to Reproduce
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x,dim=1)

net1 = Net()
net2 = Net()
avg_net = utils.federated_avg(dict(enumerate([net1, net2])))
print(""Net 1  "", list(net1.parameters())[0][0][0][0])
print(""Net 2  "", list(net2.parameters())[0][0][0][0])
print(""----------------------------"")
print(""fed_avg"", list(avg_net.parameters())[0][0][0][0])
print(""----------------------------"")
print(""avg 1+2"", 1/2*(list(net1.parameters())[0][0][0][0]+list(net2.parameters())[0][0][0][0]))
print(""----------------------------"")
print(""Net 1  "", list(net1.parameters())[0][0][0][0])
print(""Net 2  "", list(net2.parameters())[0][0][0][0])

## Expected Behavior
The result should be the average.
## Screenshots
![FA Not Correct 3](https://user-images.githubusercontent.com/68423474/87773999-3f06a780-c824-11ea-8284-330806811356.png)

## What is the Problem and how to fix?

In the method utils.federated_avg(models) you initially use
**model = type(model_list[0])()**
to sum over the input models. Unfortunatelly, model has **non zero parameters**, which causes the wrong result.
A fix could be 
![Hot Fix FA Error in Initialize](https://user-images.githubusercontent.com/68423474/87774354-b50b0e80-c824-11ea-8dd5-a9eb38c4dc10.png)
There is a further bug in the averaging method: If two nets living on the GPU are averaged, one gets an exception because the new model for the sum is initiated on the CPU.

![average cuda bug](https://user-images.githubusercontent.com/68423474/89156140-7b4b3f00-d56a-11ea-9519-3a3ea362f0ad.png)
What is the current state of this issue?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",3,2020-07-17 09:58:43,2020-11-29 00:11:35,2020-11-29 00:11:35
https://github.com/OpenMined/PySyft/issues/3854,"['bug ', 'status: stale :bread:']",Error when using embeddings in a sy.Plan ,"Error when using embeddings in a sy.Plan ## Description
I have a super simple model that uses embeddings. 
But it always fails when I try to build the plan like in the guide ""Part 08 - Introduction to Plans"".

```python
import torch
import syft as sy
import torch.nn as nn

hook = sy.TorchHook(torch)
hook.local_worker.is_client_worker = False

class Net(sy.Plan):
    def __init__(self):
        super(Net, self).__init__()
        self.embedding = nn.Embedding(5, 20)
        self.fc1 = nn.Linear(20, 3)

    def forward(self, x):
        x = self.embedding(x)
        x = self.fc1(x)
        return x

x = torch.tensor([1, 2, 3, 4], dtype=torch.long)

model = Net()
model.build(x)
``` 

I get the following error message

```
UserWarning: Failed to translate Plan with PlanTranslatorTorchscript: Traceback (most recent call last):
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 341, in handle_func_command
    cmd, args_, kwargs_, return_args_type=True
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 157, in unwrap_args_from_function
    new_args = hook_args(args_)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 356, in <lambda>
    return lambda x: f(lambdas, x)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 551, in five_fold
    lambdas[0](args_[0], **kwargs),
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 331, in <lambda>
    else lambda i: forward_func[type(i)](i)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 26, in <lambda>
    else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 26, in <genexpr>
    else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
syft.exceptions.PureFrameworkTensorFoundError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/plan.py"", line 290, in build
    self.add_translation(translator)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/plan.py"", line 497, in add_translation
    role = plan_translator(self).translate()
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/translation/torchscript.py"", line 47, in translate
    torchscript_plan = jit.trace(wrap_stateful_plan, (*args, plan_params))
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/torch/jit/__init__.py"", line 906, in trace
    _force_outplace)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/translation/torchscript.py"", line 43, in wrap_stateful_plan
    return translation_plan(*args[:-1])
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/plan.py"", line 381, in __call__
    result = self.role.execute()
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/role.py"", line 168, in execute
    self._execute_action(action)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/role.py"", line 227, in _execute_action
    response = method(*args_, **kwargs_)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py"", line 340, in overloaded_func
    response = handle_func_command(command)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/execution/placeholder.py"", line 67, in handle_func_command
    response = new_type.handle_func_command(new_command)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 384, in handle_func_command
    response = cls._get_response(cmd, args_, kwargs_)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 418, in _get_response
    response = command_method(*args_, **kwargs_)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/torch/nn/functional.py"", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py"", line 340, in overloaded_func
    response = handle_func_command(command)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 384, in handle_func_command
    response = cls._get_response(cmd, args_, kwargs_)
  File ""/home/erik/Projects/federated_ner/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 418, in _get_response
    response = command_method(*args_, **kwargs_)
RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)

  f""Failed to translate Plan with {translator.__name__}: {traceback.format_exc()}""
```

## How to Reproduce
1. Run the code above.

## Expected Behavior
Should build the plan successfully.

## System Information
 - OS: Ubuntu 20.04
 - Language Version: Python 3.7
- Torch Version: 1.4.0
- Syft (Pip) Version: 0.2.6
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.PingThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",3,2020-07-13 14:25:55,2020-12-21 00:16:05,2020-12-21 00:16:05
https://github.com/OpenMined/PySyft/issues/3848,"['bug ', 'status: stale :bread:']",Cannot move PointerTensors to GPU,"Cannot move PointerTensors to GPUSo, while trying to retrieve a model on GPU using .get(), I came across the following error:

`RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_`

Here is the traceback:

```
~/splitnn/src/utils/trainer.py in split_train(client_ids, data_paths, server_model, client_model, hook, optim, optim_params, criterion, dataloader_fn, dataloader_params, save_path, num_epochs, verbose, cuda)
    262                            dataloaders=dataloaders, criterion=criterion, num_epochs=num_epochs,
    263                            save_path=save_path, verbose=verbose, device=device)
--> 264     stats = trainer.train()
    265 
    266     return stats

~/splitnn/src/utils/trainer.py in train(self, train_clts, val_clts)
     68                 print('\nTraining client {}, epoch {}\n'.format(client_id, epoch + 1))
     69 
---> 70                 train_metrics = self._run_epoch('train', client_id)
     71                 self._log('train', 'loss', client_id, epoch + 1, train_metrics['loss'])
     72                 if self.verbose > 0:

~/splitnn/src/utils/trainer.py in _run_epoch(self, mode, client_id)
    113             else:
    114                 pred, loss = self._validate_iter(image, label, client_id)
--> 115             client = self.network.clients[client_id].get()
    116             print(""PASSED!!!!!!!!!!!!!!"")
    117             running_loss += loss

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
    673             if isinstance(nn_self.forward, Plan):

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in get_(self, *args, **kwargs)
    670         Calls get() with inplace option set to True
    671         """"""
--> 672         return self.get(*args, inplace=True, **kwargs)
    673 
    674     def allow(self, user=None) -> bool:

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    657 
    658         if inplace:
--> 659             self.set_(tensor)
    660             if hasattr(tensor, ""child""):
    661                 self.child = tensor.child

RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_
```

I manually checked that all the parameters of the model and the input images are in fact located on GPU.  After investigating the `~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py` line 671 with a lot of print statements, I found that when the model goes into the for loop:
```
~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
```

one of the `p`  values is a PointerTensor located on the CPU with `tensor.Size([ ])` whereas the previous (non-erroring) `p`s are located on GPU with regular tensor sizes (e.g. `tensor.Size([64, 3, 3, 3])`). I tried to move the PointerTensors to GPU, using `.to()` and `.cuda()` methods, but those failed to change the pointer's device. The issue got finally resolved when I wrote:

`torch.set_default_tensor_type(torch.cuda.FloatTensor)`

I don't fully understand why this is happening, but I feel it may be related to [this issue](https://github.com/OpenMined/PySyft/issues/2518). It would also be greatly useful for debugging purposes if it were possible to move PointerTensors from one device to another.
Recently I ran into the same issue while training a ResNet18 model with PySyft on GPU.

In my case, I found the error was caused by `torch.nn.BatchNorm2d`, which would generate `num_batches_tracked` tensors in Buffers and push them to CPU while `forward()`.

A quick solution is to set `track_running_stats=False` when using `torch.nn.BatchNorm2d`. However, this results in `torch.nn.BatchNorm2d` using batch statistics instead of running estimates while training ([[1](https://pytorch.org/docs/master/generated/torch.nn.BatchNorm2d.html)], [[2](https://discuss.pytorch.org/t/what-num-batches-tracked-in-the-new-bn-is-for/27097)]).This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-07-10 12:42:59,2020-08-20 00:10:33,2020-08-20 00:10:33
https://github.com/OpenMined/PySyft/issues/3845,"['bug ', 'status: stale :bread:']",clone on a remote nn.Module fails,"clone on a remote nn.Module fails## Description
Take a model, .send() it and call clone on it, it will fail.


## How to Reproduce
```
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in clone(self, *args, **kwargs)
    758 
    759         if self.has_child():
--> 760             cloned_tensor.child = self.child.clone(*args, **kwargs)
    761 
    762         return cloned_tensor

TypeError: clone() got an unexpected keyword argument 'memory_format'
```

## How to solve
Add the memory_format kwarg to the clone method of pointer tensorSame with `copy()` method as it invokes `clone`. Hi @LaRiffle, I'm trying to reproduce, but I don't quite understand how.

```
import torch
import torch.nn as nn
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")
```

I've tested 3 cases.

#### Case 1

```
model = nn.Linear(2, 1)
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

#### Case 2
```
model = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 1))
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

#### Case 3
```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc = nn.Linear(2, 1)
    def forward(self, x):
        return nn.functional.relu(self.fc(x))

model = Net()
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

All the cases fail but with a different error like:
```
...
AttributeError: 'Linear' object has no attribute 'clone'
```

How is this clone supposed to be made?

I also ended up noticing that I can do things like these ones, 

```
model_weights_copy = model_ptr.weight.clone()
model_bias_copy = model_ptr.bias.clone()
```
which works!
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",3,2020-07-10 09:12:22,2020-08-20 00:10:35,2020-08-20 00:10:35
https://github.com/OpenMined/PySyft/issues/3844,"['bug ', 'status: stale :bread:']",CUDA out of memory in middle of training due to .move() command,"CUDA out of memory in middle of training due to .move() command## Description
So, I came across a CUDA OOM issue in the middle of training when training a network with PySyft. I clearly had enough GPU memory since the first ~50 iterations did not raise any memory errors, and therefore, the OOM was due to some memory leak. Investigating the source of leak with garbage collector, I realized that it was sourced in the `move()` method of pysyft:

```
        out_client = client.forward(x)
        x_server = out_client.move(server.location, requires_grad=True)
        out_server = server.forward(x_server)
        
        return out_server
```
I modeled the above piece of code after [this](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb) Split Learning notebook, and so expected it to be bug-free. Yet, the number of items in the garbage collector increased immediately after using the move function. My understanding is that `move()` does not release the 
client activations from memory. Replacing `move()` with `send()` and `remote_get` resolved the issue:

```
        out_client = client.forward(x)
        x_server = out_client.send(server.location, requires_grad=True)
        x_server = x_server.remote_get()
        out_server = server.forward(x_server)
        
        return out_server
```
Yet, by [this](https://blog.openmined.org/federated-learning-additive-secret-sharing-pysyft/) OpenMined blog post, `move()` method should be equivalent to calling `send()` and `remote_get()` together.  

Given this, it would be great if OpenMined team could:

1.  Clarify the differences between `move()` and `send () + remote_get()`
2. Update [the blog post](https://blog.openmined.org/federated-learning-additive-secret-sharing-pysyft/) if the current description of `move()` is mislearding, or fix the memory management bug
3. Update [the split learning notebook]((https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb) ) since using `move()` causes the same memory issue as can be seen from printing the number of garbage collector objects in the data iteration loop. The code doesn't currently error out since the cifar10 dataset is so small but will if you change the dataset, increase the model complexity, or use a larger dataset. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-07-10 04:40:33,2020-08-17 00:10:47,2020-08-17 00:10:47
https://github.com/OpenMined/PySyft/issues/3834,"['bug ', 'status: stale :bread:']","""clone() got an unexpected keyword argument 'memory_format'"" at model.copy().get() ","""clone() got an unexpected keyword argument 'memory_format'"" at model.copy().get() ## Description
This bug has been recently reported before at [this issue](https://github.com/OpenMined/PySyft/issues/3514) but was closed with no follow-up.  Since problem seems quite fundamental, I decided to bring this up again.  

As the title says, trying to copy a model in a remote server raises ""clone() got an unexpected keyword argument 'memory_format'""  error.  

Here is the traceback:

```
/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    278     if state is not None:
    279         if deep:
--> 280             state = deepcopy(state, memo)
    281         if hasattr(y, '__setstate__'):
    282             y.__setstate__(state)

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    148     copier = _deepcopy_dispatch.get(cls)
    149     if copier:
--> 150         y = copier(x, memo)
    151     else:
    152         try:

~/splitnn/venv/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)
    238     memo[id(x)] = y
    239     for key, value in x.items():
--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)
    241     return y
    242 d[dict] = _deepcopy_dict

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    304             for key, value in dictiter:
    305                 key = deepcopy(key, memo)
--> 306                 value = deepcopy(value, memo)
    307                 y[key] = value
    308         else:

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    278     if state is not None:
    279         if deep:
--> 280             state = deepcopy(state, memo)
    281         if hasattr(y, '__setstate__'):
    282             y.__setstate__(state)

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    148     copier = _deepcopy_dispatch.get(cls)
    149     if copier:
--> 150         y = copier(x, memo)
    151     else:
    152         try:

~/splitnn/venv/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)
    238     memo[id(x)] = y
    239     for key, value in x.items():
--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)
    241     return y
    242 d[dict] = _deepcopy_dict

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    178                     y = x
    179                 else:
--> 180                     y = _reconstruct(x, memo, *rv)
    181 
    182     # If is its own copy, don't memoize.

~/splitnn/venv/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)
    304             for key, value in dictiter:
    305                 key = deepcopy(key, memo)
--> 306                 value = deepcopy(value, memo)
    307                 y[key] = value
    308         else:

~/splitnn/venv/lib/python3.6/copy.py in deepcopy(x, memo, _nil)
    159             copier = getattr(x, ""__deepcopy__"", None)
    160             if copier:
--> 161                 y = copier(memo)
    162             else:
    163                 reductor = dispatch_table.get(cls)

~/splitnn/venv/lib/python3.6/site-packages/torch/nn/parameter.py in __deepcopy__(self, memo)
     30             return memo[id(self)]
     31         else:
---> 32             result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)
     33             memo[id(self)] = result
     34             return result

~/splitnn/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in clone(self, *args, **kwargs)
    758 
    759         if self.has_child():
--> 760             cloned_tensor.child = self.child.clone(*args, **kwargs)
    761 
    762         return cloned_tensor

TypeError: clone() got an unexpected keyword argument 'memory_format'
```

It seems like the problem is inherent to the PySyft package since the kwarg `memory_format` is supplied by the native `__deepcopy__` method of torch which `TorchTensor` [seems to be calling](https://github.com/OpenMined/PySyft/blob/8a65122db3c09a1bcc213c803be38a86a8e909ef/syft/frameworks/torch/tensors/interpreters/native.py#L765) for its children. 
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-07-08 12:37:54,2020-08-16 00:10:38,2020-08-16 00:10:38
https://github.com/OpenMined/PySyft/issues/3833,['bug '],TypeError: add_() takes 1 positional argument but 2 were given with Adam optimizer,"TypeError: add_() takes 1 positional argument but 2 were given with Adam optimizer## Description
Running federated learning with Adam optimizer gives the error
```python
Websocket connection closed (worker: wlg)
Created new websocket connection
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-12-d30adddcefbb> in <module>
     28             loss = criterion(pred, target_batches[i][j])
     29             loss.backward()
---> 30             optimizer.step()
     31         model = model.get()
     32         loss = loss.get()

~/anaconda3/envs/Syft/lib/python3.8/site-packages/torch/optim/adam.py in step(self, closure)
     93 
     94                 # Decay the first and second moment running average coefficient
---> 95                 exp_avg.mul_(beta1).add_(1 - beta1, grad)
     96                 exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
     97                 if amsgrad:

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    208                 # Send the new command to the appropriate class and get the response
    209                 method = getattr(new_self, method_name)
--> 210                 response = method(*new_args, **new_kwargs)
    211 
    212                 # For inplace methods, just directly return self

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/generic/frameworks/hook/pointers.py in overloaded_pointer_method(self, *args, **kwargs)
     82 
     83             # Send the command
---> 84             response = owner.send_command(location, attr, self, args, kwargs)
     85 
     86             # For inplace methods, just directly return self

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    624                 cmd_name, target, args_, kwargs_, return_ids, return_value
    625             )
--> 626             ret_val = self.send_msg(message, location=recipient)
    627         except ResponseSignatureError as e:
    628             ret_val = None

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/base.py in send_msg(self, message, location)
    272 
    273         # Step 2: send the message and wait for a response
--> 274         bin_response = self._send_msg(bin_message, location)
    275 
    276         # Step 3: deserialize the response

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
     14             sleep(self.message_pending_time)
     15 
---> 16         return location._recv_msg(message)
     17 
     18     def _recv_msg(self, message: bin) -> bin:

~/anaconda3/envs/Syft/lib/python3.8/site-packages/syft/workers/websocket_client.py in _recv_msg(self, message)
    112             response = self._forward_to_websocket_server_worker(message)
    113             if not self.ws.connected:
--> 114                 raise RuntimeError(
    115                     ""Websocket connection closed and creation of new connection failed.""
    116                 )

RuntimeError: Websocket connection closed and creation of new connection failed.
```
## How to Reproduce
1. Run FL on two clients then train using the code below:
```python
for epoch in range(N_EPOCS):
    epoch_total = epoch_total_size(data_batches[0])
    current_epoch_size = 0
    for i in range(len(compute_nodes)):
        worker = data_batches[i][0].location
        print(worker)
        model.send(worker)
        for j in range(len(data_batches[i])):
            current_epoch_size += len(data_batches[i][j])
            optimizer.zero_grad()
            pred = model(data_batches[i][j])
            print(target_batches[i][j].shape, pred.shape)
            loss = criterion(pred, target_batches[i][j])
            loss.backward()
            optimizer.step()
        model = model.get()
        loss = loss.get()
```


## System Information
- PyTorch 1.4.0
- Syft 0.2.6

## Additional Context
The error raises when I finish one epoch on the first client, get the model, send it to the second client then it raises at line optimizer.step()
Hey @wmlba, could you share a notebook/script with all the code (that throws this error)? This is also happening for virtual workers, right?@gmuraru Thanks for chiming in. After some research, i figured that this issue is related to this: https://github.com/OpenMined/PySyft/issues/3349

The default Adam optimizer work but the wrapped version will. This is due to having multiple different workers. Closing now.",2,2020-07-08 11:50:22,2020-07-11 01:09:33,2020-07-11 01:09:33
https://github.com/OpenMined/PySyft/issues/3825,"['bug ', 'status: stale :bread:']",[torch] Cannot set values at indices in a tensor,"[torch] Cannot set values at indices in a tensor## Description
Code like:
```Python
t = torch.zeros((2, 3), dtype=torch.float)
indices = torch.rand_like(t) > 0.5
t[indices] = 1
```
is fine when not hooked but fails when Torch is hooked.

## How to Reproduce
```Python
import syft as sy
import torch


def set_indices():
	t = torch.zeros((2, 3), dtype=torch.float)
	indices = torch.rand_like(t) > 0.5
	t[indices] = 1
	print(""Set indices"")


# The first call works fine.
set_indices()
hook = sy.TorchHook(torch)
# This call fails.
set_indices()
```

```
Set indices
Traceback (most recent call last):
  File ""code.py"", line 16, in <module>
    set_indices()
  File ""code.py"", line 8, in set_indices
    t[indices] = 1
  File ""[REDACTED]\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 170, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""[REDACTED]\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 166, in overloaded_native_method
    response = method(*args, **kwargs)
IndexError: The shape of the mask [3] at index 0 does not match the shape of the indexed tensor [2, 3] at index 0
```



## Expected Behavior
Should be able to assign a value.

## System Information
 - OS: Windows
 - OS Version: 10
 - Language Version: Python 3.7.7
 - Package Manager Version: Anaconda
- syft==0.2.6 (Installed via Pip)
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Can anyone advise on where to make the change the correct this?I encountered the same issue when using facenet-pytorch (https://github.com/timesler/facenet-pytorch), using Python version 3.7.9, PySyft version 0.2.9 and PyTorch version 1.4. My code:
```python
from facenet_pytorch import MTCNN
from PIL import Image
import torch
import syft as sy

im = Image.open(""example.jpg"")
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

mtcnn = MTCNN(
    image_size=160, margin=0, min_face_size=20,
    thresholds=[0.6,0.7,0.7], factor=0.709, post_process=True,
    device=device, keep_all=True
)

# Calling this works fine
x_aligned = mtcnn(im)
hook = sy.TorchHook(torch)

# This call fails with an IndexError
x_aligned = mtcnn(im)
```
The error is
```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-5-44b80875f4ab> in <module>
----> 1 x_aligned = mtcnn(im)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/mtcnn.py in forward(self, img, save_path, return_prob)
    245         # Detect faces
    246         with torch.no_grad():
--> 247             batch_boxes, batch_probs = self.detect(img)
    248 
    249         # Determine if a batch or single image was passed

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/mtcnn.py in detect(self, img, landmarks)
    352                 self.pnet, self.rnet, self.onet,
    353                 self.thresholds, self.factor,
--> 354                 self.device
    355             )
    356 

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/utils/detect_face.py in detect_face(imgs, minsize, pnet, rnet, onet, threshold, factor, device)
     73         reg, probs = pnet(im_data)
     74 
---> 75         boxes_scale, image_inds_scale = generateBoundingBox(reg, probs[:, 1], scale, threshold[0])
     76         boxes.append(boxes_scale)
     77         image_inds.append(image_inds_scale)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/utils/detect_face.py in generateBoundingBox(reg, probs, scale, thresh)
    210     mask_inds = mask.nonzero()
    211     image_inds = mask_inds[:, 0]
--> 212     score = probs[mask]
    213     reg = reg[:, mask].permute(1, 0)
    214     bb = mask_inds[:, 1:].type(reg.dtype).flip(1)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    167                 except BaseException as e:
    168                     # we can make some errors more descriptive with this method
--> 169                     raise route_method_exception(e, self, args, kwargs)
    170 
    171             else:  # means that there is a wrapper to remove

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    163 
    164                 try:
--> 165                     response = method(*args, **kwargs)
    166 
    167                 except BaseException as e:

IndexError: The shape of the mask [111, 226] at index 0 does not match the shape of the indexed tensor [1, 111, 226] at index 0
```
and appears to be caused by the line `score = probs[mask]`, so I presume it is the same indexing issue.If there are technical reasons for why it is not possible, it would be nice to at least have a function which removes the hook from torch. That way one could arbitrarily switch between some standard (local) torch operations not supported by PySyft and some private operations on secretly shared data.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",5,2020-07-06 18:54:53,2020-12-21 00:16:12,2020-12-21 00:16:12
https://github.com/OpenMined/PySyft/issues/3820,[],PySyft supports Differential Privacy ?,"PySyft supports Differential Privacy ?## Question
What mechanics providing **Differential Privacy (DP)** are implemented and how can you access them?

**EDIT** by @LaRiffle 
- Opacus (formerly pytorch-dp) : [See blogpost](https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/)
- [PATE](https://github.com/OpenMined/PySyft/blob/53fc01700186b38d5330332007894f8a631c1c08/test/torch/differential_privacy/test_pate.py)

## Further Information
Does PySyft provide a library for DP besides PATE?
If so where does one find and use them?
If not which DP libraries are compatible with PySyft and can be recommended?
I'm assuming [pytorch/opacus](https://github.com/pytorch/opacus), formerly known as [PyTorch-DP](https://github.com/facebookresearch/pytorch-dp), will be compatible right?

Also is there a DP method that is used by the workers by default? #2770 suggests something like this.

Over all it is not clear to me where the DP tool, that [is being advertised](https://github.com/OpenMined/PySyft#high-level-architecture), is implemented and used.

## Problem with the Issue closing Bot

I'm sorry if this was answered anywhere before. I tried to read up on this in your issues, but all of the DP issues seem to have been closed due to inactivity rather than because they were actually solved.

Here is a list of some examples: #1933, #1824, #1953, #2200, #2770

## Additional Context
Over the past week we've been looking into PySyft for **Federated Learning (FL)** as opposed to Tensorflow Federated (TFF).
Our main issue with TFF was, that it had a fixed implementation for differential privacy, which could not be modified regarding how and where in a **FL hierarchy** it was applied.
After doing the tutorials and looking at some more of the other examples, I've found that **PySyft** does the opposite. It allows the developer to implement and apply **any DP technique** and use it at any point of a hierarchy. PySyft merely allows you to build a hierarchy (or network of any structure for that matter) of PyTorch workers.
Even though this solves the issue we had with TFF, it would still burden us to implement the DP mechanics ourselves.

PATE seems like a very specific approach and implementation combining a specific FL structure and DP. We are looking for more general DP functions.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Thanks @LaRiffle for removing the `stale` label.Yes. I face the same issue. I tried to use https://github.com/tensorflow/privacy for **TFF**, but failed. It seems I have to make a fresh start ? : ) ðŸ˜­ @catdogpandas do you mean Tensorflow Federated? I thought they had their own DP implementation out of the box.
Has been a while since I tried TFF, but it is kind of a mess. Our biggest problem was tensorflow/federated/issues/832 and in regards to DP the location of clipping and noise application was hard coded.

As a result we disregarded it for our research now and switched to pytorch with [pytorch/opacus](https://github.com/pytorch/opacus) for differential privacy. As we only do research experiments we have not yet implemented a real hierarchy with PySyft yet, but in theory it should be possible. Would be nice to have this confirmed though.

Hope this helps you.Thank you. I will try <a href=""https://github.com/pytorch/opacus"">pytorch/opacus </a> first.I think opacus was also integrated in Syft? @LaRiffle Yes we have a first integration of Opacus!
Check out: https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.@pepper-jk We have some examples here for Opacus and PyDP: https://github.com/OpenMined/PySyft/tree/dev/examples/differential-privacy

Things are in flux a little bit but we have some big stuff coming and better examples specifically for DP.
I will close this issue for now as DP is being actively worked on and when we have more to share we will announce and update the docs and examples. Thanks for your patience.> Yes we have a first integration of Opacus!
> Check out: https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/

hi @LaRiffle , i tried to run the code in this blog just recently with pysyft 0.2.9, but there is an error with parameter has no `grad_sample` attribute. 
I have seen similiar issues asked but unsolved #4917  , so could u please share were there versions of Opacus and Pysyft that can run together at the time of the blog?> > Yes we have a first integration of Opacus!
> > Check out: https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/
> 
> hi @LaRiffle , i tried to run the code in this blog just recently with pysyft 0.2.9, but there is an error with parameter has no `grad_sample` attribute.
> I have seen similiar issues asked but unsolved #4917 , so could u please share were there versions of Opacus and Pysyft that can run together at the time of the blog?

Have u known versions of Opacus and Pysyft that can run together at this blog",11,2020-07-05 11:31:30,2021-05-25 09:44:30,2021-02-18 07:36:47
https://github.com/OpenMined/PySyft/issues/3819,"['bug ', 'status: stale :bread:']","Cannot using the command "".share()"" in distributed environment","Cannot using the command "".share()"" in distributed environment## Description
When I send the tensor X from python notebook to bob worker that running by using WebsockerServer instead of the virtual machine in another instance (IP address: A). I also create another instance Alice worker by using WebsocketServer (IP address: B).  I cannot run this command ""x.share(Alice, bob)"" They said cannot serialize the WebsocketClientWorker.
`
## How to Reproduce

```
from torchvision.models.resnet import ResNet, BasicBlock
import syft as sy
from torchvision.datasets import MNIST
import torch.nn.functional as F
from tqdm.autonotebook import tqdm
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import inspect
import time
from torch import nn, optim
import torch
from torchvision.transforms import Compose, ToTensor, Normalize, Resize
from torch.utils.data import TensorDataset, DataLoader
from torchvision import datasets, transforms
from syft.workers.websocket_client import WebsocketClientWorker                                                                                                                                                                                   hook = sy.TorchHook(torch)
# verbose mode
kwargs_websocket_worker_alice = {""host"": ""xx.xx.xx.xx"", ""hook"": hook,""verbose"":False}
kwargs_websocket_worker_bob = {""host"": ""x.xx.xxx.xxx"", ""hook"": hook,""verbose"":False}
alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_worker_alice)
bob = WebsocketClientWorker(id=""bob"", port=8778, **kwargs_websocket_worker_bob)
test = torch.tensor([25]).send(bob)
check = test.share(bob,alice)
```
The error that I got.
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-4ac801f8f830> in <module>
      1 test = torch.tensor([25]).send(bob)
----> 2 check = test.share(bob,alice)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
    907                 dtype=dtype,
    908                 crypto_provider=crypto_provider,
--> 909                 **kwargs_,
    910             )
    911         else:
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
    380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
    381 
--> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
    383         return response
    384 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    624                 cmd_name, target, args_, kwargs_, return_ids, return_value
    625             )
--> 626             ret_val = self.send_msg(message, location=recipient)
    627         except ResponseSignatureError as e:
    628             ret_val = None
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    269 
    270         # Step 1: serialize the message to a binary
--> 271         bin_message = sy.serde.serialize(message, worker=self)
    272 
    273         # Step 2: send the message and wait for a response
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
     43         strategy = serialize
     44 
---> 45     return strategy(obj, worker, simplified, force_full_simplification)
     46 
     47 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
    335 
    336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
--> 337     return _serialize_msgpack_binary(simple_objects)
    338 
    339 
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
    289     # 2) Serialize
    290     # serialize into a binary
--> 291     binary = msgpack_lib.dumps(simple_objects)
    292 
    293     # 3) Compress
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
     33     See :class:`Packer` for options.
     34     """"""
---> 35     return Packer(**kwargs).pack(o)
     36 
     37 
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
TypeError: can not serialize 'WebsocketClientWorker' object
```
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.> ## Description
> When I send the tensor X from python notebook to bob worker that running by using WebsockerServer instead of the virtual machine in another instance (IP address: A). I also create another instance Alice worker by using WebsocketServer (IP address: B). I cannot run this command ""x.share(Alice, bob)"" They said cannot serialize the WebsocketClientWorker.
> `
> 
> ## How to Reproduce
> ```
> from torchvision.models.resnet import ResNet, BasicBlock
> import syft as sy
> from torchvision.datasets import MNIST
> import torch.nn.functional as F
> from tqdm.autonotebook import tqdm
> from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
> import inspect
> import time
> from torch import nn, optim
> import torch
> from torchvision.transforms import Compose, ToTensor, Normalize, Resize
> from torch.utils.data import TensorDataset, DataLoader
> from torchvision import datasets, transforms
> from syft.workers.websocket_client import WebsocketClientWorker                                                                                                                                                                                   hook = sy.TorchHook(torch)
> # verbose mode
> kwargs_websocket_worker_alice = {""host"": ""xx.xx.xx.xx"", ""hook"": hook,""verbose"":False}
> kwargs_websocket_worker_bob = {""host"": ""x.xx.xxx.xxx"", ""hook"": hook,""verbose"":False}
> alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_worker_alice)
> bob = WebsocketClientWorker(id=""bob"", port=8778, **kwargs_websocket_worker_bob)
> test = torch.tensor([25]).send(bob)
> check = test.share(bob,alice)
> ```
> 
> The error that I got.
> 
> ```
> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-7-4ac801f8f830> in <module>
>       1 test = torch.tensor([25]).send(bob)
> ----> 2 check = test.share(bob,alice)
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
>     907                 dtype=dtype,
>     908                 crypto_provider=crypto_provider,
> --> 909                 **kwargs_,
>     910             )
>     911         else:
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
>     380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
>     381 
> --> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
>     383         return response
>     384 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
>     624                 cmd_name, target, args_, kwargs_, return_ids, return_value
>     625             )
> --> 626             ret_val = self.send_msg(message, location=recipient)
>     627         except ResponseSignatureError as e:
>     628             ret_val = None
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
>     269 
>     270         # Step 1: serialize the message to a binary
> --> 271         bin_message = sy.serde.serialize(message, worker=self)
>     272 
>     273         # Step 2: send the message and wait for a response
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
>      43         strategy = serialize
>      44 
> ---> 45     return strategy(obj, worker, simplified, force_full_simplification)
>      46 
>      47 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
>     335 
>     336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
> --> 337     return _serialize_msgpack_binary(simple_objects)
>     338 
>     339 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
>     289     # 2) Serialize
>     290     # serialize into a binary
> --> 291     binary = msgpack_lib.dumps(simple_objects)
>     292 
>     293     # 3) Compress
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
>      33     See :class:`Packer` for options.
>      34     """"""
> ---> 35     return Packer(**kwargs).pack(o)
>      36 
>      37 
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> TypeError: can not serialize 'WebsocketClientWorker' object
> ```

I had the same problem. Did you solve it?",2,2020-07-05 06:12:24,2020-09-03 05:40:42,2020-08-12 00:10:07
https://github.com/OpenMined/PySyft/issues/3814,['bug '],.serve_model() throws error while serving MPC model on the grid platform,".serve_model() throws error while serving MPC model on the grid platform## Description
Tutorial: [Grid as a Secure MLaaS ](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/Part%2002%20-%20Grid%20as%20a%20Secure%20MLaaS%20to%20Cloud%20Providers.ipynb)

While serving the model, this error is thrown:
JSONDecodeError: Expecting value: line 1 column 1 (char 0)

in line:
cloud_grid_service.serve_model(model,id=model.id,allow_remote_inference=True, mpc=True)

## How to Reproduce
1. Setup grid network(PyGridNetwork) and nodes(PyGridNode).
2. Create a model which extends Plan Parent Class.
3. Serve the model

## Expected Behavior
It should split the model weights into pieces by distributing it through grid network.


## System Information
 - OS: Linux(Ubuntu)
 - OS: 20.4
 - Language Version: Python 3.8.3
 - Package Manager Version: Conda 4.6.11
 - Browser: Google ChromeThis issue was related to PyGridNetwork so I am closing this issue.This issue was related to PyGridNetwork so I am closing this issue.",2,2020-07-03 17:43:15,2020-07-03 21:23:22,2020-07-03 21:23:10
https://github.com/OpenMined/PySyft/issues/3806,"['bug ', 'status: stale :bread:']",Type conversion from float to int on remote server is not working,"Type conversion from float to int on remote server is not working## Description
Type conversion from float to int on remote server is not working.

## How to Reproduce

```
somefloat = torch.tensor([1.0, 0.5])
pointer_to_somefloat = somefloat.send(bob)
floatsum = pointer_to_somefloat.sum()
floatsum.get()
> return tensor(1.5000)
```

Since the code above works, I think code below also works.  
But it's not.

```
somefloat = torch.tensor([1.0, 0.5])
pointer_to_somefloat = somefloat.send(bob)
pointer_to_somefloat.int()
> return tensor([], dtype=torch.int32) not even a pointer
```
If someone know how to convert float into int on remote server, please let me know.  
Thanks in advance.

## Expected Behavior
```pointer_to_somefloat.int()``` should return pointer to integer tensor.

## System Information
 - OS: Ubuntu
 - OS Version: 18.04
 - Language Version: Python 3.7
 - Package Manager Version: Conda 4.6.11

## Additional Context
It could be specification. but some model like speech recognition need to convert float into int on remote server....This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-07-01 11:22:34,2020-08-08 00:10:08,2020-08-08 00:10:08
https://github.com/OpenMined/PySyft/issues/3800,"['bug ', 'status: stale :bread:']",Createplan script in notebook fails,"Createplan script in notebook fails## Description
I am trying to set up the SwiftSyft project according to the instructions and I have the iOS client compiling and in theory the python environment up and running but when I get to step 22 in the CreatePlan notebook I get this error:
```
Cannot insert Placeholder, chain does not contain AutogradTensor tensor type.
````

## How to Reproduce
I have just followed the instructions in the readme.

## Expected Behavior
The notebook executes.

## Screenshots
![Screenshot 2020-06-29 at 15 39 28](https://user-images.githubusercontent.com/7461655/86012848-c380ba00-ba1e-11ea-9cc3-9a832f4e71de.png)


## System Information
 - OS: MacOS
 - OS Version: Catalina
 - Language Version: Python 3.7

## Additional Context
Add any other context about the problem here.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-30 10:21:31,2020-08-07 00:10:28,2020-08-07 00:10:28
https://github.com/OpenMined/PySyft/issues/3796,"['bug ', 'status: stale :bread:']",add_dataset() function doesn't exist in websocket_server,"add_dataset() function doesn't exist in websocket_server## Description
https://github.com/OpenMined/PySyft/blob/275efceca60e4f8b58e5b5c98f18b8bebd15f889/run_websocket_server.py#L87

It seems like the add_dataset() function has been removed from websocket_server file.

## How to Reproduce
run the example involving this: https://github.com/OpenMined/PySyft/blob/master/run_websocket_server.py


## Expected Behavior
Adding a dataset to websocket server to be discoverable.

The new version does not support websocket. It seems that they can not solve it at this moment...This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-06-30 01:05:56,2020-08-20 00:10:39,2020-08-20 00:10:39
https://github.com/OpenMined/PySyft/issues/3794,"['bug ', 'status: stale :bread:']",PyGrid example do not work ,"PyGrid example do not work ## Description
The example for pygrid do not work. 

## How to Reproduce

I want to run the example of mnist and spam_prediction in PySyft-master/examples/tutorials/grid/federated_learning/, but both failed. 

For example of mnist, it failed for  ```NodeClient(hook, node)```:
```
import syft as sy
from syft.workers.node_client import NodeClient
import torch
import pickle
import time
import torchvision
from torchvision import datasets, transforms
import tqdm

hook = sy.TorchHook(torch)

# Connect directly to grid nodes
nodes = [""ws://localhost:3000/"",
         ""ws://localhost:3001/""]

compute_nodes = []
for node in nodes:
    compute_nodes.append( NodeClient(hook, node) )
```

The error information is:
```
Traceback (most recent call last):
  File ""C:/Users/qiang_zhang.neu/Desktop/test/testGrid.py"", line 18, in <module>
    compute_nodes.append( NodeClient(hook, node) )
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\node_client.py"", line 65, in __init__
    None,  # initial data
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 64, in __init__
    self.connect()
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 76, in connect
    self.ws = websocket.create_connection(**args_)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 201, in _open_socket
    raise err
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it
```

Should we need to create a server firstly?

On the other hand, the tutorial ""Federated_SMS_Spam_prediction [Part 1] - Populate a Grid Network (Dataset).ipynb"" require that:

```
To start the gateway:
cd gateway
python gateway.py --start_local_db --port=5000

To start one grid node:
cd app/websocket/
python websocket_app.py --start_local_db --id=alice --port=3001 --gateway_url=http://localhost:5000
```
Actually, I can not find the folder of 'gateway' and 'app'. 

## Expected Behavior
I hope PySyft can provide an example for PyGrid. And more importantly, we expect an example of clinetworker and serverworker data loading and model training in real federate learning scenario. It should be run without error.

## System Information
 - OS: win10
 - Language Version: Python 3.7
 - Package Manager Version: syft 0.2.6

## Additional Context
Really need an example.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-29 07:08:35,2020-08-06 00:09:45,2020-08-06 00:09:45
https://github.com/OpenMined/PySyft/issues/3786,"['bug ', 'status: stale :bread:']",Cifar10 accuracy with resnet18 on a single client is stuck at 75%,"Cifar10 accuracy with resnet18 on a single client is stuck at 75%## Description
Cifar10 accuracy with resnet18 on a single client is stuck at 75%
I ran for 200 epochs with a learning rate schedule of (0.1 till epoch100, 0.01 from 100-150, 0.001 from 150-200)
The accuracy I achieve on the test set is around 75%
Cifar10 accuracy with resnet18 should reach around 88-90% on centralized data.

I used the same hyper-parameters as in centralized implementation

## How to Reproduce
here is my code for a single client execution

import syft as sy  # <-- NEW: import the Pysyft library
import torch
torch.set_default_tensor_type(torch.cuda.FloatTensor)
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms, models

hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob

### modifying lr during training
def lr_function(epoch, first_lr_drop, second_lr_drop, third_lr_drop, initial_lr):
	if (epoch >= third_lr_drop):
		return initial_lr*0.1*0.1*0.1
	elif (epoch >= second_lr_drop):
		return initial_lr*0.1*0.1
	elif (epoch >= first_lr_drop):
		return initial_lr*0.1
	else:
		return initial_lr

class Arguments():
	def __init__(self):
		self.batch_size = 64
		self.test_batch_size = 1000
		self.epochs = 200
		self.lr = 0.1
		self.momentum = 0.9
		self.no_cuda = False
		self.seed = 1
		self.log_interval = 100
		self.save_model = False
		self.first_lr_drop = 100
		self.second_lr_drop = 150
		self.third_lr_drop = 200

args = Arguments()

use_cuda = not args.no_cuda and torch.cuda.is_available()

torch.manual_seed(args.seed)

device = torch.device(""cuda"" if use_cuda else ""cpu"")


transform = transforms.Compose(
	[ transforms.RandomCrop(32, padding=4),
	transforms.RandomHorizontalFlip(),
	transforms.ToTensor(),
	#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
	])

transform_test = transforms.Compose([
		transforms.ToTensor()
	])

federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
	datasets.CIFAR10('../data', train=True, download=True,
				   transform=transform)
	.federate([bob]), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
	batch_size=args.batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(
	datasets.CIFAR10('../data', train=False, transform=transform_test),
	batch_size=args.test_batch_size, shuffle=True)

print(device)
model = models.resnet18(pretrained=False)
model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)
model = model.to(device)

bobs_model = model.copy().send(bob) 

bobs_criterion = nn.CrossEntropyLoss()

criterion = nn.CrossEntropyLoss()

for epoch in range(args.epochs):
	bobs_model.train()

	bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=args.lr, momentum=args.momentum, weight_decay=2e-4)

	for param_group in bobs_opt.param_groups:
		param_group['lr'] = lr_function(epoch, args.first_lr_drop, args.second_lr_drop, args.third_lr_drop, args.lr)

	for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
		location = data.location
		data, target = data.to(device), target.to(device)
		bobs_opt.zero_grad()
		bobs_output = bobs_model(data)
		bobs_loss = bobs_criterion(bobs_output, target)
		bobs_loss.backward()
		bobs_opt.step()
		loss = bobs_loss.detach().get()

		if batch_idx % args.log_interval == 0:
			print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
				epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
				100. * batch_idx / len(federated_train_loader), loss.item()), flush=True)

	bobs_model.get()

	test_loss = 0
	correct = 0
	with torch.no_grad():
		for data, target in test_loader:
			data, target = data.to(device), target.to(device)
			output = bobs_model(data)
			test_loss += criterion(output, target).item() # sum up batch loss
			pred = output.argmax(1, keepdim=True) # get the index of the max log-probability 
			correct += pred.eq(target.view_as(pred)).sum().item()

	test_loss /= len(test_loader.dataset)

	print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
		test_loss, correct, len(test_loader.dataset),
		100. * correct / len(test_loader.dataset)))

	bobs_model.send(bob)


## Expected Behavior
I run the code with a single client 
Output after 200 epochs:

Optimizer lr:  0.0010000000000000002
Train batch size:  128
Train Epoch: 199 [0/50048 (0%)]	Loss: 0.000341
Train Epoch: 199 [6400/50048 (13%)]	Loss: 0.000293
Train Epoch: 199 [12800/50048 (26%)]	Loss: 0.000387
Train Epoch: 199 [19200/50048 (38%)]	Loss: 0.000356
Train Epoch: 199 [25600/50048 (51%)]	Loss: 0.000346
Train Epoch: 199 [32000/50048 (64%)]	Loss: 0.000281
Train Epoch: 199 [38400/50048 (77%)]	Loss: 0.000394
Train Epoch: 199 [44800/50048 (90%)]	Loss: 0.000462
Training avg batch loss: 0.0004
Epoch time:  196.71481251716614
Number of batches in epoch:  390

Test set: avg cln loss: 1.2113, cln acc: 7599/10000 (76%)

## Screenshots
If applicable, add screenshots to help explain your problem.

## System Information
 - Linux (Ubuntu)
 - Red Hat Enterprise Linux Server release 7.6
 - Python 3.7
 - Conda 4.8.3
## Additional Context
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-25 17:30:16,2020-08-02 00:09:51,2020-08-02 00:09:51
https://github.com/OpenMined/PySyft/issues/3778,"['bug ', 'status: stale :bread:']",argument of type 'WindowsPath' is not iterable,"argument of type 'WindowsPath' is not iterable## Description
Run examples/advance/websockets_mnist
ERROR:
argument of type 'WindowsPath' is not iterable

## How to Reproduce
cd path/PySyft-master/examples/tutorials/advanced/websockets_mnist
python start_websocket_servers.py

Then, I modify the start_websocket_servers.py as following:
```
...

FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py"")
FILE_PATH = str(FILE_PATH)
print(FILE_PATH)
...
```
The error of 'WindowsPath' is gone. Is it right to fix this bug?

However, a new error happen:
No module named 'pythreepio'



## System Information
 - OS: win10
 - Language Version: python 3.7.4
 - Package Manager Version: syft 0.2.6


This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-24 07:53:26,2020-08-01 00:09:36,2020-08-01 00:09:36
https://github.com/OpenMined/PySyft/issues/3774,['bug '],Connection Refused Error,"Connection Refused ErrorThe connection error is reported in my computer. 

The code is very easy:
```
import torch
import syft
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host='localhost',
                            hook=hook,
                            id=2,
                            port=8181)
```
And the error is:
```
Traceback (most recent call last):
  File ""E:/FederatedLearning/code/test/client.py"", line 11, in <module>
    port=8181)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 64, in __init__
    self.connect()
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\syft\workers\websocket_client.py"", line 76, in connect
    self.ws = websocket.create_connection(**args_)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 201, in _open_socket
    raise err
  File ""D:\ProgramData\Anaconda3\envs\general\lib\site-packages\websocket\_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [WinError 10061]  No connection could be made because the target machine actively refused itã€‚
```
However, a test code for socket is OK:
```
import socket
import sys
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
host = socket.gethostname()
port = 9999
s.connect((host, port))
msg = s.recv(1024)
s.close()
print(msg.decode('utf-8'))
```

Then, I set the  socket.gethostname() to WebsocketClientWorker, and the code is:
```
import torch
import syft
import socket
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host=socket.gethostname(),
                            hook=hook,
                            id=2,
                            port=8181)
```
But the same error is reported.

How can I fixed this error? Finally, I find the solution. 

Using socket, we must create the server firstly, and then create the client. Those, the following code should be run firstly:

```
import syft as sy
import os
import sys
import logging
import torch
hook = sy.TorchHook(torch)

from syft.workers.websocket_server import WebsocketServerWorker

server_worker  = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182)

server_worker.start()  # Might need to interrupt with `CTRL-C` or some other means

```
Then, do not close it, and run the following code:

```
import torch
import syft
import socket
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host='localhost',
                            hook=hook,
                            id=2,
                            port=8182)
```
Then, it is OK.",1,2020-06-23 09:59:53,2020-06-24 02:46:17,2020-06-24 02:46:17
https://github.com/OpenMined/PySyft/issues/3762,"['bug ', 'status: stale :bread:']",ModuleNotFoundError: No module named 'pythreepio',"ModuleNotFoundError: No module named 'pythreepio'## Description
Run examples/advance/websockets_mnist
ERROR: 
ModuleNotFoundError: No module named 'pythreepio'

## How to Reproduce
cd path/PySyft-master/examples/tutorials/advanced/websockets_mnist
python start_websocket_servers.py

## Expected Behavior
Example should work without error


## System Information
 - OS: Mac
 - OS Version: 10.15.5
 - Language Version: Python 3.6
 - Package Manager Version: latest


@thormacy, we should import syft rather than import PySyft-master/syft. 

There is something wrong with the original example, and we need some modifies. 

Copy the websockets_mnist in your Desktop or other folder (make sure it is not included by PySyft-master)

And the folder files is:
```
run_websocket_client.py
run_websocket_server.py
start_websocket_servers.py
```
the run_websocket_server.py is copied from the PySyft-master/run_websocket_server.py.

The start_websocket_servers.py should also be modified as following:
```
import subprocess
import sys
from pathlib import Path

python = Path(sys.executable).name

FILE_PATH = './run_websocket_server.py'

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]

call_bob = [python, FILE_PATH, ""--port"", ""8778"", ""--id"", ""bob""]

call_charlie = [python, FILE_PATH, ""--port"", ""8779"", ""--id"", ""charlie""]


print(""Starting server for Alice"")
subprocess.Popen(call_alice)

print(""Starting server for Bob"")
subprocess.Popen(call_bob)

print(""Starting server for Charlie"")
subprocess.Popen(call_charlie)

```

Then, you can run:
```
python start_websocket_servers.py
python run_websocket_client.py
```This works! @NeuZhangQiang 
Thanks for the information
Do you have any idea that why this up to date version doen't have the tutorial on ""websockets_mnist_parallel"", which is about asynchronous federated learning and have shown in some other branch.@HongdaWu1226 Sorry, I don't know why there is no ""websockets_mnist_parallel"" tutorial. If you can find one, please tell me. @NeuZhangQiang 
If we downgrade the syft version to 0.2.5. It should work if you following the tutorial on ""websockets_mnist_parallel"". Also, you may still face some minor problems, but it is not a big deal and easy to handle.
If you have problem on this tutorial, just contact me via e-mail.@HongdaWu1226 Thank you very much for the suggestion.

Currently, I meet a problem. PySyft use data.send(worker) to share the data. But, how can we deal with big data by PySyft? PyTorch use DataLoader, and Keras use generator for dataset lazy loading. Is it possible to share DataLoader or generator?

Any suggestion is appreciated! The point here is the latest version use a Module 'pythreepio' which is not included in the building process. Somehow I make it work for my task. Since I needs websocket works properly, I downgrade the version.

For reference:
websocket-client 0.54.0
syft             0.2.0a2

Hope they can make the latest working soon!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.# Description & reproduce
I met a similar problem on windows,
when I type in my command, `from syft.frameworks.torch.dp import pate`, the error msg is as follows:
<pre>
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\__init__.py"", line 14, in <module>
    import syft.frameworks.torch.hook.hook_args
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\hook\hook_args.py"", line 4, in <module>
    from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py"", line 16, in <module>
    from syft.generic.utils import memorize
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\utils.py"", line 1, in <module>
    from syft.generic.frameworks.attributes import allowed_commands
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\attributes.py"", line 8, in <module>
    from syft.generic.frameworks.hook.hook import FrameworkHook
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\hook.py"", line 11, in <module>
    from syft.generic.frameworks.hook.pointers import PointerHook
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\pointers.py"", line 8, in <module>
    from syft.generic.pointers.multi_pointer import MultiPointerTensor
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\pointers\multi_pointer.py"", line 11, in <module>
    from syft.workers.base import BaseWorker
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\workers\base.py"", line 12, in <module>
    from syft.execution.plan import Plan
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\plan.py"", line 21, in <module>
    from syft.execution.translation.threepio import PlanTranslatorTfjs
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\translation\threepio.py"", line 2, in <module>
    import pythreepio
ModuleNotFoundError: No module named 'pythreepio'
</pre>
How can I solve the problem? 

# System Information
python version: 3.7.6
os: windows 10
torch: 1.4.0 GPU
syft: 0.2.9> # Description & reproduce
> I met a similar problem on windows,
> when I type in my command, `from syft.frameworks.torch.dp import pate`, the error msg is as follows:
> 
> Traceback (most recent call last):
>   File """", line 1, in 
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\__init__.py"", line 14, in 
>     import syft.frameworks.torch.hook.hook_args
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\hook\hook_args.py"", line 4, in 
>     from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py"", line 16, in 
>     from syft.generic.utils import memorize
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\utils.py"", line 1, in 
>     from syft.generic.frameworks.attributes import allowed_commands
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\attributes.py"", line 8, in 
>     from syft.generic.frameworks.hook.hook import FrameworkHook
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\hook.py"", line 11, in 
>     from syft.generic.frameworks.hook.pointers import PointerHook
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\pointers.py"", line 8, in 
>     from syft.generic.pointers.multi_pointer import MultiPointerTensor
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\pointers\multi_pointer.py"", line 11, in 
>     from syft.workers.base import BaseWorker
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\workers\base.py"", line 12, in 
>     from syft.execution.plan import Plan
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\plan.py"", line 21, in 
>     from syft.execution.translation.threepio import PlanTranslatorTfjs
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\translation\threepio.py"", line 2, in 
>     import pythreepio
> ModuleNotFoundError: No module named 'pythreepio'
> How can I solve the problem?
> 
> # System Information
> python version: 3.7.6
> os: windows 10
> torch: 1.4.0 GPU
> syft: 0.2.9

I solved it by myself. 

1) First, uninstall the original pysyft--`pip uninstall syft`. 

2) And then to use this command `pip install syft -f https://download.pytorch.org/whl/torch_stable.html` from this [link](https://stackoverflow.com/questions/61850455/could-not-find-a-version-that-satisfies-the-requirement-torch-1-4-0-from-syft)

3) maybe you will meet this problem, `ModuleNotFoundError: No module named 'syft.frameworks.torch.differential_privacy'`, please change it into `ModuleNotFoundError: No module named 'syft.frameworks.torch.dp` according to this [link](https://stackoverflow.com/questions/58367187/modulenotfounderror-no-module-named-syft-pysyft)This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",10,2020-06-22 03:44:18,2020-12-21 00:16:22,2020-12-21 00:16:22
https://github.com/OpenMined/PySyft/issues/3716,[],error: symbol not found,"error: symbol not foundWhen I test the syft, there is an error:

`ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/aiortc/codecs/_opus.abi3.so, 2): Symbol not found: ____chkstk_darwin`

It seems to be a problem caused by the version of Mac. However, I have no clue how to fix it without reinstall the Mac system.Appreciate for any commentsSolved by updating the system to 10.15.5",2,2020-06-18 02:30:02,2020-06-22 06:14:03,2020-06-22 06:13:51
https://github.com/OpenMined/PySyft/issues/3712,"['bug ', 'priority: 1 - immediate :fire:', 'severity: 1 - critical :fire:']",Unable to import syft from master branch,"Unable to import syft from master branch## Description
When I try to import syft from the master branch, an error shows up. Look like a `Command` that before were in `pythreepio.utils` is there no longer. 

## How to Reproduce
1. install syft on master branch
2. import syft

## Expected Behavior
ImportError: cannot import name 'Command' from 'pythreepio.utils' (/home/joaolucas/Documents/PySyft/venv/lib/python3.7/site-packages/pythreepio/utils.py)

**UPDATE: PYSYFT IS BROKEN AS LONG AS THIS IS OPEN**Fixed by #3725",1,2020-06-16 19:05:01,2020-06-19 12:24:17,2020-06-19 12:24:17
https://github.com/OpenMined/PySyft/issues/3707,"['bug ', 'status: stale :bread:']",FederatedDataLoader returns one batch too much,"FederatedDataLoader returns one batch too much## Description
A FederatedDataLoader returns one batch to much

## How to Reproduce
1. Create a dataset with numpy in the shape of ```(2464, 140, 1)``` (batches, time samples, features).
2. Create two workers 
```
bob = sy.VirtualWorker(hook, id=""bob"")
anne = sy.VirtualWorker(hook, id=""anne"")
```

3. Create FederatedDataLoader with prepared data

```
train_inputs = torch.Tensor(np.stack(train_dataset))
train_idx = int(len(train_inputs)/2)
bob_train_dataset = sy.BaseDataset(train_inputs[:train_idx], train_labels[:train_idx]).send(bob)
anne_train_dataset = sy.BaseDataset(train_inputs[train_idx:], train_labels[train_idx:]).send(anne)
federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])
federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=BATCH_SIZE)

```

4. Observe lenght compared to returned amount of mini-batches

```
print(len(federated_train_loader))
i = 0
# Batch loop
for inputs, _ in federated_train_loader:
    print(f""do one {i}"")
    print(inputs.shape)
    print(inputs)
    i += 1
```

## Expected Behaviour
`len` returns 77. We expect to print i from 0 to 76. 77 mini batches Ã  32 samples --> 2464.
With BATCH_SIZE = {2,4,8,16} everything works fine and returns 2464 samples in total. BATCH_SIZE = 32, however, returns one additional mini_batch half the size. We have 77 (0-76) mini-batches plus one 77th batch Ã  16 samples which leads to 2480 samples.

```
do one 0
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:75587715062 -> bob:94165555059]
do one 1
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:5409223456 -> bob:28592027390]
do one 2
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:14367317392 -> bob:93351406795]
do one 3
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:4466061583 -> bob:20620554784]
do one 4
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:59665303329 -> bob:11546520660]
do one 5
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:38580083042 -> bob:66979350571]
do one 6
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:41617521325 -> bob:44073231731]
do one 7
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:33710408207 -> bob:71456839912]
do one 8
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:86871776686 -> bob:87663967169]
do one 9
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:6563401725 -> bob:37753396779]
do one 10
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:32250166805 -> bob:29664046666]
do one 11
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:58164843508 -> bob:70431450232]
do one 12
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:67089951506 -> bob:16657070331]
do one 13
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:79494023943 -> bob:89134165692]
do one 14
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:22030340358 -> bob:4211838126]
do one 15
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:15363843535 -> bob:29966055166]
do one 16
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:78508877452 -> bob:28026775779]
do one 17
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:78941146531 -> bob:77947459368]
do one 18
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:31783485721 -> bob:50867867256]
do one 19
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:2698661105 -> bob:40658093829]
do one 20
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:26355264750 -> bob:37855243955]
do one 21
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:9404037333 -> bob:92067230941]
do one 22
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:51022628098 -> bob:30716485493]
do one 23
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:58601892500 -> bob:46123558743]
do one 24
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:7371493204 -> bob:70692843143]
do one 25
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:37145459607 -> bob:88476091490]
do one 26
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:61262205847 -> bob:67651789398]
do one 27
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:50388924632 -> bob:23136716363]
do one 28
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:16977367122 -> bob:48513357772]
do one 29
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:63389385771 -> bob:6064064509]
do one 30
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:59766870903 -> bob:90260853233]
do one 31
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:14916785847 -> bob:36366137508]
do one 32
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:53862397472 -> bob:28394463410]
do one 33
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:33728795248 -> bob:84476087367]
do one 34
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:5007221398 -> bob:61034899038]
do one 35
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:13451125188 -> bob:7790028339]
do one 36
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:10694808999 -> bob:11126593888]
do one 37
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:90604028005 -> bob:66011720975]
do one 38
torch.Size([16, 140, 1])
(Wrapper)>[PointerTensor | me:34638327586 -> bob:39712694960]
do one 39
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:5221472465 -> anne:73257266513]
do one 40
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:14094987264 -> anne:81535914978]
do one 41
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:78589694443 -> anne:61626094333]
do one 42
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:25001717827 -> anne:23697359747]
do one 43
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:46861151465 -> anne:37072448682]
do one 44
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:97691637587 -> anne:84708293310]
do one 45
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:58308718567 -> anne:33269931903]
do one 46
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:34650120690 -> anne:98144416797]
do one 47
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:52483393484 -> anne:86945352997]
do one 48
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:20813153618 -> anne:54765418435]
do one 49
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:34950527657 -> anne:82857637914]
do one 50
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:74120840039 -> anne:86960225909]
do one 51
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:44701449293 -> anne:76085549923]
do one 52
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:82659191278 -> anne:44613536525]
do one 53
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:30974803897 -> anne:61315082767]
do one 54
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:23276623526 -> anne:24244743963]
do one 55
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:52592022616 -> anne:17766424606]
do one 56
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:42635413803 -> anne:74304223099]
do one 57
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:27950465557 -> anne:74471730834]
do one 58
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:5331411809 -> anne:41269768118]
do one 59
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:75111542350 -> anne:37942318832]
do one 60
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:18434972492 -> anne:64637602394]
do one 61
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:74234165662 -> anne:61660415019]
do one 62
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:26198236643 -> anne:86056515260]
do one 63
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:84669244687 -> anne:3195117600]
do one 64
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:62419167167 -> anne:4315075926]
do one 65
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:92919106309 -> anne:81786156648]
do one 66
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:7544767944 -> anne:93075136632]
do one 67
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:75713629949 -> anne:47179560384]
do one 68
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:93646623138 -> anne:87523012577]
do one 69
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:63050124655 -> anne:93939874821]
do one 70
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:88921565677 -> anne:47428995728]
do one 71
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:12936058188 -> anne:45635550608]
do one 72
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:86072636375 -> anne:17062685306]
do one 73
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:33318085590 -> anne:98199188406]
do one 74
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:34897896861 -> anne:64580185412]
do one 75
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:92884675053 -> anne:75576544748]
do one 76
torch.Size([32, 140, 1])
(Wrapper)>[PointerTensor | me:87362758801 -> anne:28714068806]
do one 77
torch.Size([16, 140, 1])
(Wrapper)>[PointerTensor | me:31909714050 -> anne:19533309877]
```

## System Information
 - OS: OSX
 - OS Version: 10.15.4
 - PySyft Version: 0.2.5
 - Torch Version: 1.4.0
 - Language Version: Python 3.6.9, 
 - Jupyter Stuff:
```
jupyter core     : 4.6.3
jupyter-notebook : 6.0.3
qtconsole        : 4.5.5
ipython          : 7.8.0
ipykernel        : 5.1.2
jupyter client   : 6.1.3
jupyter lab      : not installed
nbconvert        : 5.6.0
ipywidgets       : 7.5.1
nbformat         : 4.4.0
traitlets        : 4.3.3
```
 - Browser (if applicable): Google ChromeThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-14 16:29:47,2020-07-24 00:08:58,2020-07-24 00:08:58
https://github.com/OpenMined/PySyft/issues/3706,"['bug ', 'status: stale :bread:']",Part 2 of the Grid Tutorials Series throws TypeError in Step 2.2,"Part 2 of the Grid Tutorials Series throws TypeError in Step 2.2## Description
Running part 2 step 2.2 of the grid tutorial series with `mpc = True` throws `TypeError: can not serialize â€˜NodeClientâ€™ object`. With `mpc = False` the tutorial section works. This seems to be related to #3648.

## How to Reproduce
Just run the tutorial.

## Expected Behavior
An error message as below.

## Screenshots
```
TypeError                                 Traceback (most recent call last)
<ipython-input-4-e72cafd212c8> in <module>
      9 receive the mpc results and aggregate it, returning the inference's result.
     10 '''
---> 11 result = cloud_grid_service.run_remote_inference(""convnet"", user_input_data, mpc=True)# If mpc flag is False, It will send your real data to the platform.
     12 print(""Inference's result: "", result) # ( [2.0, 4.0] * [5.0, 3.0] ) + [1000] = [1022]

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/grid/public_grid.py in run_remote_inference(self, id, data, mpc)
    103             return self._run_unencrypted_inference(id, data)
    104         else:
--> 105             return self._run_encrypted_inference(id, data)
    106 
    107     def _serve_unencrypted_model(

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/grid/public_grid.py in _run_encrypted_inference(self, id, data, copy)
    285         # Perform Inference
    286         fetched_plan = self.hook.local_worker.fetch_plan(id, host_node, copy=copy)
--> 287         return fetched_plan(shared_data).get().float_prec()
    288 
    289     def __connect_with_node(self, node_id, node_url):

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/execution/plan.py in __call__(self, *args)
    348                 self.input_types.input_check(self, args)
    349             self.role.instantiate_inputs(args)
--> 350             result = self.role.execute()
    351             if len(result) == 1:
    352                 return result[0]

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/execution/role.py in execute(self)
    165         """"""
    166         for action in self.actions:
--> 167             self._execute_action(action)
    168 
    169         output_placeholders = tuple(

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/execution/role.py in _execute_action(self, action)
    226             response = method(*args_, **kwargs_)
    227         else:
--> 228             response = getattr(_self, cmd)(*args_, **kwargs_)
    229 
    230         if not isinstance(response, (tuple, list)):

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py in tracing_method(self, *args, **kwargs)
    174         def create_tracing_method(base_method, name):
    175             def tracing_method(self, *args, **kwargs):
--> 176                 response = base_method(self, *args, **kwargs)
    177                 command = (name, self, args, kwargs), response
    178                 if self.tracing:

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_syft_method(self, *args, **kwargs)
    114 
    115             # Send it to the appropriate class and get the response
--> 116             response = getattr(new_self, attr)(*new_args, **new_kwargs)
    117 
    118             # Put back SyftTensor on the tensors found in the response

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    208                 # Send the new command to the appropriate class and get the response
    209                 method = getattr(new_self, method_name)
--> 210                 response = method(*new_args, **new_kwargs)
    211 
    212                 # For inplace methods, just directly return self

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py in matmul(self, *args, **kwargs)
    430 
    431         # Send it to the appropriate class and get the response
--> 432         response = getattr(new_self, ""matmul"")(*new_args, **new_kwargs)
    433 
    434         # Put back SyftTensor on the tensors found in the response

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in matmul(self, other)
    646             return self._public_mul(other, ""matmul"")
    647 
--> 648         return self._private_mul(other, ""matmul"")
    649 
    650     def mm(self, *args, **kwargs):

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in _private_mul(self, other, equation)
    536             raise AttributeError(""For multiplication a crypto_provider must be passed."")
    537 
--> 538         shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field, self.dtype)
    539 
    540         return shares

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/mpc/spdz.py in spdz_mul(cmd, x_sh, y_sh, crypto_provider, field, dtype)
     32     # Get triples
     33     a, b, a_mul_b = request_triple(
---> 34         crypto_provider, cmd, field, dtype, x_sh.shape, y_sh.shape, locations
     35     )
     36 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/mpc/beaver.py in request_triple(crypto_provider, cmd, field, dtype, a_size, b_size, locations)
     37 
     38     shares = (
---> 39         res.share(*locations, field=field, dtype=dtype, crypto_provider=crypto_provider).get().child
     40     )
     41     a_shared = shares[: a.numel()].reshape(a_size)

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
    907                 dtype=dtype,
    908                 crypto_provider=crypto_provider,
--> 909                 **kwargs_,
    910             )
    911         else:

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
    380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
    381 
--> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
    383         return response
    384 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
    624                 cmd_name, target, args_, kwargs_, return_ids, return_value
    625             )
--> 626             ret_val = self.send_msg(message, location=recipient)
    627         except ResponseSignatureError as e:
    628             ret_val = None

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
    269 
    270         # Step 1: serialize the message to a binary
--> 271         bin_message = sy.serde.serialize(message, worker=self)
    272 
    273         # Step 2: send the message and wait for a response

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
     43         strategy = serialize
     44 
---> 45     return strategy(obj, worker, simplified, force_full_simplification)
     46 
     47 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
    335 
    336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
--> 337     return _serialize_msgpack_binary(simple_objects)
    338 
    339 

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
    289     # 2) Serialize
    290     # serialize into a binary
--> 291     binary = msgpack_lib.dumps(simple_objects)
    292 
    293     # 3) Compress

~/.pyenv/versions/pysyft_playground/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
     33     See :class:`Packer` for options.
     34     """"""
---> 35     return Packer(**kwargs).pack(o)
     36 
     37 

msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()

TypeError: can not serialize 'NodeClient' object
```
## System Information
 - OS: MacOS
 - OS Version: 10.15.5
 - Language Version: Python 3.7.7
 - Package Manager Version: pip 20.1.1I am facing the same issue. Has it been resolved for you?No, unfortunately for me there is no solution yet.Hi, I found a solution for this, take a look here https://github.com/kuronosec/PySyft/commit/bd69d25c22aa106bbbeb13764e09a938bb617858 and here https://github.com/kuronosec/syft-proto/commit/e63901e5ffb003fec2c6bf98fe5b10b863c3e6db. But I don't know if that's the right solution or just a workaround. This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2020-06-14 15:44:30,2020-08-16 00:10:41,2020-08-16 00:10:41
https://github.com/OpenMined/PySyft/issues/3688,"['bug ', 'status: stale :bread:']",Error handling when CrypTen computation crashes,"Error handling when CrypTen computation crashes## Description
Distributed CrypTen computation could fail due to many issues at the distributed worker level or in the local worker. We need to handle the different errors and share information between different workers in order to display clear error messages to the user accordingly.

## Expected Behavior
A clear message should be displayed to the user with enough information.
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-10 09:51:17,2020-08-16 00:10:44,2020-08-16 00:10:44
https://github.com/OpenMined/PySyft/issues/3671,"['bug ', 'priority: 1 - immediate :fire:']",FV cipher-text data change during decryption.,"FV cipher-text data change during decryption.## Description
During the decryption process, the ciphertext was soft copied and it changed the ciphertext value during decryption. So we lose the value of ciphertext.
## How to Reproduce
1. Create a ciphertext
2. Decrypt that ciphertext
3. Retry to decrypt the same ciphertext (wrong result)
This issue was not caught by earlier tests because for every test of encryption-decryption process new parameters were generated and every ciphertext was tested for correct values only ones",1,2020-06-05 17:31:25,2020-06-06 05:29:34,2020-06-06 05:29:34
https://github.com/OpenMined/PySyft/issues/3667,"['bug ', 'status: stale :bread:', 'question ']",Train models with new approch of grid,"Train models with new approch of grid## Question
Does the tool already have documentation support for training models with the new grid approach?

## Further Information
For example, I am trying to train a model, following the steps of the notebook that is available [p1](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb) and [p2](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-2%20%5D%20-%20Train%20a%20Model.ipynb), with the **Net** model and **mnist** database, but with the new grid approach, described below.

```sh
import syft as sy
import torch as th

hook = sy.TorchHook(th)
alice = sy.grid.register()

node1 = alice.connect(""bob"")
```

```sh
node1.search(""#mnist"")
    Tags: #mnist 
    Shape: torch.Size([5000, 1, 28, 28])]
```
For training I use the old approach. But the prediction is in a loop. Is training done any other way?

Loop line:

```sh
pred = model(data[i][j])
```

## System Information
 - OS: Linux
 - OS Version: Ubuntu 18
 - Language Version: Python 3.7
 - Package Manager Version: Conda

Ps.: The new approach to the grid is really cool, I'm really enjoying using it :)This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-06-03 19:30:34,2020-07-21 00:08:58,2020-07-21 00:08:57
https://github.com/OpenMined/PySyft/issues/3648,"['bug ', 'status: stale :bread:']",Cannot serialize NodeClient when `test_mul_shared_tensors()` using GridNode as remote server,"Cannot serialize NodeClient when `test_mul_shared_tensors()` using GridNode as remote server## Description
When multiplying two encrypted tensors, it occurs a `Cannot serialize NodeClient object` error
However, there's no error when the version of `syft` changed to 0.2.5
## How to Reproduce
```
import syft as sy
import torch as th
from syft.workers.node_client import NodeClient

hook = sy.TorchHook(th)
alice = NodeClient(hook, ""ws://<ip>:<port>"", id=""alice"")
bob = NodeClient(hook, ""ws://<ip>:<port>"", id=""bob"")
charlie = NodeClient(hook, ""ws://<ip>:<port>"", id=""charlie"")
grid = sy.PrivateGridNetwork(alice, bob, charlie)

x = th.tensor([[ 0.9039,  0.6291,  1.0795],
        [ 0.1586,  2.1939, -0.4900],
        [-0.1909, -0.7503,  1.9355]])

y = th.tensor([[ 0.9039,  0.1586, -0.1909],
        [ 0.6291,  2.1939, -0.7503],
        [ 1.0795, -0.4900,  1.9355]])

x_s = x.fix_prec().share(alice, bob, crypto_provider=charlie)
y_s = y.fix_prec().share(alice, bob, crypto_provider=charlie)
result_s = x_s.matmul(y_s)
```

## Expected Behavior
An error message as below

## Screenshots
```
Traceback (most recent call last):
  File ""test_mul_shared_tensors_copy_1.py"", line 24, in <module>
    result_s = x_s.matmul(y_s)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/generic/frameworks/hook/hook.py"", line 210, in overloaded_native_method
    response = method(*new_args, **new_kwargs)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/precision.py"", line 432, in matmul
    response = getattr(new_self, ""matmul"")(*new_args, **new_kwargs)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 648, in matmul
    return self._private_mul(other, ""matmul"")
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 538, in _private_mul
    shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field, self.dtype)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/mpc/spdz.py"", line 34, in spdz_mul
    crypto_provider, cmd, field, dtype, x_sh.shape, y_sh.shape, locations
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/mpc/beaver.py"", line 39, in request_triple
    res.share(*locations, field=field, dtype=dtype, crypto_provider=crypto_provider).get().child
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/frameworks/torch/tensors/interpreters/native.py"", line 909, in share
    **kwargs_,
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/generic/pointers/pointer_tensor.py"", line 382, in share
    response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/workers/base.py"", line 628, in send_command
    ret_val = self.send_msg(message, location=recipient)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/workers/base.py"", line 272, in send_msg
    bin_message = sy.serde.serialize(message, worker=self)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/serde/serde.py"", line 45, in serialize
    return strategy(obj, worker, simplified, force_full_simplification)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/serde/msgpack/serde.py"", line 337, in serialize
    return _serialize_msgpack_binary(simple_objects)
  File ""/home/billy/billy_ws/fl_0529/PySyft/syft/serde/msgpack/serde.py"", line 291, in _serialize_msgpack_binary
    binary = msgpack_lib.dumps(simple_objects)
  File ""/home/billy/miniconda3/envs/py3.6-0529/lib/python3.6/site-packages/msgpack/__init__.py"", line 35, in packb
    return Packer(**kwargs).pack(o)
  File ""msgpack/_packer.pyx"", line 286, in msgpack._cmsgpack.Packer.pack
  File ""msgpack/_packer.pyx"", line 292, in msgpack._cmsgpack.Packer.pack
  File ""msgpack/_packer.pyx"", line 289, in msgpack._cmsgpack.Packer.pack
  File ""msgpack/_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack/_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack/_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  [Previous line repeated 3 more times]
  File ""msgpack/_packer.pyx"", line 283, in msgpack._cmsgpack.Packer._pack
TypeError: can not serialize 'NodeClient' object

```

## System Information
 - OS Version: Ubuntu 18.04
 - Syft: 0.2.6
 - Language Version: Python 3.6
 - Package Manager Version: Conda 4.8.2
Thanks @bobsonlin26 , could you include the label `grid`?> Thanks @bobsonlin26 , could you include the label `grid`?

I don't know how to add a new label....
(I've tried to edit this issue, but no option for me to apply a new label)
Maybe it's because I'm not a contributor/member (?@LaRiffle @Syzygianinfern0  , I guess you have been working in multiplication of AST . I remember a bug related with this #3496 and maybe is related...This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.I'm wondering why would a NodeClient need to be sent?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",6,2020-05-31 17:47:10,2020-08-23 00:12:28,2020-08-23 00:12:28
https://github.com/OpenMined/PySyft/issues/3632,"['bug ', 'status: stale :bread:', 'status: investigating :mag:']",The MNIST train failed after several iterations with error 'typeError: addcmul...',"The MNIST train failed after several iterations with error 'typeError: addcmul...'I followed the tutorials listed as below  
https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2006%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb

to familiar with the Federated Learning on MNIST using CNN,but the train failed after several iterations with error 'typeError: addcmul_() takes 2 positional arguments but 3 were given' ,refer to below for the detail log :

```
Train Epoch: 1 [0/60032 (0%)]   Loss: 2.308438
Train Epoch: 1 [640/60032 (1%)] Loss: 1.284017
Train Epoch: 1 [1280/60032 (2%)]        Loss: 1.071603
Train Epoch: 1 [1920/60032 (3%)]        Loss: 0.472174
Train Epoch: 1 [2560/60032 (4%)]        Loss: 0.981234
Train Epoch: 1 [3200/60032 (5%)]        Loss: 0.343123
Train Epoch: 1 [3840/60032 (6%)]        Loss: 0.369976
Train Epoch: 1 [4480/60032 (7%)]        Loss: 0.250593
Train Epoch: 1 [5120/60032 (9%)]        Loss: 0.197793
Train Epoch: 1 [5760/60032 (10%)]       Loss: 0.254211
Train Epoch: 1 [6400/60032 (11%)]       Loss: 0.309393
Train Epoch: 1 [7040/60032 (12%)]       Loss: 0.252659
Train Epoch: 1 [7680/60032 (13%)]       Loss: 0.454773
Train Epoch: 1 [8320/60032 (14%)]       Loss: 0.271393
Train Epoch: 1 [8960/60032 (15%)]       Loss: 0.178069
Train Epoch: 1 [9600/60032 (16%)]       Loss: 0.119595
Train Epoch: 1 [10240/60032 (17%)]      Loss: 0.256008
Train Epoch: 1 [10880/60032 (18%)]      Loss: 0.191856
Train Epoch: 1 [11520/60032 (19%)]      Loss: 0.172837
Train Epoch: 1 [12160/60032 (20%)]      Loss: 0.249328
Train Epoch: 1 [12800/60032 (21%)]      Loss: 0.297089
Train Epoch: 1 [13440/60032 (22%)]      Loss: 0.254361
Train Epoch: 1 [14080/60032 (23%)]      Loss: 0.223871
Train Epoch: 1 [14720/60032 (25%)]      Loss: 0.200911
Train Epoch: 1 [15360/60032 (26%)]      Loss: 0.176920
Train Epoch: 1 [16000/60032 (27%)]      Loss: 0.117337
Train Epoch: 1 [16640/60032 (28%)]      Loss: 0.222319
Train Epoch: 1 [17280/60032 (29%)]      Loss: 0.344136
Train Epoch: 1 [17920/60032 (30%)]      Loss: 0.576891
Train Epoch: 1 [18560/60032 (31%)]      Loss: 0.170682
Train Epoch: 1 [19200/60032 (32%)]      Loss: 0.306101
Train Epoch: 1 [19840/60032 (33%)]      Loss: 0.282047
Train Epoch: 1 [20480/60032 (34%)]      Loss: 0.092759
Train Epoch: 1 [21120/60032 (35%)]      Loss: 0.097649
Train Epoch: 1 [21760/60032 (36%)]      Loss: 0.179511
Train Epoch: 1 [22400/60032 (37%)]      Loss: 0.194570
Train Epoch: 1 [23040/60032 (38%)]      Loss: 0.092463
Train Epoch: 1 [23680/60032 (39%)]      Loss: 0.105520
Train Epoch: 1 [24320/60032 (41%)]      Loss: 0.119190
Train Epoch: 1 [24960/60032 (42%)]      Loss: 0.097020
Train Epoch: 1 [25600/60032 (43%)]      Loss: 0.109687
Train Epoch: 1 [26240/60032 (44%)]      Loss: 0.071690
Train Epoch: 1 [26880/60032 (45%)]      Loss: 0.134879
Train Epoch: 1 [27520/60032 (46%)]      Loss: 0.249261
Train Epoch: 1 [28160/60032 (47%)]      Loss: 0.316798
Train Epoch: 1 [28800/60032 (48%)]      Loss: 0.065665
Train Epoch: 1 [29440/60032 (49%)]      Loss: 0.063461
Traceback (most recent call last):
  File ""d.py"", line 158, in <module>
    main()
  File ""d.py"", line 148, in main
    train(args, model, device, federated_train_loader, optimizer, epoch)
  File ""d.py"", line 50, in train
    optimizer.step()
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\torch\optim\lr_scheduler.py"", line 66, in wrapper
    return wrapped(*args, **kwargs)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\torch\optim\adadelta.py"", line 72, in step
    square_avg.mul_(rho).addcmul_(1 - rho, grad, grad)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 466, in overloaded_native_method
    response = method(*new_args, **new_kwargs)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 628, in overloaded_pointer_method
    response = owner.send_command(location, command)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\base.py"", line 638, in send_command
    ret_val = self.send_msg(message, location=recipient)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\base.py"", line 290, in send_msg
    bin_response = self._send_msg(bin_message, location)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\virtual.py"", line 15, in _send_msg
    return location._recv_msg(message)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\virtual.py"", line 19, in _recv_msg
    return self.recv_msg(message)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\base.py"", line 327, in recv_msg
    response = self._message_router[type(msg)](msg)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\base.py"", line 469, in execute_tensor_command
    return self.execute_computation_action(cmd.action)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\workers\base.py"", line 507, in execute_computation_action
    getattr(_self, op_name)(*args_, **kwargs_)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 427, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\syft\generic\frameworks\hook\hook.py"", line 423, in overloaded_native_method
    response = method(*args, **kwargs)
TypeError: addcmul_() takes 2 positional arguments but 3 were given
```


**The python packages installed as below:**
```
Package            Version
------------------ -------------------
aiounittest        1.3.1
alembic            1.4.2
appdirs            1.4.4
atomicwrites       1.4.0
attrs              19.3.0
black              19.10b0
bleach             3.1.0
certifi            2020.4.5.1
cffi               1.14.0
chardet            3.0.4
Click              7.0
colorama           0.4.3
coverage           5.1
cryptography       2.9.2
defusedxml         0.6.0
dnspython          1.16.0
entrypoints        0.3
eventlet           0.24.1
Flask              1.1.1
Flask-Cors         3.0.7
Flask-Executor     0.9.3
Flask-Migrate      2.5.3
Flask-SocketIO     4.2.1
Flask-Sockets      0.2.1
Flask-SQLAlchemy   2.4.3
Flask-Testing      0.8.0
gevent             1.4.0
gevent-websocket   0.10.1
greenlet           0.4.15
grid               0.7.1
gunicorn           19.9.0
idna               2.8
importlib-metadata 1.5.0
ipykernel          5.1.4
ipython            7.13.0
ipython-genutils   0.2.0
ipywidgets         7.5.1
itsdangerous       1.1.0
jedi               0.16.0
Jinja2             2.10.1
jsonschema         3.2.0
jupyter            1.0.0
jupyter-client     6.1.2
jupyter-console    6.1.0
jupyter-core       4.6.3
lz4                3.0.2
Mako               1.1.2
MarkupSafe         1.1.1
mkl-fft            1.0.15
mkl-random         1.1.0
mkl-service        2.3.0
monotonic          1.5
more-itertools     8.3.0
msgpack            1.0.0
nbconvert          5.6.1
nbformat           5.0.4
notebook           6.0.3
numpy              1.18.1
olefile            0.46
packaging          20.4
pathspec           0.8.0
phe                1.4.0
Pillow             6.2.2
pip                20.0.2
pluggy             0.13.1
prometheus-client  0.7.1
prompt-toolkit     3.0.4
protobuf           3.11.3
psycopg2-binary    2.8.5
py                 1.8.1
pycparser          2.20
Pygments           2.6.1
PyGrid             0.0.1
PyJWT              1.7.1
pyparsing          2.4.7
pyrsistent         0.16.0
pysyft             0.0.1
pytest             5.4.2
python-dateutil    2.8.1
python-editor      1.0.4
python-engineio    3.12.1
python-socketio    4.5.1
pywinpty           0.5.7
pyzmq              18.1.1
qtconsole          4.7.2
QtPy               1.9.0
regex              2020.5.14
requests           2.22.0
requests-toolbelt  0.9.1
scipy              1.4.1
Send2Trash         1.5.0
setuptools         46.1.3.post20200330
six                1.14.0
SQLAlchemy         1.3.17
syft               0.2.5
syft-proto         0.4.6
tblib              1.6.0
terminado          0.8.3
testpath           0.4.4
toml               0.10.1
torch              1.4.0
torchvision        0.5.0
tornado            4.5.3
traitlets          4.3.3
typed-ast          1.4.1
urllib3            1.25.8
wcwidth            0.1.9
webencodings       0.5.1
websocket-client   0.57.0
websockets         8.1
Werkzeug           0.15.3
wheel              0.34.2
widgetsnbextension 3.5.1
wincertstore       0.2
zipp               2.2.0

```

 **The code d.py attached** 

```
from __future__ import print_function
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.optim.lr_scheduler import StepLR

import syft as sy  # <-- NEW: import the Pysyft library




class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.5)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output


def train(args, model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        model.send(data.location) # <-- NEW: send the model to the right location
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        model.get() # <-- NEW: get the model back
        '''
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
        '''
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # <-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
            
def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss
            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))


def main():

    hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
    bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob
    alice = sy.VirtualWorker(hook, id=""alice"")  # <-- NEW: and alice

    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
    parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                        help='input batch size for training (default: 64)')
    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=4, metavar='N',
                        help='number of epochs to train (default: 14)')
    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',
                        help='learning rate (default: 1.0)')
    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',
                        help='Learning rate step gamma (default: 0.7)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disables CUDA training')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')

    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
    args = parser.parse_args()
    use_cuda = not args.no_cuda and torch.cuda.is_available()

    torch.manual_seed(args.seed)

    device = torch.device(""cuda"" if use_cuda else ""cpu"")

    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}
    '''
    train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=True, download=True,
                       transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=args.batch_size, shuffle=True, **kwargs)
    '''
    federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
            datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

    test_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=False, transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=args.test_batch_size, shuffle=True, **kwargs)

    model = Net().to(device)
    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)

    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)
    for epoch in range(1, args.epochs + 1):
        train(args, model, device, federated_train_loader, optimizer, epoch)
        test(model, device, test_loader)
        scheduler.step()

    print ('done')
    #if args.save_model:
    #    torch.save(model.state_dict(), ""mnist_cnn.pt"")


if __name__ == '__main__':
    main()
`
```Hmm, reading the stack trace, it looks like the optimizer passes the same grad to `addcmul_` twice, which looks right [according to the Torch docs](https://pytorch.org/docs/master/generated/torch.addcmul.html#torch-addcmul).
```
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\torch\optim\adadelta.py"", line 72, in step
    square_avg.mul_(rho).addcmul_(1 - rho, grad, grad)
```
I wonder if it has something to do with the way the operation is de/serialized and reconstructed on the remote `Worker`? Might have to try to try to replicate and dig into it with a debugger.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-05-29 08:48:54,2020-07-06 00:08:19,2020-07-06 00:08:19
https://github.com/OpenMined/PySyft/issues/3624,"['bug ', 'status: stale :bread:', 'status: investigating :mag:']",ERROR: Could not find a version that satisfies the requirement websockets~=8.1.0 (from syft[udacity]),"ERROR: Could not find a version that satisfies the requirement websockets~=8.1.0 (from syft[udacity])## Description
I am trying to run `pip install syft[udacity]` but it is complaining about version mentioned not available.

## How to Reproduce
1. Go to windows command prompt
2. Run `pip install syft[udacity]` 

## Expected Behavior
Should install syft.

## System Information
 - OS: windows 10

## Additional Context
```
ERROR: Could not find a version that satisfies the requirement websockets~=8.1.0 (from syft[udacity]) (from versions: 1.0, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 3.0, 3.1, 3.2, 3.3, 3.4, 4.0, 4.0.1, 5.0, 5.0.1, 6.0, 7.0, 8.0, 8.0.1, 8.0.2)
ERROR: No matching distribution found for websockets~=8.1.0 (from syft[udacity])
```
Hmm, I'm not sure why that would happen, since it does look like there are [wheels available for `websockets 8.1` for Windows](https://pypi.org/project/websockets/#files).

Could it be a `pip cache` issue? Maybe try clearing it `pip cache purge` and then try re-installing from the requirements file again?I tried removing cache but same error occurred.In that case, could you post the full output from `pip install`? Also, what's your Python version?Hmm, I'm not able to reproduce on a fresh Windows 10 install with Python 3.7.7. I get an error installing Torch:
```
C:\Users\karl\AppData\Local\Programs\Python\Python37>pip install syft[udacity]
Collecting syft[udacity]
  Downloading syft-0.2.6-py3-none-any.whl (377 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 377 kB 1.6 MB/s
Collecting syft-proto~=0.4.5
  Downloading syft_proto-0.4.6-py3-none-any.whl (57 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57 kB 2.3 MB/s
Collecting phe~=1.4.0
  Downloading phe-1.4.0.tar.gz (35 kB)
Collecting scipy~=1.4.1
  Downloading scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.9 MB 6.4 MB/s
Collecting flask-socketio~=4.2.1
  Downloading Flask_SocketIO-4.2.1-py2.py3-none-any.whl (16 kB)
Collecting Pillow~=6.2.2
  Downloading Pillow-6.2.2-cp37-cp37m-win_amd64.whl (2.0 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 6.4 MB/s
ERROR: Could not find a version that satisfies the requirement torch~=1.4.0 (from syft[udacity]) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch~=1.4.0 (from syft[udacity])
```
But then if I follow the Torch instructions for a Windows install, I get:
```
C:\Users\karl\AppData\Local\Programs\Python\Python37>pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
Looking in links: https://download.pytorch.org/whl/torch_stable.html
Collecting torch==1.4.0+cpu
  Downloading https://download.pytorch.org/whl/cpu/torch-1.4.0%2Bcpu-cp37-cp37m-win_amd64.whl (77.4 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.4 MB 6.4 MB/s
Collecting torchvision==0.5.0+cpu
  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.5.0%2Bcpu-cp37-cp37m-win_amd64.whl (485 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485 kB 3.3 MB/s
Collecting six
  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)
Collecting pillow>=4.1.1
  Downloading Pillow-7.1.2-cp37-cp37m-win_amd64.whl (2.0 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 6.8 MB/s
Collecting numpy
  Downloading numpy-1.18.4-cp37-cp37m-win_amd64.whl (12.8 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.8 MB ...
Installing collected packages: torch, six, pillow, numpy, torchvision
Successfully installed numpy-1.18.4 pillow-7.1.2 six-1.15.0 torch-1.4.0+cpu torchvision-0.5.0+cpu
```
Which then allows me to try installing PySyft again, which gives this (emphasis mine):
```
C:\Users\karl\AppData\Local\Programs\Python\Python37>pip install syft[udacity]
Collecting syft[udacity]
  Using cached syft-0.2.6-py3-none-any.whl (377 kB)
Collecting requests~=2.22.0
  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57 kB 1.1 MB/s
Requirement already satisfied: torchvision~=0.5.0 in c:\users\karl\appdata\local\programs\python\python37\lib\site-packages (from syft[udacity]) (0.5.0+cpu)
Collecting syft-proto~=0.4.5
  Using cached syft_proto-0.4.6-py3-none-any.whl (57 kB)
Collecting tblib~=1.6.0
  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)
Collecting lz4~=3.0.2
  Downloading lz4-3.0.2-cp37-cp37m-win_amd64.whl (162 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162 kB 6.8 MB/s
Collecting msgpack~=1.0.0
  Downloading msgpack-1.0.0-cp37-cp37m-win_amd64.whl (72 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72 kB 5.1 MB/s  
>>> Collecting websockets~=8.1.0
>>> Downloading websockets-8.1-cp37-cp37m-win_amd64.whl (66 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66 kB ...
[...]
```
And then the install goes on to succeed. Syft currently only supports Python 3.6-3.7, so it could be a Python version thing?Can't reproduce with fresh py36 or py37 conda environments on Win10.
@vikas-ratan Please post output of your `pip debug --verbose`.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",6,2020-05-28 13:57:36,2020-07-06 00:08:21,2020-07-06 00:08:21
https://github.com/OpenMined/PySyft/issues/3580,"['bug ', 'status: stale :bread:']",torch.tensor.size() function may get wrong shape after the tensor is sending to a gpu.,"torch.tensor.size() function may get wrong shape after the tensor is sending to a gpu.I use syft to execute a FL task, I found sometimes the torch.tensor.size() will get wrong results.
Here I implement the following code in a ubuntu 16 system to show this bug: 
>>> import torch
>>> import syft as sy
>>> data = torch.randn([8, 24, 24, 24, 3, 5])
>>> target = torch.randn([8, 24, 24, 24, 3, 5])
>>> data = data.cuda()
targe>>> target = target.cuda()
>>> hook = sy.TorchHook(torch=torch)
>>> worker1 = sy.VirtualWorker(hook, id=""worker1"")
>>> data.send(worker1)
(Wrapper)>[PointerTensor | me:32788080090 -> worker1:15663574719]
>>> data.location
>>> data = data.send(worker1)
>>> data.location
<VirtualWorker id:worker1 #objects:1>
>>> target = target.send(worker1)
>>> target.location
<VirtualWorker id:worker1 #objects:2>
>>> data.size()
torch.Size([0])
>>> target.size()
torch.Size([0])
>>> data.shape
torch.Size([8, 24, 24, 24, 3, 5])
>>> target.shape
torch.Size([8, 24, 24, 24, 3, 5])
>>> 

As shown above, we can see that when one tensor has been sent to a gpu and a worker , it's .size() function get torch.Size([0]), I don't know why this happens, and it's .shape attribute still works.

Another problem I found is for a torch.nn.Module object, we name it as model, model.send(worker).cuda() may throw exception, while model.cuda().send(worker) works.Sadly, this is a known issue that we don't currently have a way to fix. See previous discussions in #2201, #2527, #3163, #3382, and #3554.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-05-21 08:02:51,2020-06-28 00:07:09,2020-06-28 00:07:09
https://github.com/OpenMined/PySyft/issues/3579,[],pate error,"pate error**Describe the bug**
Hi, I am following the udacity tutorial and I got stuck with this import error. I created an independent conda environment and installed pip install 'syft[udacity]'
However, I get stuck into this below error. Its not that the syft library is not installed. The following error only occurs when I run. Is there any solution to this problem?

```python
from syft.frameworks.torch.differential_privacy import pate
```

Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/ubuntu/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'


**Screenshots**

<img width=""1543"" alt=""á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-05-21 á„‹á…©á„’á…® 2 52 32"" src=""https://user-images.githubusercontent.com/38973453/82528027-cf04d980-9b72-11ea-94ec-17a372a0536b.png"">

**Additional context**
(pysyft) ubuntu@nipa2019-0087:~$ pip freeze
absl-py==0.9.0
astor==0.8.1
attrs==19.3.0
backcall==0.1.0
bleach==3.1.4
certifi==2020.4.5.1
chardet==3.0.4
click==7.1.2
decorator==4.4.2
defusedxml==0.6.0
entrypoints==0.3
Flask==1.1.2
Flask-SocketIO==4.2.1
gast==0.2.2
google-pasta==0.2.0
grpcio==1.29.0
h5py==2.10.0
idna==2.8
importlib-metadata==1.5.0
ipykernel==5.1.4
ipython==7.13.0
ipython-genutils==0.2.0
ipywidgets==7.5.1
itsdangerous==1.1.0
jedi==0.17.0
Jinja2==2.11.2
jsonschema==3.2.0
jupyter==1.0.0
jupyter-client==6.1.3
jupyter-console==6.1.0
jupyter-core==4.6.3
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.2
lz4==3.0.2
Markdown==3.2.2
MarkupSafe==1.1.1
mistune==0.8.4
msgpack==1.0.0
nbconvert==5.6.1
nbformat==5.0.6
notebook==6.0.3
numpy==1.18.4
opt-einsum==3.2.1
pandocfilters==1.4.2
parso==0.7.0
pexpect==4.8.0
phe==1.4.0
pickleshare==0.7.5
Pillow==6.2.2
prometheus-client==0.7.1
prompt-toolkit==3.0.4
protobuf==3.12.0
ptyprocess==0.6.0
Pygments==2.6.1
pyrsistent==0.16.0
python-dateutil==2.8.1
python-engineio==3.12.1
python-socketio==4.5.1
PyYAML==5.3.1
pyzmq==18.1.1
qtconsole==4.7.4
QtPy==1.9.0
requests==2.22.0
scipy==1.4.1
Send2Trash==1.5.0
six==1.14.0
syft==0.2.5
syft-proto==0.4.4
tblib==1.6.0
tensorboard==1.15.0
tensorflow==1.15.3
tensorflow-estimator==1.15.1
termcolor==1.1.0
terminado==0.8.3
testpath==0.4.4
tf-encrypted==0.5.9
torch==1.4.0
torchvision==0.5.0
tornado==4.5.3
traitlets==4.3.3
urllib3==1.25.9
wcwidth==0.1.9
webencodings==0.5.1
websocket-client==0.57.0
websockets==8.1
Werkzeug==1.0.1
widgetsnbextension==3.5.1
wrapt==1.12.1
zipp==3.1.0
https://github.com/udacity/private-ai/pull/22#issue-368165596",1,2020-05-21 05:54:36,2020-05-21 06:06:49,2020-05-21 06:06:49
https://github.com/OpenMined/PySyft/issues/3562,"['bug ', 'status: stale :bread:', 'status: investigating :mag:']",Error: add_() takes 1 positional argument but 2 were given,"Error: add_() takes 1 positional argument but 2 were givenHi there, I'm trying out FL on the wisonsin breast cancer dataset, and I get the following error while I try to train.
 `Error : add_() takes 1 positional argument but 2 were given`
Here's a snippet of the training function, any help on why this occurs would be appreciated. Let me know if anything else is needed.
`def train(args, model, device, train_loader, optimizer, epoch):`
    `model.train()`
    `for batch_idx, (inputs, targets) in enumerate(federated_train_loader):` # <-- now it is a distributed   
       dataset
        `model.send(inputs.location)` # <-- NEW: send the model to the right location
        `inputs, targets = inputs.to(device), targets.to(device)`
        `optimizer.zero_grad()`
        `output = model(inputs.float())`
        `loss = criterion(output, targets.float())`
        `loss.backward()`
        `optimizer.step()`
        `model.get()` # <-- NEW: get the model back
        `if (batch_idx % args.log_interval) == 0:`
          `loss_int = loss.get()`
`device = torch.device(""cpu"")`
`for epoch in range(1, args.epochs):`
    `train(args, model, device, federated_train_loader, opt, epoch)`Hello! Thank you for reporting this, could you provide:

1. the full script to reproduce the error.
2. the stack trace/logging if you have.
3. syft and OS version.

Thank you!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-05-20 14:39:26,2020-07-06 00:08:25,2020-07-06 00:08:25
https://github.com/OpenMined/PySyft/issues/3558,['bug '],'VirtualWorker' object has no attribute '_tensors' in tutorial - 9,"'VirtualWorker' object has no attribute '_tensors' in tutorial - 9I am completely new to PySyft and got an error of ""VirtualWorker' object has no attribute '_tensors"", when I am working in Encrypted Domain Computation. Please help me.

import torch
import syft as sy
hook = sy.TorchHook(torch)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
bill = sy.VirtualWorker(hook, id=""bill"")

x = torch.tensor([25])

x
tensor([25])

x = torch.tensor([25]).share(bob, alice, bill)

bobs_share = list(bob._tensors.values())[0]


---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-6-66d08ba6d652> in <module>()
     13 x = torch.tensor([25]).share(bob, alice, bill)
     14 
---> 15 bobs_share = list(bob._tensors.values())[0]

AttributeError: 'VirtualWorker' object has no attribute '_tensors'@vtanwar-iitr I think this was broken by a recent change. Try `bob.object_store._tensors`? @karlhigley Thanks for your reply..

I tried ""ob.object_store._tensors"" but this is not working showing same error..

VirtualWorker' object has no attribute 'object_store

However, I reinstalled the complete Syft and other dependencies in a new Conda environment. It's working great.

The query has been resolved , therefore I am closing this issue.",3,2020-05-20 07:25:12,2020-05-20 17:08:25,2020-05-20 17:08:25
https://github.com/OpenMined/PySyft/issues/3547,[],torch.autograd.grad support/usage in PySyft?,"torch.autograd.grad support/usage in PySyft?**Describe the bug**
I would like to use torch.autograd.grad to calculate gradients. The input parameters are in the same WebsocketClientWorker. It would report this error:

> RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

If I fetch both parameters using tensor.copy().get(), all the grad would be None because there is no grad_fn.

However, if I remove PySyft, my tensors contains grad_fn and it runs correctly without error

**To Reproduce**
`
loss = self.net.loss(trn_X, trn_y) 

gradients = torch.autograd.grad(loss, self.net.weights())
`

**Expected behavior**
No error. Not-None gradients.

**Desktop (please complete the following information):**
 - OS: Ubuntu 18.04

**Additional context**
I guess there might be a workaround or hook for torch.autograd.grad in PySyft, so I didn't put much details of my code. How could I use torch.autograd.grad for remote tensor objects?
Hi @KunlinY - Iâ€™m afraid this is a known issue which will be fixed in the upcoming refactor. Look for the release of syft 0.3. Hi @KunlinY did you manage to solve this? I am getting the same error when I use torch.autograd.grad",2,2020-05-18 18:10:23,2020-06-21 20:42:08,2020-05-29 00:24:39
https://github.com/OpenMined/PySyft/issues/3546,"['bug ', 'good first issue :mortar_board:']",Jupyter bug due to Tornado when following readme pre-installation,"Jupyter bug due to Tornado when following readme pre-installationI followed the installation guide in the readme and had an issue using Jupyter due to its incompatibility with Tornado.

**To Reproduce**
Steps to reproduce the behavior:
1. Follow pre-installation and installation guide, Install virtual environment  
2. Run `conda install jupyter notebook ` to install `jupyter>6`
3. Running `pip install 'syft[udacity]'` will install `tornado==4.5.3` as required by [pip-dep requirements](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements.txt)

**Expected behavior**
run `jupyter notebook` and you will not be able to see files or do any work.

![jupyter_acting](https://user-images.githubusercontent.com/51087091/82234559-914c4a80-98ff-11ea-830f-4ca781b580d3.png)

**Additional Context**
As stated by [ltalirz](https://github.com/ltalirz) ""this occurs when using notebook>=6 with tornado<5
E.g. try pip install 'notebook<6' or conda install 'notebook<6'.""

See [related issue](https://github.com/jupyter/notebook/issues/2400)

**Temporary solution**
`pip install 'notebook<6'` worked for me

I hope this can be fixed as it will prevent new people from doing any work without looking up a solution for this first.
Hmm, a compatible notebook version is listed in [`requirements_notebook.txt`](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_notebooks.txt#L2). Should it also be in `requirements_udacity.txt`?Alternately, maybe it would be cleaner to add the notebook requirements to the `udacity` extras in [`setup.py`](https://github.com/OpenMined/PySyft/blob/master/setup.py#L53)?Thanks for replying @karlhigley 
Any or both solutions look great. You could also add the `jupyter<6` version requirement to the readme  Jupyter install or `tornado>5` to [pip-dep requirements](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements.txt)

I saw that it's listed in [requirements_notebook.txt](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_notebooks.txt#L2) but you won't install those requirements if you follow the readme. Maybe installing with `python setup.py install` won't yield this bug but I was not able to do so due to an `access denied` error, which could be another issue by the way.Hi, I would like to work on this issue. Please, go ahead @rajathpatel23 Thank youPR created: [PR3605](https://github.com/OpenMined/PySyft/pull/3605)Closed by #3606",8,2020-05-18 16:07:40,2020-05-28 17:11:55,2020-05-28 17:11:55
https://github.com/OpenMined/PySyft/issues/3542,"['bug ', 'status: stale :bread:']",Assignment operator *= gives the wrong result! (for AdditiveSharingTensors),"Assignment operator *= gives the wrong result! (for AdditiveSharingTensors)The assignment operator `*=` doesn't multiply properly for AdditiveSharingTensors.

See this example:

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
x = x.share(bob, alice, crypto_provider=bob)

z = x[0]
for i in range(1, len(x)):
    z *= x[i]
z.get()  # <-- returns tensor(1)!
```

This gives `tensor(1)`, which is totally wrong!

Doing the assignment explicitly works, e.g. `z = z * x[i]`.

The addition assignment operator seems to work with no problems, e.g. `z += x[i]` works correctly.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.AdditiveSharingTensors can be multiplied with long tensors and fixedPrecisionTensors
Don't directly multiply floats with AdditiveSharingTensor  as an error will come when you multiply an AdditiveSharingTensors with a FloatTensor.
But sharing with fixed_precision we will be able to handle float values like parameters in an encrypted way. 

1)if decrypt z
```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1,2,3,4])
x = x.share(bob, alice, crypto_provider=bob)
z = x[0].get() #z got decrypted 
for i in range(1, len(x)):
    z *= x[i]
z.get()  # <-- returns tensor(24)
```

2) if we use fixed_Precision
```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1.,2,3,4])
x = x.fix_prec().share(bob, alice, crypto_provider=bob)
z = x[0] # <--- z is encrypted
for i in range(1, len(x)):
    z *= x[i] # <-- inplace mul
z.get().float_prec()  # <-- returns tensor(24)
```",2,2020-05-18 05:48:56,2020-07-20 08:15:54,2020-06-28 00:07:13
https://github.com/OpenMined/PySyft/issues/3541,"['bug ', 'status: stale :bread:']",tensor.prod() does not return the right result (on an AdditiveSharingTensor) ,"tensor.prod() does not return the right result (on an AdditiveSharingTensor) `tensor.prod()` does not return the right result for an AdditiveSharingTensor. See:

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
print(x.prod())  # <- tensor(24)

x = x.share(bob, alice)
print(x.prod().get())  # <- tensor(-3063412363143033624)
```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1,2,3,4])
print(x.prod())  # <- tensor(24)
x.fix_prec().share(bob, alice, crypto_provider=bob)
x.prod() # <- tensor(24)
```

AST can be multiplied with long tensors and fixedPrecisionTensors
Don't directly multiply floats with AdditiveSharingTensor (AST) as an error will come when you multiply an AST with a FloatTensor.",2,2020-05-18 05:02:16,2020-07-20 08:15:43,2020-06-28 00:07:14
https://github.com/OpenMined/PySyft/issues/3540,"['bug ', 'status: stale :bread:']",Error when testing equality of AdditiveSharingTensors (without a crypto_provider?),"Error when testing equality of AdditiveSharingTensors (without a crypto_provider?)When I try to test equality of two AdditiveSharingTensors (`x == y`), it fails with a `ObjectNotFoundError` error. 

Here's a basic code sample to reproduce:

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
y = th.tensor([2,-1,1,0])
x = x.share(bob, alice)
y = y.share(bob, alice)

z = x == y
z.get()
```

This fails on the `==` line with: 

```
ObjectNotFoundError: Object ""7070927336"" not found on worker!!! You just tried to interact with an object ID:7070927336 on <VirtualWorker id:me #objects:0> which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines. If you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!
```

However, this seems to work if I add a separate worker as the `crypto_provider`. For example, if you replace the two lines with `.share()` above with:

```python
secure_worker = sy.VirtualWorker(hook, id=""secure_worker"")
x = x.share(bob, alice, crypto_provider=secure_worker)
y = y.share(bob, alice, crypto_provider=secure_worker)
```

^This works. Is this a bug? Or intended behavior (where is it documented)? Same problem for multiplication!

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
y = th.tensor([2,-1,1,0])
x = x.share(bob, alice)
y = y.share(bob, alice)

z = x * y  # <-- ObjectNotFoundError
z.get()
```

Only addition (`x + y`) works without specifying a `crypto_provider`.> Same problem for multiplication!
> 
> ```python
> import syft as sy
> import torch as th
> hook = sy.TorchHook(th)
> 
> bob = sy.VirtualWorker(hook, id=""bob"")
> alice = sy.VirtualWorker(hook, id=""alice"")
> 
> x = th.tensor([1,2,3,4])
> y = th.tensor([2,-1,1,0])
> x = x.share(bob, alice)
> y = y.share(bob, alice)
> 
> z = x * y  # <-- ObjectNotFoundError
> z.get()
> ```
> 
> Only addition (`x + y`) works without specifying a `crypto_provider`.

Hey, so AST uses secure multiparty communication (SMPC) to perform the operations like multiplication, division. It uses `crypto provider` to generate the triplets which are necessary to perform this operations. So crypto provider is kind of necessary ðŸ™‚It seems like `share()` is overly permissive then. Until recently (when @Prtfw added an exception), `share()` could be called with no arguments. Something similar should probably happen here: a required argument that's missing should immediately raise an exception rather than allowing incorrect behavior.Thanks @sukhadj, I figured it was something like that. A few beginner questions:

1. What is AST?
2. Why does `x + y` work without a crypto provider and not `x * y`?
3. Can I read more about this in the documentation somewhere?
4. If `crypto_provider` is not always required for `.share()`, as an alternative to @karlhigley's suggestion, can the error message be more specific? e.g. `crypto_provider required for * operation on AdditiveSharingTensors` rather than an `ObjectNotFoundError`.I also had this equality issue, even with a crypto provider, only when `requires_grad = False`> Thanks @sukhadj, I figured it was something like that. A few beginner questions:
> 
>     1. What is AST?
AdditiveSharingTensor
>     2. Why does `x + y` work without a crypto provider and not `x * y`?
So addition is just basically adding alice's share of x with alice's share of y and then module it. You can see implementation of addition [here](https://github.com/OpenMined/PySyft/blob/6b55ba01e411537e5c43f44235d24c33bdbaadf0/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L413).
>     3. Can I read more about this in the documentation somewhere?
PySyft currently don't have extensive documentation right now. But you can find more about SPDZ and triplets [here](https://mortendahl.github.io/2017/09/03/the-spdz-protocol-part1/) (Not an expert of the subject so maybe others can suggest better resources maybe :smile: )
>     4. If `crypto_provider` is not always required for `.share()`, as an alternative to @karlhigley's suggestion, can the error message be more specific? e.g. `crypto_provider required for * operation on AdditiveSharingTensors` rather than an `ObjectNotFoundError`.
That's correct we should definitely raise a warning during the sharing and exception when multiplying rather than object not found error. 
> I also had this equality issue, even with a crypto provider, only when `requires_grad = False`
Can you try again with pulling the master?
It works now when provided with crypto provider. Maybe changed in @LaRiffle's  FSS PR.Does `==` work if you set `requires_grad = False` in the `share` method?Will be solved by #3578 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",10,2020-05-18 04:07:20,2020-06-28 00:07:15,2020-06-28 00:07:15
https://github.com/OpenMined/PySyft/issues/3527,"['bug ', 'refactor ', 'status: stale :bread:', 'status: investigating :mag:']",`__del__` of ObjectPointers on Python shutdown throws errors ,"`__del__` of ObjectPointers on Python shutdown throws errors **Describe the bug**
On execution of even a very basic code such as 
```python
import torch as th
 
import syft as sy
 
hook = sy.TorchHook(th)
alice = sy.VirtualWorker(hook, id=""alice"")
bob = sy.VirtualWorker(hook, id=""bob"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")
 
a = torch.ones(1, 5)
a = a.encrypt(workers=[alice, bob], crypto_provider=crypto_provider)
```
a error is thrown when python shuts down. 

```
Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:51874166013 -> alice:36055571191]>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/syft/generic/pointers/object_pointer.py"", line 347, in __del__
  File ""/usr/local/lib/python3.6/dist-packages/syft/workers/base.py"", line 267, in send_msg
  File ""/usr/local/lib/python3.6/dist-packages/syft/serde/serde.py"", line 40, in serialize
ImportError: sys.meta_path is None, Python is likely shutting down
Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:83736240700 -> bob:18435096342]>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/syft/generic/pointers/object_pointer.py"", line 347, in __del__
  File ""/usr/local/lib/python3.6/dist-packages/syft/workers/base.py"", line 267, in send_msg
  File ""/usr/local/lib/python3.6/dist-packages/syft/serde/serde.py"", line 40, in serialize
ImportError: sys.meta_path is None, Python is likely shutting down
```
**To Reproduce**
Steps to reproduce the behavior:
1. Go to https://colab.research.google.com/drive/1CSQGnxDZo0TwMjERRpLYKTtDmQoIu9LK?usp=sharing or run given snippet pasted in a .py file from your terminal/IDE
2. See error

**Expected behavior**
Python must terminate without throwing an error@karlhigley not able to replicate the error, both in google colab and in local terminal.I have seen this happen before, though it may not be consistent. I think the cause is `PointerTensors` or `ObjectPointers` going out of scope, having their `__del__` method called (which attempts to send a message to the owner of the referenced object), and having that collide with Python shut down activities. There's not likely to be a quick fix for this though, because our GC implementation fundamentally relies on Python's GC, which offers no guarantees for when or whether the `__del__` method will be executed.

Long term, the solution is probably to come up with a better way to do distributed GC.@tudorcebere I've been thinking a lot about refactoring workers in order to make `Protocols` work, and I think we might want to consider having separate threads for message sending/receiving, message processing, and `Plan/Protocol` execution. If we did that, we'd need to be able to pass messages between threads, so we'd probably use thread-safe queues.

And if we had _that_, then maybe the `__del__` hook that gets called for garbage collection when objects go out of scope could add a delete message to the queue instead of directly trying to serialize and send it. That would turn this issue into ""Do we want to make sure outgoing delete messages are processed when Python shuts down? If so, how?""

Instead of sending outgoing delete messages when we shut down, it might make more sense for workers to GC remaining objects that came from workers they're no longer in contact with? Not sure, but seems possible.Thinking maybe we should create a milestone for async/multi-threaded workers and assign this issue to that milestone. Anyone else have thoughts on that? I can't see a good way to address this without some form of concurrency, but that doesn't mean there isn't one. ðŸ¤” @karlhigley I think this might be an awesome idea, workers really need some love, I like the idea of making send and receive on separate threads (could this help async workers as well?). This could be a step forward the actor model as well and the stack forwarding project. (maybe we would like to stick with some custom actor model?). I am not familiar with the GC behavior, but in my mind, the idea of adding a del message when an object goes out of scope could work really nice, (should make everything more transparent as well). The current GC behavior does send a delete message, but since our comms methods are currently synchronous and blocking, that means that garbage collection is a blocking operation. ðŸ™ This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",7,2020-05-14 06:37:51,2020-07-06 00:08:28,2020-07-06 00:08:28
https://github.com/OpenMined/PySyft/issues/3516,[],Update how rank_to_worker_id is stored in workers,"Update how rank_to_worker_id is stored in workers**Describe the bug**

An issue we had was that WebsocketServerWorker was storing the received rank_to_worker_id dictionary into `self` then our `crypten.load_from_party` function was trying to get that from `syft.local_worker`, a quick fix was made to store it in `syft.local_worker` as well as self, this will causes issues if :

- The worker running the server is also doing some crypten computation
- The worker running the server is doing crypten computation locally (using virtual workers)

The former was already present, but the second got introduced by the quick fix.

**Possible solution**

Store it in `self` and fetch it from the specific worker on `load_from_party`.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-05-13 13:52:52,2020-06-18 12:42:27,2020-06-18 12:42:27
https://github.com/OpenMined/PySyft/issues/3514,"['bug ', 'status: stale :bread:', 'status: investigating :mag:']","model.copy().get() cause ""clone() got an unexpected keyword argument 'memory_format'"" error","model.copy().get() cause ""clone() got an unexpected keyword argument 'memory_format'"" errorI tried to implement model averaging using the function provided by Tutorial 
""Federated Learning of a Recurrent Neural Network for text classification""

I uncomment this line:

""model_pointers = fed_avg_every_n_iters(model_pointers, iter, args.federate_after_n_batches)""

to run this function:
def fed_avg_every_n_iters(model_pointers, iter, federate_after_n_batches):
        models_local = {}
        
        if(iter % args.federate_after_n_batches == 0):
            for worker_name, model_pointer in model_pointers.items():
                #need to assign the model to the worker it belongs to.
                models_local[worker_name] = model_pointer.copy().get() ############# error here
            model_avg = utils.federated_avg(models_local)
           
            for worker in workers_virtual:
                model_copied_avg = model_avg.copy()
                model_ptr = model_copied_avg.send(worker) 
                model_pointers[worker.id] = model_ptr
                
        return(model_pointers)     

and the error message was:
TypeError: clone() got an unexpected keyword argument 'memory_format'@ZhechunZhou I have some guesses where this might come from, but it's a little bit difficult to pin down. Could you post a stack trace for this error?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.I meet the same problem. The key is to call get for the weight of the model instead of the model itself.",3,2020-05-13 11:03:44,2020-07-15 20:03:27,2020-07-05 00:08:44
https://github.com/OpenMined/PySyft/issues/3507,[],Adam and other stateful optimizers do not work on federated models,"Adam and other stateful optimizers do not work on federated modelsI have [a very basic FL setup](https://gist.github.com/kennysong/80b5c02f2506de39b5aa7c2abd6c4140) with 10 virtual workers training on MNIST.

Training the models works correctly with `torch.optim.SGD`. Switching to `torch.optim.Adam` or any other stateful optimizer (e.g. SGD with momentum, RMSProp, Adagrad) fails with this error on the `opt.step()` line:

```
TypeError: add_() takes 1 positional argument but 2 were given
```

Seems like a bug with how the PySyft hook overrides tensor methods. 

Here's [a notebook](https://gist.github.com/kennysong/80b5c02f2506de39b5aa7c2abd6c4140) that replicates the error.
Oh, just found a few duplicate bugs:

- #2070 
- #3349 

Looks like this is fixed by using the new PySyft optim wrapper.",1,2020-05-12 10:01:05,2020-05-12 10:08:13,2020-05-12 10:08:12
https://github.com/OpenMined/PySyft/issues/3503,"['bug ', 'good first issue :mortar_board:', 'testing ']",Flaky test ```test_spinup_time```,"Flaky test ```test_spinup_time```**Describe the bug**
```test_spinup_time```  fails during automated PR-checking test runs.

**Expected behavior**
Should pass reliably.

**Screenshots**
```
_______________________________ test_spinup_time _______________________________

hook = <syft.frameworks.torch.hook.hook.TorchHook object at 0x7f5ca2437710>

    def test_spinup_time(hook):
        """"""Tests to ensure that virtual workers intialized with 10000 data points
        load in under 1 seconds. This is needed to ensure that virtual workers
        spun up inside web frameworks are created quickly enough to not cause timeout errors""""""
        data = []
        for i in range(10000):
            data.append(torch.Tensor(5, 5).random_(100))
        start_time = time()
        dummy = sy.VirtualWorker(hook, id=""dummy"", data=data)
        end_time = time()
>       assert (end_time - start_time) < 1
E       assert (1589214859.5729005 - 1589214858.5710597) < 1
```

**LE**: Skip this test altogether from the automation pipelineI haven't figured out a good way to run the time-based tests. The efficiency tests are skipped during the builds, and maybe this one should be too?
> I haven't figured out a good way to run the time-based tests. The efficiency tests are skipped during the builds, and maybe this one should be too?

I think this is a good idea! Will edit the issue and also marking it ```Good first issue```",2,2020-05-11 16:57:47,2020-05-24 20:15:42,2020-05-24 20:15:42
https://github.com/OpenMined/PySyft/issues/3478,"['bug ', 'status: stale :bread:']",Serialize a Torch Paillier Tensor with encrypted values ,"Serialize a Torch Paillier Tensor with encrypted values **Describe the bug**
I am trying to serialize a torch Paillier Tensor (which has been previously encrypted) in order to send it/store it somewhere. I am getting the following error:
AttributeError: 'numpy.ndarray' object has no attribute 'grad'

**To Reproduce**
Steps to reproduce the behavior:
```python
import torch
import syft as sy
hook = sy.TorchHook(torch)
pub, pri = sy.keygen()

x_tensor = torch.Tensor([1, 2, 3])
x_encrypted = x_tensor.encrypt(protocol=""paillier"", public_key=pub)
x_serialized = sy.serde.serialize(obj=x_encrypted)
```
The last step ```sy.serde.serialize(obj=x_encrypted)``` would throw the error:
```
/usr/local/lib/python3.6/dist-packages/syft/generic/tensor.py in grad(self)
    121     @property
    122     def grad(self):
--> 123         child_grad = self.child.grad
    124         if child_grad is None:
    125             return None

AttributeError: 'numpy.ndarray' object has no attribute 'grad'
```
**Expected behavior**
```x_serialized``` should be a serialized tensor (with all its elements encrypted using paillier homomorphic encryption).

**Desktop (please complete the following information):**
 - OS: Windows 10

**Additional context**
I am new to the library so I might not be using the correct functions to serialize. However, the follow comment can be found in the sy.serde.serialize [file](https://github.com/OpenMined/PySyft/blob/11dc345fd71ab156edd0a99d49b1527a8f73092a/syft/serde/serde.py#L15):
```
## SECTION:  High Level Public Functions (these are the ones you use)
```
I tried modifying the ```python self.child.grad``` in a forked repo but then the next error message is:
```bash
\lib\site-packages\msgpack\__init__.py"", line 35, in packb
    return Packer(**kwargs).pack(o)
  File ""msgpack\_packer.pyx"", line 286, in msgpack._cmsgpack.Packer.pack
  File ""msgpack\_packer.pyx"", line 292, in msgpack._cmsgpack.Packer.pack
  File ""msgpack\_packer.pyx"", line 289, in msgpack._cmsgpack.Packer.pack
  File ""msgpack\_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack\_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack\_packer.pyx"", line 283, in msgpack._cmsgpack.Packer._pack
TypeError: can not serialize 'PaillierTensor' object
```
It looks like the external library [msgpack](https://msgpack-python.readthedocs.io/en/latest/api.html#msgpack.Packer) is having problems when transforming the 'PaillierTensor' object into binary code. 

Does anybody knows any other way to serializer a PaillierTensor? I think that the send function from Workers does serialize this kind of tensors I created a function myself to serialize a Paillier Tensor into a  json/string :D
I would love to contribute to the serde section of PySyft with this function but I am do not understand 100% all the functions and where would this function fit. Nevertheless, here is the code I wrote (if I can help in anything please let me know, it would be a honor to contribute.

```python
from syft.frameworks.torch.tensors.interpreters.paillier import PaillierTensor
from phe.paillier import EncryptedNumber, PaillierPublicKey
import numpy as np
import syft as sy
import torch
import json
hook = sy.TorchHook(torch)

def serialize_paillier(tensor):
  if (isinstance(tensor.child, PaillierTensor)):
    struct = {}
    first_element = tensor.child.child[0]
    if (isinstance(first_element,np.ndarray)):
      values = []
      struct['public_key'] = {'g': first_element[0].public_key.g, 'n': first_element[0].public_key.n}
      for subtensor in tensor.child.child:
        row = [(str(subtensor[i].ciphertext()), str(subtensor[i].exponent)) for i in range(len(subtensor))]
        values.append(row)
      struct['values'] = values
    else:
      struct['public_key'] = {'g': first_element.public_key.g, 'n': first_element.public_key.n}
      struct['values'] = [(str(tensor[i].ciphertext()), str(tensor[i].exponent)) for i in range(len(tensor))]
    return json.dumps(struct)
  else:
    raise TypeError(type(tensor))

def deserialize_paillier(obj):
  if (isinstance(obj,str)):
    struct = json.loads(obj)
    tensor = PaillierTensor()
    public_key = struct['public_key']
    pub = PaillierPublicKey(n=int(public_key['n']))
    if (isinstance(struct['values'][0][0], list)):    
      values = [ [EncryptedNumber(pub, int(x[0]), int(x[1])) for x in y] for y in struct['values'] ]
    else:
      values = [EncryptedNumber(pub, int(x[0]), int(x[1])) for x in struct['values']]
    tensor.child = np.array(values)
    syft_tensor = tensor.wrap()
    return syft_tensor
  else:
    raise TypeError(type(obj))

# The next lines are to test the functions
# Array declaration
array1 = np.array([1,4]) # 1 dimension array
array2 = np.array([[5,2,3],[1,4,4],[2,4,4],[2,4,4]]) # 3 or n dimension array

# Declaring a tensor
x_tensor1 = torch.Tensor(array1)
x_tensor2 = torch.Tensor(array2)

# Encrypting the tensor
pub, pri = sy.keygen()
x_encrypted1 = x_tensor1.encrypt(protocol=""paillier"", public_key=pub)
x_encrypted2 = x_tensor2.encrypt(protocol=""paillier"", public_key=pub)

# Serialization process
obj1 = serialize_paillier(x_encrypted1)
obj2 = serialize_paillier(x_encrypted2)

# Deserialization process
tensor1 = deserialize_paillier(obj1)
tensor2 = deserialize_paillier(obj2)

# Decrypting the tensor
x_decrypted1 = tensor1.decrypt(protocol=""paillier"", private_key=pri)
x_decrypted2 = tensor2.decrypt(protocol=""paillier"", private_key=pri)
``` This is related to #3510. If you look at [the bottom of `paillier.py`](https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/tensors/interpreters/paillier.py#L258-L295), there are two methods `simplify` and `detail`, which convert a `PaillierTensor` to Python primitives like `list`, `dict`, `int`, `str`, etc to prepare it for serialization with msgpack. The methods already exist but they don't have a corresponding test to verify that they actually work. There's a [stub for a test](https://github.com/OpenMined/PySyft/blob/368630afaba985ee9c26cc0aadd1c56c42bb38a6/test/serde/serde_helpers.py#L2012-L2032), but it still needs to be filled in.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue still exists no? Any update? I am trying to do the same but get the same error on serialization.Hi Usamazf! I was not able to solve it (It did not passed the testings) but I am using this function to serialize Paillier tensors:
```python
from syft.frameworks.torch.tensors.interpreters.paillier import PaillierTensor
from syft.serde.serde import deserialize
from phe.paillier import EncryptedNumber
from phe.paillier import PaillierPublicKey
from numpy import ndarray
from numpy import array


def serialize_paillier(element):
  # Case 1: tensor recursion
  if isinstance(element, torch.Tensor):
    paillier = element.child
    if isinstance(paillier, PaillierTensor):
      child = [serialize_paillier(subchild) for subchild in paillier.child]
      return {'n': paillier.pubkey.n, 'values': child} # in PaillierPublicKey g = n + 1
    else:
      raise TypeError(type(paillier))

  # Case 2: ndarray recursion
  elif isinstance(element, ndarray):
    return [serialize_paillier(subelement) for subelement in element]

  # Case 3: EncryptedNumber serialization
  elif isinstance(element, EncryptedNumber):
    return (str(element.ciphertext()), str(element.exponent))

  # Case 4: Unknown type
  else:
    raise TypeError(type(element))
def deserialize_paillier(struct, pub=None):
  # Case 1: dict recursion
  if isinstance(struct, dict):
    pub = PaillierPublicKey(n=int(struct['n']))
    child = [deserialize_paillier(substruct, pub) for substruct in struct['values']]
    # Building Paillier Tensor
    tensor = PaillierTensor()
    tensor.child = array(child)
    tensor.pubkey = pub
    return tensor.wrap()

  # Case 2: list recursion
  elif isinstance(struct, list):
    return [deserialize_paillier(substruct, pub) for substruct in struct]

  # Case 3: Tuple deserialization
  elif isinstance(struct, tuple):
    return EncryptedNumber(pub, int(struct[0]), int(struct[1]))

  # Case 4: Unknown type
  else:
    raise TypeError(type(struct))
```
In case you need a Encrypted Number Object to transform it to Paillier (for serialization) use:
```python
def to_paillier(element, public_key):
    if isinstance(element, torch.Tensor) and isinstance(element.child, PaillierTensor):
        element.child.pubkey = public_key
        child = element.child.child
        if isinstance(child, ndarray):
          return element
        elif isinstance(child, EncryptedNumber):
          element.child.child = array([child])
          return element
        else:
          raise Exception(""The tensor does not have an EncryptedNumber or a np.ndarray as child"")
    elif isinstance(element, PaillierTensor):
        element.pubkey = public_key
        return element.wrap()
    elif isinstance(element, ndarray):
        tensor = PaillierTensor()
        tensor.child = element
        tensor.pubkey = public_key
        return tensor.wrap()
    elif isinstance(element, list):
        tensor = PaillierTensor()
        tensor.child = array(element)
        tensor.pubkey = public_key
        return tensor.wrap()
    elif isinstance(element, EncryptedNumber):
        tensor = PaillierTensor()
        tensor.child = array([element])
        tensor.pubkey = public_key
        return tensor.wrap()
    else:
        raise TypeError(type(element))
```

I am actively working with Paillier tensors for my thesis and I would love to know what are you working on, maybe we can collaborate in something.@NicoSerranoP Excellent. Now I just need to figure out where I can serialize it when sending encrypted tensors to workers. Thanks you for sharing!

P.S. I have just started exploring privacy and communication efficiency in FL systems.@usamazf if you are planning to do federated learning with multiple people/users/data providers/parties then SMPC is the best way to go (PySyft has done an incredible work in that area)",8,2020-05-08 22:33:32,2020-07-26 15:30:11,2020-06-21 00:07:01
https://github.com/OpenMined/PySyft/issues/3471,"['bug ', 'testing ', 'status: stale :bread:', 'status: investigating :mag:']",`test_torch_tanh_approx` is flaky,"`test_torch_tanh_approx` is flaky**Describe the bug**
`test_torch_tanh_approx` often fails during automated PR-checking test runs.

**To Reproduce**
Run the test or the test suite a few times until it fails.

**Expected behavior**
Should pass reliably.

**Screenshots**
```
 ____________________ test_torch_tanh_approx[sigmoid-3-0.1] _____________________
 
 method = 'sigmoid', prec_frac = 3, tolerance = 0.1
 workers = {'alice': <VirtualWorker id:alice #objects:7>, 'bob': <VirtualWorker id:bob #objects:7>, 'charlie': <VirtualWorker id:charlie #objects:6>, 'james': <VirtualWorker id:james #objects:6>, ...}
 
     @pytest.mark.parametrize(
         ""method, prec_frac, tolerance"",
         [
             (""chebyshev"", 3, 3 / 100),
             (""chebyshev"", 4, 2 / 100),
             (""sigmoid"", 3, 10 / 100),
             (""sigmoid"", 4, 5 / 100),
         ],
     )
     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
         """"""
         Test the approximate tanh with different tolerance depending on
         the precision_fractional considered
         """"""
         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
     
         t = torch.tensor(range(-10, 10)) * 0.5
         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
         r_sh = t_sh.tanh(method)
         r = r_sh.get().float_prec()
         t = t.tanh()
         diff = (r - t).abs().max()
         norm = (r + t).abs().max() / 2
     
 >       assert (diff / (tolerance * norm)) < 1
 E       assert (tensor(0.1001) / (0.1 * tensor(1.0000))) < 1
 
 test/torch/tensors/test_precision.py:512: AssertionError
```

**Additional context**
Possible that several of the parameterized cases are flaky.
I will look on this.Seen this again, here:
```
2020-05-15T10:08:51.0720029Z =================================== FAILURES ===================================
2020-05-15T10:08:51.0721859Z ____________________ test_torch_tanh_approx[sigmoid-3-0.1] _____________________
2020-05-15T10:08:51.0722192Z 
2020-05-15T10:08:51.0722841Z method = 'sigmoid', prec_frac = 3, tolerance = 0.1
2020-05-15T10:08:51.0723543Z workers = {'alice': <VirtualWorker id:alice #objects:1>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:0>, ...}
2020-05-15T10:08:51.0723844Z 
2020-05-15T10:08:51.0724137Z     @pytest.mark.parametrize(
2020-05-15T10:08:51.0724423Z         ""method, prec_frac, tolerance"",
2020-05-15T10:08:51.0724702Z         [
2020-05-15T10:08:51.0724982Z             (""chebyshev"", 3, 3 / 100),
2020-05-15T10:08:51.0725298Z             (""chebyshev"", 4, 2 / 100),
2020-05-15T10:08:51.0725575Z             (""sigmoid"", 3, 10 / 100),
2020-05-15T10:08:51.0725839Z             (""sigmoid"", 4, 5 / 100),
2020-05-15T10:08:51.0726117Z         ],
2020-05-15T10:08:51.0726385Z     )
2020-05-15T10:08:51.0726666Z     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
2020-05-15T10:08:51.0726956Z         """"""
2020-05-15T10:08:51.0727241Z         Test the approximate tanh with different tolerance depending on
2020-05-15T10:08:51.0727539Z         the precision_fractional considered
2020-05-15T10:08:51.0727820Z         """"""
2020-05-15T10:08:51.0728136Z         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
2020-05-15T10:08:51.0728430Z     
2020-05-15T10:08:51.0728923Z         t = torch.tensor(range(-10, 10)) * 0.5
2020-05-15T10:08:51.0729246Z         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
2020-05-15T10:08:51.0729547Z         r_sh = t_sh.tanh(method)
2020-05-15T10:08:51.0729828Z         r = r_sh.get().float_prec()
2020-05-15T10:08:51.0730108Z         t = t.tanh()
2020-05-15T10:08:51.0730596Z         diff = (r - t).abs().max()
2020-05-15T10:08:51.0730890Z         norm = (r + t).abs().max() / 2
2020-05-15T10:08:51.0731163Z     
2020-05-15T10:08:51.0731433Z >       assert (diff / (tolerance * norm)) < 1
2020-05-15T10:08:51.0731714Z E       assert (tensor(0.1021) / (0.1 * tensor(1.0000))) < 1
2020-05-15T10:08:51.0731925Z 
```
[Link](https://pipelines.actions.githubusercontent.com/tPFNPqeRbvWdN0L3FU84cUvH4mGjAPQ3yYz8CFZWN08ePzUDwG/_apis/pipelines/1/runs/4726/signedlogcontent/4?urlExpires=2020-05-15T10%3A58%3A25.7158601Z&urlSigningMethod=HMACV1&urlSignature=LC4XWEEH8D9P7UbpZMTe1olEd4B3XTD2qrq7Frc81oU%3D)@gmuraru Is this a case where we should increase the tolerance on this test? I've hesitated to fix it that way, because I don't know how much that weakens the test assertion, but think I remember seeing similar tests adjusted that way in the past.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2020-05-08 13:38:36,2020-07-05 00:08:48,2020-07-05 00:08:48
https://github.com/OpenMined/PySyft/issues/3467,"['bug ', 'testing ']",test_fit[gaussian_mixture-1-cpu] is flaky,"test_fit[gaussian_mixture-1-cpu] is flaky**Describe the bug**
test_fit[gaussian_mixture-1-cpu] has undefined behavior between multiple runs.

**To Reproduce**
Run the tests multiple times.

**Expected behavior**
To be deterministic between similar runs.

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version: 20

Error:
assert loss_after < loss_before
assert tensor(0.6931, grad_fn=<NllLossBackward>) < tensor(0.6931, grad_fn=<NllLossBackward>)Closed because it was added an ```=``` sign in this [PR](https://github.com/OpenMined/PySyft/pull/3461/files#diff-1b4e80baf02b99d38e2a1837ac3620a8)Does it still fail though? (I think it does, but could be wrong.)Each time I have seen this failing was because there were the same values. Maybe we need to keep an eye open for this issue and if we see it again, re-open this? Cool, will reopen if I see it happen.",4,2020-05-08 09:51:38,2020-05-31 14:17:50,2020-05-31 02:29:12
https://github.com/OpenMined/PySyft/issues/3464,['bug '],New PySyft workers are created with FSS `Plans` in their object storage,"New PySyft workers are created with FSS `Plans` in their object storage**Describe the bug**
When a new worker is created, it comes with some `Plans` already loaded into the object storage:
```
{67822474598: <Plan Plan id:67822474598 owner:bob Tags: #fss_eq_plan_1 built>,
 42739784794: <Plan Plan id:42739784794 owner:bob Tags: #fss_eq_plan_2 built>,
 98376427733: <Plan Plan id:98376427733 owner:bob Tags: #fss_comp_plan_1 built>,
 48876976143: <Plan Plan id:48876976143 owner:bob Tags: #fss_comp_plan_2 built>,
 22552634480: <Plan Plan id:22552634480 owner:bob Tags: #xor_add_1 built>,
 96804360037: <Plan Plan id:96804360037 owner:bob Tags: #xor_add_2 built>}
```

**To Reproduce**
```
hook = TorchHook(torch)
bob = syft.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
bob._objects
```

**Expected behavior**
New workers should start with empty object stores.

**Additional context**
Probably a result of the recent Function Secret Sharing PR.
I confirm this bug as well",1,2020-05-07 17:57:13,2020-05-14 16:03:08,2020-05-14 16:03:08
https://github.com/OpenMined/PySyft/issues/3463,[],Value Error in torch_serde._detail_torch_tensor when calling async_fit from LAN WebSocketWorker,"Value Error in torch_serde._detail_torch_tensor when calling async_fit from LAN WebSocketWorkerHello All,

I'm referencing the advanced tutorial: [websocket-mnist-parallel](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets_mnist_parallel) and I'm running into a `ValueError: not enough values to unpack (expected 9, got 7)`. When running the servers and notebook from the same device, there are no issues, but when I switch to a different device for the notebook, get thrown the above error.

Again, the error locates when calling `async_fit` and specifically in the function `syft/serde/msgpack/torch_serde.py in _detail_torch_tensor(worker, tensor_tuple)`.

Running on two MBP on the same local network.
Syft version 0.2.4, syft-proto version 0.4.2, python version 3.8.2 on both devices.

Here's a full traceback:
```ValueError                                Traceback (most recent call last)
<ipython-input-24-40944cb95694> in <module>
      5     logger.info(""Training round %s/%s"", curr_round, args.training_rounds)
      6 
----> 7     results = await asyncio.gather(
      8         *[
      9             rwc.fit_model_on_worker(

~/Documents/async_learning/run_websocket_client.py in fit_model_on_worker(worker, traced_model, batch_size, curr_round, max_nr_batches, lr)
    368     )
    369     train_config.send(worker)
--> 370     loss = await worker.async_fit(dataset_key=""bank"", return_ids=[0])
    371     model = train_config.model_ptr.get().obj
    372     return worker.id, model, loss

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/workers/websocket_client.py in async_fit(self, dataset_key, device, return_ids)
    173 
    174         # Return the deserialized response.
--> 175         return sy.serde.deserialize(response)
    176 
    177     def fit(self, dataset_key: str, **kwargs):

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/serde.py in deserialize(binary, worker, strategy)
     67         object: the deserialized form of the binary input.
     68     """"""
---> 69     return strategy(binary, worker)

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in deserialize(binary, worker)
    380 
    381     simple_objects = _deserialize_msgpack_binary(binary, worker)
--> 382     return _deserialize_msgpack_simple(simple_objects, worker)
    383 
    384 

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in _deserialize_msgpack_simple(simple_objects, worker)
    371     # as msgpack's inability to serialize torch tensors or ... or
    372     # python slice objects
--> 373     return _detail(worker, simple_objects)
    374 
    375 

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/serde.py in _detail(worker, obj, **kwargs)
    497     """"""
    498     if type(obj) in (list, tuple):
--> 499         val = detailers[obj[0]](worker, obj[1], **kwargs)
    500         return _detail_field(obj[0], val)
    501     else:

/opt/anaconda3/envs/fedML/lib/python3.8/site-packages/syft/serde/msgpack/torch_serde.py in _detail_torch_tensor(worker, tensor_tuple)
    180     """"""
    181 
--> 182     (
    183         tensor_id,
    184         tensor_bin,

ValueError: not enough values to unpack (expected 9, got 7)```
PySyft doesn't yet support Python 3.8, so it could be related to that. Could you post the versions of PySyft and syft-proto running on each machine?After updating to lates version of syft (0.2.5), the issue has disappeared. Closing issue",2,2020-05-07 16:09:13,2020-05-07 16:26:09,2020-05-07 16:26:09
https://github.com/OpenMined/PySyft/issues/3459,[],Syft and Jupyter have incompatible requirements for tornado,"Syft and Jupyter have incompatible requirements for tornadoIn a fresh venv, run:

```
pip install jupyter
pip install syft
```

Jupyter requires `tornado>=5.0`, while Syft requires `tornado==4.5.3`. After running the second line, it downgrades tornado to `4.5.3` which breaks Jupyter.

Logs:

```
> pip install syft
...
ERROR: notebook 6.0.3 has requirement tornado>=5.0, but you'll have tornado 4.5.3 which is incompatible.
Installing collected packages: websocket-client, protobuf, syft-proto, websockets, tblib, Pillow, numpy, torch, torchvision, tornado, idna, chardet, urllib3, certifi, requests, Werkzeug, click, itsdangerous, Flask, lz4, scipy, phe, msgpack, python-engineio, python-socketio, flask-socketio, syft
  Found existing installation: tornado 6.0.4
    Uninstalling tornado-6.0.4:
      Successfully uninstalled tornado-6.0.4
  Running setup.py install for tornado ... done
  Running setup.py install for phe ... done
```You can find a set of compatible versions in the [notebook requirements file](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_notebooks.txt). You can also use `make notebook` to set up an environment.Ah, thanks for the reference. In case someone else runs into the same problem (the Jupyter PyPi package is kind of confusingly versioned), I got this working in a venv with:

```
pip install 'syft[udacity]'
pip install notebook==5.7.8  # This installs normal jupyter as well
pip install jupyterlab  # Optional, currently working at 2.1.2
```

Didn't try `make notebook` since that seems more for doing development in the Syft repo than using it as a package. Thanks! ```
pip install -r pip-dep/requirements_notebook.txt
pip install jupyterlab
```
should also work.",3,2020-05-07 07:51:22,2020-05-07 16:38:44,2020-05-07 13:20:12
https://github.com/OpenMined/PySyft/issues/3440,[],ImportError: cannot import name 'OperationMessage',"ImportError: cannot import name 'OperationMessage'Not sure if this is something I will have to post in syft-proto or here. Either ways I will post in both. I installed syft-proto from source. 

`Traceback (most recent call last):
  File ""run_websocket_client.py"", line 10, in <module>
    import syft as sy
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/__init__.py"", line 15, in <module>
    import syft.frameworks.torch.hook.hook_args
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 6, in <module>
    from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 13, in <module>
    from syft.frameworks.torch.tensors.interpreters.crt_precision import _moduli_for_fields
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/crt_precision.py"", line 7, in <module>
    from syft.frameworks.torch.tensors.interpreters.precision import FixedPrecisionTensor
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py"", line 7, in <module>
    from syft.generic.pointers.multi_pointer import MultiPointerTensor
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/generic/pointers/multi_pointer.py"", line 11, in <module>
    from syft.workers.base import BaseWorker
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/workers/base.py"", line 21, in <module>
    from syft.generic.pointers.object_pointer import ObjectPointer
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py"", line 15, in <module>
    from syft.messaging.message import ForceObjectDeleteMessage
  File ""/Users/hrishikesh/opt/anaconda3/envs/py3_6_3/lib/python3.6/site-packages/syft/messaging/message.py"", line 14, in <module>
    from syft_proto.messaging.v1.message_pb2 import OperationMessage as OperationMessagePB
ImportError: cannot import name 'OperationMessage'`I was using incompatible syft-proto and PySyft versions.",1,2020-05-03 02:12:48,2020-05-03 05:16:57,2020-05-03 05:16:57
https://github.com/OpenMined/PySyft/issues/3439,"['bug ', 'status: stale :bread:']",flatten() removes the object!,"flatten() removes the object!**Describe the bug**
when .flatten() is called on AST or a remote torch tensor it removes the original tensor from the worker
**To Reproduce**
A= torch.rand(4)
a=A.fix_prec().share(bob, alice, crypto_provider=james) #or A.send(bob)
b=a.flatten()
a.get()

note: this happens only with 1D tensor, 2D works fine@Syzygianinfern0 is this related to your recent GC fixes?Hey, 
I had a look at this, and I think the issue is that in torch the .flatten operation on 1d array is actually an _inplace_ operation. You can do the above example with .view(-1) and it will work fine.
I have fixed the issue locally by modifying the is_inplace_method in torch_attributes.py
```
        try:
            return self.inplace_methods[method_name]
        except KeyError:
            is_inplace = True if re.search(self._inplace_pattern, method_name) else False
            is_inplace = True if method_name == ""flatten"" else is_inplace # This would fix problem with flatten
            self.inplace_methods[method_name] = is_inplace
            return is_inplace
```
But note that this would only work for 1d array.
Not entirely sure what would be a good fix to this, as I don't think we use the input shape in anyway to decide if the operation is inplace.> @Syzygianinfern0 is this related to your recent GC fixes?

Seems to be the case (confirmed from a `git bisect`). Although don't know if I can look into it right away. 

> .flatten operation on 1d array is actually an _inplace_ operation

@MaksymPetyak I had tried the same thing earlier today but that didn't seem to be solving the issue. Can you confirm if that is the only change required with a recent copy of the codebase. > operation ... is actually an inplace operation

The number of such edge cases that might be hidden for pretty much every method we have scares me now 
:open_mouth:Hey @MaksymPetyak , would you make a pull request with your changes?> b=a.flatten()
> a.get()

After some discussion with @MaksymPetyak it's important to be noted that if anyone is working on this, **don't** use `a.get()` to decide if the pointer exists or not. It is easily misinterpretable that you have a solution if you've managed to make this work. This is since, if made into an inplace operation, it just creates `a` to be a duplicate of `b` and hence it pretends that the tensor exists :thinking: 

Use this instead
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)
alice = sy.VirtualWorker(hook, id=""alice"")
bob = sy.VirtualWorker(hook, id=""bob"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")

torch = th
syft = sy

# a = torch.ones(1, 5)  # <<<Toggle between this (works as expected)
a = torch.rand(4)  # <<< and this (broken)
a = a.encrypt(workers=[alice, bob], crypto_provider=crypto_provider)

print(f""Before: {len(alice._tensors)}"")  # 1 (expected: 1)
b = a.flatten()
print(f""After: {len(alice._tensors)}"")  # 1 (expected: 2)
```This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",7,2020-05-02 15:54:28,2020-06-11 00:06:14,2020-06-11 00:06:14
https://github.com/OpenMined/PySyft/issues/3401,"['bug ', 'good first issue :mortar_board:', 'testing ', 'status: stale :bread:']",`test_torch_tanh_approx` is flaky,"`test_torch_tanh_approx` is flaky**Describe the bug**
The ```test_torch_tanh_approx``` test fails intermittently during automated PR testing.

**To Reproduce**
Run the test (or full suite) until it fails.

**Screenshots**
```
2020-04-24T13:00:44.9923763Z method = 'sigmoid', prec_frac = 3, tolerance = 0.1
2020-04-24T13:00:44.9925054Z workers = {'alice': <VirtualWorker id:alice #objects:112>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:88>, ...}
2020-04-24T13:00:44.9925523Z 
2020-04-24T13:00:44.9927154Z     @pytest.mark.parametrize(
2020-04-24T13:00:44.9928770Z         ""method, prec_frac, tolerance"",
2020-04-24T13:00:44.9929162Z         [
2020-04-24T13:00:44.9929727Z             (""chebyshev"", 3, 3 / 100),
2020-04-24T13:00:44.9930283Z             (""chebyshev"", 4, 2 / 100),
2020-04-24T13:00:44.9931907Z             (""sigmoid"", 3, 10 / 100),
2020-04-24T13:00:44.9932292Z             (""sigmoid"", 4, 5 / 100),
2020-04-24T13:00:44.9932554Z         ],
2020-04-24T13:00:44.9932811Z     )
2020-04-24T13:00:44.9933080Z     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
2020-04-24T13:00:44.9933338Z         """"""
2020-04-24T13:00:44.9933695Z         Test the approximate tanh with different tolerance depending on
2020-04-24T13:00:44.9934214Z         the precision_fractional considered
2020-04-24T13:00:44.9934531Z         """"""
2020-04-24T13:00:44.9935194Z         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
2020-04-24T13:00:44.9935474Z     
2020-04-24T13:00:44.9936409Z         t = torch.tensor(range(-10, 10)) * 0.5
2020-04-24T13:00:44.9936742Z         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
2020-04-24T13:00:44.9937146Z         r_sh = t_sh.tanh(method)
2020-04-24T13:00:44.9937583Z         r = r_sh.get().float_prec()
2020-04-24T13:00:44.9937975Z         t = t.tanh()
2020-04-24T13:00:44.9938588Z         diff = (r - t).abs().max()
2020-04-24T13:00:44.9938866Z         norm = (r + t).abs().max() / 2
2020-04-24T13:00:44.9939168Z     
2020-04-24T13:00:44.9939675Z >       assert (diff / (tolerance * norm)) < 1
2020-04-24T13:00:44.9940476Z E       assert (tensor(0.1101) / (0.1 * tensor(1.0000))) < 1
2020-04-24T13:00:44.9940636Z 
2020-04-24T13:00:44.9942016Z test/torch/tensors/test_precision.py:512: AssertionError
```
**Expected behavior**
The test should always pass

**Additional context**
This started being an issue when the order of the test suite was randomized (specifically to shake out flaky tests like this.)
Can i work on this issue? is it open?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2020-04-24 13:32:40,2020-06-16 00:06:39,2020-06-16 00:06:39
https://github.com/OpenMined/PySyft/issues/3400,[],"TypeError: expected str, bytes or os.PathLike object, not PosixPath","TypeError: expected str, bytes or os.PathLike object, not PosixPathHey, can anybody please tell me what is the cause of this error while running start_websocket_servers.py ? is it because of using subprocess.py file in the anaconda path?

> shekhar$ python start_websocket_servers.py 
Starting server for Alice
Traceback (most recent call last):
  File ""start_websocket_servers.py"", line 17, in <module>
    subprocess.Popen(call_alice)
  File ""/anaconda3/lib/python3.6/subprocess.py"", line 709, in __init__
    restore_signals, start_new_session)
  File ""/anaconda3/lib/python3.6/subprocess.py"", line 1275, in _execute_child
    restore_signals, start_new_session, preexec_fn)
TypeError: expected str, bytes or os.PathLike object, not PosixPath
this error was there because due to whatsoever reason, in this python file, the interpreter was not able to load the path of the file  start_websocket_servers.py.

this cause of error got confirmed because of the realization that no matter what was the path value in this command FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.pyâ€)  in the start_websocket_servers.py file, there was no change in the error output. so the solution what i did was that i hardcoded the path of the file run_websocket_server.py in the command like this:  call_alice = [python,  ""run_websocket_server.py"", ""--port"", ""8777"", ""--id"", ""aliceâ€]
instead of original 
[
FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py"")

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]
]

this solved the problem .",1,2020-04-24 08:49:19,2020-04-25 19:38:36,2020-04-25 19:38:35
https://github.com/OpenMined/PySyft/issues/3388,[], syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file,"syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol filewhile running the start_websocket_servers.py, this issue (syft.exceptions.UndefinedProtocolTypeError) shows up. does anybody have a solution?
following below is the complete error:
File ""/Users/shekhar/PySyft/syft/serde/msgpack/proto.py"", line 71, in proto_type_info
    raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")
    raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")
syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file
syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file
    raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")
syft.exceptions.UndefinedProtocolTypeError: syft.execution.placeholder_id.PlaceholderId is not defined in the protocol file

That sounds like a mismatch between PySyft and `syft-proto` versions. I'd try re-installing the PySyft requirements from `pip-dep/requirements.txt` and see if that resolves it.> That sounds like a mismatch between PySyft and `syft-proto` versions. I'd try re-installing the PySyft requirements from `pip-dep/requirements.txt` and see if that resolves it.

I had the same problem. Re-installing the requirements solved it. Thank you. hey man, thanks a lot. although I did this earlier. it showed

>  [ERROR: syft 0.2.4 has requirement syft-proto~=0.2.5.a1, but you'll have syft-proto 0.2.9a2 which is incompatible. ]
then I quit this step of upgrading syft-proto but after your answer, I did that anyway and the error got resolved.",3,2020-04-22 03:47:23,2020-04-24 05:01:36,2020-04-24 05:01:35
https://github.com/OpenMined/PySyft/issues/3382,"['bug ', 'status: stale :bread:']",PySyft Tensor shape and size() call returns different values,"PySyft Tensor shape and size() call returns different values**Describe the bug**
After sending tensor to a worker the size() call returns `torch.Size([0])` while .shape returns correct value.



**To Reproduce**
Steps to reproduce the behavior:
1. 
data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)
bobs_data = data.send(bob)
print(bobs_data.shape) -> torch.Size([4, 2])
print(bobs_data.size()) -> torch.Size([0])



**Expected behavior**
size() method call should return correct value

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [Ubuntu]
 - Version [18]

**Additional context**
This is very important as Pytorch essentially uses size() for getting shape/size of attribute, shape attribute is only to give some similarity with numpy.  
And in most of pre-defined Pytorch models size() is used. So it won't  be **possible to use most pre-defined Pytorch** models with PySyft
Hey, this is a known issue: it is not possible to hook the size like we did for the shape because the size is used by the print function, which for Pointers wrapped into an empty torch tensor needs to be applied on this wrapper and not on the remote value.
Well maybe there is a way to fix this, but this is why we didn't manage to get it working :)@LaRiffle 
![image](https://user-images.githubusercontent.com/16415585/81976943-45e02680-95f7-11ea-948f-6d919d58ee7b.png)

If I am not mistaken now we are getting the size of the (empty) torch tensor, How does this happen differently when it comes to Size method only?
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.Hi @LaRiffle, any news about this issue?
The (big) problem related to this is that models cannot be executed on private tensors :( Hey @xanderwallace85!
This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?> Hey @xanderwallace85!
> This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?

Hi @LaRiffle ! Apparently, even simple CNN models do not work when using private tensors. I believe this is due to the size function :(  For instance, a model like the one below won't work as the function size is required (by the nn.Linear?).
```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```

Is there an alternative to private tensors? As I am looking for a solution to hide the data in the nodes (so not allowing the .get(), for example). 
Would be a pity to not be able to fully exploit private tensors though :(",7,2020-04-21 13:55:20,2020-09-24 18:11:17,2020-07-05 00:08:50
https://github.com/OpenMined/PySyft/issues/3369,[],securenn.maxpool2d isn't implemented appropriately,"securenn.maxpool2d isn't implemented appropriately **Describe the bug**
securenn.maxpool2d is implemented with arg a_sh that must be a **wrapped** AdditiveSharingTensor. and after calling .fix_prec() on it the chain becomes `fixed_prec>wrapper(torch.Tensor)>AdditiveSharingTensor` which is confused with a normal fixed_prec tensor chain `fixed_prec>torch.Tensor`
I could change the conditions to identify if it's a wrapper (I did that as a hot fix) but I don't know if that's the best solution since we'll have to change it in a lot of other places

**To Reproduce**
Steps to reproduce the behavior:
```
import torch
import syft as sy
import cProfile
from torch import nn

hook = sy.TorchHook(torch)
import torch.nn.functional as F

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


resnet = Net()
resnet.fix_prec().share(bob, alice, crypto_provider=crypto_provider)
data = torch.ones(1, 1, 32, 32).fix_prec().share(bob, alice, crypto_provider=crypto_provider)

cProfile.run(resnet(data))
```
run it in the debugger if you will :)

**Desktop (please complete the following information):**
 - OS: windows
 - Version 10

**Expected behavior:** 
securenn.maxpool2d(a_sh: AdditiveSharingTensor) not securenn.maxpool2d(a_sh: torch.Tensor)Might be good to fix this issue independently, but Syft Core has concluded that we should remove wrappers from the code base entirely. (It'll take a while.)",1,2020-04-17 12:04:29,2020-04-17 19:39:58,2020-04-17 19:39:58
https://github.com/OpenMined/PySyft/issues/3355,"['bug ', 'testing ']",`test_local_remote_gradient_clipping` is flaky,"`test_local_remote_gradient_clipping` is flaky**Describe the bug**
An issue that started to happen when running the tests in random order.

**To Reproduce**
Run the test (or full suite) until it fails.

**Expected behavior**
The test should reliably pass.

**Screenshots**
```
        # Remote gradient clipping
        remote_parameters = alice_model.parameters()
        total_norm_remote = nn.utils.clip_grad_norm_(remote_parameters, 2)
    
        # Local gradient clipping
        local_alice_model = alice_model.get()
        local_parameters = local_alice_model.parameters()
        total_norm_local = nn.utils.clip_grad_norm_(local_parameters, 2)
    
        # Is the output of the remote gradient clipping version equal to
        # the output of the local gradient clipping version?
>       assert total_norm_remote.get() == total_norm_local
E       assert tensor([1.3774]) == 1.3774276244053927
E         +tensor([1.3774])
E         -1.3774276244053927
```

**Additional context**
This started being an issue when the order of the test suite was randomized (specifically to shake out flaky tests like this.)Resolved by #3356.",1,2020-04-14 14:28:43,2020-04-14 17:37:51,2020-04-14 17:37:51
https://github.com/OpenMined/PySyft/issues/3349,[],"Vanilla FL: Adam optimizer doesn't work but SGD does, problem with add_()","Vanilla FL: Adam optimizer doesn't work but SGD does, problem with add_()**Description**
Based on the issue #3338 I ran a Vanilla FL process on a small ResNet on the Cifar10 dataset. 
I believe #3338 should be resolved, but I noticed an error which I can't understand. 
I ran the below code a couple of times with SGD optimizer and no lr-scheduler (and no momentum) which resulted in a perfectly normal training process (after 6 epochs around 60% acc. for plain ResNet18) 
Running the code multiple times with standard Adam optimizer however the following error produced itself at 50% through the first epoch. I was under the impression (as also shown in #3293 and in [this tutorial](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2007%20-%20Federated%20Learning%20with%20Federated%20Dataset.ipynb) ) that moment-based optimizers can be used. (Especially in non Vanilla FL without SMPC why shouldn't it?)

**Error-Message:** 
In Short: To expand please visit the Google Colab Link
<img width=""1348"" alt=""Screenshot 2020-04-13 11 20 52"" src=""https://user-images.githubusercontent.com/13786323/79109570-e59c6180-7d78-11ea-94c6-b81d24bb477a.png"">

**To Reproduce**
The following code (altered from #3293) was executed with Vanilla SDG optimizer (lr=0.01) and Vanilla Adam-Optimizer in Google Colab after installing pysyft with `!pip install syft` and GPU computing enabled. 

**Google Colab:** https://colab.research.google.com/drive/1IIoSdT3oGf8VMaoGjp9_8Ti3q5ILAtDQ

**Expected behavior**
Should have trained to the end as it did when using Vanilla SGD as optimizer. 
also would like to know the answer to this one. some previous issues suggest fl.optimizer module might have resolved this, but it's unclear to me how to use that? hey @NiWaRe - i looked through the issues and PRs. I think this might resolve it for us 

https://github.com/OpenMined/PySyft/pull/3179/files

there's now an example in https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2002%20-%20Intro%20to%20Federated%20Learning.ipynb @NiWaRe - I can confirm this works. i can now federate the adam optimizer. the example in the tutorial 2 using `from syft.federated.floptimizer import Optims` is accurate. 

thanks @rimijoker + @iamtrask! @roblewis1237 Perfect, thanks for checking in further!",4,2020-04-13 09:23:58,2020-05-27 08:23:52,2020-05-27 08:23:52
https://github.com/OpenMined/PySyft/issues/3344,"['bug ', 'testing ']",`test_instantiate_tfe_layer` is flaky,"`test_instantiate_tfe_layer` is flaky**Describe the bug**
This test semi-regularly fails 

**To Reproduce**
Run the test (or full suite) until it fails.

**Expected behavior**
The test should reliably pass.

**Screenshots**
```
        # compares results and raises error if not equal up to 0.001
>       np.testing.assert_allclose(actual, expected, rtol=0.001)
E       AssertionError: 
E       Not equal to tolerance rtol=0.001, atol=0
E       
E       Mismatched elements: 4 / 20 (20%)
E       Max absolute difference: 0.00031287
E       Max relative difference: 0.00110612
E        x: array([[-0.163999, -1.074379, -1.394909, -0.963268,  0.888889],
E              [-0.163999, -1.074379, -1.394909, -0.963268,  0.888889],
E              [-0.163999, -1.074379, -1.394909, -0.963268,  0.888889],
E              [-0.163999, -1.074379, -1.394909, -0.963268,  0.888889]])
E        y: array([[-0.164181, -1.074468, -1.395135, -0.9634  ,  0.889202],
E              [-0.164181, -1.074468, -1.395135, -0.9634  ,  0.889202],
E              [-0.164181, -1.074468, -1.395135, -0.9634  ,  0.889202],...
```

**Additional context**
This started being an issue when the order of the test suite was randomized (specifically to shake out flaky tests like this.)
There are two potential issues here:
1. Randomized functions in tests should be seeded, since integration tests should be deterministic. By randomizing the order of tests, the seed that these tolerance values are tuned against might be getting reset.
2. The rtol value here is working against the test definition, which is what makes the error dependent on seed.

To explain 2 a bit more:The loss of precision from TFE's fixed point representation truncating floating points is relatively worse for values closer to 0, and sampling kernel_initializer from a standard normal means we have a high likelihood of sampling numbers near 0. Relative error between the expected and actual value of the kernel will thus increase for numbers near 0 (whereas absolute error should be better).

If you want to randomize testing order, I'd double check that you're setting seeds after sampling the testcase order (so that each test can still be deterministic). I'd additionally either change the kernel_initializer to a distribution that doesn't have an expected value at 0 (normal -> uniform), or switch from rtol to atol (this is less satisfying but should at least make the test less susceptible to precision errors).The issue that prompted randomizing the test case order was that changes to the directory structure (without code changes) could cause test failures, since the tests are run in alphabetical order and randomized functions in the tests are inconsistently (re-)seeded.(For anyone picking up this issue, the test randomization is performed with [`pytest-randomly`](https://github.com/pytest-dev/pytest-randomly).)>randomized functions in the tests are inconsistently (re-)seeded

Seems like a great use case for [pytest fixtures](https://docs.pytest.org/en/latest/fixture.html)Not sure I follow. Are you suggesting using fixtures to set random seeds?Yes, assuming there's a reason that no global seed is used.There is a global seed used, which is set to the timestamp of the start of the test run. (There are actually multiple random seeds at play though (the Python random seed, the PyTorch random seed, and the Numpy random seed), and I'm not sure they all get set. ðŸ¤” 

Setting fixed random seeds at the beginning of a test run doesn't solve the issue though, because the order of the tests is not fixed, so the numbers generated for each individual test may vary. If individual tests can't be written in a fashion that makes them (pretty much) deterministic despite the randomness within, they can set whatever random seeds they need to.>Setting fixed random seeds at the beginning of a test run doesn't solve the issue though, because the order of the tests is not fixed, so the numbers generated for each individual test may vary.

I see, I misunderstood. Dynamically setting the seed based on timestamp is not what I'd consider ""fixed seed"" because it doesn't allow for exact reproducibility of a test run across time & machines (which is what all unit/integration tests should strive for imo). But at least the problem is clear now, we need same numbers across runs for this issue to be fixedIt does allow for reproducibility, because each test run prints out the random seed at the beginning and you can pass it back in with a flag.

IMO, we need tests that are resilient to receiving different numbers, because the tests are already not guaranteed to run in the same order on every run (due to package path changing refactors.) I'd much rather intentionally deal with the problem of tests that flake (by randomizing their order and fixing issues) than have unrelated tests fail unexpectedly while refactoring due to order dependence of the test suite.Anyway, #3358 adjusts the thresholds to make this test pass reliably, so this game of whack-a-mole has shifted to other parts of the code base.",10,2020-04-12 15:44:42,2020-04-15 14:43:06,2020-04-15 14:43:05
https://github.com/OpenMined/PySyft/issues/3333,[],Need changes in Experimental notebook for PaillierTensor,"Need changes in Experimental notebook for PaillierTensor**To Reproduce**
Run PySyft/examples/experimental/PaillierTensor.ipynb and on running 3rd block it will throw an error.

**Expected behavior**
Should encrypt tensor without throwing the error ðŸ˜

**Additional context**
change encrypt and decrypt like:
x = th.Tensor([1,2,3]).encrypt(protocol=""paillier"", public_key=pub)
out = out.decrypt(protocol=""paillier"", private_key=pri)
What's the error? Post a stack trace.> What's the error? Post a stack trace.

Error is due to the recent changes in encrypt method.
```
AttributeError                            Traceback (most recent call last)
 in 
----> 1 x = th.Tensor([1,2,3]).encrypt(pub)
      2 y = th.Tensor([2,2,2])

~/Desktop/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in encrypt(self, protocol, **kwargs)
   1018 
   1019         """"""
-> 1020         if protocol.lower() == ""mpc"":
   1021             workers = kwargs.pop(""workers"")
   1022             crypto_provider = kwargs.pop(""crypto_provider"")

AttributeError: 'PaillierPublicKey' object has no attribute 'lower'
```@Syzygianinfern0 I think this changed most recently in one of your PRs. Give it a look?Ok. @karlhigley",4,2020-04-09 20:03:04,2020-04-19 15:08:51,2020-04-19 15:08:51
https://github.com/OpenMined/PySyft/issues/3331,[],Tutorial Part 05 Welcome to Sandbox- module scipy._lib not found,"Tutorial Part 05 Welcome to Sandbox- module scipy._lib not foundI am trying to run the first code snippet from the Tutorial and I keep getting a **ModuleNotFoundError : No module named 'scipy._lib'.** I have installed scikit-learn dependency with pip3 install scipy and pip install scipy in hopes to fix this error. It didn't work.
Can anybody assist me?

**To Reproduce**
1. I started my Juypter notebook locally by typing `juypter notebook` in the terminal.
2. Copied the code snippet
 `import torch`
 `import syft as sy`
 `sy.create_sandbox(globals())`
**Expected behavior**
That the code should run without errors

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.
have you restarted your kernel?yes, I restarted the Python kernel many times.",2,2020-04-09 12:27:23,2020-04-12 14:54:11,2020-04-12 14:54:11
https://github.com/OpenMined/PySyft/issues/3330,[],Requirements need updates,"Requirements need updates**Describe the bug**
ERROR: syft 0.2.4 has requirement syft-proto~=0.2.5.a1, but you'll have syft-proto 0.2.9a2 which is incompatible
ERROR: syft 0.2.4 has requirement tornado==4.5.3, but you'll have tornado 6.0.4 which is incompatible.

**To Reproduce**
pip install syft-proto --upgrade

**Desktop (please complete the following information):**
 - OS: Windows
 - Version 10
`pip install --upgrade syft-proto` will force an upgrade to the newest available version of `syft-proto`, which is indeed incompatible with `syft 0.2.4`.

Fixes for the `tornado` version issue were merged in #3196, #3204, and #3288. (It may require manually downgrading your `tornado` version, because the previous dependency specification was overly optimistic about compatibility.)",1,2020-04-09 12:26:56,2020-04-09 15:51:16,2020-04-09 15:50:56
https://github.com/OpenMined/PySyft/issues/3312,[],AttributeError: module 'syft.grid' has no attribute 'WebsocketGridClient',"AttributeError: module 'syft.grid' has no attribute 'WebsocketGridClient'Hi, I assumed that the `grid` functionality has been totally merged into the `syft` environment, and it is not necessary to install `grid` separately. But I have received this error:

> AttributeError: module 'syft.grid' has no attribute 'WebsocketGridClient'

Has the attribute's name changed?I think it's just called `GridClient` now.",1,2020-04-06 11:47:42,2020-04-29 15:22:16,2020-04-29 15:22:16
https://github.com/OpenMined/PySyft/issues/3289,[],Jupyter Notebook Version Conflict Following Conda Installation Instructions,"Jupyter Notebook Version Conflict Following Conda Installation Instructions**Bug**
Following the Conda pre-installation and installation instructions in README.md in Linux results in the following version conflict:
ERROR: notebook 6.0.3 has requirement tornado>=5.0, but you'll have tornado 4.5.3 which is incompatible.

Then when running jupyter notebook, the browser tab fails to display any files and there is no option to create a Python notebook. This was also noticed by youben11 [here](https://github.com/OpenMined/PySyft/pull/3196#issuecomment-600144632).

**To Reproduce**
Steps to reproduce the behavior:
```
conda create -n pysyft python=3.7
conda activate pysyft # some older version of conda require ""source activate pysyft"" instead.
conda install jupyter notebook
pip install syft[udacity]
```

**Workaround**
Per [this closed issue](https://github.com/OpenMined/PySyft/issues/3019#issuecomment-605706131), install jupyter notebook at the same time as syft using:
```
conda create -n pysyft python=3.7
conda activate pysyft # some older version of conda require ""source activate pysyft"" instead.
pip install syft[udacity,notebooks]
```
To test the workaround, I've been able to successfully open and run the [first example jupyter notebook](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2001%20-%20The%20Basic%20Tools%20of%20Private%20Deep%20Learning.ipynb).

Running `conda list` shows the following versions were installed: 
tornado 4.5.3
ipykernel 5.2.0
ipython 7.13.0
ipython-genutils 0.2.0
ipywidgets 7.5.1
jupyter 1.0.0
jupyter-client 6.1.2
jupyter-console 6.1.0
jupyter-core 4.6.3
notebook 5.7.8This has been fixed in the requirements file in #3204, but people with installations from before the fix will still need to run the workaround mentioned here.",1,2020-04-01 17:27:44,2020-04-03 15:14:29,2020-04-03 15:14:29
https://github.com/OpenMined/PySyft/issues/3282,[],"Error abou x.encrypt(protocol=""paillier"", public_key=pub)","Error abou x.encrypt(protocol=""paillier"", public_key=pub)When I use `x.encrypt(protocol=""paillier"", `public_key=pub),` it tells me that **""'Tensor' object has no attribute 'encrypt'""**ã€‚But in fact I could excute `pub, pri = sy.keygen()` successfully, and I already download the class file **""paillier.py""**.

You can try the following
```python
import torch
import syft as sy

hook = sy.TorchHook(torch)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
james = sy.VirtualWorker(hook, id=""james"")

x = torch.randint(10, (1, 5), dtype=torch.float32)

# MPC
x_encrypted = x.encrypt(workers=[bob, alice], crypto_provider=james)
x_decrypted = x_encrypted.decrypt()
assert (x == x_decrypted).all()

# Paillier
public, private = sy.frameworks.torch.he.paillier.keygen()
x_encrypted = x.encrypt(protocol=""paillier"", public_key=public)
x_decrypted = x_encrypted.decrypt(protocol=""paillier"", private_key=private)
assert (x == x_decrypted).all()
```


My guess if you've forgotten to hook PySyft. You can do that by adding ```hook = sy.TorchHook(torch)``` after the importsThere is  an error ""encrypt() got an unexpected keyword argument 'protocol'.""
I install the library with `pip install syft[udacity]`, the version is 0.2.4, but I found there is difference in /syft/frameworks/torch/tensors/interpreters/native.py/ about the defination of encrypt() method with codes on Github. It seems the updated version about the method encrypt(protocol=""pailiar"", *kwarg) don't exist. When I download the site package `syft` and place it to python3.7/site-packages, it show me an error when I import syft. So I think maybe you have fogot to update the library with pip method. 
And there is syft-proto= 0.2.8.a1ï¼Œ but the latest version of syft=0.2.4 could only match the syft-proto=0.2.5.a1. So I have no idea to update the latest syft which could use `encrypt(protocol=""pailiar"", *kwarg)` to achieve HE. So I really wish you could offer me help.Thanks



 Since the feature was implemented very recently it's not available on any release as of now. Please try installing from source.
[Link](https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md)
Thanks!




------------------&nbsp;åŽŸå§‹é‚®ä»¶&nbsp;------------------
å‘ä»¶äºº:&nbsp;""The Syzygian Inferno""<notifications@github.com&gt;;
å‘é€æ—¶é—´:&nbsp;2020å¹´3æœˆ31æ—¥(æ˜ŸæœŸäºŒ) æ™šä¸Š11:37
æ”¶ä»¶äºº:&nbsp;""OpenMined/PySyft""<PySyft@noreply.github.com&gt;;
æŠ„é€:&nbsp;""ganjf""<1194520007@qq.com&gt;;""Author""<author@noreply.github.com&gt;;
ä¸»é¢˜:&nbsp;Re: [OpenMined/PySyft] Error abou x.encrypt(protocol=""paillier"", public_key=pub) (#3282)





 
Since the feature was implemented very recently it's not available on any release as of now. Please try installing from source.
 Link
 
â€”
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or unsubscribe.",4,2020-03-31 13:01:59,2020-04-01 09:10:41,2020-04-01 09:10:41
https://github.com/OpenMined/PySyft/issues/3272,[],Dependency SkLearn (used by Sandbox in Tutorial 5) is missing at notebook requirements,"Dependency SkLearn (used by Sandbox in Tutorial 5) is missing at notebook requirements**Describe the bug**
The tutorial 5 uses the create_sandbox function wich requires sklearn. But sklearn in not in notebook requirement.

**To Reproduce**
Steps to reproduce the behavior:
1. Run the pre-installation as described in readMe
2. Run the installation as described in readMe
3. Run `make notebook`
4. Open tutorial 5 (~/Pysyft/examples/tutorials/Part 05 - Welcome to the Sandbox.ipynb)
5. Run the first code snippet
4. See error

**Expected behavior**
The code would run and there would be no errors.

**Screenshots**
![Captura de tela de 2020-03-29 17-07-09](https://user-images.githubusercontent.com/25506122/77859445-c2ea4480-71df-11ea-85fc-94cac6ad56fc.png)


**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version 18.04

**Additional context**
Even if the sklearn it's no longer a dependence of the Pysyft I think it would make sense that it would be a dependence in the notebooks requirements specially because `make notebook` creates it's own venv so installing in my own pysyft conda venv would not resolve the problem, i would need to either edit the makefile or the notebook requirements in order to work.I'd like to resolve if possibleYeah, I have the same problem. 
Anyone from the dev team? Can you help us?Sure, adding it to the notebook requirements makes sense to me. I've tripped over that issue a few times myself. Submit a PR?I fixed this by adding the line `scikit-learn~=0.22.2.post1 `in the **requirements.txt** and then typing `make notebook` again.
After this I could run Tutorial Code 5 and 7 without any problems!@potsch  in the pip-dep/requirements-notebook.txt u meant?@ucalyptus  No, I added it in the pip-dep/requirements.txt",6,2020-03-29 20:34:59,2020-04-12 15:39:18,2020-04-12 15:39:18
https://github.com/OpenMined/PySyft/issues/3261,['bug '],fix_precision() is inplace when applied to a pointer tensor.,"fix_precision() is inplace when applied to a pointer tensor.**Description of the bug**
The method fix_precision() applied on pointers is 'inplace'. This should not be the case

In the following code:

```
a = torch.Tensor([2., 3.]).send(bob)
a.fix_precision()
a = a.get()
print(type(a))
```

The variable  `a` after calling `get()` is a fixed precision tensor which is a bug, because the original variable `a` defined as `torch.Tensor([2., 3.])` is not a fixed precision tensor.

However, this bug is not existing in case when  `a` is not a pointer:

```
a = torch.Tensor([2., 3.])
a.fix_precision()
print(type(a))
```

`a` here is not a fixed precision tensor. which is the desired behavior.


**Desktop:**
 - OS: Archlinux
 - Version 0.3.2


I can take this!!Hey @AlanAboudib @karlhigley @LaRiffle ,
so if I understand this correctly,

```python
x = th.Tensor([1.,2.,3.]).send(bob)
x_fx = x.fix_precision()
x = x_fx.get()

```
x_fx is a `PointerTensor` and expected behavior is to be a `FixedPrecisionTensor` with `PointerTensor` as child?

Moreover when we .get() the x_fx, it returns `FixedPrecisionTensor`, which I think is a correct behavior, as we haven't called float_precision yet.not exactly, fix_precision() should be applied anyway on the remote value when called on a pointer (and it works fine)

the issue is that currently we have this for pointers:
```
a = torch.Tensor([2., 3.]).send(bob)
a_fp = a.fix_precision()
# a_fp is a pointer to a fixed precision, but a is too!
```
while for non pointers:
```
a = torch.Tensor([2., 3.])
a_fp = a.fix_precision()
# a_fp is a wrapper onto a fixed precision, but a is not!
```

So for pointers, `fix_precision` behaves as `fix_precision_` while it shouldn't",3,2020-03-27 13:48:18,2020-03-31 19:44:14,2020-03-31 19:44:14
https://github.com/OpenMined/PySyft/issues/3260,[],Websocket Secure error SSL: CERTIFICATE_VERIFY_FAILED,"Websocket Secure error SSL: CERTIFICATE_VERIFY_FAILEDI am running the old version of [websockets_mnist_parallel](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets_mnist_parallel) example with `websocket secure`. It seems the initial handshake is fine but once computing the loss in `run_websocket_client.py` script, it produces the error:

> Traceback (most recent call last):
  File ""asynchronous_federated_learning.py"", line 124, in <module>
    asyncio.run(main(args,device))
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/runners.py"", line 43, in run
    return loop.run_until_complete(main)
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/base_events.py"", line 583, in run_until_complete
    return future.result()
  File ""asynchronous_federated_learning.py"", line 65, in main
    for worker in worker_instances
  File ""run_websocket_client.py"", line 114, in fit_model_on_worker
    loss = await worker.async_fit(dataset_key=""mnist"", return_ids=[0])
  File ""/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py"", line 149, in async_fit
    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL
  File ""/miniconda3/envs/pysyft/lib/python3.7/site-packages/websockets/client.py"", line 517, in __aenter__
    return await self
  File ""/miniconda3/envs/pysyft/lib/python3.7/site-packages/websockets/client.py"", line 535, in __await_impl__
    transport, protocol = await self._create_connection()
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/base_events.py"", line 985, in create_connection
    ssl_handshake_timeout=ssl_handshake_timeout)
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/base_events.py"", line 1013, in _create_connection_transport
    await waiter
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/sslproto.py"", line 530, in data_received
    ssldata, appdata = self._sslpipe.feed_ssldata(data)
  File ""/miniconda3/envs/pysyft/lib/python3.7/asyncio/sslproto.py"", line 189, in feed_ssldata
    self._sslobj.do_handshake()
  File ""/miniconda3/envs/pysyft/lib/python3.7/ssl.py"", line 774, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1076)

Just to note that I am using `PySyft 0.2.4` and `Python 3.7`.Would something like [this](https://github.com/cloudfoundry-community/cf-python-client/issues/51#issuecomment-536428838) work to address that?Actually I am not sure. I followed the advise proposed to add the following code at the beginning of my code and it does not work:

```python 
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    # Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
    # Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context
``` 

I have also tried adding to the `WebsocketClientWorker`, but no success. Done the same thing with `WebsocketServerWorker` and no success either.I tried to manually give WebsocketClientWorker the cert file but I faced another error:

> ssl.SSLError: [SSL] called a function you should not call

@IonesioJunior did you try the `WebsocketClientWorker` and `WebsocketServerWorker` in `async` mode?I have done these changes and I think now it works. In the constructor of the class `WebsocketClientWorker` I add:

```Python
if self.secure:
    self.ssl_context = ssl._create_unverified_context()
```

and in the `async_fit` function, instead of:

```Python 
async with websockets.connect(
                    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL
            ) as websocket:
```
I add the `ssl=self.ssl_context` to have:

```Python 
async with websockets.connect(
                    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL,ssl=self.ssl_context
            ) as websocket:
```Would be great to capture these changes in a PR somehow, so that anyone else running locally in secure mode doesn't hit the same problem. ðŸ‘ @karlhigley Ok, I ll make the PR ready and submit it",6,2020-03-27 13:35:41,2020-04-05 09:27:31,2020-04-01 08:08:54
https://github.com/OpenMined/PySyft/issues/3259,['bug '],Indexing pointer tensors with a list,"Indexing pointer tensors with a listWhen running the following code
```python
hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")

a = torch.tensor([10,20,30])
print(a[[0,2]])

b = torch.tensor([10,20,30]).send(bob)
print(b[[0,2]])
```
the first tensor `a` get displayed correctly as 
```python
tensor([10, 30])
```
but the second tensor raises the following error:
```python
IndexError: too many indices for tensor of dimension 1
```

I have Python 3.7.6, PySyft 0.2.4 and PyTorch 1.4.0.

I'm new to PySyft, so maybe it is an expected behavior for some reasons, but I don't really see why (since remote tensors are supposed to have the same functionalities as normal tensors as far as I understand). I can take a look.",1,2020-03-27 12:46:06,2020-04-07 13:59:24,2020-04-07 13:59:24
https://github.com/OpenMined/PySyft/issues/3250,['bug '],Cannot find dataset pointers sent to a remote client ,"Cannot find dataset pointers sent to a remote client **Describe the bug**
After tagging a tensor and sending it to the NodeClient object, nothing comes out of the ClientNode. The search method returns no objects.

**To Reproduce**
- Setup a remote client (Grid node)
- Create a simple tensor `data = torch.tensor([1, 1, 1, 1, 1])`
- Tag the tensor `data.tag('mytag')`
- Send the tensor to the remote node `data.send(remote_node)`
- Search for the tenor `remote_node.search('mytag')`  -> This will return an empty list []
- Search for the tensor on the grid gateway (`grid_gateway.search('mytag')`) . It will return an empty list []


I checked the redis db and I found the tags but they won't show up in the search method:
`redis_db.hgetall('key')`


**Screenshots**
![Screen Shot 2020-03-24 at 6 50 31 PM](https://user-images.githubusercontent.com/18373707/77392705-6adac900-6e00-11ea-81ff-06222b0df71c.png)

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - PySyft 0.2.4 msgpack 1.0.0


worker.search() is for local use only. for a remote worker use `me.request_search(['mytag'], location= worker)`. this will send you back an object_pointer that points to the dataset. that enables you to call .get() on it only for now not full functionality of dataset_pointer.
update: me.request_search() returns a dataset_pointer now",1,2020-03-24 05:52:09,2020-04-29 15:13:27,2020-04-29 15:13:27
https://github.com/OpenMined/PySyft/issues/3245,['bug '],Error with PySyft federated learning remote worker ,"Error with PySyft federated learning remote worker **Describe the bug**
TrainConfig.send() to a remote client throw an error

**To Reproduce**
Steps to reproduce the behavior:
1- Create a remote client on a different server.
2- Run the code in Introduction To TrainConfig notebook.
3- replace localhost with the IP of the remote server that has the worker running
4- train_config.send(alice) will throw an error

**Error Message **
This is the error message from the worker side:

`worker <WebsocketServerWorker id:alice #objects:0> received WorkerCommandMessage ('_log_msgs', ((), {'value': False}, []))
Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'ObjectMessage' object has no attribute 'contents'"")>
Traceback (most recent call last):
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py"", line 317, in recv_msg
    print(f""worker {self} received {type(msg).__name__} {msg.contents}"")
AttributeError: 'ObjectMessage' object has no attribute 'contents'
Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'ObjectMessage' object has no attribute 'contents'"")>
Traceback (most recent call last):
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""/home/ec2-user/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py"", line 317, in recv_msg
    print(f""worker {self} received {type(msg).__name__} {msg.contents}"")
AttributeError: 'ObjectMessage' object has no attribute 'contents'`

**Screenshots**
Notebook Screenshot:
![Screen Shot 2020-03-24 at 12 21 16 AM](https://user-images.githubusercontent.com/18373707/77311739-8fce2e00-6d65-11ea-9e17-144749eea3df.png)

**Desktop (please complete the following information):**
 - OS: Amazon Linux x86_64
 - Python 3.7
- PySyft 0.2.4


You probably run it with `--verbose` arg which causes the `msg.contents` print. Try running the remote worker without the param, as a temporary fix.I think the underlying issue [is in `BaseWorker`](https://github.com/OpenMined/PySyft/blob/master/syft/workers/base.py#L316-L317). The problem is that the base `Message` class no longer has a `contents` property, so none of the sub-classes do either.I think this issue is already fixed in the following commit:
https://github.com/OpenMined/PySyft/commit/e4b5cab232910968036f8bac1d499b19356de41c

@karlhigley If you agree this issue could be closed",3,2020-03-23 11:26:37,2020-05-05 18:44:08,2020-05-05 18:44:08
https://github.com/OpenMined/PySyft/issues/3228,[],Update our custom crypten load to only wrap the original one,"Update our custom crypten load to only wrap the original one**Is your feature request related to a problem? Please describe.**
We can't track updates to crypten.load and update our custom one.

**Describe the solution you'd like**
As CrypTen has introduced a [new way](https://github.com/facebookresearch/CrypTen/pull/53) to load cryptensors, we can now only wrap around their function while loading tensors using their tags.

**Additional context**
This might not be possible at the current time, as this functionality comes with a version of CrypTen that isn't compatible with syft, however, we should keep an eye on this.This was addressed in a different PR",1,2020-03-19 19:10:03,2020-04-18 14:40:15,2020-04-18 14:40:15
https://github.com/OpenMined/PySyft/issues/3214,['bug '],Fix parameter serialization,"Fix parameter serializationIn some situations, parameters are not serialized properly. I suspect this is due to our implementation of parameter.data

Here is one example:
```python
class Net(sy.Plan):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(1, 1)

    def forward(self, x):
        return self.fc1(x)

plan = Net()
plan.build(th.tensor([1.2]))

x = th.tensor([-1.0])
expected = plan(x)

plan.fix_precision().share(alice, bob, crypto_provider=charlie)
print(plan.state.tensors())
ptr_plan = plan.send(james)

# Fetch plan
fetched_plan = plan.owner.fetch_plan(ptr_plan.id_at_location, james)
print('***')
print(fetched_plan.state.tensors())
```
Output
```
[Parameter containing:
(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:94226517866 -> alice:74685210613]
	-> [PointerTensor | me:30028513485 -> bob:91228892047]
	*crypto provider: charlie*, Parameter containing:
(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:16955185561 -> alice:5015164314]
	-> [PointerTensor | me:77573712688 -> bob:21883177159]
	*crypto provider: charlie*]
***
[FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:94226517866 -> alice:74685210613]
	-> [PointerTensor | me:30028513485 -> bob:91228892047]
	*crypto provider: charlie*, FixedPrecisionTensor>[AdditiveSharingTensor]
	-> [PointerTensor | me:16955185561 -> alice:5015164314]
	-> [PointerTensor | me:77573712688 -> bob:21883177159]
	*crypto provider: charlie*]
```I can take a look",1,2020-03-17 23:33:26,2020-03-27 13:17:25,2020-03-27 13:17:25
https://github.com/OpenMined/PySyft/issues/3209,[],No module named 'syft.federated.floptimizer',"No module named 'syft.federated.floptimizer'**Describe the bug**
When I try to run PySyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb
(https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2002%20-%20Intro%20to%20Federated%20Learning.ipynb), I get this error:

ModuleNotFoundError: No module named 'syft.federated.floptimizer'

**To Reproduce**
>>from syft.federated.floptimizer import Optims

torch version:1.4.0
syft version: 0.2.3

@eceisik Please follow this INSTALLATION.md, that should fix the issue for you.
This would be fixed with a version update, so in the next version of syft it should work fine.We'll need to release a new version to address that. Coming soon!@eceisik @rimijoker Just released v0.2.4, which should address this issue. Let me know if upgrading works for you!I followed the installation.md for windows 
I only needed to change installation part of torch as below:

pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html

It worked.
Thank you for help",4,2020-03-17 13:23:15,2020-03-19 16:10:03,2020-03-19 16:10:03
https://github.com/OpenMined/PySyft/issues/3208,[],Setting requires_grad as True in Pysyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb,"Setting requires_grad as True in Pysyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb**Describe the bug**

In the file: Pysyft/examples/tutorials/Part 02 - Intro to Federated Learning.ipynb

Only the weights are needed to be updated. Why did we set requires_grad as True for x and y? I think it can be confusing for beginners.

data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)
target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)


@eceisik Send a PR that fixes it? ðŸ˜„ Could be related to #3180",2,2020-03-17 12:35:20,2020-03-18 11:30:57,2020-03-18 11:30:57
https://github.com/OpenMined/PySyft/issues/3207,"['bug ', 'status: stale :bread:']",Inconsistency in remote_send and remote_get operations,"Inconsistency in remote_send and remote_get operations**Describe the bug**
The remote pointer operations, remote_get and remote_send work fine together, but break when used in a sequence. Found this issue while working on #2864 

**To Reproduce**
```import torch
import syft as sy
hook = sy.TorchHook(torch)

def print_config():
    print('-'*10)
    print('   me:',  me._objects)
    print('  bob:', bob._objects)
    print('alice:',alice._objects)
    print('-'*10)

def check_remote_get():
    print(""Checking remote_get"")
    # me (pointer) -> alice (pointer)-> bob (tensor)
    p2p2x = torch.tensor([1,2,3,4]).send(alice).send(bob)
    print('p2p2x:', p2p2x)
    print_config()

    # after calling remote_get on p2p2x
    # me (pointer) -> alice (tensor)
    p2x = p2p2x.remote_get()
    print('p2x:', p2x)
    print_config()
    print('***remote_get() works fine***')
    print('\n', '*'*10, '\n')

def check_remote_send():
    print(""Checking remote_send"")
    # me (pointer) -> bob (tensor)
    p2x = torch.tensor([1,2,3,4]).send(bob)
    print('p2x:', p2x)
    print_config()

    # after calling remote_send on p2x
    # me (pointer) -> bob (pointer) -> alice (tensor)
    p2p2x = p2x.remote_send(alice)
    print('p2p2x:', p2p2x)
    print_config()
    print('***remote_send() works fine***')
    print('\n', '*'*10, '\n')

def check_remote_operations_sequence():
    # me (pointer) -> bob (tensor)
    print(""Checking remote_send and remote_get sequence"")
    p2x = torch.tensor([1,2,3,4]).send(bob)
    print('p2x:', p2x)
    print_config()

    # after calling remote_send on p2x
    # me (pointer) -> bob (pointer) -> alice (tensor)
    p2p2x = p2x.remote_send(alice)
    print('p2p2x:', p2p2x)
    print_config()

    # after calling remote_get on p2p2x
    # me (pointer) -> bob (tensor)
    p2x_ = p2p2x.remote_get()
    print('p2x_:', p2x_)
    print_config()

    # Throws ObjectNotFoundError
    z = p2x_ + p2x_

def clear_objects():
    bob.clear_objects()
    alice.clear_objects()
    
if __name__ == ""__main__"":
    me = sy.local_worker
    bob = sy.VirtualWorker(hook, id='bob')
    alice = sy.VirtualWorker(hook, id='alice')
    clear_objects()
    
    check_remote_get()
    clear_objects()

    check_remote_send()
    clear_objects()
    
    check_remote_operations_sequence()
    clear_objects()
```

**Output**
```Checking remote_get
p2p2x: (Wrapper)>[PointerTensor | me:89240781371 -> bob:20411805653]
----------
   me: {}
  bob: {20411805653: (Wrapper)>[PointerTensor | bob:20411805653 -> alice:69485423954]}
alice: {69485423954: tensor([1, 2, 3, 4])}
----------
p2x: (Wrapper)>[PointerTensor | me:89240781371 -> bob:20411805653]
----------
   me: {}
  bob: {20411805653: tensor([1, 2, 3, 4])}
alice: {}
----------
***remote_get() works fine***

 ********** 

Checking remote_send
p2x: (Wrapper)>[PointerTensor | me:9842172577 -> bob:52458556840]
----------
   me: {}
  bob: {52458556840: tensor([1, 2, 3, 4])}
alice: {}
----------
p2p2x: (Wrapper)>[PointerTensor | me:9842172577 -> bob:52458556840]
----------
   me: {}
  bob: {52458556840: (Wrapper)>[PointerTensor | bob:87311029150 -> alice:52458556840]}
alice: {52458556840: tensor([1, 2, 3, 4])}
----------
***remote_send() works fine***

 ********** 

Checking remote_send and remote_get sequence
p2x: (Wrapper)>[PointerTensor | me:76396849905 -> bob:80366686695]
----------
   me: {}
  bob: {80366686695: tensor([1, 2, 3, 4])}
alice: {}
----------
p2p2x: (Wrapper)>[PointerTensor | me:76396849905 -> bob:80366686695]
----------
   me: {}
  bob: {80366686695: (Wrapper)>[PointerTensor | bob:43416594800 -> alice:80366686695]}
alice: {80366686695: tensor([1, 2, 3, 4])}
----------
p2x_: (Wrapper)>[PointerTensor | me:76396849905 -> bob:80366686695]
----------
   me: {}
  bob: {80366686695: (Wrapper)>[PointerTensor | bob:43416594800 -> alice:80366686695], 43416594800: tensor([1, 2, 3, 4])}
alice: {}
----------

---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/Desktop/GSoC/OpenMined/PySyft/syft/generic/object_storage.py in get_obj(self, obj_id)
     68         try:
---> 69             obj = self._objects[obj_id]
     70         except KeyError as e:

KeyError: 80366686695

During handling of the above exception, another exception occurred:

ObjectNotFoundError                       Traceback (most recent call last)
<ipython-input-2-ca8d557e9987> in <module>
     78     clear_objects()
     79 
---> 80     check_remote_operations_sequence()
     81     clear_objects()

<ipython-input-2-ca8d557e9987> in check_remote_operations_sequence()
     60 
     61     # Throws Error
---> 62     z = p2x_ + p2x_
     63 
     64 def clear_objects():
.
.
.

ObjectNotFoundError: Object ""80366686695"" not found on worker!!! You just tried to interact with an object ID:80366686695 on <VirtualWorker id:alice #objects:0> which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines. If you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!
```

**Expected behavior**

The remote_get and remote_send operations are Pointer Chain Operations and intuitively should
- remote_get: call .get() on the last pointer in chain, move tensor from last worker to its predecessor worker in the pointer chain. Method call should return a PointerTensor, which is at the beginning of chain of pointers which ends at the tensor object.

- remote_send: call .send(new_worker) on the tensor at the end of pointer chain, move tensor from last worker to new_worker in the pointer chain. Method call should return a PointerTensor at the beginning of the chain of pointers which ends at the tensor object on new_worker's machine.
I guess the fault is with remote_send method.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2020-03-17 05:58:10,2020-05-22 00:04:56,2020-05-22 00:04:56
https://github.com/OpenMined/PySyft/issues/3183,"['bug ', 'status: stale :bread:']",KeyError: 'evaluate',"KeyError: 'evaluate'**Describe the bug**

when I run PySyft/examples/tutorials/advanced/websockets-example-MNIST-parallel/run_websocket_client.py

/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
/usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:93: RuntimeWarning: coroutine 'WebsocketServerWorker._consumer_handler' was never awaited
  self._consumer_handler(websocket)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:535: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)
2020-03-12 13:36:22,100 | Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.7/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'dict' object has no attribute 'owner'"")>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 663, in register_response
    register_response_function = register_response_functions[attr_id]
KeyError: 'evaluate'





I will take a lookHey @ERICPENGZ 
I could not reproduce your problem. I ran the following commands in a docker container and everything worked fine:
python start_websocket_servers.py
python run_websocket_client.py

Could you try to pull the latest master and retest?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",3,2020-03-12 05:45:49,2020-05-22 00:05:00,2020-05-22 00:05:00
https://github.com/OpenMined/PySyft/issues/3180,['bug '],Runtime Error asking all parameters to have requires_grad=True,"Runtime Error asking all parameters to have requires_grad=True**Describe the bug**
I'm trying to finetune a alexnet model and i've set the parameters except for the final layer of the model to requires_grad=False and have created a new classification layer with the desired outputs i want. However the .send() function keeps throwing a runtime error `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

```
import syft
import torch
from torchvision import models
import torch.nn as nn

hook = syft.TorchHook(torch)
worker = syft.VirtualWorker(hook, id=""worker"")

model = models.alexnet(pretrained=True)
for param in model.parameters():
    param.requires_grad=False
model.classifier[6] = nn.Linear(model.classifier[6].in_features, 3)
model.send(worker)
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-15-a250859d9a13> in <module>
----> 1 model.send(worker)

~/implementation/PyGrid/gateway/src/syft/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, force_send, *dest, **kwargs)
    608 
    609             if module_is_missing_grad(nn_self):
--> 610                 create_grad_objects(nn_self)
    611 
    612             for p in nn_self.parameters():

~/implementation/PyGrid/gateway/src/syft/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    600             for p in model.parameters():
    601                 o = p.sum()
--> 602                 o.backward()
    603                 if p.grad is not None:
    604                     p.grad -= p.grad

~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/trace.py in trace_wrapper(*args, **kwargs)
     81                 syft.hook.trace.logs.append((command, response))
     82             else:
---> 83                 response = func(*args, **kwargs)
     84 
     85             return response

~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    436                 except BaseException as e:
    437                     # we can make some errors more descriptive with this method
--> 438                     raise route_method_exception(e, self, args, kwargs)
    439 
    440             else:  # means that there is a wrapper to remove

~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    432 
    433                 try:
--> 434                     response = method(*args, **kwargs)
    435 
    436                 except BaseException as e:

~/anaconda3/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    193                 products. Defaults to ``False``.
    194         """"""
--> 195         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    196 
    197     def register_hook(self, hook):

~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
 
```@avinath1998 If you are trying to change the whole **model.classifier** block, then your input dimension (which you put 2) is wrong. The input dimension of **model.classifier** should be 256x6x6.
refer: https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py

```
self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )
```@imraniac Oh shoot, i only added this as an example and didnt see that. Regardless, the error still comes up, ive updated the issue accordinglyHave you still updated the issue with an example? Because it should be 256 * 6 * 6 and not 224@imraniac updated accordingly, still doesn't work, the error occursI will check this.@tudorcebere, assigned you",6,2020-03-11 15:34:39,2020-03-16 12:32:12,2020-03-16 12:32:12
https://github.com/OpenMined/PySyft/issues/3174,[],UnicodeDecodeError trying to get the loss back,"UnicodeDecodeError trying to get the loss backI am running the [mnist-federated-learning tutorial](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets-example-MNIST) on two separate machines. Once I try to get the loss back in  `train_on_batches` function of [run_websocket_client script](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/websockets-example-MNIST/run_websocket_client.py), I have received the following error:

> UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte


The traceback of the error is:

> File ""synchronous_federated_learning.py"", line 79, in <module>
    abort_after_one=abort_after_one)
  File ""/home/run_websocket_client.py"", line 129, in train
    worker, curr_batches, model, device, lr
  File ""/home/run_websocket_client.py"", line 66, in train_on_batches
    loss = loss.get()  # <-- NEW: get the loss back
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 578, in get
    tensor = self.child.get(*args, user=user, reason=reason, **kwargs)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/generic/pointers/pointer_tensor.py"", line 317, in get
    tensor = ObjectPointer.get(self, user=user, reason=reason, deregister_ptr=deregister_ptr)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py"", line 269, in get
    obj = self.owner.request_obj(self.id_at_location, self.location, user, reason)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/workers/base.py"", line 628, in request_obj
    obj = self.send_msg(ObjectRequestMessage((obj_id, user, reason)), location)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/workers/base.py"", line 285, in send_msg
    response = sy.serde.deserialize(bin_response, worker=self)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/serde/serde.py"", line 69, in deserialize
    return strategy(binary, worker)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/serde/msgpack/serde.py"", line 368, in deserialize
    simple_objects = _deserialize_msgpack_binary(binary, worker)
  File ""/home/miniconda3/envs/pysyft/lib/python3.6/site-packages/syft/serde/msgpack/serde.py"", line 343, in _deserialize_msgpack_binary
    simple_objects = msgpack_lib.loads(binary, use_list=False)
  File ""msgpack/_unpacker.pyx"", line 195, in msgpack._cmsgpack.unpackb
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte

Do you have any idea? Thank you.I have realized that the value of `binary` as the input of `simple_objects = msgpack_lib.loads(binary, use_list=False)` is encoded as `windows-1252` (which is expected to be `utf-8`), and that is the reason it is unable to decode with `utf-8`. I am not sure but the reason might be the fact that I use the three different Ubuntu virtual machines (one server and two workers) on top of my `Windows` operating system. Once I run it on an Ubuntu machine (server) with two other Ubuntu virtual machines (workers) on top of it, then it works fine.",1,2020-03-10 17:29:20,2020-03-12 11:11:30,2020-03-12 11:11:30
https://github.com/OpenMined/PySyft/issues/3152,"['bug ', 'good first issue :mortar_board:']",Installation error: invalid command 'udacity',"Installation error: invalid command 'udacity'**Describe the bug**
While installing pysyft according to steps in INSTALLATION.md, running `python setup.py install udacity` gives `error: invalid command 'udacity'`.

**To Reproduce**
Steps to reproduce the behavior:
1.Follow instructions in INSTALLATION.md to install PySyft for Linux.
2. run `python setup.py install udacity`

**Desktop (please complete the following information):**
 - OS: [linux ubuntu 18.04]
Were you able to install PySyft or not ?
If not then just try running
`python setup.py install`I think udacity command also installs `tf_encrypted` besides core requirements.
That I think you can manually install in my opinion.I think we should mention that you can install tf_encrypted using req_udacity.txt in the pip-dep folder, should I make changes in the INSTALLATION.md?@J-Yash  PR got merged. If this issue is resolved, it should not be opened anymore",4,2020-03-06 23:47:27,2020-03-17 14:13:32,2020-03-17 14:13:32
https://github.com/OpenMined/PySyft/issues/3151,[],ERROR while syft[udacity] installation via pip in conda env,"ERROR while syft[udacity] installation via pip in conda env**Describe the bug**
While installing pysyft via `pip install syft[udacity]` in a conda env, an error regarding tensorflow is generated.

```
ERROR: Could not find a version that satisfies the requirement tensorflow<2,>=1.12.0 (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == ""udacity""->syft[udacity]) (from versions: none)
ERROR: No matching distribution found for tensorflow<2,>=1.12.0 (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == ""udacity""->syft[udacity])
```


**To Reproduce**
Steps to reproduce the behavior:
1. run: `pip install syft[udacity]` according to the README.md instructions.

**Desktop (please complete the following information):**
 - OS: [linux ubuntu 18.04]
After tinkering with it for a while, I found that it was not working because Python 3.8 was installed in my conda env. Tensorflow(according to docs) is available only for python 3.5-3.7 and hence pip cannot find it if Python 3.8 is installed. So, I would recommend installing python 3.7 in the virtual environment and then running the syft installation command.",1,2020-03-06 22:56:28,2020-03-07 00:30:50,2020-03-07 00:30:50
https://github.com/OpenMined/PySyft/issues/3131,[],Sigmoid in SMPC failing for some shapes,"Sigmoid in SMPC failing for some shapes**Describe the bug**
 Examples to illustrate:

Working
```python
a = torch.Tensor([1,2,3])
a = a.fix_precision().share(bob, alice, crypto_provider = crypto_provider, requires_grad = True)
torch.nn.Sigmoid()(a)
```
Not working
```python
a = torch.Tensor([[1,2,3],[4,5,6]])
a = a.fix_precision().share(bob, alice, crypto_provider = crypto_provider, requires_grad = True)
torch.nn.Sigmoid()(a)
```
Error: `AssertionError: Must be batches of square matrices`

(same with `requires_grad=False`)

The error seems linked to tensor shape
It worked before by the way. Like a month agoMight need to add a test for this.I can take it @LaRiffle",3,2020-03-02 15:50:38,2020-03-22 13:49:22,2020-03-22 13:49:22
https://github.com/OpenMined/PySyft/issues/3112,[],Error installing PySyft(syft package),"Error installing PySyft(syft package)**Getting trouble in installing syft package**
I have cloned the pysyft repository and installed it in my local pc. 
After that, I followed the exact steps as written in the INSTALLATION.md.

`python setup.py install` command runs successfully but while testing using `python setup.py test` gives me the following error.

**Screenshots**
![Error](https://user-images.githubusercontent.com/38887333/75441027-e6bd2f00-5982-11ea-91d2-f1303371a68c.png)

**Desktop**
 - Windows 10
Make sure you have the latest version of the PySyft master branch and the latest version of syft-proto. This error indicates an incompatibility between your versions of the two.@shuvamlal9 Any luck with upgrading?@karlhigley nope still struggling to get the latest version.
I did what's given there to install the syft package but I'm not able to load that package.@shuvamlal9 What's the latest commit you have on the `master` branch?@karlhigley I have **commit 7d61c7** on my master branch. Previously, I wrote a simple article for installing pysfyt and get get rid of zstd error [(here)](https://medium.com/secure-and-private-ai-writing-challenge/installing-pysyft-package-ffa1ff0ad83c), but that doesn't seem to work now.Ah, okay! That's from a few weeks ago, before v0.2.3 was released. I'm about to release v0.2.4 in the next day or two, so you can do one of these things:
* Update your master branch to the latest commit on the main repo (currently `784cd9df`)
* Install v0.2.3 (and the corresponding version of `syft-proto` listed in the requirements file)
* Install v0.2.4 (once it's released)

The zstd dependency has been removed and should no longer be needed in v0.2.4.@shuvamlal9 Just released v0.2.4. Let me know if that works for you!_(Maybe not the good place but this a feedback I just got)_
**For Windows Users**
Install Microsoft VIsual C++ 14.0 first helps a lotThanks @karlhigley, v0.2.4 seems to work. Thanks a lot for the help.",9,2020-02-27 11:37:09,2020-03-20 23:04:34,2020-03-20 23:04:33
https://github.com/OpenMined/PySyft/issues/3105,[],Custom federated learning network (LSTM),"Custom federated learning network (LSTM)So, Im practicing federated learning with PyTorch, and I want to implement LSTM network for text generation. 

Here is the network: 
`
class LSTM(nn.Module):

    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):
        super(LSTM, self).__init__()
        self.embed = nn.Embedding(vocab_size, embed_size)  
        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)
        self.linear = nn.Linear(hidden_size, vocab_size)

    def forward(self, x, h):
        x = self.embed(x)

        out, (h, c) = self.lstm(x, h)  # (input , hidden state)

        out = out.reshape(out.size(0) * out.size(1), out.size(2))

        out = self.linear(out)
        return out, (h, c)
`
But, because federated learning requires dataset to be in specific form:

`base = sy.BaseDataset(torch.tensor(train), torch.tensor(test))
base_federated = base.federate((bob, adrian, patrycja, alice))
federated_train_loader = sy.FederatedDataLoader(base_federated, batch_size=args.batch_size)
`
Im getting an error that wrong object is passed to the network:

`RuntimeError: input.size(-1) must be equal to input_size. Expected 6431, got 0
`

I know that, this is because of how the data is structured:
`(Wrapper)>[PointerTensor | me:29040208176 -> bob:89708341131]
`
`
20 # batch size 
`
`
<class 'torch.Tensor'> # type`

and what I actually need is:

> `tensor([[ 112,  193,  592,  ...,  503,  143,  630],
        [ 492,   96, 1080,  ...,  378, 1106,   73],
        [ 284,  386,   97,  ...,    0,  284, 1502],
        ...,
        [  44,   45,   17,  ..., 5666,    0, 5667],
        [ 783, 6020,    0,  ...,    0,  178,  206],
        [   0,  151,   79,  ..., 6408, 5044,   77]])`

bare tensor data. 

So my question is, how to strip that weird `(Wrapper)>[PointerTensor | me:29040208176 -> bob:89708341131]
`
and obtain raw data from that sensor ?

hi,
wher you able to fix this error message",1,2020-02-26 10:40:47,2020-11-09 23:12:07,2020-02-26 10:55:47
https://github.com/OpenMined/PySyft/issues/3102,[],syft.exceptions.UndefinedProtocolTypeError: syft.messaging.message.Operation is not defined in the protocol file,"syft.exceptions.UndefinedProtocolTypeError: syft.messaging.message.Operation is not defined in the protocol file
    when i installed pysyft,  run  _python run_websocket_server.py_  in pysyft-master directoriy. it comes out ""syft.exceptions.UndefinedProtocolTypeError: syft.messaging.message.Operation is not defined in the protocol file"". 
    i have tried to re-install the system(ubuntu 16.04) and pysyft, but it did't work .   
    On my other machine, the same method is successful. What should i do to solve the problem?I met the same Error as your when importing syft.
Did anyone solve this problem?the latest version of syft-proto seems to have issues.
try: pip install syft-proto==0.1.1a1.post20> the latest version of syft-proto seems to have issues.
> try: pip install syft-proto==0.1.1a1.post20

Perfect solutionï¼The [PR corresponding to those changes in PySyft](https://github.com/OpenMined/PySyft/pull/3090) hadn't yet been reviewed and merged. New PySyft version with those changes coming soon.Should be fixed by recent releases (v0.2.3 or v0.2.4.)",5,2020-02-26 06:14:27,2020-03-18 15:51:57,2020-03-18 15:51:57
https://github.com/OpenMined/PySyft/issues/3095,[],TypeError in compute_q_noisy_max_approx function,"TypeError in compute_q_noisy_max_approx function**Describe the bug**
Type error because of the subtraction between `counts`(which is a list) and `counts[winner]`(which is a float). 

**Expected behavior**
The final answer to this computation should be 0.8

**Screenshots**
![Screenshot from 2020-02-25 21-50-19](https://user-images.githubusercontent.com/39258575/75266815-e86ae380-5818-11ea-9eb3-3cbab288bbcc.png)

**Desktop (please complete the following information):**
 - OS: Linux Ubuntu 16.04

**Additional context**
Add any other context about the problem here.
To solve this, there has to be a loop to iterate `counts` so that the correct code should be 
` 
for i in range(len(counts)):
   counts_normalized = noise_eps * (counts[i] - counts[winner])
`


Well sc should be a torch tensor, not a list.Ohh, my bad. Thank you for letting me know. You can close this issue.

On Tue, 25 Feb 2020 at 10:34 PM, Pierre Pocreau <notifications@github.com>
wrote:

> Well sc should be a torch tensor, not a list.
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3095?email_source=notifications&email_token=AJLQTT6DAS3DTPBGXXDDB7DREVFSFA5CNFSM4K3N3NI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEM4VNFY#issuecomment-590960279>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJLQTTYYZXE6QISVMDMCETDREVFSFANCNFSM4K3N3NIQ>
> .
>",2,2020-02-25 16:22:55,2020-02-26 05:20:38,2020-02-26 05:20:38
https://github.com/OpenMined/PySyft/issues/3091,[],AttributeError: module 'syft.messaging' has no attribute 'plan',"AttributeError: module 'syft.messaging' has no attribute 'plan'I get this problem when connecting to the WebSocketGridClient.  
Can anyone help me with this issue?
```
File ""/usr/local/lib/python3.7/site-packages/grid/__init__.py"", line 3, in <module>
   from grid.websocket_client import WebsocketGridClient
File ""/usr/local/lib/python3.7/site-packages/grid/websocket_client.py"", line 30, in <module>
    class WebsocketGridClient(WebsocketClientWorker, FederatedClient):
File ""/usr/local/lib/python3.7/site-packages/grid/websocket_client.py"", line 478, in WebsocketGridClient
    def serve_encrypted_model(self, encrypted_model: sy.messaging.plan.Plan) -> bool:
AttributeError: module 'syft.messaging' has no attribute 'plan'
```
It looks like that code was deprecated and later removed in #476, which [suggests](https://github.com/OpenMined/PyGrid/commit/2b543d075b86a6846d815ab5bdba45b551f48654#diff-b1ef8a3aed029ba9fb6663df43b6c7daL16) using PySyft's `syft.grid` module instead.@DanielMorales9 is this issue still present? Hi @gmuraru, after following this it works fine. 

> It looks like that code was deprecated and later removed in #476, which [suggests](https://github.com/OpenMined/PyGrid/commit/2b543d075b86a6846d815ab5bdba45b551f48654#diff-b1ef8a3aed029ba9fb6663df43b6c7daL16) using PySyft's `syft.grid` module instead.",3,2020-02-24 13:41:34,2020-03-14 14:17:42,2020-03-14 14:17:42
https://github.com/OpenMined/PySyft/issues/3079,[],Attribute error,"Attribute errormodule 'syft' has no attribute 'ID_PROVIDER'
![tempsnip](https://user-images.githubusercontent.com/41802909/75015792-778d9980-54af-11ea-86bf-b77b93e19837.png)


@AnchalAgarwal21 What PySyft version are you using?@karlhigley 0.2.3a1@AnchalAgarwal21 Huh, haven't seen that issue with that version. Could you share the output of `pip list` and the imports above in the notebook?I have a silly question but have done a full â€˜import syft as syâ€™ before?
I had a similar error when doing strange things during the syft import

What is the full sample of code you re trying to run?@karlhigley 
import torch as th
from torch import nn,optim
import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.exceptions import WorkerNotFoundExceptionI copied the entire code on another notebook and to my surprise, it didn't give any error but now I have encountered another error.
![tempsnip1](https://user-images.githubusercontent.com/41802909/75114484-2bdc1b00-567c-11ea-82c2-611d5c502344.png)
 You forgot to hook torch with `hook = sy.TorchHook(torch) `to extend torch tensors methods.Thank you @pierrepocreau ..I missed placing the hook torch.",8,2020-02-21 08:09:44,2020-02-25 17:40:13,2020-02-25 17:40:13
https://github.com/OpenMined/PySyft/issues/3063,[],Asynchronous FL on MNIST: call WebsocketClientWorker evaluate() method causes error,"Asynchronous FL on MNIST: call WebsocketClientWorker evaluate() method causes errorHello! 
I am trying to run the example from [tutorials](https://github.com/OpenMined/PySyft/tree/09f052aae8654377ffea7faeb6b12d0f75ba319a/examples/tutorials/advanced/websockets-example-MNIST-parallel).  Everything works great until the models' evaluation. The script crashes with the error:

Client message

> RuntimeError                              Traceback (most recent call last)
> <ipython-input-14-63915de412fc> in async-def-wrapper()
>      37             )
>      38 
> ---> 39     # Federate models (note that this will also change the model in models[0]
>      40     for worker_id, worker_model, worker_loss in results:
>      41         if worker_model is not None:
> 
> <ipython-input-13-38da89661156> in evaluate_model_on_worker(model_identifier, worker, dataset_key, model, nr_bins, batch_size, print_target_hist)
>      67         nr_bins=nr_bins,
>      68         return_loss=True,
> ---> 69         return_raw_accuracy=True
>      70     )
>      71     test_loss = result[""loss""]
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in evaluate(self, dataset_key, return_histograms, nr_bins, return_loss, return_raw_accuracy)
>     221             nr_bins=nr_bins,
>     222             return_loss=return_loss,
> --> 223             return_raw_accuracy=return_raw_accuracy,
>     224         )
>     225 
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in _send_msg_and_deserialize(self, command_name, *args, **kwargs)
>     113         # Send the message and return the deserialized response.
>     114         serialized_message = sy.serde.serialize(message)
> --> 115         response = self._send_msg(serialized_message)
>     116         return sy.serde.deserialize(response)
>     117 
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in _send_msg(self, message, location)
>      81 
>      82     def _send_msg(self, message: bin, location=None) -> bin:
> ---> 83         return self._recv_msg(message)
>      84 
>      85     def _forward_to_websocket_server_worker(self, message: bin) -> bin:
> 
> ~/Library/Python/3.7/lib/python/site-packages/syft/workers/websocket_client.py in _recv_msg(self, message)
>     102             if not self.ws.connected:
>     103                 raise RuntimeError(
> --> 104                     ""Websocket connection closed and creation of new connection failed.""
>     105                 )
>     106         return response
> 
> RuntimeError: Websocket connection closed and creation of new connection failed.

Server message:

> 2020-02-18 17:54:56,388 | Task exception was never retrieved
> future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /opt/conda/lib/python3.6/site-packages/syft/workers/websocket_server.py:95> exception=AttributeError(""'dict' object has no attribute 'owner'"",)>
> Traceback (most recent call last):
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
>     response = self._recv_msg(message)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
>     return self.recv_msg(message)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/base.py"", line 310, in recv_msg
>     response = self._message_router[type(msg)](msg.contents)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/workers/base.py"", line 457, in execute_command
>     command_name, response, list(return_ids), self
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 665, in register_response
>     new_response = register_response_function(response, response_ids=response_ids, owner=owner)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 766, in <lambda>
>     return lambda x, **kwargs: f(lambdas, x, **kwargs)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 522, in two_fold
>     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 744, in <lambda>
>     else lambda i, **kwargs: register_tensor(i, **kwargs)
>   File ""/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py"", line 712, in register_tensor
>     tensor.owner = owner
> AttributeError: 'dict' object has no attribute 'owner'

Exactly the same issue is described [here](https://stackoverflow.com/questions/60202610/pysyft-federated-learning-error-with-websockets?newreg=9254d6ab17014bcb896f3a2a45843b18)

Version of the lib is '0.2.3a1' See #2948 Sounds like we might need to release a new version with recent fixes.Wait, #2948 was included in 0.2.3.a1...I checked [2948](https://github.com/OpenMined/PySyft/pull/2948). It is not the source of the problem.The source of the problem is incorrect type of the function output. According to `Operation` class (from `syft/messaging/message.py`) the output must be `Tensor`. But `evaluate()` function (from `syft/federated/federated_client.py`) returns dictionary of floats. Facing the same Issue with recently published docker image also @karlhigley @karlhigley I have more or less the same problem running the same tutorial.  @9sashafr could you find any workaround?I'm in the process of doing some clean-up deep in the guts of Plans and Operations, starting with #3078. It may take a while to resolve this issue; not sure if making the output type more flexible or adding separate messages to the Syft protocol will turn out to be a preferable approach. Will keep this issue in mind as we sort through issues with the core abstractions.I was able to workaround by changing the generic/frameworks/hook/hook_args.py file so the register_tensor function is:

```python
def register_tensor(
    tensor: FrameworkTensorType, owner: AbstractWorker, response_ids: List = list()
):
    """"""
    Registers a tensor.

    Args:
        tensor: A tensor.
        owner: The owner that makes the registration.
        response_ids: List of ids where the tensor should be stored
            and each id is pop out when needed.
    """"""

    #tensor.owner = owner
    #try:
    #    tensor.id = response_ids.pop(-1)
    #except IndexError:
    #    raise exceptions.ResponseSignatureError

    owner.register_obj(tensor, response_ids.pop(-1))
```@brandonhee After doing, what you suggested I got another error saying dict object has no attribute 'id'. 

Any ideas?@Dhrumilsoni I have tried with the master and I think the bug has been fixed and it works now. Fixed in master and should work in the next release.",12,2020-02-18 15:33:40,2020-03-17 14:22:48,2020-03-17 14:22:48
https://github.com/OpenMined/PySyft/issues/3045,[],Try fix problem regarding to {RuntimeError} in Ch06 (please see detail thanks),"Try fix problem regarding to {RuntimeError} in Ch06 (please see detail thanks) The bug can be found here (my pull request)
[here](https://github.com/OpenMined/PySyft/pull/2766), which shows the attempt to fix the GPU error by myself.

It is my first time contributing to open source project, please let me if there is any mistake, thank you so much!

Let's keep the conversation on this issue over in #2766. Left a comment there about a test failure in the CI checks.",1,2020-02-10 14:19:30,2020-02-10 14:25:54,2020-02-10 14:25:54
https://github.com/OpenMined/PySyft/issues/3043,[],"Create a syft.load(tensor, src=worker_id) functionality","Create a syft.load(tensor, src=worker_id) functionalityThis should be equivalent to worker.search, but is supposed to be retrieving information _locally_, when src matches the current worker. (behaviour is supposed to be close to crypten.load)
As is, this function is supposed not to fail and to always return something  (even random) when using in a plan at building.
Details on implementation are not all solved yet.Can I work on this @LaRiffle ?There is a PR on this, currently linked [here](https://github.com/OpenMined/PySyft/pull/3074). Sorry I did not put the reference in the PR :(",2,2020-02-10 08:30:05,2020-04-02 13:54:29,2020-04-02 13:54:29
https://github.com/OpenMined/PySyft/issues/3040,[],AttributeError: module 'torch' has no attribute 'quint8',"AttributeError: module 'torch' has no attribute 'quint8'I installed Pysyft on my local machine following this [ installation guide](https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md) and when i import syft. it shows this error: 

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-3-44770bd007ea> in <module>
----> 1 import syft

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/__init__.py in <module>
     41 
     42 # Import grids
---> 43 from syft.grid.private_grid import PrivateGridNetwork
     44 from syft.grid.public_grid import PublicGridNetwork
     45 

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/grid/private_grid.py in <module>
      9 # Syft imports
     10 from syft.grid.abstract_grid import AbstractGrid
---> 11 from syft.workers.node_client import NodeClient
     12 from syft.messaging.plan.plan import Plan
     13 from syft.frameworks.torch.tensors.interpreters.additive_shared import AdditiveSharingTensor

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/workers/node_client.py in <module>
      5 
      6 # Syft imports
----> 7 from syft.serde import serialize
      8 from syft.messaging.plan import Plan
      9 from syft.codes import REQUEST_MSG, RESPONSE_MSG

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/serde/__init__.py in <module>
----> 1 from syft.serde.serde import *

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/serde/serde.py in <module>
     10 from syft.workers.abstract import AbstractWorker
     11 
---> 12 from syft.serde import msgpack
     13 
     14 ## SECTION:  High Level Public Functions (these are the ones you use)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/serde/msgpack/__init__.py in <module>
----> 1 from syft.serde.msgpack import serde
      2 from syft.serde.msgpack import native_serde
      3 from syft.serde.msgpack import torch_serde
      4 from syft.serde.msgpack import proto
      5 

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/serde/msgpack/serde.py in <module>
     78 
     79 if dependency_check.torch_available:
---> 80     from syft.serde.msgpack.torch_serde import MAP_TORCH_SIMPLIFIERS_AND_DETAILERS
     81 else:
     82     MAP_TORCH_SIMPLIFIERS_AND_DETAILERS = {}

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/serde/msgpack/torch_serde.py in <module>
     20 from syft.codes import TENSOR_SERIALIZATION
     21 
---> 22 from syft.serde.torch.serde import TORCH_DTYPE_STR
     23 from syft.serde.torch.serde import TORCH_STR_DTYPE
     24 from syft.serde.torch.serde import TORCH_MFORMAT_ID

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_unlocked(spec)

~/anaconda3/envs/pysyft/lib/python3.7/importlib/_bootstrap.py in _load_backward_compatible(spec)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.2.3a1-py3.7.egg/syft/serde/torch/serde.py in <module>
     23     torch.bool: ""bool"",
     24     torch.qint8: ""qint8"",
---> 25     torch.quint8: ""quint8"",
     26     torch.qint32: ""qint32"",
     27     torch.bfloat16: ""bfloat16"",

AttributeError: module 'torch' has no attribute 'quint8'
```

**Desktop:**
- OS: Ubuntu 18.04.3 LTS
- Python 3.7
- PyTorch 1.1


Ah, yeah, I think these types were introduced in newer versions of PyTorch. Youâ€™ll currently need 1.4.",1,2020-02-10 02:43:18,2020-02-10 13:08:00,2020-02-10 03:04:03
https://github.com/OpenMined/PySyft/issues/3027,[],Investigate alternatives to Plans,"Investigate alternatives to PlansUsing Plans in CrypTen is both convenient and painful, because we can't easily ask Plans to support crypten specific operations. Hence, we're also exploring alternative solutions, if they exist, to collect (close to arbitrary) operations in a function and send them to another worker.An alternative would be to send the source code of the function definition (we can get it from the function object using the dill library), then each worker will need to run static analysis (using [AST](https://docs.python.org/3/library/ast.html) or a similar library) to make sure the function is safe.

Running static analysis, we can have a whitelist of allowed function calls, and flag as unsafe any function that goes beyond those calls. We can do the same for attributes, however, we will also need to track variable types as  the _objects attribute might be a safe to access on object X but not on object Y. So the whitelist must be a list of (type, func | attr) pairs to have both flexibility and security.If it helps - for Tensorflow the current roadmap is to use TFF to create Tensorflow's version of ""plans"" and then ship those over (still wrapped in a ""Plan"" like object?)Another alternative would be to jail the execution of the sent function in a secure execution environment. This means that only crypten functionalities are available, no filesystem access, no networking etc. I'm checking this [library](https://github.com/zopefoundation/RestrictedPython) and if we can use it to secure the function sharing across workers.Sending whitelisted functions from one machine to another is _exactly_ what Plans are supposed to do - if Plans don't support this use case, we need to fix plans (instead of build an alternative)Closing this as Jail is now being demo-ed.",5,2020-02-07 21:44:10,2020-05-21 12:50:21,2020-05-21 12:50:21
https://github.com/OpenMined/PySyft/issues/3019,[],Websocket worker start Error,"Websocket worker start Error**Describe the bug**
Trying to play nicely with websocket but got nasty error

**To Reproduce**
Start the worker in some notbook
```python
import torch
import syft as sy

hook = sy.TorchHook(torch)

from syft.workers.websocket_server import WebsocketServerWorker

local_worker = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8183)

local_worker.start()
```

**Expected behavior**
Should wait quietly to hear from the client

**Stacktrace**
```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-1-0df61b862dcd> in <module>
     12                             port=8183)
     13 
---> 14 local_worker.start()

~/code/PySyft/syft/workers/websocket_server.py in start(self)
    171             )
    172 
--> 173         asyncio.get_event_loop().run_until_complete(start_server)
    174         print(""Serving. Press CTRL-C to stop."")
    175         try:

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py in run_until_complete(self, future)
    553         future.add_done_callback(_run_until_complete_cb)
    554         try:
--> 555             self.run_forever()
    556         except:
    557             if new_task and future.done() and not future.cancelled():

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py in run_forever(self)
    508         self._check_closed()
    509         if self.is_running():
--> 510             raise RuntimeError('This event loop is already running')
    511         if events._get_running_loop() is not None:
    512             raise RuntimeError(

RuntimeError: This event loop is already running
```

**Desktop (please complete the following information):**
 - OS: macOS Catalina
 - Python 3.7.*
- PyTorch 1.4
- tornado 6.0.2

**Additional info**
I can make a hard fix using [this stackoverflow solution](https://stackoverflow.com/questions/53248431/asyncio-runtimeerror-this-event-loop-is-already-running/53525009)
```
pip install tornado==4.5.3
```Can I work on this issue @LaRiffle we need to downgrade the tornadoHi,

When downgrading the version of tornado, more recent versions of jupyter notebook (& lab) stop working (notebook 6.0.3). Fixed this by running `pip install syft[udacity,notebooks]` so I can get a proper compatible version",3,2020-02-06 08:46:19,2020-03-29 21:41:06,2020-03-15 11:31:48
https://github.com/OpenMined/PySyft/issues/3014,[],ConnectionRefusedError: [Errno 111] Connection refused,"ConnectionRefusedError: [Errno 111] Connection refusedHi, I am using PyTorch 1.4.0, and syft version 0.2.3.a1. I am trying to run [grid tutorial on federated learning](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb). Once I do `compute_nodes.append( NodeClient(hook, node) )`, I get the following error:

> ConnectionRefusedError: [Errno 111] Connection refused

This is the full stack of the error:

> File ""./train.py"", line 26, in <module>
    compute_nodes.append( NodeClient(hook, node) )
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/node_client.py"", line 56, in __init__
    super().__init__(
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/websocket_client.py"", line 57, in __init__
    self.connect()
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/websocket_client.py"", line 69, in connect
    self.ws = websocket.create_connection(**args)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_core.py"", line 222, in connect
    self.sock, addrs = connect(url, self.sock_opt, proxy_info(**options),
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 201, in _open_socket
    raise err
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [Errno 111] Connection refusedDid you initiate each node/grid?This is the code snippet I used:
```python
import syft as sy 
from syft.workers.node_client import NodeClient
from syft.grid.public_grid import PublicGridNetwork
import torch

hook = sy.TorchHook(torch)
nodes = [""ws://localhost:3000/"",""ws://localhost:3001/""]
compute_nodes = []
for node in nodes:
    compute_nodes.append( NodeClient(hook, node) )
```But if you just did it without support of docker/command line, that's not supposed to work. You have to initiate the gateway and both node using docker from [grid](https://github.com/OpenMined/PyGrid/) documentation or using the following commands:

Gateway (at grid/gateway):
`python gateway.py --port=5000 --start_local_db`

Each node (at grid/app/websocket):
`python websocket_app.py --id=bob --port=3001 --gateway_url=http://localhost:5000`
`python websocket_app.py --id=alice --port=3001 --gateway_url=http://localhost:5000`thank you so much. It works when I run them as you said, in the background.",4,2020-02-05 11:42:07,2020-02-18 11:48:46,2020-02-18 11:48:46
https://github.com/OpenMined/PySyft/issues/3002,[],Error when try to send data using dataloader,"Error when try to send data using dataloader**Describe the bug**
Hello! I'm trying to build an all enviroment using PyGrid/PySyft since a while. My testes went good since today, when i update syft library and an error including dataloader shows up. The error hapens when i try to iterate on my last dataloader, no matter if 2, 3 or x dataloader, the error always appears when the last dataloader will be iterated.

**To Reproduce**
1. Build a data loader (in my case, my dataloader was built with cifar10 images)
2. Iterate trought this dataloader (sending the data for worker(s))
3. At the last interaction, the error below must appears

**Screenshots**
![image](https://user-images.githubusercontent.com/23393117/73663280-0743e300-467c-11ea-9a62-2b647061310c.png)


**Desktop (please complete the following information):**
 - OS: Ubuntu Mate
 - Version 16.04

**Additional context**
If i add a False flag at line 63 syft/generic/frameworks/hook/trace.py it work's, but clearly not the best option. 
Hum, so it says that `syft.hook` is a function while it's supposed to be an instance of `TorchHook`Could you provide a small example? Because it is used bu Tutorial 6 and seems to be working there.That was exactly what I was writing, I was using DataLoader from torch and not from syft. Maybe if I use `sy.FederatedDataLoader` it works, but I don't know for sure. I'm going to test it and return with a feedback. While I was testing, I just realize that I want to send my dataset with tags in pygrid, so I think that is not the best option to me. For now I'm using a stable version that works to me, just a few commits ago.

Here is a small example that you asked for: https://gist.github.com/joaolcaas/4be061459b5893cfc2b73b9a1620c94f

The error here hapens before the any call to send because here exists just one `data_iter`.  The `./data2` is a path for cifar10 dataset. I don't know if you would like to test once the error is related to grid, but is a syft error.



@LaRiffle sorry, my mistake. I was not instantiating `hook = sy.TorchHook(torch)` because i thought my main file was getting `hook` from another file. So, not to worry about :smile:",5,2020-02-03 15:00:32,2020-02-04 19:53:38,2020-02-04 19:53:38
https://github.com/OpenMined/PySyft/issues/3001,"['bug ', 'status: stale :bread:']",Issue with Encrypted Aggregation,"Issue with Encrypted AggregationTutorial Part 10, when I call 

```
# iterate through each parameter
for param_i in range(len(params[0])):

    # for each worker
    spdz_params = list()
    for remote_index in range(len(compute_nodes)):
        
        # select the identical parameter from each worker and copy it
        copy_of_parameter = params[remote_index][param_i].copy()
        
        # since SMPC can only work with integers (not floats), we need
        # to use Integers to store decimal information. In other words,
        # we need to use ""Fixed Precision"" encoding.
        fixed_precision_param = copy_of_parameter.fix_precision()
        
        # now we encrypt it on the remote machine. Note that 
        # fixed_precision_param is ALREADY a pointer. Thus, when
        # we call share, it actually encrypts the data that the
        # data is pointing TO. This returns a POINTER to the 
        # MPC secret shared object, which we need to fetch.
        encrypted_param = fixed_precision_param.share(bob, alice, crypto_provider=james)
        
        # now we fetch the pointer to the MPC shared value
        param = encrypted_param.get()
        
        # save the parameter so we can average it with the same parameter
        # from the other workers
        spdz_params.append(param)

    # average params from multiple workers, fetch them to the local machine
    # decrypt and decode (from fixed precision) back into a floating point number
    new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2
    
    # save the new averaged parameter
    new_params.append(new_param)
```
I get this error:

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    662         # Load the utility function to register the response and transform tensors with pointers
--> 663         register_response_function = register_response_functions[attr_id]
    664         # Try running it

KeyError: 'numpy'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-15-34467fe3bdcd> in <module>
     12         # to use Integers to store decimal information. In other words,
     13         # we need to use ""Fixed Precision"" encoding.
---> 14         fixed_precision_param = copy_of_parameter.fix_precision()
     15 
     16         # now we encrypt it on the remote machine. Note that

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, storage, field_type, no_wrap, *args, **kwargs)
    765 
    766         max_precision = _get_maximum_precision()
--> 767         need_large_prec = self._requires_large_precision(max_precision, base, prec_fractional)
    768 
    769         if storage == ""crt"":

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in _requires_large_precision(self, max_precision, base, precision_fractional)
    837         # We need to use NumPy here as log2 is not yet implemented for LongTensor PyTorch objects
    838         return np.any(
--> 839             np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision
    840         )
    841 

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/trace.py in trace_wrapper(*args, **kwargs)
     81                 syft.hook.trace.logs.append((command, response))
     82             else:
---> 83                 response = func(*args, **kwargs)
     84 
     85             return response

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    475                 # Send the new command to the appropriate class and get the response
    476                 method = getattr(new_self, method_name)
--> 477                 response = method(*new_args, **new_kwargs)
    478 
    479                 # For inplace methods, just directly return self

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    638             command = (attr, self, args, kwargs)
    639 
--> 640             response = owner.send_command(location, command)
    641 
    642             # For inplace methods, just directly return self

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    510         try:
    511             ret_val = self.send_msg(
--> 512                 Operation(cmd_name, cmd_owner, cmd_args, cmd_kwargs, return_ids), location=recipient
    513             )
    514         except ResponseSignatureError as e:

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in send_msg(self, message, location)
    275 
    276         # Step 2: send the message and wait for a response
--> 277         bin_response = self._send_msg(bin_message, location)
    278 
    279         # Step 3: deserialize the response

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/virtual.py in _send_msg(self, message, location)
      5 class VirtualWorker(BaseWorker, FederatedClient):
      6     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 7         return location._recv_msg(message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/virtual.py in _recv_msg(self, message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:
---> 10         return self.recv_msg(message)

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in recv_msg(self, bin_message)
    308 
    309         # Step 1: route message to appropriate function
--> 310         response = self._message_router[type(msg)](msg.contents)
    311 
    312         # Step 2: Serialize the message to simple python objects

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/workers/base.py in execute_command(self, message)
    455             try:
    456                 response = hook_args.register_response(
--> 457                     command_name, response, list(return_ids), self
    458                 )
    459                 return response

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    670         register_response_functions[attr_id] = register_response_function
    671         # Run it
--> 672         new_response = register_response_function(response, response_ids=response_ids, owner=owner)
    673 
    674     # Remove the artificial tuple

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in <lambda>(x, **kwargs)
    764         f = many_fold
    765 
--> 766     return lambda x, **kwargs: f(lambdas, x, **kwargs)

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    520 
    521 def two_fold(lambdas, args, **kwargs):
--> 522     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    523 
    524 

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in <lambda>(i, **kwargs)
    742         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    743         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 744         else lambda i, **kwargs: register_tensor(i, **kwargs)
    745         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    746     ]

~/anaconda3/lib/python3.7/site-packages/syft-0.2.2a1-py3.7.egg/syft/generic/frameworks/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    710             and each id is pop out when needed.
    711     """"""
--> 712     tensor.owner = owner
    713     try:
    714         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```

OS: Ubuntu 18.04.3 LTS
Python 3.7
PyTorch 1.4I would like to work on this issueI have same issue.

I seems the problem was already fixed at https://github.com/OpenMined/PySyft/pull/2990 .
But still I could not how to avoid this error...> I would like to work on this issue

Hey Nilesh did you find any solution?
This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2020-02-03 13:26:06,2020-05-22 00:05:31,2020-05-22 00:05:31
https://github.com/OpenMined/PySyft/issues/2987,[],Send Plans to crypten parties,"Send Plans to crypten partiesWe'd like to send a built and serialized plan to a crypten party, which will then ask his syft worker to execute it for him, but in crypten mode and with crypten tensorsTried to list some challenges for this. What I have been facing so far:
1. Plans support hooked torch operations exclusively, crypten tensor types aren't supported by syft for the moment.
2. When running a multiparty computation, crypten operations supports the use of the `src` parameter which specify a special behavior at party with rank `src`. If we initialized crypten with a single party group then the build will throw an error `invalid tensor source` as the `src` might be for a party with rank greater than the number of parties initialized.
3. As plans are built by running the function and recording the executed ops, running a single crypten party when more are required will block as synchronization is required between parties to complete the computation.So I think that actually plans would be built using pure torch.tensors, which is ok to record operations in the `run_multiprocess`. The only pb is regarding the crypten specific bits:
```

@mpc.run_multiprocess(world_size=2)
def examine_binary_shares():
    x_enc = crypten.load('models/tutorial4_alice_model.pth', dummy_model=dummy_model, src=ALICE)
    
    y = x_enc * 2  # This is easy
    return y
```

Regarding the `crypten.load('path', src...)`, I'd favour replacing it by a simple `syft.search('#tag',src=alice)`  (which needs to be implemented)

If we do this, we can (at the expense of slightly changing the syntax as shown above) record all the meaningful operations by running the plan only once on the client using cleartext pure torch tensors, and then forward this to the remote workers which hold the crypten workers. (Here syft.search would be recorded by a `@tracer` decorator, but would output probably just a random tensors without really doing a search (we don't want to bother alice))
We may require a new plan builder for crypten. I think we can solve issues 2 and 3 listed above by setupping local parties using virtual workers, running the crypten computation and recording operations.Solved by the amazing @gmuraru",4,2020-01-31 17:17:30,2020-05-21 13:31:53,2020-05-21 13:31:52
https://github.com/OpenMined/PySyft/issues/2973,[],module 'torch._C' has no attribute 'Function' - error when importing syft,"module 'torch._C' has no attribute 'Function' - error when importing syft**Describe the bug**
I'm having a lot of troubles installing pysyft on Ubuntu 18.04. I cloned the repo and tried to install it according to those instructions:
````
Install Python 3.6 or higher
Install PyTorch 1.3
Clone PySyft (git clone https://github.com/OpenMined/PySyft.git)
cd PySyft
pip install -r pip-dep/requirements.txt
pip install -r pip-dep/requirements_udacity.txt
python setup.py install udacity
python setup.py test
````
I managed to install all requirements but then got an error on the second to last step (`python setup.py install udacity`) saying `error: invalid command 'udacity'`

I then tried to install pysyft using `pip install syft` and it was successful but when I'm trying to import it I get the following error (`AttributeError: module 'torch._C' has no attribute 'Function'`)

What should I do to be able to use pysyft?

````
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-5-44770bd007ea> in <module>
----> 1 import syft

~/.local/lib/python3.6/site-packages/syft/__init__.py in <module>
     41 
     42 # Import grids
---> 43 from syft.grid.private_grid import PrivateGridNetwork
     44 from syft.grid.public_grid import PublicGridNetwork
     45 

~/.local/lib/python3.6/site-packages/syft/grid/private_grid.py in <module>
      9 # Syft imports
     10 from syft.grid.abstract_grid import AbstractGrid
---> 11 from syft.workers.node_client import NodeClient
     12 from syft.messaging.plan.plan import Plan
     13 from syft.frameworks.torch.tensors.interpreters.additive_shared import AdditiveSharingTensor

~/.local/lib/python3.6/site-packages/syft/workers/node_client.py in <module>
      5 
      6 # Syft imports
----> 7 from syft.serde import serialize
      8 from syft.messaging.plan import Plan
      9 from syft.codes import REQUEST_MSG, RESPONSE_MSG

~/.local/lib/python3.6/site-packages/syft/serde/__init__.py in <module>
----> 1 from syft.serde.serde import *

~/.local/lib/python3.6/site-packages/syft/serde/serde.py in <module>
     10 from syft.workers.abstract import AbstractWorker
     11 
---> 12 from syft.serde import msgpack
     13 
     14 ## SECTION:  High Level Public Functions (these are the ones you use)

~/.local/lib/python3.6/site-packages/syft/serde/msgpack/__init__.py in <module>
----> 1 from syft.serde.msgpack import serde
      2 from syft.serde.msgpack import native_serde
      3 from syft.serde.msgpack import torch_serde
      4 from syft.serde.msgpack import proto
      5 

~/.local/lib/python3.6/site-packages/syft/serde/msgpack/serde.py in <module>
     79 
     80 if dependency_check.torch_available:
---> 81     from syft.serde.msgpack.torch_serde import MAP_TORCH_SIMPLIFIERS_AND_DETAILERS
     82 else:
     83     MAP_TORCH_SIMPLIFIERS_AND_DETAILERS = {}

~/.local/lib/python3.6/site-packages/syft/serde/msgpack/torch_serde.py in <module>
    295         torch.device: (_simplify_torch_device, _detail_torch_device),
    296         torch.jit.ScriptModule: (_simplify_script_module, _detail_script_module),
--> 297         torch._C.Function: (_simplify_script_module, _detail_script_module),
    298         torch.jit.TopLevelTracedModule: (_simplify_script_module, _detail_script_module),
    299         torch.nn.Parameter: (_simplify_torch_parameter, _detail_torch_parameter),

AttributeError: module 'torch._C' has no attribute 'Function'
````I think we need to spin a new pysyft version? @karlhigley@s-marta Just published [a new release](https://pypi.org/project/syft/0.2.3a1/) that we think should address this issue. Could you give it a try and let us know if that resolves your issue?@karlhigley I updated and it seems to be working!  I managed to import it and basics from the first tutorial seem to be working as well. Many thanks for such quick help. Thanks for letting us know!",4,2020-01-29 23:58:15,2020-01-30 19:42:32,2020-01-30 19:42:32
https://github.com/OpenMined/PySyft/issues/2969,[],ModuleNotFoundError: No module named 'requests',"ModuleNotFoundError: No module named 'requests'**Describe the bug**
After installing, `import syft` gives the following error: 

`Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/xxxxx/opt/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/__init__.py"", line 44, in <module>
    from syft.grid.public_grid import PublicGridNetwork
  File ""/Users/xxxxx/opt/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/public_grid.py"", line 2, in <module>
    import requests
ModuleNotFoundError: No module named 'requests'
`


**To Reproduce**
Steps to reproduce the behavior:
1. `conda create -n pysyft python=3`
2. `conda activate pysyft`
3. `conda install jupyter notebook`
4. `pip install syft`
5. `python`
6. `import syft`
7. Result = See error above

**Environment :**
 - OS: macOS Catalina 10.15.1
 - python 3.7.6

If you can't find the package through typing `pip list` or other commands that gives you a list of installed packages on your virtual system, you can simply install it manually.
`pip install requests` which might need to be included in requirements.txt or something.Seems like it will be fixed by this PR https://github.com/OpenMined/PySyft/pull/2970/commits/033fc646ddd9c023c738a22e4493407ab0043b24Could you close this issue @jfraj?",3,2020-01-28 06:21:54,2020-01-29 17:42:04,2020-01-29 17:42:04
https://github.com/OpenMined/PySyft/issues/2966,[],Illegal instruction error once trying to import syft,"Illegal instruction error once trying to import syftHi, I have done the `syft` installation as explained in the installation part. Everything goes fine, but after installation once I try to `import syft` it ends up with the following error `Illegal instruction` and even terminated the python prompt. Do you have any idea? thank you.@fermat97 Could you post a stack trace? That will help with troubleshooting the issue.There is no stack trace. I start python prompt. Once I `import syft`, it quits python prompt and just showed `Illegal instruction`. Wow, that is puzzling. What `syft` version and what Python version?I have installed them couple of days ago, so I think it was the latest version 0.2.2a1. I have followed the pre-installation and installation guide on [PySyft git](https://github.com/OpenMined/PySyft). It is version 3.7.6 for the Python, and version 1.3.0 for the PyTorch. Hmm, well, we did see some issues with 0.2.2.a1 related to the update to PyTorch 1.4 and we released a newer version (0.2.3.a1) yesterday that might help. Maybe give that a try?I tried to update I couldn't, then I removed the environment and install everything from beginning, then I got this error:

> Collecting python-socketio>=4.3.0
Using cached python_socketio-4.4.0-py2.py3-none-any.whl (50 kB)
ERROR: Could not find a version that satisfies the requirement tensorflow<2,>=1.12.0 (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == ""udacity""->syft[udacity]) (from versions: none)
ERROR: No matching distribution found for tensorflow<2,>=1.12.0 (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == ""udacity""->syft[udacity])
I have tried once more, using `pip install syft` on the same environment, and it was successful. Now I can import syft without problem.",7,2020-01-27 13:09:35,2020-02-01 12:40:56,2020-02-01 12:40:55
https://github.com/OpenMined/PySyft/issues/2937,"['bug ', 'testing ', 'status: stale :bread:']",Flaky test in test_precision.py,"Flaky test in test_precision.py**Describe the bug**
The test `test_torch_sigmoid_approx` in `test/torch/tensors/test_precision.py` fails intermittently (4 out of 30 times that i tried) with the following error:

```python
>               assert (diff / (tolerance * norm)) < 1  
E               assert (tensor(0.0585) / (0.05 * tensor(0.9880))) < 1  
```
Does this indicate a bug or a dependency issue? I can help contribute to a fix if suggested.

**To Reproduce**
The error can be reproduced using the following seed:
```
def test_torch_sigmoid_approx(workers):
       torch.manual_seed(7893584826795948387)
       .....
```

**Expected behavior**
The test should always pass

**Screenshots**
NA

**Desktop (please complete the following information):**
Environment:
```
Ubuntu 16.04
python 3.7
numpy==1.17.4
syft-tensorflow==0.1.0
tensorflow==1.15.0
torch==1.3.0
torchvision==0.4.1 
```

**Additional context**
Full error log:
```
Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0.so'
WARNING:tensorflow:From python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

=============================================================================================== test session starts ===============================================================================================
platform linux -- Python 3.7.6, pytest-5.3.2, py-1.8.1, pluggy-0.13.1 -- bin/python
cachedir: .pytest_cache
rootdir: PySyft, inifile: setup.cfg
collecting ... collected 1 item

test/torch/tensors/test_precision.py::test_torch_sigmoid_approx FAILED

==================================================================================================== FAILURES =====================================================================================================
____________________________________________________________________________________________ test_torch_sigmoid_approx ____________________________________________________________________________________________

workers = {'alice': <VirtualWorker id:alice #objects:580>, 'bob': <VirtualWorker id:bob #objects:544>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:81>, ...}

    @assert_time(max_time=40)
    def test_torch_sigmoid_approx(workers):
        """"""
        Test the approximate sigmoid with different tolerance depending on
        the precision_fractional considered
        """"""
        #np.random.seed(771475754)
        torch.manual_seed(7893584826795948387)
        alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
    
        fix_prec_tolerance_by_method = {
            ""exp"": {3: 5 / 100, 4: 1 / 100, 5: 1 / 100},
            ""maclaurin"": {3: 7 / 100, 4: 15 / 100, 5: 15 / 100},
        }
    
        for method, fix_prec_tolerance in fix_prec_tolerance_by_method.items():
            for prec_frac, tolerance in fix_prec_tolerance.items():
                t = torch.tensor(range(-10, 10)) * 0.5
                t_sh = t.fix_precision(precision_fractional=prec_frac).share(
                    alice, bob, crypto_provider=james
                )
                r_sh = t_sh.sigmoid(method=method)
                r = r_sh.get().float_prec()
                t = t.sigmoid()
                diff = (r - t).abs().max()
                norm = (r + t).abs().max() / 2
    
>               assert (diff / (tolerance * norm)) < 1
E               assert (tensor(0.0585) / (0.05 * tensor(0.9880))) < 1

test/torch/tensors/test_precision.py:474: AssertionError
================================================================================================ 1 failed in 5.91s ================================================================================================

```@loopylangur could you test this after #2998 gets merged?@loopylangur the PR got merged - could you retest this, please?Hi, I can still reproduce the error with the latest version.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2020-01-20 18:49:19,2020-05-22 00:06:05,2020-05-22 00:06:05
https://github.com/OpenMined/PySyft/issues/2931,[],Conda install on Manjaro error on import. ModuleNotFoundError: No module named 'pysyft_proto',"Conda install on Manjaro error on import. ModuleNotFoundError: No module named 'pysyft_proto'**Describe the bug**
Conda install on Manjaro error on import. Obtaining  `ModuleNotFoundError: No module named 'pysyft_proto' `

**To Reproduce**
```
conda create -n pysyft python=3
conda activate pysyft # some older version of conda require ""source activate pysyft"" instead.
conda install jupyter notebook
pip install ""syft[udacity]""
```

Then, in Python

```
import syft as sy
```

results in 

```
Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0.so'
WARNING:tensorflow:From /home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/__init__.py"", line 76, in <module>
    from syft import serde
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/__init__.py"", line 1, in <module>
    from syft.serde.serde import *
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/serde.py"", line 89, in <module>
    from syft.serde.proto import proto_type_info
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/proto.py"", line 13, in <module>
    from pysyft_proto import proto_info
ModuleNotFoundError: No module named 'pysyft_proto'

```

**Expected behavior**
Import without issue

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: Manjaro Linux
 - Python: 3.7.6
- syft: 0.2.1a1

**Additional context**
Installation on Conda
The library `pysyft-proto` has been renamed to `syft-proto` since `syft v0.2.1a1` was released. Our previous release manager no longer has time to fill that role, and we're a bit behind on publishing releases. ðŸ˜… 

I'm in the process of sorting out our release pipeline and expect another release to published sometime this week, which should fix the underlying issue and which I assume will fix the `conda` issue.Thanks for the explanation! Do you have any suggestions on how to fix it in the meantime or should I just wait? :) @IanQS PySyft v0.2.2.a1 has been published to PyPI. Give that a try, and let me know if it works better!@karlhigley Sorry, ran into a different bug now. Running 

```
import pysyft as sy
```

results in 

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/__init__.py"", line 44, in <module>
    from syft.grid.public_grid import PublicGridNetwork
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/public_grid.py"", line 2, in <module>
    import requests
ModuleNotFoundError: No module named 'requests'
```

Doing `pip install requests` solves the issue. 

Have verified that this is the case on 

```
syft                 0.2.2a1            
syft-proto           0.1.0a1.post36     
```

Should I mark this as closed? Ah, interesting. Grid functionality just got moved into PySyft with somewhat partial tests, and I bet that's why our check suite didn't catch the dependency issue. Let's call this issue closed and create a separate issue for the `requests` dependencyâ€”that way I can assign it to the Grid team.@IanQS When I create a new virtualenv with `make venv`, I end up with `requests` installed, but it's not directly listed in any of the requirements files. Seems like it must be a transitive dependency of something else in one of the requirements files, but I'm not sure which file or which package.Absolutely no worries :) Just wanted to let you know. FWIW it's a simple fix although I'm surprised conda didn't make it work out of the box

Thanks for looking into this! Yeah, `conda` packaging is kinda new and we haven't ironed out all the issues yet. (@systemshift has been working on it recently.)",8,2020-01-20 01:45:26,2020-01-23 20:07:34,2020-01-23 16:13:23
https://github.com/OpenMined/PySyft/issues/2927,['bug '],Small rounding errors in handcrafted Conv2d and Pool2d Layers,"Small rounding errors in handcrafted Conv2d and Pool2d Layers**Describe the bug**
There is a small rounding error in these layers, as discussed in https://github.com/OpenMined/PySyft/pull/2896/files/fa21f480c8bfe4196dac2f911cd938db7ff96f03#diff-369e971f29cf5226c9b64f75072095ac

**To Reproduce**
Run the following unit tests

https://github.com/OpenMined/PySyft/blob/39d2be0aeb4b5aa0413b6b8696cccb7fb960ab0d/test/torch/nn/test_conv.py#L7

https://github.com/OpenMined/PySyft/blob/39d2be0aeb4b5aa0413b6b8696cccb7fb960ab0d/test/torch/nn/test_pool.py#L6


**Expected behavior**
Ideally there would be 0 rounding error, but this might be a PyTorch issue not us.

I investigated this a bit and it seems we need to do a direct summation instead of calculating sum of sums. The following modifications are required:
* [`conv.py`](https://github.com/OpenMined/PySyft/blob/acdc96828cebae674817d238f68e0e81dfd41071/syft/frameworks/torch/nn/conv.py#L94-L95) - change `.sum(3).sum(3)` to `.sum((3, 4))`
* [`pool.py`](https://github.com/OpenMined/PySyft/blob/acdc96828cebae674817d238f68e0e81dfd41071/syft/frameworks/torch/nn/pool.py#L65) - change `.sum(2).sum(2)` to `.sum((2, 3))`

By making the above changes, we get exactly the same output for both the pooling implementations. However, a rounding error is still present for convolution possibly due to floating-point arithmetic as indicated [here](https://discuss.pytorch.org/t/pytorch-conv2d-vs-numpy-reference-different-outcomes-rounding-error-or-mistake/8921).@arshjot Thanks for looking into it! Could you submit a PR with those changes?Yes, I'll be happy to do so!Incredible work! 

Sent from my iPhone

> On 21 Jan 2020, at 19:20, Arshjot Singh Khehra <notifications@github.com> wrote:
> 
> ï»¿
> Yes, I'll be happy to do so!
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
As reported - there is still rounding error in the Conv2d implementation. This issue should stay open until it is resolved. I have spent a few more hours looking into it and haven't found anything yet.That's strange, it looks like the PR solved it and chnaged the test form approx to exact check didn't it?The issue is solved for the pooling implementation but not for Conv2d. The Conv2d implementation also had the same discrepancy but even after rectifying it we do not get an exact match. I guess I should have specified that the PR solves *part* of this issue.This issue was fixed by #2964 (for the conv2d layer) and #2945 (for the pooling layer)",8,2020-01-18 16:00:31,2020-01-27 22:00:06,2020-01-27 22:00:05
https://github.com/OpenMined/PySyft/issues/2921,[],ModuleNotFoundError: No module named 'syft_proto',"ModuleNotFoundError: No module named 'syft_proto'I am attempting to install Syft on a Raspberry Pi 4 with Raspbian Buster (armv71). I've successfully compiled PyTorch 1.4 from [this wheel](https://github.com/sungjuGit/Pytorch-and-Vision-for-Raspberry-Pi-4B).

After pip installing syft, I got the same error with `importlib` [which is reported in this issue](https://github.com/OpenMined/PySyft/pull/2908), and as of writing this, was fixed and merged to master a few hours ago.

So I tried to install syft directly from the master branch (`pip3 install git+https://github.com/OpenMined/PySyft/`), but now I get this error:

```
$ python3 -c ""import syft""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/__init__.py"", line 15, in <module>
    import syft.frameworks.torch.hook.hook_args
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 6, in <module>
    from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 13, in <module>
    from syft.frameworks.torch.tensors.interpreters.crt_precision import _moduli_for_fields
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/crt_precision.py"", line 7, in <module>
    from syft.frameworks.torch.tensors.interpreters.precision import FixedPrecisionTensor
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py"", line 4, in <module>
    from syft.frameworks.torch.tensors.interpreters.additive_shared import AdditiveSharingTensor
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 12, in <module>
    from syft_proto.frameworks.torch.tensors.interpreters.v1.additive_shared_pb2 import (
ModuleNotFoundError: No module named 'syft_proto'
```

Maybe this will be fixed when syft [adds PyTorch 1.4 support](https://github.com/OpenMined/PySyft/issues/2916) officially? Is there a way around this error?
Try `pip install syft-proto`. It should get installed with the other dependencies if you install with `python setup.py install`, so let us know if you did that and still ended up having this issue. Otherwise, Iâ€™m guessing it has to do with building from source, but not sure exactly why.Did that and now I get:

$ python3 -c ""import syft""

```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/__init__.py"", line 43, in <module>
    from syft.grid.private_grid import PrivateGridNetwork
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/grid/private_grid.py"", line 11, in <module>
    from syft.workers.node_client import NodeClient
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/workers/node_client.py"", line 7, in <module>
    from syft.serde import serialize
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/__init__.py"", line 1, in <module>
    from syft.serde.serde import *
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/serde.py"", line 12, in <module>
    from syft.serde import msgpack
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/msgpack/__init__.py"", line 1, in <module>
    from syft.serde.msgpack import serde
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 81, in <module>
    from syft.serde.msgpack.torch_serde import MAP_TORCH_SIMPLIFIERS_AND_DETAILERS
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/msgpack/torch_serde.py"", line 297, in <module>
    torch._C.Function: (_simplify_script_module, _detail_script_module),
AttributeError: module 'torch._C' has no attribute 'Function'
```

Could this be an issue with PyTorch 1.4? I am using the [wheel found here](https://github.com/sungjuGit/Pytorch-and-Vision-for-Raspberry-Pi-4B). Haven't found an armv71 build for 1.3. Update: I just got it to work by switching PyTorch back to 1.3 using [this build](https://discuss.pytorch.org/t/pytorch-1-3-wheels-for-raspberry-pi-python-3-7/58580) and now it works, so the issue can be closed.  Possibly the above is something to look into for updating syft to PyTorch 1.4.Yeah, thereâ€™s an open issue for Torch 1.4 compatibility, but 1.4 was just released so we havenâ€™t resolved the issue yet.I'm having same issue on OSX/conda env, is the compatibility with 1.4 not yet resolved? do I need to downgrade pytorch to 1.3?I also have the same issue.@ajnovice What versions of Python, PySyft, syft-proto, and PyTorch are you using?",7,2020-01-18 00:02:07,2020-04-05 13:34:36,2020-01-18 21:55:57
https://github.com/OpenMined/PySyft/issues/2861,[],"RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363","RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363Runtime error when running:

` def train( ):
  opt = torch.optim.SGD(params=model.parameters(),lr=0.1)
  for epoch in range (20):
    model.train()
    print(""Training started.."")

    for x_data,y_data in datasets:

      model.send(x_data.location) 
      
      opt.zero_grad()
      
       #forwardpass
       #the model here is the linear regression model
      y_pred = model(x_data)

      #ComputeLoss
      loss=criterion(y_pred,y_data)

      #BackwardPass
      loss.backward()

      opt.step()

      model.get() #MIGHT HAVE AN ERROR, since .get() method is used only on pointers

      print(loss.get())`

**Error message:**

` PureFrameworkTensorFoundError             Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    287             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
--> 288                 cmd, args, kwargs, return_args_type=True
    289             )

25 frames
PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    320             # in the execute_command function
    321             if isinstance(args, tuple):
--> 322                 response = eval(cmd)(*args, **kwargs)
    323             else:
    324                 response = eval(cmd)(args, **kwargs)

RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363`


**Expected behavior**
I expect the error message to be clearer and easily understandable. I find it very difficult to understand the error.

Not 100% sure, but I think the `PureFrameworkTensorFoundError` is telling you that Syft expected to receive a pointer to a remote tensor but got a local Torch tensor instead, and the second error is coming from deep with PyTorch's linear algebra library, where it's trying to do tensor math but not getting valid parameters (maybe as a result of the first issue.) I can't quite trace all the way through the code to verify that's exactly what's happening, but hopefully it's enough to point in a useful direction.> Not 100% sure, but I think the `PureFrameworkTensorFoundError` is telling you that Syft expected to receive a pointer to a remote tensor but got a local Torch tensor instead, and the second error is coming from deep with PyTorch's linear algebra library, where it's trying to do tensor math but not getting valid parameters (maybe as a result of the first issue.) I can't quite trace all the way through the code to verify that's exactly what's happening, but hopefully it's enough to point in a useful direction.

Yes! you were right, moving the model.get() outside loop helped Thanks! But I now face a dimension error saying, ""Dimension out of range (expected to be in range of [-1, 0], but got 1)"" Hmm, not sure I've helped much yet. At least we know it's the `model.get()` where the problem occurs, but I think you already knew that.Check this issue if the RunTime error persists. https://github.com/pytorch/pytorch/issues/20006
This error is related to PyTorch.",4,2019-12-26 09:37:02,2020-11-18 18:39:12,2020-01-02 09:23:42
https://github.com/OpenMined/PySyft/issues/2859,[],module 'syft' has no attribute 'KerasHook' ,"module 'syft' has no attribute 'KerasHook' module 'syft' has no attribute 'KerasHook' 

how could it happend???Do you have the ```tf-privacy``` module installed?Nope...should I run pip install tensorflow.privacy?Sorry for the late reply.
Could you run:
```pip install -r pip-deps/requirements_tensorflow.txt```

And check if it works?@Li-Ziyuan hi Ziyuan, did you solve the problem?Has anybody been able to solve this? I installed both tf-privacy and tfencrypted in my pysyft environment but this attiribute error doesn't seem to go away!Post the output of `pip list` in that environment?@karlhigley The output is 
Package                Version            
---------------------- -------------------
absl-py                0.9.0              
appnope                0.1.0              
astunparse             1.6.3              
attrs                  19.3.0             
backcall               0.1.0              
bleach                 3.1.0              
cachetools             4.1.0              
certifi                2020.4.5.1         
chardet                3.0.4              
click                  7.1.1              
decorator              4.4.1              
defusedxml             0.6.0              
entrypoints            0.3                
Flask                  1.1.1              
Flask-SocketIO         4.2.1              
gast                   0.3.3              
google-auth            1.13.1             
google-auth-oauthlib   0.4.1              
google-pasta           0.2.0              
grpcio                 1.28.1             
h5py                   2.10.0             
idna                   2.8                
importlib-metadata     1.5.0              
ipykernel              5.1.4              
ipython                7.12.0             
ipython-genutils       0.2.0              
ipywidgets             7.5.1              
itsdangerous           1.1.0              
jedi                   0.16.0             
Jinja2                 2.11.1             
json5                  0.9.0              
jsonschema             3.2.0              
jupyter-client         5.3.4              
jupyter-console        6.1.0              
jupyter-core           4.6.1              
jupyterlab             2.1.0              
jupyterlab-server      1.0.7              
Keras-Preprocessing    1.1.0              
lz4                    3.0.2              
Markdown               3.2.1              
MarkupSafe             1.1.1              
mistune                0.8.4              
msgpack                1.0.0              
nbconvert              5.6.1              
nbformat               5.0.4              
notebook               6.0.3              
numpy                  1.18.1             
oauthlib               3.1.0              
opt-einsum             3.2.0              
pandocfilters          1.4.2              
parso                  0.6.1              
pexpect                4.8.0              
phe                    1.4.0              
pickleshare            0.7.5              
Pillow                 6.2.2              
pip                    20.0.2             
prometheus-client      0.7.1              
prompt-toolkit         3.0.3              
protobuf               3.11.3             
ptyprocess             0.6.0              
pyasn1                 0.4.8              
pyasn1-modules         0.2.8              
Pygments               2.5.2              
pyrsistent             0.15.7             
python-dateutil        2.8.1              
python-engineio        3.11.2             
python-socketio        4.4.0              
pyzmq                  18.1.1             
qtconsole              4.6.0              
requests               2.22.0             
requests-oauthlib      1.3.0              
rsa                    4.0                
scipy                  1.4.1              
Send2Trash             1.5.0              
setuptools             45.2.0.post20200210
six                    1.14.0             
syft                   0.2.4              
syft-proto             0.2.5a1            
tblib                  1.6.0              
tensorboard            2.2.0              
tensorboard-plugin-wit 1.6.0.post3        
tensorflow             2.2.0rc3           
tensorflow-estimator   2.2.0rc0           
termcolor              1.1.0              
terminado              0.8.3              
testpath               0.4.4              
torch                  1.4.0              
torchsummary           1.5.1              
torchvision            0.5.0              
tornado                6.0.4              
traitlets              4.3.3              
urllib3                1.25.8             
wcwidth                0.1.8              
webencodings           0.5.1              
websocket-client       0.57.0             
websockets             8.1                
Werkzeug               1.0.0              
wheel                  0.34.2             
widgetsnbextension     3.5.1              
wrapt                  1.12.1             
zipp                   2.2.0              
zstd                   1.4.4.0    @karlhigley tf privacy and tfencrypted are installed from source I think that's why they dont show up here
Even packages installed from source (at least via `pip install .`) should show up on that list.Yeah thanks @karlhigley . My tensorflow privacy installation was broken thanks!",10,2019-12-26 07:52:12,2020-04-14 18:07:17,2020-04-14 18:07:17
https://github.com/OpenMined/PySyft/issues/2858,[],Bind Address Fail when starting a local socketServerWorker,"Bind Address Fail when starting a local socketServerWorker**Describe the bug**
When I Use python commandline prompt to run the script in websocket tutorial, I cannot bind the address when start the worker.
* error message:
`OSError: [Errno 99] error while attempting to bind on address ('::1', 8182, 0, 0): cannot assign requested address`

**To Reproduce**
Steps to reproduce the behavior:
1. use terminal (not notebook)
1. run`python`
1. run (this code is copied from *PySyft/examples/tutorials/websocket/*):
```python
import torch
import os
import sys
import logging
import syft as sy
hook = sy.TorchHook(torch)
from syft.workers.websocket_server import WebsocketServerWorker
local_worker = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182)
local_worker.start()
```

**Expected behavior**
server is launched with no error

**Screenshots**
![image](https://user-images.githubusercontent.com/35265996/71463583-d2797c00-27f1-11ea-883a-93f00c833950.png)

**Desktop (please complete the following information):**
* OS: Ubuntu 18.04
* pytorch version: 1.3.0
* syft version: 0.2.0a2

Thanks very much!
[This ipython issue](https://github.com/ipython/ipython/issues/6193) has some potentially relevant info about this socket error. Long story short, IPv6 `::1`, IPv4 `127.0.0.1`, and the `localhost` hostname are often but not always interchangeable. What happens if you change the `WebSocketServerWorker` instantiation to set `host=""127.0.0.1""`?Wow you genius! It works!!I've just seen these kinds of issues recently. ðŸ˜„ Hi @karlhigley 
I am not sure if my question is relevant to this thread. I am running the [Federated Learning - MNIST Example of grid tutorial](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb) on Google Colab. Once using ``` NodeClient(hook, node) ```, I got the following error:

```
OSError: [Errno 99] Cannot assign requested address
```
Do you have any idea? Thank you.",4,2019-12-26 07:15:26,2020-01-27 09:51:55,2019-12-30 09:05:24
https://github.com/OpenMined/PySyft/issues/2829,[],Error in dependency_check.py,"Error in dependency_check.pyI got some errors while running some examples.
My OS is Window 10 and Ubuntu 18.04,
I used miniconda on windows and venv for the latter, and  both uses python 3.6.x

I checked the library and figured it out that 'util' is another submodule of 'importlib', that is, not defined as an attribute in `__init__.py` in importlib.

So this lead me to here to say, 
```python
import importlib.util
```
must be added to 'dependency_check.py'
Another guess is something deprecated in `FrozedImporter` of `importlib._bootstrap` is used

If not, what am i supposed to fix this error ?
```bash
Traceback (most recent call last):
  File ""server_ex.py"", line 1, in <module>
    import syft as sy
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 656, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 626, in _load_backward_compatible
  File ""C:\Users\xxx\AppData\Local\Continuum\miniconda3\envs\pysyftex\lib\site-packages\syft-0.2.0a2-py3.6.egg\syft\__init__.py"", line 7, in <module>
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 656, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 626, in _load_backward_compatible
  File ""C:\Users\xxx\AppData\Local\Continuum\miniconda3\envs\pysyftex\lib\site-packages\syft-0.2.0a2-py3.6.egg\syft\dependency_check.py"", line 18, in <module>
AttributeError: module 'importlib' has no attribute 'util'
```Thank you @klize for reporting. I could reproduce the issue on an archlinux system, with python 3.6 in miniconda. 

I got the same error after installing `pip install syft` and importing `import syft`. Is anyone aware of this bug @LaRiffle @iamtrask ?We just merged [a fix](https://github.com/OpenMined/PySyft/pull/2908) for this yesterday and haven't released a new version yet.> We just merged [a fix](https://github.com/OpenMined/PySyft/pull/2908) for this yesterday and haven't released a new version yet.

Awesome. That is good to know. I think we can close this issue?",3,2019-12-17 00:46:43,2020-01-19 17:34:09,2020-01-19 17:34:09
https://github.com/OpenMined/PySyft/issues/2800,[],Cannot convert a pytorch nn model to pysyft LargePrecision model,"Cannot convert a pytorch nn model to pysyft LargePrecision modelI want create a NN using Pytorch and Pysyft with support for Large Precision. There seems to be a bug preventing this.

**To Reproduce**
```
# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10
model = torch.nn.Sequential(
    torch.nn.Linear(D_in, H),
    torch.nn.ReLU(),
    torch.nn.Linear(H, D_out),
)
large_model = model.fix_prec(internal_type=torch.int16, precision_fractional=128, verbose=True)
 
```
This is the expected way to create large_model according to [this example](https://github.com/OpenMined/PySyft/blob/master/examples/experimental/Large%20Precision%20Tensor.ipynb)
However, this gives the error `Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.` 

But then I can't detach the pytorch nn model, I guess that defeats the point of creating the NN.

**I have tried this on Google Colab and pysft installed with `!pip install syft[udacity]`**

Hey,
Large Precision is depreciated and will removed in the future,
Can you use _classic_ Fixed Precision for your usecase?Oh, I see, that was why #2734 was closed. I was trying to work on it.
Somehow, I usually end up with a ""bad"" first issue. Maybe there should be a ""good second issue"" label.",2,2019-12-09 17:09:38,2020-02-08 09:54:40,2020-02-08 09:54:40
https://github.com/OpenMined/PySyft/issues/2796,[],No module named 'syft.frameworks.torch.fl',"No module named 'syft.frameworks.torch.fl'Hello,

when running the example:
'Federated learning with websockets and federated averaging.ipynb'


I am getting this error at very beginning: 

ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-3-720bf18bab2b> in <module>
      5 from torchvision import datasets, transforms
      6 
----> 7 from syft.frameworks.torch.fl import utils

ModuleNotFoundError: No module named 'syft.frameworks.torch.fl'

Any ideas?you need to import like  `from syft.frameworks.torch.federated import utils`Which version of syft are you using? In the latest one it should be working... Tell me if it doesn'tHere is my output:

pi@rasp-m:~ $ python3
Python 3.7.3 (default, Apr  3 2019, 05:39:12)
[GCC 8.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import torch
>>> print(torch.__version__)
1.3.0a0+de394b6
>>> import syft as sy
>>> print(sy.__version__)
0.2.0a2
>>>@abdulbasitds is working ðŸ‘ 
replace: ""from syft.frameworks.torch.fl import utils""
with
""from syft.frameworks.torch.federated import utils""@LaRiffle It does not work in the official docker image providedThe Docker image is out of date. Weâ€™re working on getting updates published.I am seeing the same issue still with the openmined/pysyft-notebook image. I am also using the code ""syft.frameworks.torch.federated""",7,2019-12-08 15:55:27,2021-12-07 11:21:33,2019-12-09 07:37:11
https://github.com/OpenMined/PySyft/issues/2795,[],torrch.jit. script RuntimeError: undefined value _Reduction:,"torrch.jit. script RuntimeError: undefined value _Reduction:**Describe the bug**
I was trying to reproduce Asynchronous-federated-learning-on-MNIST fromadvanced example. where `@torrch.jit.script`  is used before loss function. I am getting this error and have no clue what this is about

> RuntimeError: 
> undefined value _Reduction:
> at /home/ab/.virtualenvs/aic/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py:1829:20
>   reduction = _Reduction.legacy_get_string(size_average, reduce)
                    ~~~~~~~~~~ <--- HERE
It is actually caused by these lines

```
@torch.jit.script
def loss_fn(pred, target):
    return F.nll_loss(input=pred, target=target)

train_config = sy.TrainConfig(
        model=traced_model,
        loss_fn=loss_fn,
        batch_size=batch_size,
        shuffle=True,
        max_nr_batches=max_nr_batches,
        epochs=1,
        optimizer=""SGD"",
        optimizer_args={""lr"": lr},
    )
```

![Screenshot from 2019-12-08 03-43-51](https://user-images.githubusercontent.com/33634518/70383366-1ef93680-196d-11ea-98e1-7a188fe9d7e8.png)
Issue solved after moving jit function to top of the file",1,2019-12-08 02:45:23,2019-12-13 06:22:42,2019-12-13 06:22:42
https://github.com/OpenMined/PySyft/issues/2789,[],Broken backprop from given gradient,"Broken backprop from given gradient**Describe the bug**
The bug occurs when performing backprop from a given gradient when the gradient and variable are held on a remote host. 

**To Reproduce**
I have made two notebooks. One demonstrates what should [what should be happening](https://github.com/blockpass-identity-lab/PySyft/blob/dev/examples/experimental/Split%20Neural%20Network/Simple-VanillaSplitNN-NoPySyft.ipynb).

The other demonstrates [what happens when I try to do this function on a worker](https://github.com/blockpass-identity-lab/PySyft/blob/dev/examples/experimental/Split%20Neural%20Network/Simple-VanillaSplitNN.ipynb)

**Desktop:**
 - OS: Im using MacOS Catalina
 - Version 10.15

Hey @H4LL.

It is working now? What was the problem? :) The backward function was not on the list of ambiguous methods so the vesrion of backward() that i needed was not cached. Fixed though by this commit; https://github.com/OpenMined/PySyft/pull/2799",2,2019-12-06 16:36:05,2019-12-12 10:34:07,2019-12-11 17:38:11
https://github.com/OpenMined/PySyft/issues/2784,[],fix_prec() doesn't work for crt or large,"fix_prec() doesn't work for crt or large**Describe the bug**
Converting a model to fixed precision doesn't work for LargePrecision or CRTPrecision.

**To Reproduce**
Steps to reproduce the behavior:
1. Run tutorial Part 11 - Secure Deep Learning Classification up to `model.fix_precision().share(alice, bob, crypto_provider=crypto_provider)`
If you're planning to run multiple tests, you may want to save the model and reload it as it can take awhile to train.
2. Change the parameters to `model.fix_prec(storage='crt')` or `model.fix_prec(storage='large')`

**Expected behavior**
Convert the model parameters to the specified precision strategy.

**Screenshots**
`model.fix_prec(storage='crt')`

> ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-25-e8fb399cdba4> in <module>()
> ----> 1 model.fix_prec(storage='crt').share(alice, bob, crypto_provider=crypto_provider)
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_share_(nn_self, *args, **kwargs)
>     613             """"""Overloads fix_precision for torch.nn.Module.""""""
>     614             # TODO: add .data and .grad to syft tensors
> --> 615             if module_is_missing_grad(nn_self):
>     616                 create_grad_objects(nn_self)
>     617 
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_is_missing_grad(model)
>     543             """"""Checks if all the parameters in the model have been assigned a gradient""""""
>     544             for p in model.parameters():
> --> 545                 if p.grad is None:
>     546                     return True
>     547             return False
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in grad(self)
>     343 
>     344             if hasattr(self, ""child""):
> --> 345                 to_return = self.child.attr(""grad"")
>     346                 if to_return is not None and isinstance(to_return.child, PointerTensor):
>     347                     if to_return.child.is_none():
> 
> AttributeError: 'CRTPrecisionTensor' object has no attribute 'attr'


`model.fix_prec(storage='large')`

> ---------------------------------------------------------------------------
> RuntimeError                              Traceback (most recent call last)
> <ipython-input-15-c2e4c0429286> in <module>()
> ----> 1 model.fix_prec(storage='large').share(alice, bob, crypto_provider=crypto_provider)
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_fix_precision_(nn_self, *args, **kwargs)
>     630 
>     631             for p in nn_self.parameters():
> --> 632                 p.fix_precision_(*args, **kwargs)
>     633 
>     634             return nn_self
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec_(self, *args, **kwargs)
>     721         """"""
>     722         # We specify id to make sure the inplace op doesn't change the tensor id
> --> 723         self.child = self.fix_prec(*args, no_wrap=True, id=self.id, **kwargs)
>     724         self.is_wrapper = True
>     725         return self
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, storage, field_type, no_wrap, *args, **kwargs)
>     687             fpt_tensor = (
>     688                 syft.LargePrecisionTensor(*args, **kwargs)
> --> 689                 .on(self, wrap=False)
>     690                 .fix_large_precision()
>     691             )
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/large_precision.py in fix_large_precision(self)
>     184 
>     185     def fix_large_precision(self):
> --> 186         self.child = self._create_internal_representation()
>     187         return self
>     188 
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/large_precision.py in _create_internal_representation(self)
>      71     def _create_internal_representation(self):
>      72         """"""Decompose a tensor into an array of numbers that represent such tensor with the required precision""""""
> ---> 73         self_scaled = self.child.numpy() * self.base ** self.precision_fractional
>      74 
>      75         # floor is applied otherwise, long float is not accurate
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
>     379                 except BaseException as e:
>     380                     # we can make some errors more descriptive with this method
> --> 381                     raise route_method_exception(e, self, args, kwargs)
>     382 
>     383             else:  # means that there is a wrapper to remove
> 
> ~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
>     376 
>     377                 try:
> --> 378                     response = method(*args, **kwargs)
>     379                 except BaseException as e:
>     380                     # we can make some errors more descriptive with this method
> 
> RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.

**Desktop (please complete the following information):**
 - OS: MacOS
 - Version 10.14.5
Is this issue still open? If yes, I can work on it.@sukhadj There's [an open PR](https://github.com/OpenMined/PySyft/pull/2982) that removes both of these classes. I'll leave this issue open until that PR gets merged, but probably not worth trying to fix the issue as described.",2,2019-12-05 03:18:28,2020-04-21 05:33:57,2020-04-21 05:33:57
https://github.com/OpenMined/PySyft/issues/2767,[],not able to install pysyft for pytorch version 1.3,"not able to install pysyft for pytorch version 1.3![Screenshot (3)](https://user-images.githubusercontent.com/42209500/70046397-fc24f600-15eb-11ea-8f84-d7df9d69ffba.png)

I had the same problem and have solved it.

This problem seems only occur on Windows.

Reason: on windows, pip cannot find a version for torch==1.3,  but can find a version for torch==1.3.x (like torch 1.3.1). 
```powershell
(dl) PS C:\Users\Chenghui_S> pip install torch==1.3
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Collecting torch==1.3
ERROR: Could not find a version that satisfies the requirement torch==1.3 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.3
(dl) PS C:\Users\Chenghui_S> pip install torch==1.3.1
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: torch==1.3.1 in c:\programdata\miniconda3\envs\dl\lib\site-packages (1.3.1)
Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\dl\lib\site-packages (from torch==1.3.1) (1.17.4)
```

So if you change the requirement from 1.3 to 1.3.x (in your computer), you can solve this.

Details:
1. download source code
```powershell
git clone -b dev --single-branch https://github.com/openmined/PySyft.git
```
2. change the requirement file in path:     `./PySyft/pip-dep/requirements.txt`
![æ‰¹æ³¨ 2019-12-03 201433](https://user-images.githubusercontent.com/22197327/70050307-96476700-1609-11ea-95cc-066abfc8e728.png)
3. install
```powershell
cd PySyft
python setup.py install
```
4. in this step, if you occurs error about: `Microsoft Visual C++ 14.0 is required`, you can download Visual Studio 2019.  See: https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-batInstalling pytorch with `conda install pytorch==1.3.0 -c pytorch` before syft worked for me on Win10.
(Note exact 1.3.0 version, not just 1.3)@somiljain7 are you still having the issue?I tried most of the solution that I read but no one is useful 
this is the error

ERROR: Could not find a version that satisfies the requirement torch~=1.4.0 (from syft) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch~=1.4.0 (from syft)

Getting the same error as @Naif18 > Getting the same error as @Naif18
I found the right solution that could solve this issue:
- Reinstall pytorch from here [https://pytorch.org/get-started/locally/#mac-package-manager](url)

- Make sure the **torch** version is 1.4.0 if it's not run the following command:
pip install syft -f https://download.pytorch.org/whl/torch_stable.html

- Now, you can download **syft** successfully:
pip install syft

to check the version of packages:
conda list",6,2019-12-03 11:12:18,2020-08-08 14:12:30,2020-01-28 19:25:49
https://github.com/OpenMined/PySyft/issues/2748,[],error: invalid command 'udacity',"error: invalid command 'udacity'**Describe the bug**
all the step before ""python setup.py install udacity"" is ok, 
when i input ""python setup.py install udacity
"", return error: invalid command 'udacity'

i have tried in win10 and google colab.
![image](https://user-images.githubusercontent.com/35960345/69206740-7c793f00-0b88-11ea-91b9-5adfd2057f84.png)
win10
![image](https://user-images.githubusercontent.com/35960345/69206793-b0ecfb00-0b88-11ea-8eac-f7e673370604.png)
colab

i follow the instructions in https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2001%20-%20The%20Basic%20Tools%20of%20Private%20Deep%20Learning.ipynb@jvmancuso looks like your recent chang e(https://github.com/OpenMined/PySyft/commit/ef8a61b264819c4b5b0c830f0f1333aec20752d6) might havee issues on win10 and colab?@chenjinhua1993, for now just leave off ```udacity``` until @jvmancuso replies.(Also, @chenjinhua1993 - make sure you're on the latest master branch)Hi, yesterday , in win10 , i try ""python setup.py install ""  without ""udacity"", it works. At the same time, i  do it in the same fashion. But after this , i try ""pip install syft "" in colab. It works as well.Anyway, now i can use PySyft in my local desktop or colab. thanks for yours contributions!",4,2019-11-20 03:30:09,2019-11-22 03:17:53,2019-11-22 03:17:53
https://github.com/OpenMined/PySyft/issues/2730,[],PyTorch 1.3 installation: No matching distribution found,"PyTorch 1.3 installation: No matching distribution foundERROR: Could not find a version that satisfies the requirement torch==1.3 (from syft[udacity]) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.3 (from syft[udacity])Hi
Are you using a virtual environment?
If yes then are you referring to the correct python installation

For example when you're in a virtual environment and want to install something via pip using this is better

python -m pip install [ package ]
Also are you on a supported python version?my python version is 3.7.4, I think it's supported. 
I run the command python -m pip install syft[udacity] on cmd and I get the same errorThis looks like a pytorch installation error.
You should maybe ask on pytorch forums to try to understand how to install pytorch 1.3 with pip with you python / OSHave you solved this issue?  I have met this problem today and I can not solve it.Even I am facing this same problem - any solution?I was finally able to solve the problem @chunrongH , @LaRiffle , @haikuoY , @hasnain2808 after a lot of trial and error. Here are the sequence of steps that I had followed in Windows 10.

1.  Installed Build Tools for Visual Studio 2019 from [here](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2019)
2. Created a new environment using conda `conda create --name syft python=3.7`
3. Installed the following packages from conda-forge:
```
conda install -c conda-forge websocket-client
conda install -c conda-forge websockets
conda install -c conda-forge lz4
conda install -c conda-forge tblib
conda install -c conda-forge msgpack-python
conda install -c conda-forge jupyterlab
conda install pytorch torchvision cpuonly -c pytorch
```
4. Went to proto repository [here](https://github.com/OpenMined/proto) and downloaded their repo and installed with:
```
python setup.py build
python setup.py install
```
5. Downloaded the syft repo [here](https://github.com/OpenMined/PySyft) and downloaded their repo and installed with:
```
python setup.py build
python setup.py install
```
The above process installed everything but ended with an error:
```
Searching for torch==1.3
Reading https://pypi.org/simple/torch/
No local packages or working download links found for torch==1.3
error: Could not find suitable distribution for Requirement.parse('torch==1.3')
```
6. Ignore the above error and start python. I was able to run `import syft as sy`.Thank you for answering my question, I will try as you suggest.

At 2019-11-27 22:37:11, ""Indrajit Sen Gupta"" <notifications@github.com> wrote:


I was finally able to solve the problem @chunrongH , @LaRiffle , @haikuoY , @hasnain2808 after a lot of trial and error. Here are the sequence of steps that I had followed in Windows 10.

Installed Build Tools for Visual Studio 2019 from here
Created a new environment using conda conda create --name syft python=3.7
Installed the following packages from conda-forge:
conda install -c conda-forge websocket-client
conda install -c conda-forge websockets
conda install -c conda-forge lz4
conda install -c conda-forge tblib
conda install -c conda-forge msgpack-python
conda install -c conda-forge jupyterlab
conda install pytorch torchvision cpuonly -c pytorch

Went to proto repository here and downloaded their repo and installed with:
python setup.py build
python setup.py install

Downloaded the syft repo here and downloaded their repo and installed with:
python setup.py build
python setup.py install


The above process installed everything but ended with an error:

Searching for torch==1.3
Reading https://pypi.org/simple/torch/
No local packages or working download links found for torch==1.3
error: Could not find suitable distribution for Requirement.parse('torch==1.3')

Ignore the above error and start python. I was able to run import syft as sy.

â€”
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.Do remember to import torch before you import syft.Closing this issue since we have updated to pytorch 1.4 and the requirements files seem updates",9,2019-11-12 07:58:54,2020-03-27 11:10:23,2020-03-27 11:10:23
https://github.com/OpenMined/PySyft/issues/2729,"['bug ', 'priority: 2 - high :cold_sweat:']",Output pointer to pointer of an operation is duplicated twice,"Output pointer to pointer of an operation is duplicated twice**Describe the bug**
When a double pointer is operated with some function/operation the output tensor double pointer is stored twice in the worker containing the double pointer 

**To Reproduce**
Steps to reproduce the behavior:
follow through the tutorial part 03 python notebook
exact image of reproducing step provided below

**Expected behavior**
The worker who have double pointer must store the output of the operation only once

**Screenshots**

<img width=""910"" alt=""Screenshot 2019-11-11 at 10 29 16 AM"" src=""https://user-images.githubusercontent.com/19199814/68601735-f0ea1900-04ca-11ea-9b33-7cef52abaea2.png"">


**Desktop (please complete the following information):**
 - OS: OSX MojaveHi, I think this is due to the object pointer in Alice having to be unwrapped  and then re-wrapped when getting the response. 

However, when re-wrapping, the object is incorrectly registered to make the first copy in Alice (due to the default setting of [`register=True` in  `wrap()`](https://github.com/OpenMined/PySyft/blob/1cf824502fc83ef4b8e17135458a14d35753c745/syft/generic/pointers/object_pointer.py#L163)):
```
class ObjectPointer(AbstractObject):
    ...
    def wrap(self, register=True, type=None, **kwargs): 
```

Then, when we actually want to register the response as we normally would when executing the command, the registered response creates a second copy in Alice. 

I'm not super familiar with the code to know if this intended, or actually makes sense (sorry if I've misunderstood something!), but thought it could be helpful. **Approach**
I currently have implemented a fix where I add a parameter to check if a tensor had been unwrapped and is now getting rewrapped in the hook response (`rewrap=True` which by default will be False to not break code). 

It takes advantage of the [`build_rule()` in `build_wrap_response_from_function()`](https://github.com/OpenMined/PySyft/blob/8f7705fbba623827f1edaf5a2a351a973e2e001d/syft/generic/frameworks/hook/hook_args.py#L254) to check if the data type is a tensor (and not int, str etc). When it's building a wrap function, it checks if both `rule == 1` on the args passed and ` rewrap==True`, and if so, I set an attribute like `tensor.rewrap = True` which gets checked in the `wrap()` function as to whether to register.

**Passes tests but is slow?**
It currently passes 100% of tests BUT seems inefficient given the point of the build rule is to efficiently check if things need to be wrapped whereas this loops over the args.

**Other possible solutions**
Alternatively, I thought we could pass `wrap_args = {'register'=False}` for these tensors in the hook response, but it seems the [lambda for TorchTensor defined in `backward_func()` as](https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/hook/hook_args.py#L39-L46):
```
backward_func = {
    TorchTensor: lambda i: i.wrap(), # how to give the lambda arg register=False?
    torch.Tensor: lambda i: i.wrap(),
    torch.nn.Parameter: lambda i: torch.nn.Parameter(data=i),
    AutogradTensor: lambda i: AutogradTensor(data=i).on(i, wrap=False),
    LoggingTensor: lambda i: LoggingTensor().on(i, wrap=False),
    PaillierTensor: lambda i: PaillierTensor().on(i, wrap=False),
}
```
**Code changes**
Here is the code changes: 
https://github.com/linamnt/PySyft/commit/97a7a24b3c061c99a73482f6c6c9c3ab4cad3d42
Do I submit a PR so it can be reviewed formally? or wait til the best approach is figured out?",2,2019-11-11 16:04:14,2019-12-30 12:36:56,2019-12-30 12:36:56
https://github.com/OpenMined/PySyft/issues/2725,"['bug ', 'status: stale :bread:']",Parameter update error using set_() in Encrypted Gradient Aggregation,"Parameter update error using set_() in Encrypted Gradient AggregationHi,
I've got a question concerning the tutorial 10 ""Federated Learning with Encrypted Gradient Aggregation"".

I followed the instructions of this tutorial to use this technology and adapted it to my image classification task, but I've encountered some problems.

The first iteration of the ""main loop"" (following the exact code from the tutorial) in the train function `for data_index in range(len(remote_dataset[0])-1):` works fine, iterating through the first batch of data of both `alice` and `bob`.

However, the second iteration of this loop, which should process the second batches throws an exception. In detail, it does so on the first try of updating his model at the `pred = model(data)` step, specifically at the first convolutional layer of my NN. 

The error which gets thrown is ""weight should have at least three dimensions"" - which is quite interesting, because it always works fine on the first iteration of `alice` and `bob` data. 

The following is my quite basic neural net.
```
    def forward(self, x):
        x = F.relu(self.conv0(x))
        x = self.pool(F.relu(self.conv1(x)))
        x = F.relu(self.conv2(x))
        x = self.pool(F.relu(self.conv3(x)))
        x = self.dropout(x)
        x = x.view(-1, 256*4*4)
        x = self.fc0(x)
        x = self.dropout(x)
        x = self.fc1(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```

Does someone have an idea why this happens?

OS: Windows 10
Python: 3.7
torch: 1.1.0
syft: 0.1.28a1

The following is the whole error:

```
---------------------------------------------------------------------------
PureFrameworkTensorFoundError             Traceback (most recent call last)
c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    286             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
--> 287                 cmd, args, kwargs, return_args_type=True
    288             )

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in unwrap_args_from_function(attr, args, kwargs, return_args_type)
    165         # Try running it
--> 166         new_args = hook_args(args)
    167 

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in <lambda>(x)
    358 
--> 359     return lambda x: f(lambdas, x)
    360 

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in seven_fold(lambdas, args, **kwargs)
    573     return (
--> 574         lambdas[0](args[0], **kwargs),
    575         lambdas[1](args[1], **kwargs),

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook_args.py in <lambda>(i)
    336         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 337         else lambda i: forward_func[type(i)](i)
    338         for a, r in zip(args, rules)  # And do this for all the args / rules provided

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\hook\hook_args.py in <lambda>(i)
     20     if hasattr(i, ""child"")
---> 21     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     22     torch.nn.Parameter: lambda i: i.child

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\hook\hook_args.py in <genexpr>(.0)
     20     if hasattr(i, ""child"")
---> 21     else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
     22     torch.nn.Parameter: lambda i: i.child

PureFrameworkTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-12-69ad3b15b6dc> in <module>
      2 for epoch in range(1, 201):
      3     print(f""Epoch {epoch}"")
----> 4     trainSMPC(epoch)
      5     test()

<ipython-input-10-9fd0824454ee> in trainSMPC(epoch)
      6             print(data)
      7             print(target)
----> 8             models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])
      9 
     10         print(""aggregation"")

<ipython-input-9-c309a36730fe> in update(data, target, model, optimizer)
     19     model.send(data.location)
     20     optimizer.zero_grad()
---> 21     pred = model(data)
     22     loss = F.cross_entropy(pred, target)
     23     loss.backward()

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-8-0497bcc9c994> in forward(self, x)
     19     def forward(self, x):
     20         print(x.shape)
---> 21         x = F.relu(self.conv0(x))
     22         x = self.pool(F.relu(self.conv1(x)))
     23         x = F.relu(self.conv2(x))

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\torch\nn\modules\conv.py in forward(self, input)
    336                             _pair(0), self.dilation, self.groups)
    337 
--> 338         return F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)
    339 
    340 

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook.py in overloaded_func(*args, **kwargs)
    426                 handle_func_command = syft.framework.Tensor.handle_func_command
    427 
--> 428             response = handle_func_command(command)
    429 
    430             return response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    295             new_command = (cmd, None, new_args, new_kwargs)
    296             # Send it to the appropriate class and get the response
--> 297             response = new_type.handle_func_command(new_command)
    298             # Put back the wrappers where needed
    299             response = hook_args.hook_response(cmd, response, wrap_type=args_type)

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\pointers\object_pointer.py in handle_func_command(cls, command)
     87 
     88         # Send the command
---> 89         response = owner.send_command(location, command)
     90 
     91         return response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in send_command(self, recipient, message, return_ids)
    485 
    486         try:
--> 487             ret_val = self.send_msg(Operation(message, return_ids), location=recipient)
    488         except ResponseSignatureError as e:
    489             ret_val = None

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in send_msg(self, message, location)
    256 
    257         # Step 2: send the message and wait for a response
--> 258         bin_response = self._send_msg(bin_message, location)
    259 
    260         # Step 3: deserialize the response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\virtual.py in _send_msg(self, message, location)
      5 class VirtualWorker(BaseWorker, FederatedClient):
      6     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 7         return location._recv_msg(message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\virtual.py in _recv_msg(self, message)
      8 
      9     def _recv_msg(self, message: bin) -> bin:
---> 10         return self.recv_msg(message)

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in recv_msg(self, bin_message)
    290             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    291         # Step 1: route message to appropriate function
--> 292         response = self._message_router[msg_type](contents)
    293 
    294         # Step 2: Serialize the message to simple python objects

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\workers\base.py in execute_command(self, message)
    430                 command = getattr(command, path)
    431 
--> 432             response = command(*args, **kwargs)
    433 
    434         # some functions don't return anything (such as .backward())

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\generic\frameworks\hook\hook.py in overloaded_func(*args, **kwargs)
    426                 handle_func_command = syft.framework.Tensor.handle_func_command
    427 
--> 428             response = handle_func_command(command)
    429 
    430             return response

c:\users\flo\appdata\local\programs\python\python37\lib\site-packages\syft-0.1.28a1-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    319             # in the execute_command function
    320             if isinstance(args, tuple):
--> 321                 response = eval(cmd)(*args, **kwargs)
    322             else:
    323                 response = eval(cmd)(args, **kwargs)

RuntimeError: weight should have at least three dimensions
```It turns out that the models are not correctly updated, even if 
```
for remote_index in range(len(compute_nodes)):
        for param_index in range(len(params[remote_index])):
            params[remote_index][param_index].set_(new_params[param_index])
```
is correctly called.

Following tutorial 10, the `params` list is updated, but the update of these values are not updated neither in `alices_model.parameters()` nor `bobs_model.parameters()`.

Unfortunately, I don't know how to fix this

I've updated pytorch to 1.3.0 and pysyft to 0.2.0a2, and by rerunning the notebooks I now receive the same error as issue #2634 #issuecomment-546368259 

Fix see #2634 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",3,2019-11-08 18:30:09,2020-05-24 00:08:23,2020-05-24 00:08:23
https://github.com/OpenMined/PySyft/issues/2715,"['bug ', 'status: stale :bread:']",WebsocketClientWorker:  TimeoutError:Connection timed out,"WebsocketClientWorker:  TimeoutError:Connection timed outI use ""python run_websocket_server.py --port 8780 --id bob --host 10.0.0.5"" on my Mac to run the run_websocket_server.py under the examples/tutorials/advanced/websockets-example-MNIST-parallel folder. And I want to connect it with Linux server. I import packages and run the following codes in ipython.
hook = sy.TorchHook(torch)
kwargs_websocket = {""host"": ""10.0.0.5"", ""hook"": hook, ""verbose"": False}
bob = WebsocketClientWorker(id=""bob"", port=8780, **kwargs_websocket)
But it reports an error--TimeoutError: [Errno 110] Connection timed out
How could I solve this problem?
If possible, could you write a detailed document that implements federated learning on different computer devices? I sincerely hope there can be an example realized by different computers, but not all servers in one computer.Hi, does it work in local mode? (connected through the localhost)

Also, cross device computation will increasingly handled in PyGrid 
https://github.com/OpenMined/PyGridIf both servers' ""host"" are ""localhost"", it is OKInteresting! So yes I _think_ Websocket with PySyft currently only work in local networks. You need to use PyGrid across devices, but maybe the PyGrid team can confirmOK, thank youThis issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",5,2019-11-04 12:20:20,2020-05-24 00:08:31,2020-05-24 00:08:31
https://github.com/OpenMined/PySyft/issues/2682,[],Plans Notebook is Broken,"Plans Notebook is Broken**Describe the bug**
When I try to create a neural network plan, I get an error.

**To Reproduce**
Steps to reproduce the behavior:
Run this notebook: https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2008%20-%20Introduction%20to%20Plans.ipynb

and you'll see:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-15-1df7f0407b15> in <module>()
----> 1 net = Net()

<ipython-input-14-87940bb14ced> in __init__(self)
      5         self.fc2 = nn.Linear(3, 2)
      6 
----> 7         self.add_to_state('fc1', 'fc2')
      8 
      9     def forward(self, x):

AttributeError: 'Net' object has no attribute 'add_to_state'
```

**Desktop (please complete the following information):**
 - OS: OSX 10.14.6
 - Version 0.1.29a1

**Additional context**
Add any other context about the problem here.
Fixed by https://github.com/OpenMined/PySyft/pull/2671",1,2019-10-19 17:36:05,2019-10-21 11:29:25,2019-10-21 11:29:25
https://github.com/OpenMined/PySyft/issues/2680,[],Encrypted Linear Regression Test Failure,"Encrypted Linear Regression Test Failure**Describe the bug**
There's a failing test.

**To Reproduce**
Steps to reproduce the behavior:
```
git checkout dev
python setup.py install
python setup.py test
```

which returns

```
============================================ warnings summary =============================================
/Users/atrask/anaconda/lib/python3.6/site-packages/scipy/stats/morestats.py:12
  /Users/atrask/anaconda/lib/python3.6/site-packages/scipy/stats/morestats.py:12: DeprecationWarning: Importing from numpy.testing.decorators is deprecated since numpy 1.15.0, import from numpy.testing instead.
    from numpy.testing.decorators import setastest

test/torch/linalg/test_lr.py::test_crypto_lr[False]
  /Users/atrask/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
    return (self.a < x) & (x < self.b)
  /Users/atrask/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
    return (self.a < x) & (x < self.b)
  /Users/atrask/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1738: RuntimeWarning: invalid value encountered in greater_equal
    cond2 = (x >= self.b) & cond0

-- Docs: https://docs.pytest.org/en/latest/warnings.html
===================== 1 failed, 498 passed, 11 skipped, 4 warnings in 168.73 seconds ======================
```
**Desktop (please complete the following information):**
 - OS: 10.14.6
 - PySyft Version: dev
 - PyTorch version: 1.1.0
@andrelmfarias any hint on this?
It's working fine on my laptop but also failing on Travis :(I just ran it on my laptop and got the same warnings but no failure...

![image](https://user-images.githubusercontent.com/43521764/67163142-c72a5000-f36b-11e9-9734-ea465484bd01.png)

@iamtrask , is the failure you got related to crypto_lr test?

I will try to find out why we are getting these warningsI found out a fix. I will be opening a PR fixing it",3,2019-10-19 14:54:12,2019-10-22 17:10:40,2019-10-22 17:10:40
https://github.com/OpenMined/PySyft/issues/2669,[],Send tensor to worker bug,"Send tensor to worker bug**Describe the bug**
If you send a tensor to a worker and you don't save the apprioriate pointer, you get an empty response list using the search functionality.

**To Reproduce**
Steps to reproduce the behavior:

`import torch as th`
`import syft as sy`

`hook = sy.TorchHook(th)`

`bob=sy.VirtualWorker(hook, id=""bob"")`

`x = th.tensor([1, 2, 3]).tag('#dataset')`
`x.send(bob)`
`results = bob.search(['#dataset'])`
`pointer = results[0]`
`print(pointer)`

**Expected behavior**
Results list shouldn't be empty.

Server traceback:

`IndexError                                Traceback (most recent call last)`
`<ipython-input-2-33a97d2ca3b1> in <module>`
`      9 x.send(bob)`
`     10 results = bob.search(['#dataset'])`
`---> 11 pointer = results[0]`
`     12 print(pointer)`

`IndexError: list index out of range`

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Python Version: 3.7.4
 - PyTorch Version: 1.1.0 
 - PySyft Version: 0.1.29a1

**Additional context**
Using `x_ptr = x.send(bob)` instead of `x.send(bob)` works fine.
@luggi961 I tried to reproduce it, but it seems it got fixed.
Could you also retest it on the latest version?`send` is not inplace, you need to do: `p = x.send(bob)` instead of `x.send(bob)`",2,2019-10-17 07:20:37,2019-11-13 00:37:36,2019-11-13 00:37:36
https://github.com/OpenMined/PySyft/issues/2664,['bug '],"Failed to run ""python setup.py test"" with test/keras/test_sequential.py","Failed to run ""python setup.py test"" with test/keras/test_sequential.pyWhen I try to run `python setup.py test` in the PySyft project, such error messages appear. What would be the problems and how to solve it?

Thank you!

    test/generic/test_id_provider.py::test_get_recorded_ids PASSED                                                                                     [ 21%]
    test/generic/test_object_storage.py::test_clear_objects PASSED                                                                                     [ 21%]
    test/generic/test_object_storage.py::test_clear_objects_return_None PASSED                                                                         [ 21%]
    test/keras/test_sequential.py::test_instantiate_tfe_layer Fatal Python error: Segmentation fault

    Thread 0x00007f65afd54700 (most recent call first):

    Thread 0x00007f65b0555700 (most recent call first):

    Current thread 0x00007f663925e740 (most recent call first):
    File ""/usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0-py3.6-linux-x86_64.egg/tensorflow/python/framework/ops.py"", line 1864 in _create_c_op
    File ""/usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0-py3.6-linux-x86_64.egg/tensorflow/python/framework/ops.py"", line 2027 in __init__
    File ""/usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0-py3.6-linux-x86_64.egg/tensorflow/python/framework/ops.py"", line 3616 in create_op
    File ""/usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0-py3.6-linux-x86_64.egg/tensorflow/python/util/deprecation.py"", line 507 in new_func
    File ""/usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0-py3.6-linux-x86_64.egg/tensorflow/python/framework/op_def_library.py"", line 788 in _apply_op_helper
    File ""<string>"", line 77 in secure_seeded_random_uniform
    File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.9-py3.6-linux-x86_64.egg/tf_encrypted/operations/secure_random/secure_random.py"", line 96 in seeded_random_uniform
    File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.9-py3.6-linux-x86_64.egg/tf_encrypted/tensor/native.py"", line 394 in value
    File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.9-py3.6-linux-x86_64.egg/tf_encrypted/tensor/native.py"", line 241 in sub
    File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.9-py3.6-linux-x86_64.egg/tf_encrypted/tensor/native.py"", line 209 in __sub__
    File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.9-py3.6-linux-x86_64.egg/tf_encrypted/protocol/pond/pond.py"", line 772 in _share
    File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.9-py3.6-linux-x86_64.egg/tf_encrypted/protocol/pond/pond.py"", line 343 in define_private_variable
    File ""/home/test/programming/PySyft-0.1.29a/test/keras/test_sequential.py"", line 37 in test_instantiate_tfe_layer
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/python.py"", line 170 in pytest_pyfunc_call
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/callers.py"", line 187 in _multicall
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 86 in <lambda>
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 92 in _hookexec
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/hooks.py"", line 286 in __call__
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/python.py"", line 1423 in runtest
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 125 in pytest_runtest_call
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/callers.py"", line 187 in _multicall
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 86 in <lambda>
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 92 in _hookexec
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/hooks.py"", line 286 in __call__
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 201 in <lambda>
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 229 in from_call
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 201 in call_runtest_hook
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 176 in call_and_report
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 95 in runtestprotocol
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/runner.py"", line 80 in pytest_runtest_protocol
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/callers.py"", line 187 in _multicall
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 86 in <lambda>
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 92 in _hookexec
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/hooks.py"", line 286 in __call__
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/main.py"", line 256 in pytest_runtestloop
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/callers.py"", line 187 in _multicall
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 86 in <lambda>
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 92 in _hookexec
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/hooks.py"", line 286 in __call__
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/main.py"", line 235 in _main
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/main.py"", line 191 in wrap_session
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/main.py"", line 228 in pytest_cmdline_main
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/callers.py"", line 187 in _multicall
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 86 in <lambda>
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/manager.py"", line 92 in _hookexec
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pluggy-0.13.0-py3.6.egg/pluggy/hooks.py"", line 286 in __call__
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest-5.2.1-py3.6.egg/_pytest/config/__init__.py"", line 90 in main
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest_runner-5.1-py3.6.egg/ptr.py"", line 220 in run_tests
    File ""/home/test/programming/PySyft-0.1.29a/.eggs/pytest_runner-5.1-py3.6.egg/ptr.py"", line 209 in run
    File ""/usr/lib/python3.6/distutils/dist.py"", line 974 in run_command
    File ""/usr/lib/python3.6/distutils/dist.py"", line 955 in run_commands
    File ""/usr/lib/python3.6/distutils/core.py"", line 148 in setup
    File ""/home/test/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 145 in setup
    File ""setup.py"", line 34 in <module>
    Segmentation fault
me tooProblem solved. Run `pip install -r requirements.txt` before `python setup.py install`.> Problem solved. Run `pip install -r requirements.txt` before `python setup.py install`.

No, I have this issue too, but after I run `pip install -r requirements.txt` and `sudo pip install -r requirements.txt` before `python setup.py install`, it still can't pass the test and get an error of `segmentation fault`.
By the way, I have installed pytest the file mentioned.The problem still exists!
Replaced the pyft version, the problem still existsplatform linux -- Python 3.6.8, pytest-5.2.1, py-1.8.0, pluggy-0.13.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/pysyft25, inifile: setup.cfg
plugins: flake8-1.0.4
collected 458 items                                                                                                                          

test/test_dependency_check.py::test_tensorflow_available SKIPPED                                                                       [  0%]
test/test_dependency_check.py::test_tf_encrypted_available PASSED                                                                      [  0%]
test/test_dependency_check.py::test_torch_available PASSED                                                                             [  0%]
test/test_dependency_check.py::test_tensorflow_missing PASSED                                                                          [  0%]
test/test_dependency_check.py::test_tf_encrypted_missing PASSED                                                                        [  1%]
test/test_exceptions.py::test_tensors_not_collated_exception PASSED                                                                    [  1%]
test/test_grid.py::test_virtual_grid PASSED                                                                                            [  1%]
test/test_local_worker.py::test_is_client_true PASSED                                                                                  [  1%]
test/test_local_worker.py::test_is_client_false PASSED                                                                                 [  1%]
test/test_local_worker.py::test_in_known_workers PASSED                                                                                [  2%]
test/test_sandbox.py::test_sandbox PASSED                                                                                              [  2%]
test/test_serde.py::test_tuple_simplify PASSED                                                                                         [  2%]
test/test_serde.py::test_list_simplify PASSED                                                                                          [  2%]
test/test_serde.py::test_set_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_float_simplify PASSED                                                                                         [  3%]
test/test_serde.py::test_int_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_string_simplify PASSED                                                                                        [  3%]
test/test_serde.py::test_dict_simplify PASSED                                                                                          [  3%]
test/test_serde.py::test_range_simplify PASSED                                                                                         [  4%]
test/test_serde.py::test_torch_tensor_simplify PASSED                                                                                  [  4%]
test/test_serde.py::test_ndarray_simplify PASSED                                                                                       [  4%]
test/test_serde.py::test_ellipsis_simplify PASSED                                                                                      [  4%]
test/test_serde.py::test_torch_device_simplify PASSED                                                                                  [  5%]
test/test_serde.py::test_pointer_tensor_simplify PASSED                                                                                [  5%]
test/test_serde.py::test_torch_Tensor[True] PASSED                                                                                     [  5%]
test/test_serde.py::test_torch_Tensor[False] PASSED                                                                                    [  5%]
test/test_serde.py::test_torch_Tensor_convenience[True] PASSED                                                                         [  5%]
test/test_serde.py::test_torch_Tensor_convenience[False] PASSED                                                                        [  6%]
test/test_serde.py::test_tuple[True] PASSED                                                                                            [  6%]
test/test_serde.py::test_tuple[False] PASSED                                                                                           [  6%]
test/test_serde.py::test_bytearray[True] PASSED                                                                                        [  6%]
test/test_serde.py::test_bytearray[False] PASSED                                                                                       [  6%]
test/test_serde.py::test_ndarray_serde[True] PASSED                                                                                    [  7%]
test/test_serde.py::test_ndarray_serde[False] PASSED                                                                                   [  7%]
test/test_serde.py::test_compress_decompress[41] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[42] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[40] PASSED                                                                                [  8%]
test/test_serde.py::test_compressed_serde[41] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[42] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[40] PASSED                                                                                   [  8%]
test/test_serde.py::test_dict[True] PASSED                                                                                             [  8%]
test/test_serde.py::test_dict[False] PASSED                                                                                            [  9%]
test/test_serde.py::test_range_serde[True] PASSED                                                                                      [  9%]
test/test_serde.py::test_range_serde[False] PASSED                                                                                     [  9%]
test/test_serde.py::test_list[True] PASSED                                                                                             [  9%]
test/test_serde.py::test_list[False] PASSED                                                                                            [ 10%]
test/test_serde.py::test_set[True] PASSED                                                                                              [ 10%]
test/test_serde.py::test_set[False] PASSED                                                                                             [ 10%]
test/test_serde.py::test_slice[True] PASSED                                                                                            [ 10%]
test/test_serde.py::test_slice[False] PASSED                                                                                           [ 10%]
test/test_serde.py::test_float[True] PASSED                                                                                            [ 11%]
test/test_serde.py::test_float[False] PASSED                                                                                           [ 11%]
test/test_serde.py::test_hooked_tensor[True-41] PASSED                                                                                 [ 11%]
test/test_serde.py::test_hooked_tensor[False-41] PASSED                                                                                [ 11%]
test/test_serde.py::test_hooked_tensor[True-42] PASSED                                                                                 [ 12%]
test/test_serde.py::test_hooked_tensor[False-42] PASSED                                                                                [ 12%]
test/test_serde.py::test_hooked_tensor[True-40] PASSED                                                                                 [ 12%]
test/test_serde.py::test_hooked_tensor[False-40] PASSED                                                                                [ 12%]
test/test_serde.py::test_pointer_tensor PASSED                                                                                         [ 12%]
test/test_serde.py::test_pointer_tensor_detail[10000] PASSED                                                                           [ 13%]
test/test_serde.py::test_pointer_tensor_detail[10001] PASSED                                                                           [ 13%]
test/test_serde.py::test_numpy_tensor_serde PASSED                                                                                     [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[True] PASSED                                                                    [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[False] PASSED                                                                   [ 13%]
test/test_serde.py::test_fixed_precision_tensor_serde[True] PASSED                                                                     [ 14%]
test/test_serde.py::test_fixed_precision_tensor_serde[False] PASSED                                                                    [ 14%]
test/test_serde.py::test_serde_object_wrapper_int PASSED                                                                               [ 14%]
test/test_serde.py::test_serialize_and_deserialize_torch_scriptmodule SKIPPED                                                          [ 14%]
test/test_serde.py::test_torch_jit_script_module_serde SKIPPED                                                                         [ 15%]
test/test_serde.py::test_serde_virtual_worker PASSED                                                                                   [ 15%]
test/test_serde.py::test_full_serde_virtual_worker PASSED                                                                              [ 15%]
test/test_serde.py::test_serde_object_wrapper_traced_module PASSED                                                                     [ 15%]
test/test_udacity.py::test_section_1_differential_privacy PASSED                                                                       [ 15%]
test/test_udacity.py::test_section_2_federated_learning PASSED                                                                         [ 16%]
test/test_udacity.py::test_section_3_securing_fl PASSED                                                                                [ 16%]
test/federated/test_federated_client.py::test_add_dataset PASSED                                                                       [ 16%]
test/federated/test_federated_client.py::test_add_dataset_with_duplicate_key PASSED                                                    [ 16%]
test/federated/test_federated_client.py::test_remove_dataset PASSED                                                                    [ 17%]
test/federated/test_federated_client.py::test_set_obj_train_config PASSED                                                              [ 17%]
test/federated/test_federated_client.py::test_set_obj_other PASSED                                                                     [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-1] PASSED                                                           [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-10] PASSED                                                          [ 17%]
test/federated/test_federated_client.py::test_fit[another_dataset-1] PASSED                                                            [ 18%]
test/federated/test_federated_client.py::test_evaluate SKIPPED                                                                         [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_script_module SKIPPED                                                  [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace SKIPPED                                                          [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_send_twice_with_fit SKIPPED                                      [ 18%]
test/federated/test_train_config.py::test___str__ PASSED                                                                               [ 19%]
test/federated/test_train_config.py::test_send PASSED                                                                                  [ 19%]
test/federated/test_train_config.py::test_send_model_and_loss_fn PASSED                                                                [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_async SKIPPED                                                    [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_sync SKIPPED                                                     [ 20%]
test/generic/test_id_provider.py::test_pop_no_given_ids PASSED                                                                         [ 20%]
test/generic/test_id_provider.py::test_pop_with_given_ids PASSED                                                                       [ 20%]
test/generic/test_id_provider.py::test_given_ids_side_effect PASSED                                                                    [ 20%]
test/generic/test_id_provider.py::test_set_next_ids PASSED                                                                             [ 20%]
test/generic/test_id_provider.py::test_set_next_ids_with_id_checking PASSED                                                            [ 21%]
test/generic/test_id_provider.py::test_start_recording_ids PASSED                                                                      [ 21%]
test/generic/test_id_provider.py::test_get_recorded_ids PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects_return_None PASSED                                                             [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[lstm] PASSED                                                                                [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[gru] PASSED                                                                                 [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_tanh] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_relu] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_federated[lstm] PASSED                                                                          [ 23%]
test/integration/test_rnn.py::test_rnn_federated[gru] PASSED                                                                           [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_tanh] PASSED                                                                      [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_relu] PASSED                                                                      [ 23%]
test/keras/test_sequential.py::test_instantiate_tfe_layer Fatal Python error: Segmentation fault

Thread 0x00007f1143dbf700 (most recent call first):

Thread 0x00007f11435be700 (most recent call first):

Current thread 0x00007f11b19c4740 (most recent call first):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1864 in _create_c_op
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 2027 in __init__
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3616 in create_op
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507 in new_func
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788 in _apply_op_helper
  File ""<string>"", line 77 in secure_seeded_random_uniform
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random.py"", line 96 in seeded_random_uniform
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py"", line 394 in value
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py"", line 241 in sub
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py"", line 209 in __sub__
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/protocol/pond/pond.py"", line 772 in _share
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/protocol/pond/pond.py"", line 343 in define_private_variable
  File ""/mnt/pysyft25/test/keras/test_sequential.py"", line 37 in test_instantiate_tfe_layer
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/python.py"", line 170 in pytest_pyfunc_call
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/python.py"", line 1423 in runtest
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 125 in pytest_runtest_call
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 201 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 229 in from_call
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 201 in call_runtest_hook
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 176 in call_and_report
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 95 in runtestprotocol
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 80 in pytest_runtest_protocol
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 256 in pytest_runtestloop
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 235 in _main
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 191 in wrap_session
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 228 in pytest_cmdline_main
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/config/__init__.py"", line 90 in main
  File ""/mnt/pysyft25/.eggs/pytest_runner-5.1-py3.6.egg/ptr.py"", line 220 in run_tests
  File ""/mnt/pysyft25/.eggs/pytest_runner-5.1-py3.6.egg/ptr.py"", line 209 in run
  File ""/usr/lib/python3.6/distutils/dist.py"", line 974 in run_command
  File ""/usr/lib/python3.6/distutils/dist.py"", line 955 in run_commands
  File ""/usr/lib/python3.6/distutils/core.py"", line 148 in setup
  File ""/usr/local/lib/python3.6/dist-packages/setuptools/__init__.py"", line 145 in setup
  File ""setup.py"", line 34 in <module>
æ®µé”™è¯¯ (æ ¸å¿ƒå·²è½¬å‚¨)
pysyft 0.1.26a
tensorflow 1.13.2
tf_encrypted 0.5.8
It is OK!!!

running pytest
Searching for pytest-flake8
Reading https://pypi.org/simple/pytest-flake8/
Downloading https://files.pythonhosted.org/packages/4b/99/a6e993c0927665522602058e1f2ea61ba1c8c51a60e3006f1eb1153b37e2/pytest_flake8-1.0.4-py2.py3-none-any.whl#sha256=d7e2b6b274a255b7ae35e9224c85294b471a83b76ecb6bd53c337ae977a499af
Best match: pytest-flake8 1.0.4
Processing pytest_flake8-1.0.4-py2.py3-none-any.whl
Installing pytest_flake8-1.0.4-py2.py3-none-any.whl to /mnt/pysyft/.eggs
writing requirements to /mnt/pysyft/.eggs/pytest_flake8-1.0.4-py3.6.egg/EGG-INFO/requires.txt

Installed /mnt/pysyft/.eggs/pytest_flake8-1.0.4-py3.6.egg
Searching for flake8>=3.5
Reading https://pypi.org/simple/flake8/
Downloading https://files.pythonhosted.org/packages/26/de/3f815a99d86eb10464ea7bd6059c0172c7ca97d4bdcfca41051b388a653b/flake8-3.7.8-py2.py3-none-any.whl#sha256=8e9dfa3cecb2400b3738a42c54c3043e821682b9c840b0448c0503f781130696
Best match: flake8 3.7.8
Processing flake8-3.7.8-py2.py3-none-any.whl
Installing flake8-3.7.8-py2.py3-none-any.whl to /mnt/pysyft/.eggs
writing requirements to /mnt/pysyft/.eggs/flake8-3.7.8-py3.6.egg/EGG-INFO/requires.txt

Installed /mnt/pysyft/.eggs/flake8-3.7.8-py3.6.egg
Searching for pyflakes<2.2.0,>=2.1.0
Reading https://pypi.org/simple/pyflakes/
Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl#sha256=17dbeb2e3f4d772725c777fabc446d5634d1038f234e77343108ce445ea69ce0
Best match: pyflakes 2.1.1
Processing pyflakes-2.1.1-py2.py3-none-any.whl
Installing pyflakes-2.1.1-py2.py3-none-any.whl to /mnt/pysyft/.eggs

Installed /mnt/pysyft/.eggs/pyflakes-2.1.1-py3.6.egg
Searching for pycodestyle<2.6.0,>=2.5.0
Reading https://pypi.org/simple/pycodestyle/
Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl#sha256=95a2219d12372f05704562a14ec30bc76b05a5b297b21a5dfe3f6fac3491ae56
Best match: pycodestyle 2.5.0
Processing pycodestyle-2.5.0-py2.py3-none-any.whl
Installing pycodestyle-2.5.0-py2.py3-none-any.whl to /mnt/pysyft/.eggs

Installed /mnt/pysyft/.eggs/pycodestyle-2.5.0-py3.6.egg
Searching for entrypoints<0.4.0,>=0.3.0
Reading https://pypi.org/simple/entrypoints/
Downloading https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl#sha256=589f874b313739ad35be6e0cd7efde2a4e9b6fea91edcc34e58ecbb8dbe56d19
Best match: entrypoints 0.3
Processing entrypoints-0.3-py2.py3-none-any.whl
Installing entrypoints-0.3-py2.py3-none-any.whl to /mnt/pysyft/.eggs
writing requirements to /mnt/pysyft/.eggs/entrypoints-0.3-py3.6.egg/EGG-INFO/requires.txt

Installed /mnt/pysyft/.eggs/entrypoints-0.3-py3.6.egg
running egg_info
writing syft.egg-info/PKG-INFO
writing dependency_links to syft.egg-info/dependency_links.txt
writing requirements to syft.egg-info/requires.txt
writing top-level names to syft.egg-info/top_level.txt
reading manifest file 'syft.egg-info/SOURCES.txt'
writing manifest file 'syft.egg-info/SOURCES.txt'
running build_ext
============================================================ test session starts =============================================================
platform linux -- Python 3.6.8, pytest-5.2.1, py-1.8.0, pluggy-0.13.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/pysyft, inifile: setup.cfg
plugins: flake8-1.0.4
collected 463 items                                                                                                                          

test/test_dependency_check.py::test_tensorflow_available SKIPPED                                                                       [  0%]
test/test_dependency_check.py::test_tf_encrypted_available PASSED                                                                      [  0%]
test/test_dependency_check.py::test_torch_available PASSED                                                                             [  0%]
test/test_dependency_check.py::test_tensorflow_missing PASSED                                                                          [  0%]
test/test_dependency_check.py::test_tf_encrypted_missing PASSED                                                                        [  1%]
test/test_exceptions.py::test_tensors_not_collated_exception PASSED                                                                    [  1%]
test/test_grid.py::test_virtual_grid PASSED                                                                                            [  1%]
test/test_local_worker.py::test_is_client_true PASSED                                                                                  [  1%]
test/test_local_worker.py::test_is_client_false PASSED                                                                                 [  1%]
test/test_local_worker.py::test_in_known_workers PASSED                                                                                [  2%]
test/test_sandbox.py::test_sandbox PASSED                                                                                              [  2%]
test/test_serde.py::test_tuple_simplify PASSED                                                                                         [  2%]
test/test_serde.py::test_list_simplify PASSED                                                                                          [  2%]
test/test_serde.py::test_set_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_float_simplify PASSED                                                                                         [  3%]
test/test_serde.py::test_int_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_string_simplify PASSED                                                                                        [  3%]
test/test_serde.py::test_dict_simplify PASSED                                                                                          [  3%]
test/test_serde.py::test_range_simplify PASSED                                                                                         [  4%]
test/test_serde.py::test_torch_tensor_simplify PASSED                                                                                  [  4%]
test/test_serde.py::test_ndarray_simplify PASSED                                                                                       [  4%]
test/test_serde.py::test_ellipsis_simplify PASSED                                                                                      [  4%]
test/test_serde.py::test_torch_device_simplify PASSED                                                                                  [  4%]
test/test_serde.py::test_pointer_tensor_simplify PASSED                                                                                [  5%]
test/test_serde.py::test_torch_Tensor[True] PASSED                                                                                     [  5%]
test/test_serde.py::test_torch_Tensor[False] PASSED                                                                                    [  5%]
test/test_serde.py::test_torch_Tensor_convenience[True] PASSED                                                                         [  5%]
test/test_serde.py::test_torch_Tensor_convenience[False] PASSED                                                                        [  6%]
test/test_serde.py::test_tuple[True] PASSED                                                                                            [  6%]
test/test_serde.py::test_tuple[False] PASSED                                                                                           [  6%]
test/test_serde.py::test_bytearray[True] PASSED                                                                                        [  6%]
test/test_serde.py::test_bytearray[False] PASSED                                                                                       [  6%]
test/test_serde.py::test_ndarray_serde[True] PASSED                                                                                    [  7%]
test/test_serde.py::test_ndarray_serde[False] PASSED                                                                                   [  7%]
test/test_serde.py::test_compress_decompress[41] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[42] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[40] PASSED                                                                                [  7%]
test/test_serde.py::test_compressed_serde[41] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[42] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[40] PASSED                                                                                   [  8%]
test/test_serde.py::test_dict[True] PASSED                                                                                             [  8%]
test/test_serde.py::test_dict[False] PASSED                                                                                            [  9%]
test/test_serde.py::test_range_serde[True] PASSED                                                                                      [  9%]
test/test_serde.py::test_range_serde[False] PASSED                                                                                     [  9%]
test/test_serde.py::test_list[True] PASSED                                                                                             [  9%]
test/test_serde.py::test_list[False] PASSED                                                                                            [  9%]
test/test_serde.py::test_set[True] PASSED                                                                                              [ 10%]
test/test_serde.py::test_set[False] PASSED                                                                                             [ 10%]
test/test_serde.py::test_slice[True] PASSED                                                                                            [ 10%]
test/test_serde.py::test_slice[False] PASSED                                                                                           [ 10%]
test/test_serde.py::test_float[True] PASSED                                                                                            [ 11%]
test/test_serde.py::test_float[False] PASSED                                                                                           [ 11%]
test/test_serde.py::test_hooked_tensor[True-41] PASSED                                                                                 [ 11%]
test/test_serde.py::test_hooked_tensor[False-41] PASSED                                                                                [ 11%]
test/test_serde.py::test_hooked_tensor[True-42] PASSED                                                                                 [ 11%]
test/test_serde.py::test_hooked_tensor[False-42] PASSED                                                                                [ 12%]
test/test_serde.py::test_hooked_tensor[True-40] PASSED                                                                                 [ 12%]
test/test_serde.py::test_hooked_tensor[False-40] PASSED                                                                                [ 12%]
test/test_serde.py::test_pointer_tensor PASSED                                                                                         [ 12%]
test/test_serde.py::test_pointer_tensor_detail[10000] PASSED                                                                           [ 12%]
test/test_serde.py::test_pointer_tensor_detail[10001] PASSED                                                                           [ 13%]
test/test_serde.py::test_numpy_tensor_serde PASSED                                                                                     [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[True] PASSED                                                                    [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[False] PASSED                                                                   [ 13%]
test/test_serde.py::test_fixed_precision_tensor_serde[True] PASSED                                                                     [ 14%]
test/test_serde.py::test_fixed_precision_tensor_serde[False] PASSED                                                                    [ 14%]
test/test_serde.py::test_serde_object_wrapper_int PASSED                                                                               [ 14%]
test/test_serde.py::test_serialize_and_deserialize_torch_scriptmodule SKIPPED                                                          [ 14%]
test/test_serde.py::test_torch_jit_script_module_serde SKIPPED                                                                         [ 14%]
test/test_serde.py::test_serde_virtual_worker PASSED                                                                                   [ 15%]
test/test_serde.py::test_full_serde_virtual_worker PASSED                                                                              [ 15%]
test/test_serde.py::test_serde_object_wrapper_traced_module PASSED                                                                     [ 15%]
test/test_serde.py::test_no_simplifier_found PASSED                                                                                    [ 15%]
test/test_udacity.py::test_section_1_differential_privacy PASSED                                                                       [ 15%]
test/test_udacity.py::test_section_2_federated_learning PASSED                                                                         [ 16%]
test/test_udacity.py::test_section_3_securing_fl PASSED                                                                                [ 16%]
test/federated/test_federated_client.py::test_add_dataset PASSED                                                                       [ 16%]
test/federated/test_federated_client.py::test_add_dataset_with_duplicate_key PASSED                                                    [ 16%]
test/federated/test_federated_client.py::test_remove_dataset PASSED                                                                    [ 17%]
test/federated/test_federated_client.py::test_set_obj_train_config PASSED                                                              [ 17%]
test/federated/test_federated_client.py::test_set_obj_other PASSED                                                                     [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-1] PASSED                                                           [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-10] PASSED                                                          [ 17%]
test/federated/test_federated_client.py::test_fit[another_dataset-1] PASSED                                                            [ 18%]
test/federated/test_federated_client.py::test_evaluate SKIPPED                                                                         [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_script_module SKIPPED                                                  [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace SKIPPED                                                          [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_send_twice_with_fit SKIPPED                                      [ 19%]
test/federated/test_train_config.py::test___str__ PASSED                                                                               [ 19%]
test/federated/test_train_config.py::test_send PASSED                                                                                  [ 19%]
test/federated/test_train_config.py::test_send_model_and_loss_fn PASSED                                                                [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_async SKIPPED                                                    [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_sync SKIPPED                                                     [ 20%]
test/generic/test_id_provider.py::test_pop_no_given_ids PASSED                                                                         [ 20%]
test/generic/test_id_provider.py::test_pop_with_given_ids PASSED                                                                       [ 20%]
test/generic/test_id_provider.py::test_given_ids_side_effect PASSED                                                                    [ 20%]
test/generic/test_id_provider.py::test_set_next_ids PASSED                                                                             [ 20%]
test/generic/test_id_provider.py::test_set_next_ids_with_id_checking PASSED                                                            [ 21%]
test/generic/test_id_provider.py::test_start_recording_ids PASSED                                                                      [ 21%]
test/generic/test_id_provider.py::test_get_recorded_ids PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects_return_None PASSED                                                             [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[lstm] PASSED                                                                                [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[gru] PASSED                                                                                 [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_tanh] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_relu] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_federated[lstm] PASSED                                                                          [ 23%]
test/integration/test_rnn.py::test_rnn_federated[gru] PASSED                                                                           [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_tanh] PASSED                                                                      [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_relu] PASSED                                                                      [ 23%]
test/keras/test_sequential.py::test_instantiate_tfe_layer PASSED                                                                       [ 23%]
test/keras/test_sequential.py::test_share PASSED                                                                                       [ 24%]
test/message/test_message.py::test_message_serde PASSED                                                                                [ 24%]
test/message/test_message.py::test_cmd_message PASSED                                                                                  [ 24%]
test/message/test_message.py::test_obj_message PASSED                                                                                  [ 24%]
test/message/test_message.py::test_obj_req_message PASSED                                                                              [ 25%]
test/message/test_message.py::test_get_shape_message PASSED                                                                            [ 25%]
test/message/test_message.py::test_force_object_delete_message PASSED                                                                  [ 25%]
test/message/test_message.py::test_is_none_message PASSED                                                                              [ 25%]
test/message/test_message.py::test_search_message_serde PASSED                                                                         [ 25%]
test/message/test_plan.py::test_plan_built_automatically PASSED                                                                        [ 26%]
test/message/test_plan.py::test_stateful_plan_built_automatically PASSED                                                               [ 26%]
test/message/test_plan.py::test_plan_build PASSED                                                                                      [ 26%]
test/message/test_plan.py::test_stateful_plan_build PASSED                                                                             [ 26%]
test/message/test_plan.py::test_plan_built_automatically_with_any_dimension PASSED                                                     [ 26%]
test/message/test_plan.py::test_raise_exception_for_invalid_shape PASSED                                                               [ 27%]
test/message/test_plan.py::test_raise_exception_when_sending_unbuilt_plan PASSED                                                       [ 27%]
test/message/test_plan.py::test_plan_execute_locally PASSED                                                                            [ 27%]
test/message/test_plan.py::test_add_to_state PASSED                                                                                    [ 27%]
test/message/test_plan.py::test_plan_method_execute_locally PASSED                                                                     [ 28%]
test/message/test_plan.py::test_stateful_plan_method_execute_locally PASSED                                                            [ 28%]
test/message/test_plan.py::test_plan_multiple_send PASSED                                                                              [ 28%]
test/message/test_plan.py::test_stateful_plan_multiple_send PASSED                                                                     [ 28%]
test/message/test_plan.py::test_plan_built_on_class PASSED                                                                             [ 28%]
test/message/test_plan.py::test_multiple_workers PASSED                                                                                [ 29%]
test/message/test_plan.py::test_stateful_plan_multiple_workers PASSED                                                                  [ 29%]
test/message/test_plan.py::test_fetch_plan PASSED                                                                                      [ 29%]
test/message/test_plan.py::test_plan_serde PASSED                                                                                      [ 29%]
test/message/test_plan.py::test_execute_plan_remotely PASSED                                                                           [ 30%]
test/message/test_plan.py::test_execute_plan_module_remotely PASSED                                                                    [ 30%]
test/message/test_plan.py::test_train_plan_locally_and_then_send_it PASSED                                                             [ 30%]
test/message/test_plan.py::test_replace_worker_ids_two_strings PASSED                                                                  [ 30%]
test/message/test_plan.py::test_replace_worker_ids_one_string_one_int PASSED                                                           [ 30%]
test/message/test_plan.py::test_replace_worker_ids_two_ints PASSED                                                                     [ 31%]
test/message/test_plan.py::test__replace_message_ids PASSED                                                                            [ 31%]
test/message/test_plan.py::test_send_with_plan PASSED                                                                                  [ 31%]
test/torch/test_federated_learning.py::TestFederatedLearning::test_toy_federated_learning PASSED                                       [ 31%]
test/torch/test_federated_learning.py::test_lstm PASSED                                                                                [ 31%]
test/torch/test_functions.py::test_combine_pointers PASSED                                                                             [ 32%]
test/torch/test_hook.py::test___init__ PASSED                                                                                          [ 32%]
test/torch/test_hook.py::test_torch_attributes PASSED                                                                                  [ 32%]
test/torch/test_hook.py::test_worker_registration PASSED                                                                               [ 32%]
test/torch/test_hook.py::test_pointer_found_exception PASSED                                                                           [ 33%]
test/torch/test_hook.py::test_build_get_child_type PASSED                                                                              [ 33%]
test/torch/test_hook.py::test_get_pointer_unary_method[abs] PASSED                                                                     [ 33%]
test/torch/test_hook.py::test_get_pointer_binary_method[add] PASSED                                                                    [ 33%]
test/torch/test_hook.py::test_get_pointer_binary_method[mul] PASSED                                                                    [ 33%]
test/torch/test_hook.py::test_get_pointer_to_pointer_unary_method[abs] PASSED                                                          [ 34%]
test/torch/test_hook.py::test_get_pointer_to_pointer_binary_method[add] PASSED                                                         [ 34%]
test/torch/test_hook.py::test_get_pointer_to_pointer_binary_method[mul] PASSED                                                         [ 34%]
test/torch/test_hook.py::test_hook_module_functional[relu] PASSED                                                                      [ 34%]
test/torch/test_hook.py::test_hook_module_functional[celu] PASSED                                                                      [ 34%]
test/torch/test_hook.py::test_hook_module_functional[elu] PASSED                                                                       [ 35%]
test/torch/test_hook.py::test_functional_same_in_both_imports[relu] PASSED                                                             [ 35%]
test/torch/test_hook.py::test_functional_same_in_both_imports[celu] PASSED                                                             [ 35%]
test/torch/test_hook.py::test_functional_same_in_both_imports[elu] PASSED                                                              [ 35%]
test/torch/test_hook.py::test_hook_tensor PASSED                                                                                       [ 36%]
test/torch/test_hook.py::test_properties PASSED                                                                                        [ 36%]
test/torch/test_hook.py::test_signature_cache_change PASSED                                                                            [ 36%]
test/torch/test_hook.py::test_parameter_hooking PASSED                                                                                 [ 36%]
test/torch/test_hook.py::test_torch_module_hook PASSED                                                                                 [ 36%]
test/torch/test_hook.py::test_functional_hook PASSED                                                                                   [ 37%]
test/torch/test_hook.py::test_hook_args_and_cmd_signature_malleability PASSED                                                          [ 37%]
test/torch/test_hook.py::test_torch_func_signature_without_tensor PASSED                                                               [ 37%]
test/torch/test_hook.py::test_RNN_grad_set_backpropagation PASSED                                                                      [ 37%]
test/torch/test_hook.py::test_local_remote_gradient_clipping PASSED                                                                    [ 38%]
test/torch/test_hook.py::test_remote_gradient_clipping PASSED                                                                          [ 38%]
test/torch/test_hook.py::test_local_gradient_clipping PASSED                                                                           [ 38%]
test/torch/crypto/test_snn.py::test_xor_implementation PASSED                                                                          [ 38%]
test/torch/crypto/test_snn.py::test_private_compare PASSED                                                                             [ 38%]
test/torch/crypto/test_snn.py::test_share_convert PASSED                                                                               [ 39%]
test/torch/crypto/test_snn.py::test_relu_deriv PASSED                                                                                  [ 39%]
test/torch/crypto/test_snn.py::test_relu PASSED                                                                                        [ 39%]
test/torch/crypto/test_snn.py::test_division PASSED                                                                                    [ 39%]
test/torch/crypto/test_snn.py::test_maxpool PASSED                                                                                     [ 39%]
test/torch/crypto/test_snn.py::test_maxpool_deriv PASSED                                                                               [ 40%]
test/torch/differential_privacy/test_pate.py::test_base_dataset PASSED                                                                 [ 40%]
test/torch/differential_privacy/test_pate.py::test_base_dataset_torch PASSED                                                           [ 40%]
test/torch/differential_privacy/test_pate.py::test_torch_ref_match PASSED                                                              [ 40%]
test/torch/federated/test_dataloader.py::test_federated_dataloader PASSED                                                              [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_shuffle PASSED                                                      [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_num_iterators PASSED                                                [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_iter_per_worker PASSED                                              [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_one_worker PASSED                                                   [ 41%]
test/torch/federated/test_dataset.py::test_base_dataset PASSED                                                                         [ 42%]
test/torch/federated/test_dataset.py::test_base_dataset_transform PASSED                                                               [ 42%]
test/torch/federated/test_dataset.py::test_federated_dataset PASSED                                                                    [ 42%]
test/torch/federated/test_dataset.py::test_dataset_to_federate PASSED                                                                  [ 42%]
test/torch/federated/test_dataset.py::test_federated_dataset_search PASSED                                                             [ 42%]
test/torch/federated/test_utils.py::test_extract_batches_per_worker PASSED                                                             [ 43%]
test/torch/federated/test_utils.py::test_add_model PASSED                                                                              [ 43%]
test/torch/federated/test_utils.py::test_scale_model PASSED                                                                            [ 43%]
test/torch/federated/test_utils.py::test_accuracy PASSED                                                                               [ 43%]
test/torch/hook/test_hook_args.py::test_build_rule_syft_tensors_and_pointers PASSED                                                    [ 44%]
test/torch/hook/test_hook_args.py::test_build_rule_numpy PASSED                                                                        [ 44%]
test/torch/linalg/test_linalg.py::test_inv_sym PASSED                                                                                  [ 44%]
test/torch/pointers/test_callable_pointer.py::test_create_callable_pointer PASSED                                                      [ 44%]
test/torch/pointers/test_callable_pointer.py::test_get_obj_callable_pointer PASSED                                                     [ 44%]
test/torch/pointers/test_callable_pointer.py::test_call_callable_pointer PASSED                                                        [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_init PASSED                                                                           [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_create_pointer PASSED                                                                 [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_send_default_garbage_collector_true PASSED                                            [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_send_garbage_collect_data_false PASSED                                                [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_gc_false PASSED                                                                  [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_gc_true PASSED                                                                   [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_disable_gc PASSED                                                                [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_get PASSED                                                                       [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_inplace_send_get PASSED                                                               [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_repeated_send PASSED                                                                  [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_remote_autograd PASSED                                                                [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_gradient_send_recv PASSED                                                             [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_method_on_attribute PASSED                                                            [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_grad_pointer PASSED                                                                   [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_move PASSED                                                                           [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_combine_pointers PASSED                                                               [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_remote_to_cpu_device PASSED                                                           [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_get_remote_shape PASSED                                                               [ 49%]
test/torch/pointers/test_pointer_tensor.py::test_remote_function_with_multi_ouput PASSED                                               [ 49%]
test/torch/pointers/test_pointer_tensor.py::test_raising_error_when_item_func_called PASSED                                            [ 49%]
test/torch/tensors/test_additive_shared.py::test_wrap PASSED                                                                           [ 49%]
test/torch/tensors/test_additive_shared.py::test__str__ PASSED                                                                         [ 49%]
test/torch/tensors/test_additive_shared.py::test_encode_decode PASSED                                                                  [ 50%]
test/torch/tensors/test_additive_shared.py::test_virtual_get PASSED                                                                    [ 50%]
test/torch/tensors/test_additive_shared.py::test_autograd_kwarg PASSED                                                                 [ 50%]
test/torch/tensors/test_additive_shared.py::test_send_get PASSED                                                                       [ 50%]
test/torch/tensors/test_additive_shared.py::test_add PASSED                                                                            [ 50%]
test/torch/tensors/test_additive_shared.py::test_sub PASSED                                                                            [ 51%]
test/torch/tensors/test_additive_shared.py::test_mul PASSED                                                                            [ 51%]
test/torch/tensors/test_additive_shared.py::test_public_mul PASSED                                                                     [ 51%]
test/torch/tensors/test_additive_shared.py::test_div PASSED                                                                            [ 51%]
test/torch/tensors/test_additive_shared.py::test_pow PASSED                                                                            [ 52%]
test/torch/tensors/test_additive_shared.py::test_operate_with_integer_constants PASSED                                                 [ 52%]
test/torch/tensors/test_additive_shared.py::test_stack PASSED                                                                          [ 52%]
test/torch/tensors/test_additive_shared.py::test_cat PASSED                                                                            [ 52%]
test/torch/tensors/test_additive_shared.py::test_chunk PASSED                                                                          [ 52%]
test/torch/tensors/test_additive_shared.py::test_roll PASSED                                                                           [ 53%]
test/torch/tensors/test_additive_shared.py::test_nn_linear PASSED                                                                      [ 53%]
test/torch/tensors/test_additive_shared.py::test_matmul PASSED                                                                         [ 53%]
test/torch/tensors/test_additive_shared.py::test_mm PASSED                                                                             [ 53%]
test/torch/tensors/test_additive_shared.py::test_torch_conv2d PASSED                                                                   [ 53%]
test/torch/tensors/test_additive_shared.py::test_fixed_precision_and_sharing PASSED                                                    [ 54%]
test/torch/tensors/test_additive_shared.py::test_fixed_precision_and_sharing_on_pointer PASSED                                         [ 54%]
test/torch/tensors/test_additive_shared.py::test_pointer_on_fixed_precision_and_sharing PASSED                                         [ 54%]
test/torch/tensors/test_additive_shared.py::test_get_item PASSED                                                                       [ 54%]
test/torch/tensors/test_additive_shared.py::test_eq PASSED                                                                             [ 55%]
test/torch/tensors/test_additive_shared.py::test_comp PASSED                                                                           [ 55%]
test/torch/tensors/test_additive_shared.py::test_max PASSED                                                                            [ 55%]
test/torch/tensors/test_additive_shared.py::test_argmax PASSED                                                                         [ 55%]
test/torch/tensors/test_additive_shared.py::test_mod PASSED                                                                            [ 55%]
test/torch/tensors/test_additive_shared.py::test_torch_sum PASSED                                                                      [ 56%]
test/torch/tensors/test_additive_shared.py::test_torch_mean PASSED                                                                     [ 56%]
test/torch/tensors/test_additive_shared.py::test_torch_dot PASSED                                                                      [ 56%]
test/torch/tensors/test_additive_shared.py::test_unbind PASSED                                                                         [ 56%]
test/torch/tensors/test_additive_shared.py::test_handle_func_command PASSED                                                            [ 57%]
test/torch/tensors/test_additive_shared.py::test_init_with_no_crypto_provider PASSED                                                   [ 57%]
test/torch/tensors/test_additive_shared.py::test_zero_refresh PASSED                                                                   [ 57%]
test/torch/tensors/test_additive_shared.py::test_cnn_model PASSED                                                                      [ 57%]
test/torch/tensors/test_autograd.py::test_wrap PASSED                                                                                  [ 57%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__add__] PASSED                                   [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__sub__] PASSED                                   [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__mul__] PASSED                                   [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__matmul__] PASSED                                [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__add__] PASSED                                  [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__sub__] PASSED                                  [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__mul__] PASSED                                  [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__matmul__] PASSED                               [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_inplace_binary_cmd_with_autograd[__iadd__] PASSED                               [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_inplace_binary_cmd_with_autograd[__isub__] PASSED                               [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes0-__add__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes0-__sub__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes1-__add__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes1-__sub__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes2-__add__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes2-__sub__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes3-__add__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes3-__sub__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes4-__add__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes4-__sub__] PASSED    [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[True-__add__] PASSED                            [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[True-__mul__] PASSED                            [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[True-__matmul__] PASSED                         [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[False-__add__] PASSED                           [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[False-__mul__] PASSED                           [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[False-__matmul__] PASSED                        [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_inplace_binary_cmd_with_autograd[__iadd__] PASSED                        [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_inplace_binary_cmd_with_autograd[__isub__] PASSED                        [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_local_autograd[__add__] PASSED                                [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_local_autograd[__mul__] PASSED                                [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_local_autograd[__matmul__] PASSED                             [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sqrt] PASSED                                    [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[asin] PASSED                                    [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sin] PASSED                                     [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sinh] PASSED                                    [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[tanh] PASSED                                    [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sigmoid] PASSED                                 [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[True-__add__] PASSED                          [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[True-__mul__] PASSED                          [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[True-__matmul__] PASSED                       [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[False-__add__] PASSED                         [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[False-__mul__] PASSED                         [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[False-__matmul__] PASSED                      [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_linear_model_on_fix_prec_params_with_autograd PASSED                            [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[True-__add__] PASSED                   [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[True-__mul__] PASSED                   [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[True-__matmul__] PASSED                [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[False-__add__] PASSED                  [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[False-__mul__] PASSED                  [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[False-__matmul__] PASSED               [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_div_with_autograd[True] PASSED                                  [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_div_with_autograd[False] PASSED                                 [ 69%]
test/torch/tensors/test_autograd.py::test_addmm_backward_for_additive_shared_with_autograd PASSED                                      [ 69%]
test/torch/tensors/test_autograd.py::test_relu_backward_or_additive_shared_with_autograd PASSED                                        [ 69%]
test/torch/tensors/test_autograd.py::test_backward_for_linear_model_on_additive_shared_with_autograd PASSED                            [ 69%]
test/torch/tensors/test_autograd.py::test_remote_share_with_requires_grad PASSED                                                       [ 69%]
test/torch/tensors/test_autograd.py::test_encrypted_training_with_linear_model PASSED                                                  [ 70%]
test/torch/tensors/test_autograd.py::test_get_float_prec_on_autograd_tensor PASSED                                                     [ 70%]
test/torch/tensors/test_autograd.py::test_serialize_deserialize_autograd_tensor PASSED                                                 [ 70%]
test/torch/tensors/test_autograd.py::test_types_auto_remote_tensors PASSED                                                             [ 70%]
test/torch/tensors/test_autograd.py::test_train_remote_autograd_tensor PASSED                                                          [ 71%]
test/torch/tensors/test_crt_precision.py::test__str__ PASSED                                                                           [ 71%]
test/torch/tensors/test_crt_precision.py::test_eq PASSED                                                                               [ 71%]
test/torch/tensors/test_crt_precision.py::test__neg__ PASSED                                                                           [ 71%]
test/torch/tensors/test_crt_precision.py::test_add PASSED                                                                              [ 71%]
test/torch/tensors/test_crt_precision.py::test_sub PASSED                                                                              [ 72%]
test/torch/tensors/test_crt_precision.py::test_mul PASSED                                                                              [ 72%]
test/torch/tensors/test_crt_precision.py::test_send_and_get PASSED                                                                     [ 72%]
test/torch/tensors/test_crt_precision.py::test_share_and_get PASSED                                                                    [ 72%]
test/torch/tensors/test_gc.py::test_explicit_garbage_collect_pointer PASSED                                                            [ 73%]
test/torch/tensors/test_gc.py::test_explicit_garbage_collect_double_pointer PASSED                                                     [ 73%]
test/torch/tensors/test_gc.py::test_implicit_garbage_collection_pointer PASSED                                                         [ 73%]
test/torch/tensors/test_gc.py::test_implicit_garbage_collect_double_pointer PASSED                                                     [ 73%]
test/torch/tensors/test_gc.py::test_inplace_method_on_pointer PASSED                                                                   [ 73%]
test/torch/tensors/test_gc.py::test_explicit_garbage_collect_logging_on_pointer PASSED                                                 [ 74%]
test/torch/tensors/test_gc.py::test_implicit_garbage_collect_logging_on_pointer PASSED                                                 [ 74%]
test/torch/tensors/test_gc.py::test_websocket_garbage_collection PASSED                                                                [ 74%]
test/torch/tensors/test_large_precision.py::test_wrap PASSED                                                                           [ 74%]
test/torch/tensors/test_large_precision.py::test_fix_prec PASSED                                                                       [ 74%]
test/torch/tensors/test_large_precision.py::test_2d_tensors PASSED                                                                     [ 75%]
test/torch/tensors/test_large_precision.py::test_3d_tensors PASSED                                                                     [ 75%]
test/torch/tensors/test_large_precision.py::test_negative_numbers PASSED                                                               [ 75%]
test/torch/tensors/test_large_precision.py::test_add_multiple_dimensions PASSED                                                        [ 75%]
test/torch/tensors/test_large_precision.py::test_add_negative_values PASSED                                                            [ 76%]
test/torch/tensors/test_large_precision.py::test_add PASSED                                                                            [ 76%]
test/torch/tensors/test_large_precision.py::test_iadd PASSED                                                                           [ 76%]
test/torch/tensors/test_large_precision.py::test_add_different_dims PASSED                                                             [ 76%]
test/torch/tensors/test_large_precision.py::test_mul PASSED                                                                            [ 76%]
test/torch/tensors/test_large_precision.py::test_imul PASSED                                                                           [ 77%]
test/torch/tensors/test_large_precision.py::test_mul_multiple_dims PASSED                                                              [ 77%]
test/torch/tensors/test_large_precision.py::test_concat_ops PASSED                                                                     [ 77%]
test/torch/tensors/test_large_precision.py::test_uint8_representation PASSED                                                           [ 77%]
test/torch/tensors/test_large_precision.py::test_sub PASSED                                                                            [ 77%]
test/torch/tensors/test_large_precision.py::test_isub PASSED                                                                           [ 78%]
test/torch/tensors/test_large_precision.py::test_diff_dims_in_same_tensor PASSED                                                       [ 78%]
test/torch/tensors/test_large_precision.py::test_mod PASSED                                                                            [ 78%]
test/torch/tensors/test_large_precision.py::test_types[x0-expected0] PASSED                                                            [ 78%]
test/torch/tensors/test_large_precision.py::test_types[x1-expected1] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x2-expected2] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x3-expected3] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x4-expected4] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x5-expected5] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x6-expected6] PASSED                                                            [ 80%]
test/torch/tensors/test_large_precision.py::test_types[x7-expected7] PASSED                                                            [ 80%]
test/torch/tensors/test_large_precision.py::test_types[x8-expected8] PASSED                                                            [ 80%]
test/torch/tensors/test_large_precision.py::test_types[x9-expected9] PASSED                                                            [ 80%]
test/torch/tensors/test_logging.py::test_wrap PASSED                                                                                   [ 80%]
test/torch/tensors/test_logging.py::test_overwritten_method_on_log_chain PASSED                                                        [ 81%]
test/torch/tensors/test_logging.py::test_method_on_log_chain PASSED                                                                    [ 81%]
test/torch/tensors/test_logging.py::test_hook_module_functional_on_log_chain[relu] PASSED                                              [ 81%]
test/torch/tensors/test_logging.py::test_hook_module_functional_on_log_chain[celu] PASSED                                              [ 81%]
test/torch/tensors/test_logging.py::test_hook_module_functional_on_log_chain[elu] PASSED                                               [ 82%]
test/torch/tensors/test_logging.py::test_function_on_log_chain PASSED                                                                  [ 82%]
test/torch/tensors/test_logging.py::test_send_get_log_chain PASSED                                                                     [ 82%]
test/torch/tensors/test_logging.py::test_inplace_send_get_log_chain PASSED                                                             [ 82%]
test/torch/tensors/test_logging.py::test_remote_method_on_log_chain PASSED                                                             [ 82%]
test/torch/tensors/test_logging.py::test_remote_function_on_log_chain PASSED                                                           [ 83%]
test/torch/tensors/test_logging.py::test_print_log_chain PASSED                                                                        [ 83%]
test/torch/tensors/test_multi_pointer.py::test_multi_pointers PASSED                                                                   [ 83%]
test/torch/tensors/test_multi_pointer.py::test_dim PASSED                                                                              [ 83%]
test/torch/tensors/test_multi_pointer.py::test_simplify PASSED                                                                         [ 84%]
test/torch/tensors/test_native.py::test___str__ PASSED                                                                                 [ 84%]
test/torch/tensors/test_native.py::test___repr__ PASSED                                                                                [ 84%]
test/torch/tensors/test_native.py::test_overload_reshape PASSED                                                                        [ 84%]
test/torch/tensors/test_native.py::test_owner_default PASSED                                                                           [ 84%]
test/torch/tensors/test_native.py::test_create_pointer PASSED                                                                          [ 85%]
test/torch/tensors/test_native.py::test_create_pointer_defaults PASSED                                                                 [ 85%]
test/torch/tensors/test_native.py::test_get PASSED                                                                                     [ 85%]
test/torch/tensors/test_native.py::test_invalid_remote_get PASSED                                                                      [ 85%]
test/torch/tensors/test_native.py::test_remote_get PASSED                                                                              [ 85%]
test/torch/tensors/test_native.py::test_copy PASSED                                                                                    [ 86%]
test/torch/tensors/test_native.py::test_size PASSED                                                                                    [ 86%]
test/torch/tensors/test_native.py::test_dim PASSED                                                                                     [ 86%]
test/torch/tensors/test_native.py::test_does_not_require_large_precision PASSED                                                        [ 86%]
test/torch/tensors/test_native.py::test_requires_large_precision PASSED                                                                [ 87%]
test/torch/tensors/test_native.py::test_roll PASSED                                                                                    [ 87%]
test/torch/tensors/test_parameter.py::test_param_on_pointer PASSED                                                                     [ 87%]
test/torch/tensors/test_parameter.py::test_param_send_get PASSED                                                                       [ 87%]
test/torch/tensors/test_parameter.py::test_param_inplace_send_get PASSED                                                               [ 87%]
test/torch/tensors/test_parameter.py::test_param_double_send_get PASSED                                                                [ 88%]
test/torch/tensors/test_parameter.py::test_param_remote_binary_method PASSED                                                           [ 88%]
test/torch/tensors/test_parameter.py::test_local_param_in_nn_module_linear PASSED                                                      [ 88%]
test/torch/tensors/test_parameter.py::test_remote_param_in_nn_module_linear PASSED                                                     [ 88%]
test/torch/tensors/test_precision.py::test_wrap PASSED                                                                                 [ 88%]
test/torch/tensors/test_precision.py::test_encode_decode[False] PASSED                                                                 [ 89%]
test/torch/tensors/test_precision.py::test_encode_decode[True] PASSED                                                                  [ 89%]
test/torch/tensors/test_precision.py::test_inplace_encode_decode PASSED                                                                [ 89%]
test/torch/tensors/test_precision.py::test_add_method PASSED                                                                           [ 89%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[False-t] PASSED                                                   [ 90%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[False-matmul] PASSED                                              [ 90%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[True-t] PASSED                                                    [ 90%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[True-matmul] PASSED                                               [ 90%]
test/torch/tensors/test_precision.py::test_torch_add PASSED                                                                            [ 90%]
test/torch/tensors/test_precision.py::test_torch_add_ PASSED                                                                           [ 91%]
test/torch/tensors/test_precision.py::test_torch_sub_ PASSED                                                                           [ 91%]
test/torch/tensors/test_precision.py::test_torch_sub PASSED                                                                            [ 91%]
test/torch/tensors/test_precision.py::test_torch_mul PASSED                                                                            [ 91%]
test/torch/tensors/test_precision.py::test_torch_div PASSED                                                                            [ 92%]
test/torch/tensors/test_precision.py::test_torch_pow PASSED                                                                            [ 92%]
test/torch/tensors/test_precision.py::test_torch_matmul PASSED                                                                         [ 92%]
test/torch/tensors/test_precision.py::test_torch_addmm PASSED                                                                          [ 92%]
test/torch/tensors/test_precision.py::test_torch_dot PASSED                                                                            [ 92%]
test/torch/tensors/test_precision.py::test_torch_conv2d PASSED                                                                         [ 93%]
test/torch/tensors/test_precision.py::test_torch_nn_functional_linear PASSED                                                           [ 93%]
test/torch/tensors/test_precision.py::test_operate_with_integer_constants PASSED                                                       [ 93%]
test/torch/tensors/test_precision.py::test_fixed_precision_and_sharing PASSED                                                          [ 93%]
test/torch/tensors/test_precision.py::test_get_preserves_attributes PASSED                                                             [ 93%]
test/torch/tensors/test_precision.py::test_comp PASSED                                                                                 [ 94%]
test/torch/tensors/test_tensor.py::test_init PASSED                                                                                    [ 94%]
test/torch/tensors/test_variable.py::test_gradient_serde PASSED                                                                        [ 94%]
test/workers/test_base.py::test_create_already_existing_worker PASSED                                                                  [ 94%]
test/workers/test_base.py::test_clear_object_for_worker_created_with_pre_existing_id PASSED                                            [ 95%]
test/workers/test_base.py::test_create_already_existing_worker_with_different_type PASSED                                              [ 95%]
test/workers/test_base.py::test_execute_command_self PASSED                                                                            [ 95%]
test/workers/test_virtual.py::test_send_msg PASSED                                                                                     [ 95%]
test/workers/test_virtual.py::test_send_msg_using_tensor_api PASSED                                                                    [ 95%]
test/workers/test_virtual.py::test_recv_msg PASSED                                                                                     [ 96%]
test/workers/test_virtual.py::tests_worker_convenience_methods PASSED                                                                  [ 96%]
test/workers/test_virtual.py::test_search PASSED                                                                                       [ 96%]
test/workers/test_virtual.py::test_obj_not_found PASSED                                                                                [ 96%]
test/workers/test_virtual.py::test_get_not_permitted PASSED                                                                            [ 96%]
test/workers/test_virtual.py::test_spinup_time PASSED                                                                                  [ 97%]
test/workers/test_virtual.py::test_send_jit_scriptmodule SKIPPED                                                                       [ 97%]
test/workers/test_websocket_worker.py::test_websocket_worker_basic[True] PASSED                                                        [ 97%]
test/workers/test_websocket_worker.py::test_websocket_worker_basic[False] PASSED                                                       [ 97%]
test/workers/test_websocket_worker.py::test_websocket_workers_search PASSED                                                            [ 98%]
test/workers/test_websocket_worker.py::test_list_objects_remote PASSED                                                                 [ 98%]
test/workers/test_websocket_worker.py::test_objects_count_remote PASSED                                                                [ 98%]
test/workers/test_websocket_worker.py::test_clear_objects_remote PASSED                                                                [ 98%]
test/workers/test_websocket_worker.py::test_connect_close PASSED                                                                       [ 98%]
test/workers/test_websocket_worker.py::test_websocket_worker_multiple_output_response PASSED                                           [ 99%]
test/workers/test_websocket_worker.py::test_evaluate SKIPPED                                                                           [ 99%]
test/workers/test_worker.py::test___init__ PASSED                                                                                      [ 99%]
test/workers/test_worker.py::test_get_unknown_worker PASSED                                                                            [ 99%]
test/workers/test_worker.py::test_search PASSED                                                                                        [100%]

============================================================== warnings summary ==============================================================
/usr/local/lib/python3.6/dist-packages/_pytest/mark/structures.py:325
  /usr/local/lib/python3.6/dist-packages/_pytest/mark/structures.py:325: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

test/torch/differential_privacy/test_pate.py::test_base_dataset_torch
test/torch/differential_privacy/test_pate.py::test_torch_ref_match
  /mnt/pysyft/syft/frameworks/torch/hook/hook.py:484: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
    current_tensor = hook_self.torch.native_tensor(*args, **kwargs)

-- Docs: https://docs.pytest.org/en/latest/warnings.html
========================================== 452 passed, 11 skipped, 3 warnings in 142.63s (0:02:22) ===========================================Tested this on the latest ```dev branch``` and there is no problem. @wind23 could you please retest and close the issues if it is solved?",7,2019-10-14 06:12:19,2019-11-15 08:51:19,2019-11-15 08:51:18
https://github.com/OpenMined/PySyft/issues/2631,['bug '],MPC not working with more than or equal to 3 workers,"MPC not working with more than or equal to 3 workersI tried training a model using MPC, using 2 workers was successful. (A minor issue I noticed when using refresh() in computing loss, the loss values are good, otherwise it's computes big large values, which is not interpretable, any clue why this happens can be great to my research.)
Anyways but when using 3 or more workers, I'm facing errors.
First I got error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-902fb9b77716> in <module>
     12 x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
     13 m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
---> 14 o=m(x)

/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)
     90     @weak_script_method
     91     def forward(self, input):
---> 92         return F.linear(input, self.weight, self.bias)
     93 
     94     def extra_repr(self):

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    745                 handle_func_command = TorchTensor.handle_func_command
    746 
--> 747             response = handle_func_command(command)
    748 
    749             return response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    310             new_command = (cmd, None, new_args, new_kwargs)
    311             # Send it to the appropriate class and get the response
--> 312             response = new_type.handle_func_command(new_command)
    313             # Put back the wrappers where needed
    314             response = syft.frameworks.torch.hook_args.hook_response(

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in handle_func_command(cls, command)
    236             # Try to get recursively the attributes in cmd = ""<attr1>.<attr2>.<attr3>...""
    237             cmd = cls.rgetattr(cls, cmd)
--> 238             return cmd(*args, **kwargs)
    239         except AttributeError:
    240             pass

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in linear(*args)
    201                     Un-hook the function to have its detailed behaviour
    202                     """"""
--> 203                     return torch.nn.functional.native_linear(*args)
    204 
    205                 module.linear = linear

/usr/local/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)
   1406         ret = torch.addmm(bias, input, weight.t())
   1407     else:
-> 1408         output = input.matmul(weight.t())
   1409         if bias is not None:
   1410             output += bias

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in method_with_grad(*args, **kwargs)
    138                 )
    139 
--> 140                 result = getattr(new_self, name)(*new_args, **new_kwargs)
    141 
    142                 # Put back SyftTensor on the tensors found in the response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py in matmul(self, *args, **kwargs)
    414 
    415         # Send it to the appropriate class and get the response
--> 416         response = getattr(new_self, ""matmul"")(*new_args, **new_kwargs)
    417 
    418         # Put back SyftTensor on the tensors found in the response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in matmul(self, other)
    515             return self._public_mul(other, ""matmul"")
    516 
--> 517         return self._private_mul(other, ""matmul"")
    518 
    519     def mm(self, *args, **kwargs):

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in _private_mul(self, other, equation)
    413             raise AttributeError(""For multiplication a crypto_provider must be passed."")
    414 
--> 415         shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field)
    416 
    417         return shares

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/crypto/spdz.py in spdz_mul(cmd, x_sh, y_sh, crypto_provider, field)
     43         j = sy.MultiPointerTensor(children=[j1, j0])
     44     else:
---> 45         j = sy.MultiPointerTensor(children=[j1] + j0.child.values())
     46 
     47     delta_b = cmd(delta, b)

TypeError: can only concatenate list (not ""dict_values"") to list
```

I tried cloning the repo, fixing this issue by passing  `j0.child.values()` to list constructor. Then I faced another error:

```

Traceback (most recent call last):
   <ipython-input-7-902fb9b77716> in <module>
     o=m(x)
   File ""/Users/sandeep/syft/venv/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
     result = self.forward(*input, **kwargs)
   File ""a3.py"", line 31, in forward
     x=F.relu(self.fc1(x))
   File ""/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py"", line 413, in overloaded_func
     response = handle_func_command(command)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/native.py"", line 297, in handle_func_command
     response = new_type.handle_func_command(new_command)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 237, in handle_func_command
     return cmd(*args, **kwargs)
  File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 207, in relu
     return tensor.relu()
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py"", line 141, in method_with_grad
     result = getattr(new_self, name)(*new_args, **new_kwargs)
   File ""/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py"", line 306, in overloaded_syft_method
     response = getattr(new_self, attr)(*new_args, **new_kwargs)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py"", line 793, in relu
     return securenn.relu(self)
   File ""/Users/sandeep/syft/PySyft/syft/frameworks/torch/crypto/securenn.py"", line 427, in relu
     alice, bob = a_sh.locations
ValueError: too many values to unpack (expected 2)
```

**To Reproduce**
Run this to reproduce:
```
def connect_to_workers(n_workers):
    return [
        sy.VirtualWorker(hook, id=f""worker{i+1}"")
        for i in range(n_workers)
    ]
def connect_to_crypto_provider():
    return sy.VirtualWorker(hook, id=""crypto_provider"")

workers = connect_to_workers(n_workers=3)
sw = connect_to_crypto_provider()

x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
o=m(x)
```

**Desktop (please complete the following information):**
 - OS: MacOS
 - Version 10.14.6
I'm having the same issue. I know this is a bit old but have you found a solution for this? (Not necessarily using PySyft, but on any Federated Learning solution)",1,2019-09-27 10:45:27,2020-05-08 01:26:04,2020-05-08 01:26:04
https://github.com/OpenMined/PySyft/issues/2623,[],Microsoft Visual Studio 14.0 required error pops up while installing PySyft and VS 14.0 is already installed in system,"Microsoft Visual Studio 14.0 required error pops up while installing PySyft and VS 14.0 is already installed in system**Installation bug**
I was trying to install PySyft from the Anaconda Command Prompt and an error popped up saying ""Microsoft Visual Studio 14.0 required"". The latest version is already installed in my system


**To Reproduce**
Steps to reproduce the behavior:
1. Create an environment in conda
2. try ""pip install syft"" and error popped up


**Desktop (please complete the following information):**
 - OS: Windows 10
 - Version 1809
 - Python version: 3.7.4
can you show the full error prompt you got in terminal?",1,2019-09-23 05:19:46,2020-01-27 04:28:35,2020-01-27 04:28:35
https://github.com/OpenMined/PySyft/issues/2618,[],Why does Input to Model requires gradient when using Secure MPC.,"Why does Input to Model requires gradient when using Secure MPC.**Describe the bug**
When we share the model and data to different virtual workers, then obviously it's the Model whose requires_grad should be True and data's requires_grad should be False, but when I pass this data which doesn't requires gradient to the model, I get following error:
""RuntimeError: bool value of Tensor with more than one value is ambiguous""

While when set requires_grad True for Data as well, then it works perfectly fine.  But when doing this, I get model gradients as None after backward

**To Reproduce**

```
import torch as th
import torch.nn.functional as F
import syft as sy
import random
import numpy as np

hook = sy.TorchHook(th)

bob=sy.VirtualWorker(hook, id=""bob"")
alice=sy.VirtualWorker(hook, id=""alice"")
sw=sy.VirtualWorker(hook, id=""SecureWorker"")

bob.clear_objects()
alice.clear_objects()
sw.clear_objects()

bob.add_workers([alice, sw])
alice.add_workers([bob, sw])
sw.add_workers([alice, bob])

x = th.tensor([[0,0], [0,1], [1,0], [1,1]]).to(th.float)
y = th.tensor([0,0,1,1]).to(th.float)

model=th.nn.Linear(2,1)

#print(list(model.parameters()))
enc_model = model.fix_precision().share(alice, bob, crypto_provider=sw, requires_grad=True)
optimizer = th.optim.SGD(enc_model.parameters(), lr=0.1)
optimizer = optimizer.fix_precision()

enc_data = x.fix_precision().share(alice, bob, crypto_provider=sw)
enc_target = y.fix_precision().share(alice, bob, crypto_provider=sw)

max_epochs=1
for i in range(max_epochs):
    optimizer.zero_grad()
    enc_pred = enc_model(enc_data).squeeze(1)
    l = (((enc_pred - enc_target) ** 2)).sum().refresh()
    l.backward()
    optimizer.step()
    l = l.get().float_precision()
    print(l.item())

model = enc_model.get().float_precision()
for params in model.parameters():
    print(params.grad)
print(enc_pred.get().float_precision())
```


Just run above code to reproduce error. Add ```requires_grad=True``` to enc_data and enc_target, to reproduce other error.

Please fix this.
Thanks.Hey, thanks for your feedback.
> While when set requires_grad True for Data as well, then it works perfectly fine. But when doing this, I get model gradients as None after backward

This is a bug related to `.squeeze(1)`. Remove this and you will get the gradient. I opened an Issue #2621 

> When we share the model and data to different virtual workers, then obviously it's the Model whose requires_grad should be True and data's requires_grad should be False

You're 100% right. However, if you know about PySyft, you know it relies chain of tensors like `Parameter>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]...`. We currently hardly handle operating tensors with different chain structure, and in particular we don't support currently operating tensors with autograd and some who don't have them, that's why we asked `require_grad=True` for every tensor. But I'll report this as an issue and we'll try to have a better support. #2622 Okay. Thanks. I'll close this then.",2,2019-09-17 11:31:44,2019-09-27 10:11:57,2019-09-27 10:10:55
https://github.com/OpenMined/PySyft/issues/2615,[],method2plan is not supported anymore error in Introduction to plan part 08,"method2plan is not supported anymore error in Introduction to plan part 08in Introduction to plan part 08 there is method2plan but it is not supported anymore

**To Reproduce**
Steps to reproduce the behavior:
Run 14th code cell in the tutorial

I was working on google colabHey,
The tutorial has been updated, you should update your repo :)
https://github.com/OpenMined/PySyft/pull/2569/commits/36330ab3a7df7c874819b320071e3dc2a7252b4d",1,2019-09-13 14:45:07,2019-09-22 13:27:45,2019-09-22 13:27:45
https://github.com/OpenMined/PySyft/issues/2609,"['bug ', 'status: stale :bread:']",Grid search test breaks if we wrap the search results.,"Grid search test breaks if we wrap the search results.**Describe the bug**

Grid search test breaks if we wrap the search results.

https://github.com/OpenMined/PySyft/blob/dev/syft/workers/base.py#L890

Do we really need to wrap the search results?

I think I know what the problem is, when we wrap the pointer we register it on `._objects` but we're running a loop on the keys in _objects so then we get: â€œRuntimeError: dictionary changed size during iterationâ€
@LaRiffle This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2019-09-10 22:38:47,2020-05-24 00:08:53,2020-05-24 00:08:53
https://github.com/OpenMined/PySyft/issues/2607,[],TypeError: object of type 'NoneType' has no len(),"TypeError: object of type 'NoneType' has no len()**Describe the bug**
TypeError: object of type 'NoneType' has no len()

**My code**
```python
x_train = torch.tensor(train_x)
y_train = torch.tensor(train_y)

import syft as sy
# Hook that extends the Pytorch library to enable all computations with pointers of tensors sent to other workers
hook = sy.TorchHook(torch)

# Creating 2 virtual workers
bob = sy.VirtualWorker(hook, id=""bob"")
anne = sy.VirtualWorker(hook, id=""anne"")
#datasets=[]
# threshold indexes for dataset split (one half for Bob, other half for Anne)
train_idx = int(len(x_train)/2)


# Sending toy datasets to virtual workers
#data_bob = x_train[:train_idx].send(bob)
#data_anne = x_train[train_idx:].send(anne)
#target_bob = y_train[:train_idx].send(bob)
#target_anne = y_train[train_idx:].send(anne)

#bob_train_dataset = sy.BaseDataset(data_bob , target_bob).send(bob)
#anne_train_dataset = sy.BaseDataset(data_anne, target_anne).send(anne)

#datasets = [(data_bob,target_bob),(data_anne,target_anne)]
#federated_train_dataset = sy.FederatedDataset([(data_bob,target_bob), (data_anne, target_anne)])
#bob_train_dataset = sy.BaseDataset(data_bob, target_bob).send(bob)
#anne_train_dataset = sy.BaseDataset(data_anne, target_anne).send(anne)
# Creating federated datasets, an extension of Pytorch TensorDataset class
#federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])


# Creating federated dataloaders, an extension of Pytorch DataLoader class
#federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=64)


# Hook that extends the Pytorch library to enable all computations with pointers of tensors sent to other workers
#hook = sy.TorchHook(torch)

# Creating 2 virtual workers
#bob = sy.VirtualWorker(hook, id=""bob"")
#anne = sy.VirtualWorker(hook, id=""anne"")

# threshold indexes for dataset split (one half for Bob, other half for Anne)
#train_idx = int(len(train_labels)/2)

# Sending toy datasets to virtual workers
bob_train_dataset = sy.BaseDataset(x_train[:train_idx], y_train[:train_idx]).send(bob)
anne_train_dataset = sy.BaseDataset(x_train[train_idx:], y_train[train_idx:]).send(anne)

# Creating federated datasets, an extension of Pytorch TensorDataset class
federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])
# Creating federated dataloaders, an extension of Pytorch DataLoader class
federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=64)

class GRUNet(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):
        super(GRUNet, self).__init__()
        self.hidden_dim = hidden_dim
        self.n_layers = n_layers
        
        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
        
    def forward(self, x, h):
        out, h = self.gru(x, h)
        out = self.fc(self.relu(out[:,-1]))
        return out, h
    
    def init_hidden(self, batch_size):
        weight = next(self.parameters()).data
        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)
        return hidden

class LSTMNet(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):
        super(LSTMNet, self).__init__()
        self.hidden_dim = hidden_dim
        self.n_layers = n_layers
        
        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
        
    def forward(self, x, h):
        out, h = self.lstm(x, h)
        out = self.fc(self.relu(out[:,-1]))
        return out, h
    
    def init_hidden(self, batch_size):
        weight = next(self.parameters()).data
        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),
                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))
        return hidden

batch_size = 64
def train(federated_train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=""GRU""):
    
    # Setting common hyperparameters
    input_dim = next(iter(federated_train_loader))[0].shape[2]
    output_dim = 1
    n_layers = 2
    # Instantiating the models
    if model_type == ""GRU"":
        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)
    else:
        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)
    model.to(device)
    
    # Defining loss function and optimizer
    criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)
    
    model.train()
    print(""Starting Training of {} model"".format(model_type))
    epoch_times = []
    # Start training loop
    for epoch in range(1,EPOCHS+1):
        start_time = time.clock()
        h = model.init_hidden(batch_size)
        avg_loss = 0.
        counter = 0
        for x, label in federated_train_loader:
            worker = x.location
            #h = torch.Tensor(np.zeros((batch_size))).send(worker)
            model.send(worker)
            counter += 1
            if model_type == ""GRU"":
                h = h.data
            else:
                h = tuple([e.data for e in h])
            model.zero_grad()
           
            
            out, h = model(x.to(device).float(), h)
            loss = criterion(out, label.to(device).float())
            loss.backward()
            optimizer.step()
            avg_loss += loss.item()
            if counter%200 == 0:
                print(""Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}"".format(epoch, counter, len(train_loader), avg_loss/counter))
        current_time = time.clock()
        print(""Epoch {}/{} Done, Total Loss: {}"".format(epoch, EPOCHS, avg_loss/len(train_loader)))
        print(""Time Elapsed for Epoch: {} seconds"".format(str(current_time-start_time)))
        epoch_times.append(current_time-start_time)
    print(""Total Training Time: {} seconds"".format(str(sum(epoch_times))))
    return model
```
**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version : 16.04

**Additional context**
Starting Training of GRU model

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-37-6d641218ab70> in <module>()
      1 lr = 0.001
      2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

<ipython-input-36-ba6a40ede7c3> in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
     38 
     39 
---> 40             out, h = model(x.to(device).float(), h)
     41             loss = criterion(out, label.to(device).float())
     42             loss.backward()

Actually, I do not know what happen on my dataset?
Why my data is Nonetype?When using `model.to(device)` you are trying to move your data structure to a GPU, right? Well, as far as I know, this operation is not supported in PySyft yet. Keep the computation on the CPU for now.> When using `model.to(device)` you are trying to move your data structure to a GPU, right? Well, as far as I know, this operation is not supported in PySyft yet. Keep the computation on the CPU for now.

Thanks for your reply. I solved my previous problem because the version of PySyft was too old. Now there is a new bug.
RuntimeError                              Traceback (most recent call last)
<ipython-input-62-6d641218ab70> in <module>()
      1 lr = 0.001
      2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

<ipython-input-61-0ac6d91a093c> in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
     48             print(x.shape)
     49             print(label.shape)
---> 50             out, h = model(x, h)
     51             loss = criterion(out, label.float())
     52             loss.backward()

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-54-a172098b1c99> in forward(self, x, h)
     10 
     11     def forward(self, x, h):
---> 12         out, h = self.gru(x, h)
     13         out = self.fc(self.relu(out[:,-1]))
     14         return out, h

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
    205             hx = self.permute_hidden(hx, sorted_indices)
    206 
--> 207         self.check_forward_args(input, hx, batch_sizes)
    208         _impl = _rnn_impls[self.mode]
    209         if batch_sizes is None:

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
    173 
    174     def check_forward_args(self, input, hidden, batch_sizes):
--> 175         self.check_input(input, batch_sizes)
    176         expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
    177 

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
    151             raise RuntimeError(
    152                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--> 153                     self.input_size, input.size(-1)))
    154 
    155     @weak_script_method

RuntimeError: input.size(-1) must be equal to input_size. Expected 5, got 0Can you please show me how the `device` variable is defined?

Also, you may want to try your code without the `.to(device)` call in your code.> Can you please show me how the `device` variable is defined?
> 
> Also, you may want to try your code without the `.to(device)` call in your code.
```python
# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False
is_cuda = torch.cuda.is_available()

# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.
if is_cuda:
    device = torch.device(""cuda"")
else:
    device = torch.device(""cpu"")
```Yes, that's exactly what I meant. PySyft does not support CUDA GPUs yet, though we'd like to support this functionality in the future @robert-wagner 

What is the result of running your code when removing all statements `.to(device)` @niklausliu ?> Yes, that's exactly what I meant. PySyft does not support CUDA GPUs yet, though we'd like to support this functionality in the future @robert-wagner
> 
> What is the result of running your code when removing all statements `.to(device)` @niklausliu ?

Thanks for your reply. But I have a new bug about rnn.py, you can see more detail as follow:

RuntimeError Traceback (most recent call last)
in ()
1 lr = 0.001
2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
48 print(x.shape)
49 print(label.shape)
---> 50 out, h = model(x, h)
51 loss = criterion(out, label.float())
52 loss.backward()

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)
491 result = self._slow_forward(*input, **kwargs)
492 else:
--> 493 result = self.forward(*input, **kwargs)
494 for hook in self._forward_hooks.values():
495 hook_result = hook(self, input, result)

in forward(self, x, h)
10
11 def forward(self, x, h):
---> 12 out, h = self.gru(x, h)
13 out = self.fc(self.relu(out[:,-1]))
14 return out, h

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)
491 result = self._slow_forward(*input, **kwargs)
492 else:
--> 493 result = self.forward(*input, **kwargs)
494 for hook in self._forward_hooks.values():
495 hook_result = hook(self, input, result)

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
205 hx = self.permute_hidden(hx, sorted_indices)
206
--> 207 self.check_forward_args(input, hx, batch_sizes)
208 _impl = _rnn_impls[self.mode]
209 if batch_sizes is None:

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
173
174 def check_forward_args(self, input, hidden, batch_sizes):
--> 175 self.check_input(input, batch_sizes)
176 expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
177

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
151 raise RuntimeError(
152 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--> 153 self.input_size, input.size(-1)))
154
155 @weak_script_method

RuntimeError: input.size(-1) must be equal to input_size. Expected 5, got 0Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.

Alternatively, @andrelmfarias  could have some other ideas?

Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?> Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.
> 
> Alternatively, @andrelmfarias could have some other ideas?
> 
> Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?

But I found that I deleted all the statements about the device or the bug I described above.> > Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.
> > Alternatively, @andrelmfarias could have some other ideas?
> > Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?
> 
> But I found that I deleted all the statements about the device or the bug I described above.

Sorry, I mean, I deleted all the statements about the device, but it did not work and the bug still exists.Can you please print the output you get from your dataset before and after hooking torch?> Can you please print the output you get from your dataset before and after hooking torch?
![image](https://user-images.githubusercontent.com/31737021/64689120-4781a980-d4c0-11e9-95d4-6ea294a36e95.png)

![image](https://user-images.githubusercontent.com/31737021/64689149-5cf6d380-d4c0-11e9-94f4-75359fe1e289.png)

![image](https://user-images.githubusercontent.com/31737021/64689251-929bbc80-d4c0-11e9-9a5b-737aba54f4d9.png)

![image](https://user-images.githubusercontent.com/31737021/64689279-9cbdbb00-d4c0-11e9-9966-108178b67676.png)
> Can you please print the output you get from your dataset before and after hooking torch?

![image](https://user-images.githubusercontent.com/31737021/64689389-db537580-d4c0-11e9-8718-1e374d581df4.png)
@niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.

Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

But I have seen many examples of syft GRUs module and have not found any difference with my pytorch native GRUs. Can you give me a few examples of the syft GRUs module?
> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

And I can not find syft.framworks.torch.nn in this website https://pysyft.readthedocs.io/en/latest/modules/syft.core.frameworks.html They were recently added to pysyft, so they are not included in the main documentation yet.

You can take a look at the modules here:
https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/nn/rnn.py

But in fact, they work exactly as PyTorch API (same args, etc.) you just need to import them from `syft.frameworks.torch.nn` (eg: `from syft.frameworks.torch.nn import GRU, LSTM, RNN` ) and manage them the same way you would manage a pytorch GRU> They were recently added to pysyft, so they are not included in the main documentation yet.
> 
> You can take a look at the modules here:
> https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/nn/rnn.py
> 
> But in fact, they work exactly as PyTorch API (same args, etc.) you just need to import them from `syft.frameworks.torch.nn` (eg: `from syft.frameworks.torch.nn import GRU, LSTM, RNN` ) and manage them the same way you would manage a pytorch GRU

Thanks for your help. I will adjust my code again and I will tell you any updates. Thank you again for your help.> Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.

@niklausliu - **We're happy to help in the OpenMined community.**  But as a general rule, we're not tech support.  While you may have a problem running PySyft, and there may be a legitimate issue here, **everyone** who works on the OpenMined project works for free.  If we spent all of our time fixing people's implementations of PySyft, we'd never have time to write code for PySyft itself. 
 Either way, providing our personal email addresses so that you can ping us questions is not acceptable.

I'm going to close this issue for now as it seems that problem you're now having is totally unrelated to the original issue.  If that's not the case, please send me a message on Slack and I'll be happy to re-open the issue.> > Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.
> 
> @niklausliu - **We're happy to help in the OpenMined community.** But as a general rule, we're not tech support. While you may have a problem running PySyft, and there may be a legitimate issue here, **everyone** who works on the OpenMined project works for free. If we spent all of our time fixing people's implementations of PySyft, we'd never have time to write code for PySyft itself.
> Either way, providing our personal email addresses so that you can ping us questions is not acceptable.
> 
> I'm going to close this issue for now as it seems that problem you're now having is totally unrelated to the original issue. If that's not the case, please send me a message on Slack and I'll be happy to re-open the issue.

I am sorry for my impoliteness. However, I did not ask OpenMined workers to provide me with free technical support. It may be that there is a problem with my expression. I apologize again for this. I really appreciate the efforts of the OpenMined workers for the PySyft project, and I hope to contribute to the community as a whole.Not a problem @niklausliu!  We're happy to have people passionate about the project like yourself.  It seems this particular issue has gotten off-topic.  I'd suggest you post your questions in the #team_pysyft channel on Slack and give 1-2 days for someone to reply.  If not, submit a new issue here.> Not a problem @niklausliu! We're happy to have people passionate about the project like yourself. It seems this particular issue has gotten off-topic. I'd suggest you post your questions in the #team_pysyft channel on Slack and give 1-2 days for someone to reply. If not, submit a new issue here.

OK, I got it! Thank you for your help!!!",23,2019-09-10 14:37:18,2019-09-11 15:30:21,2019-09-11 14:53:48
https://github.com/OpenMined/PySyft/issues/2603,[],Bug with sending AST made by inplace fix_prec_ and share_,"Bug with sending AST made by inplace fix_prec_ and share_**Describe the bug**
Combining both trigger a weird error, which I don't really understand:

**FAILS**
```python
dan.clear_objects()
x = th.tensor([-1.0])
x_sh = x.fix_precision_().share_(alice, bob, crypto_provider=charlie)
p = x_sh.send_(dan)

assert p.id_at_location in dan._objects
```

**WORKS**
```python
dan.clear_objects()
x = th.tensor([-1.0])
x_sh = x.fix_precision_().share(alice, bob, crypto_provider=charlie)
p = x_sh.send_(dan)

assert p.id_at_location in dan._objects
```
```python
dan.clear_objects()
x = th.tensor([-1.0])
x_sh = x.fix_precision().share_(alice, bob, crypto_provider=charlie)
p = x_sh.send_(dan)

assert p.id_at_location in dan._objects
```
```python
dan.clear_objects()
x = th.tensor([-1.0])
x_sh = x.fix_precision().share(alice, bob, crypto_provider=charlie)
p = x_sh.send_(dan)

assert p.id_at_location in dan._objects
```

Is solved with the refactor plan to come",1,2019-09-09 16:52:20,2019-12-09 03:24:01,2019-12-09 03:24:01
https://github.com/OpenMined/PySyft/issues/2601,[],Copy Plan attributes instead of passing references,"Copy Plan attributes instead of passing references**Describe the bug**
Currently, copies of plans share the same attributes, so they can be modified in a shadow way (see example)
See:
https://github.com/OpenMined/PySyft/pull/2590#discussion_r321975723

**To Reproduce**
```python
class O():
    def __init__(self, o):
        self.a = o

c1 = O([1, 2, 3])

c2 = O(c1.a)

print(c1.a) # [1, 2, 3]
c2.a.append(4)
print(c2.a) # [1, 2, 3, 4]
print(c1.a) # [1, 2, 3, 4] OMG!!
```
Is solved with refactor plan to come",1,2019-09-08 10:01:31,2019-11-13 00:01:55,2019-11-13 00:01:55
https://github.com/OpenMined/PySyft/issues/2587,[],MNIST example using PySyft,"MNIST example using PySyft**Describe the bug**
I made a code snippet for MNIST example using PySyft based on the tutorial:
```python
from __future__ import print_function                                                                                                                                                                                                                                                                                                                                                                                                                                                          
import argparse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
from tqdm import tqdm                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
import torch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
import torch.nn as nn                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
import torch.nn.functional as F                                                                                                                                                                                                                                                                                                                                                                                                                                                                
import torch.optim as optim                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
from torchvision import datasets, transforms                                                                                                                                                                                                                                                                                                                                                                                                                                                   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
import syft as sy                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
from torch.multiprocessing import set_start_method                                                                                                                                                                                                                                                                                                                                                                                                                                             
try:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
     set_start_method('forkserver')                                                                                                                                                                                                                                                                                                                                                                                                                                                            
except RuntimeError:                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
    pass                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
class Net(nn.Module):                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
    def __init__(self):                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
        super(Net, self).__init__()                                                                                                                                                                                                                                                                                                                                                                                                                                                            
        self.conv1 = nn.Conv2d(1, 20, 5, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                    
        self.conv2 = nn.Conv2d(20, 50, 5, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                   
        self.fc1 = nn.Linear(4*4*50, 500)                                                                                                                                                                                                                                                                                                                                                                                                                                                      
        self.fc2 = nn.Linear(500, 10)                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
    def forward(self, x):                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
        x = F.relu(self.conv1(x))                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = F.max_pool2d(x, 2, 2)                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = F.relu(self.conv2(x))                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = F.max_pool2d(x, 2, 2)                                                                                                                                                                                                                                                                                                                                                                                                                                                              
        x = x.view(-1, 4*4*50)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
        x = F.relu(self.fc1(x))                                                                                                                                                                                                                                                                                                                                                                                                                                                                
        x = self.fc2(x)                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
        return F.log_softmax(x, dim=1)                                                                                                                                                                                                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
def train(args, model, device, train_loader, optimizer, epoch):                                                                                                                                                                                                                                                                                                                                                                                                                                
    model.train()                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
    with tqdm(enumerate(train_loader), total=len(train_loader), desc=""epoch {:02d}"".format(epoch)) as t:                                                                                                                                                                                                                                                                                                                                                                                       
        for batch_idx, (data, target) in t:                                                                                                                                                                                                                                                                                                                                                                                                                                                    
            model.send(data.location)                                                                                                                                                                                                                                                                                                                                                                                                                                                          
            data, target = data.to(device), target.to(device)                                                                                                                                                                                                                                                                                                                                                                                                                                  
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
            optimizer.zero_grad()                                                                                                                                                                                                                                                                                                                                                                                                                                                              
            output = model(data)                                                                                                                                                                                                                                                                                                                                                                                                                                                               
            loss = F.nll_loss(output, target)                                                                                                                                                                                                                                                                                                                                                                                                                                                  
            loss.backward()                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
            optimizer.step()                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
            model.get()                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
    #if batch_idx % args.log_interval == 0:                                                                                                                                                                                                                                                                                                                                                                                                                                                    
    loss = loss.get() # <-- NEW: get the loss back                                                                                                                                                                                                                                                                                                                                                                                                                                             
    print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(                                                                                                                                                                                                                                                                                                                                                                                                                            
        epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size,                                                                                                                                                                                                                                                                                                                                                                                                               
        100. * batch_idx / len(train_loader), loss.item()))                                                                                                                                                                                                                                                                                                                                                                                                                                    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
def test(args, model, device, test_loader):                                                                                                                                                                                                                                                                                                                                                                                                                                                    
    model.eval()                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
    test_loss = 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
    correct = 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
    with torch.no_grad():                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
        for data, target in test_loader:                                                                                                                                                                                                                                                                                                                                                                                                                                                       
            data, target = data.to(device), target.to(device)
            output = model(data)

            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss
            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))


def main():
    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch + PySyft MNIST Example')
    parser.add_argument('--batch-size', type=int, default=256, metavar='N',
                        help='input batch size for training (default: 256)')
    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=100, metavar='N',
                        help='number of epochs to train (default: 100)')
    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
                        help='learning rate (default: 0.01)')
    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
                        help='SGD momentum (default: 0.5)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disable CUDA training')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')
    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
    args = parser.parse_args()

    torch.manual_seed(args.seed)
    #torch.set_default_tensor_type(torch.cuda.FloatTensor)

    use_cuda = not args.no_cuda and torch.cuda.is_available()
    device = torch.device(""cuda"" if use_cuda else ""cpu"")

    hook = sy.TorchHook(torch)

    bob = sy.VirtualWorker(hook, id=""bob"")
    alice = sy.VirtualWorker(hook, id=""alice"")

    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

    federated_train_loader = sy.FederatedDataLoader(
        datasets.MNIST('../data', train=True, download=True,
            transform=transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])).federate((bob, alice)),
        batch_size=args.batch_size, shuffle=True, **kwargs)

    test_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=False, transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=args.test_batch_size, shuffle=False, **kwargs)

    model = Net().to(device)
    optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment

    for epoch in range(1, args.epochs + 1):
        train(args, model, device, federated_train_loader, optimizer, epoch)
        test(args, model, device, test_loader)

    if (args.save_model):
        torch.save(model.state_dict(), ""mnist_cnn.pt"")


if __name__ == '__main__':
    main()
```
When I got two problems:
1. without `torch.set_default_tensor_type(torch.cuda.FloatTensor)`, it produces a RuntimeError as:
```
Traceback (most recent call last):
  File ""main.py"", line 142, in <module>
    main()
  File ""main.py"", line 130, in main
    model = Net().to(device)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 386, in to
    return self._apply(convert)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 193, in _apply
    module._apply(fn)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 199, in _apply
    param.data = fn(param.data)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py"", line 393, in data
    self.set_(new_data)
RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 'source'
```
2. with the `set_default_tensor_type`, it shows another error as:
```
Traceback (most recent call last):
  File ""main.py"", line 142, in <module>
    main()
  File ""main.py"", line 135, in main
    test(args, model, device, test_loader)
  File ""main.py"", line 65, in test
    for data, target in test_loader:
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 193, in __iter__
    return _DataLoaderIter(self)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 469, in __init__
    w.start()
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py"", line 112, in start
    self._popen = self._Popen(self)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/context.py"", line 291, in _Popen
    return Popen(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/popen_forkserver.py"", line 35, in __init__
    super().__init__(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/popen_fork.py"", line 20, in __init__
    self._launch(process_obj)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/popen_forkserver.py"", line 47, in _launch
    reduction.dump(process_obj, buf)
  File ""/home/jinserk/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/reduction.py"", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed
```

**To Reproduce**
If you have `torch`, `torchvision`, and `pysyft`, just do
```
python main.py
```

**Expected behavior**
Obtain the proper operation without errors

**Screenshots**
None

**Desktop (please complete the following information):**
 - OS: Ubuntu
 - Version: 18.04
 - Python: 3.7.4

**Additional context**
Add any other context about the problem here.
Hey!
Thanks for thee feedback,
So only CPU is supported currently :/ this explains PB 1
Regarding the 2nd one, which version of PyTorch are you using? I think `multiprocessing` is responsible for the failure, and should be deactivated is this makes senseThanks @LaRiffle ! 
I used PyTorch 1.1.0. but 1.2.0 also shows the same. so could you let me know more clearly how to deactivate the `multiprocessing`?
and what time line you will add GPU support? MNIST is very simple task so it's okay to use CPU, but typically GPU is very critical and inevitable to train a big model and big data.
Try on the latest code of the dev branch. I just tested your code there and it works.",3,2019-09-04 14:46:27,2019-11-18 10:14:40,2019-11-18 10:14:40
https://github.com/OpenMined/PySyft/issues/2576,[],syft.frameworks.torch.tensors.interpreters.native.Tensor.shape BUG,"syft.frameworks.torch.tensors.interpreters.native.Tensor.shape BUG**Describe the bug**
When attempting to call .shape on a Syft tensor contained in a BaseDataset, it always return torch.Size([0]).

**To Reproduce**
```
t = torch.tensor([1.,2.,3.])
t.shape                         # torch.Size([3])
bds = sy.BaseDataset(t, t)
bds.send(bob)
bds.data.shape                  # expected torch.Size([3]), but got torch.Size([0])
```

**Desktop (please complete the following information):**
 - OS: win10
 - Version: Pytorch 1.1.0, PySyft 0.1.24a1

That's strange, I have torch.Size([3])
Maybe update the syft package and rerun this snippetSolved after bumping up to 0.1.26a1. :)",2,2019-08-29 10:17:15,2019-09-07 17:53:54,2019-09-07 17:53:54
https://github.com/OpenMined/PySyft/issues/2574,[],"Could not find a version that satisfies the requirement torch>=1.0.1 (from syft) (from versions: 0.1.2, 0.1.2.p","Could not find a version that satisfies the requirement torch>=1.0.1 (from syft) (from versions: 0.1.2, 0.1.2.p**Describe the bug**
A clear and concise description of whI am using a windows machine, with anaconda navigator I installed as per the instructions given in the readme.md

created an enviornment named pysyft and activated it
initialized pip install syft
The error mentioned above is displayed
I am Udacity Student for Secure and Private AI


![syfterror](https://user-images.githubusercontent.com/44531236/63923638-c7c6fa00-ca3e-11e9-93f1-49671b3dc71f.png)

The issue seems to me that torch 1.2 (latest) isn't compatible with syft ?, & You can't get torch 1.1 for windows.

Current Versions:
Windows 10
Base Env: torch                  1.2.0+cpu
torchvision                        0.4.0+cpu

Second Env:
torch        1.0.1

Both giving the same dependency error from syft torch 1.1.

Even if I follow https://pytorch.org/get-started/locally/ and install particular versions of torch on windows I still get the same error. 

ie conda install pytorch-cpu torchvision-cpu -c pytorch or 
# Python 3.7
pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl
pip3 install torchvision

Any ideas welcome. 
Does pysyft work with windows and if so how do I rectify the torch 1.1 error ?I meet the same error, I think â€œtorch==1.1â€ in requirements.txt case this bug, however there is no version 1.1, it mast be 1.1.0  for the mark ""=="". I change the  requirements.txt and install it. it's running well.Closing this as we now support torch>=1.3Thanks, much appreciated.Hi 
I am struggling with torch, cuda and syft!

for using cuda I need torch> 1.11, but syft is noy=t compatible with that!

pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113
Requirement already satisfied: torch in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (1.10.0)
Requirement already satisfied: torchvision in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (0.12.0+cu113)
Requirement already satisfied: torchaudio in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (0.11.0+cu113)
Requirement already satisfied: typing-extensions in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torch) (4.0.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torchvision) (9.0.1)
Requirement already satisfied: numpy in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torchvision) (1.21.4)
Collecting torch
  Using cached https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp38-cp38-win_amd64.whl (2186.1 MB)
Requirement already satisfied: requests in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torchvision) (2.26.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (3.3)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (1.26.9)
Requirement already satisfied: charset-normalizer~=2.0.0 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (2.0.12)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (2021.10.8)
Installing collected packages: torch
  Attempting uninstall: torch
    Found existing installation: torch 1.10.0
    Uninstalling torch-1.10.0:
      Successfully uninstalled torch-1.10.0
_ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
syft 0.6.0 requires torch<=1.10.0,>=1.8.1, but you have torch 1.11.0+cu113 which is incompatible._
Successfully installed torch-1.11.0+cu113",4,2019-08-29 08:31:29,2022-05-10 03:18:23,2019-11-15 09:08:42
https://github.com/OpenMined/PySyft/issues/2562,"['bug ', 'help wanted :wave:', 'status: stale :bread:']",resnet50 not supported when torch 1.0.1 / 1.1 is hooked,"resnet50 not supported when torch 1.0.1 / 1.1 is hooked ```
import torch
import syft
hook = syft.TorchHook(torch)
import torchvision.models as models

def make_model(num_out_classes: int):
    """"""Load a resnet50 and add a new head to it.""""""
    model = models.resnet50(pretrained=True) 
    num_ftrs = model.fc.in_features
    model.fc = torch.nn.Linear(num_ftrs, num_out_classes)
    return model

model = make_model(7)
model(torch.zeros(torch.Size([1, 3, 224, 224])))
```

Error:

```
...
~/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    745                 handle_func_command = TorchTensor.handle_func_command
    746 
--> 747             response = handle_func_command(command)
    748 
    749             return response

~/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    336             # in the execute_command function
    337             if isinstance(args, tuple):
--> 338                 response = eval(cmd)(*args, **kwargs)
    339             else:
    340                 response = eval(cmd)(args, **kwargs)

~/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in <module>

AttributeError: module 'torch._C._nn' has no attribute 'native_avg_pool2d'
```
---
torch version 1.0.1 and 1.1
syft dev versionWeird... I don't think there is a `native_avg_pool2d` in Pytorch, only `avg_pool2d`. Did you try to load the model without hooking torch?

Maybe the hook changes the name of the method...> Did you try to load the model without hooking torch?

Yes, it works just fine.@mari-linhares  For some reason, the command created by the native.py file for the avg_pool2d layer looks like this:

syft.local_worker.hook.torch._C._nn.native_avg_pool2d

While the max_pool2d looks like this:

syft.local_worker.hook.torch.nn.functional.native_max_pool2d

I am still trying to understand why this particular layer is being called from torch._C and not torch.nn, but for practical testing purposes, I just created an if to change avg_pool2d's command to conform to that of max_pool2d, and it worked normally. I was able to load networks like ResNet and MobileNet.

To fix it, simply open the native.py file and change the construction of the cmd variable to the following:

```
            if (cmd.split (""."")[- 1] == 'avg_pool2d'):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â cmd = 'syft.local_worker.hook.torch.nn.functional.native_avg_pool2d'
Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â cmd = (
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ""syft.local_worker.hook.""
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â + ""."". join (cmd.split (""."") [: - 1])
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â + "".native_""
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â + cmd.split (""."") [- 1]
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â )
```
[EDIT]
A more automatic way to correct this problem is to replace calls from _C_nn to nn.functional. I will propose this solution through a pull request.

```
            # Change library path to avoid problems with AvgPooling layer
            cmd = cmd.replace('_C._nn', 'nn.functional')

            cmd = (
                ""syft.local_worker.hook.""
                + ""."".join(cmd.split(""."")[:-1])
                + "".native_""
                + cmd.split(""."")[-1]
            )
```

Then just run python setup.py install again to overwrite the library with your change. I will try to propose a solution that is not unique to avg_pool, but for now this will work.To me this looks like we are hooking _C._nn after we are hooking torch.nn.functional. In my opinion we should not be hooking _C._nn at all which might solve this problem@mari-linhares should we close this issue since currently we are on torch 1.4?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",6,2019-08-27 12:58:25,2020-05-24 00:09:15,2020-05-24 00:09:15
https://github.com/OpenMined/PySyft/issues/2559,['bug '],relu and relu_deriv require serializable workers,"relu and relu_deriv require serializable workers**This is a blocker for having [EMLaaS implemented](https://github.com/OpenMined/Grid/issues/203)**.

Relu and relu_derive require serializable workers. Apparently these operations require serializable workers in order to execute `.share` with pointer tensors. GridWorkers are currently not serializable.@iamtrask and @LaRiffle pointed out that serializing workers is not actually a problem since this consists basically of sending the worker id over the wire.

But the problem is that currently only VirtualWorkers are serializable which means that GridWorkers or WebsocketWorkers will not be able to run these operations.",1,2019-08-26 14:35:20,2019-08-29 07:58:54,2019-08-29 07:58:54
https://github.com/OpenMined/PySyft/issues/2556,['bug '],Argmax on encrypted  data fails,"Argmax on encrypted  data failsThe argmax-call on an encrypted tensor throws an exception. Minimal code example for reproduction:
```
import torch
import syft as sy
hook = sy.TorchHook(torch)

alice = sy.VirtualWorker(hook, 'alice')
bob = sy.VirtualWorker(hook, 'bob')

a = torch.arange(6)
enc_a = a.share(alice, bob)
print(enc_a.argmax())
```
Executing this script results in a `KeyError: 'Object ""44504679185"" not found on worker!!!You just tried to interact with an object ID:44504679185 on <VirtualWorker id:alice #objects:36> which does not exist!!!`

My python environment (Ubuntu 18.04):
torch 1.1.0
syft 0.1.24a1This should work :)
Add a crypto_provider and call fix_precision() 

```python
import torch
import syft as sy
hook = sy.TorchHook(torch)

alice = sy.VirtualWorker(hook, 'alice')
bob = sy.VirtualWorker(hook, 'bob')
crypto_provider = sy.VirtualWorker(hook, 'crypto_provider')

a = torch.arange(6).fix_precision()
enc_a = a.share(alice, bob, crypto_provider=crypto_provider)
print(enc_a.argmax())
```Thank you! I checked that both modifications are necessary to fix the problem.I assumed that I did not need fix precision encoding on an integer tensor. The need for an explicit crypto provider wasn't clear to me either. Could you explain on both?So actually you should have to do it, even if it doesn't raise an error: even if you work with integers, fix precision elements are in a field while integers are not, so it is a  best practice. And actually for some reason it doesn't work if you don't do it (argmax does smthg strange)
Same for crypto provider, it should be possible to not explicitoit,  but it doesn't work for some reason :/",4,2019-08-26 07:41:36,2019-09-03 17:07:02,2019-09-03 15:24:56
https://github.com/OpenMined/PySyft/issues/2554,"['bug ', 'status: stale :bread:', 'status: investigating :mag:']",.federate() does not work with torchvision's ImageFolder dataset,".federate() does not work with torchvision's ImageFolder dataset**Describe the bug**
When you try to federate a `torchvision.datasets.ImageFolder`, you get the custom exception AttributeError(""Could not find inputs in dataset"")

**To Reproduce**
Steps to reproduce the behavior:

1) Have the following file structure locally:
```
+-- dataset
|   +-- class1
|   |   +-- whatever1.jpg
|   |   +-- whatever2.jpg
```
Those jpgs can be any image of at least 256x256 size.

2) Run: 
```
import torch
from torchvision import datasets, transforms
import syft as sy  

hook = sy.TorchHook(torch)  
bob = sy.VirtualWorker(hook, id=""bob"")  
alice = sy.VirtualWorker(hook, id=""alice"")

imagefolder_dataset = datasets.ImageFolder(root='./dataset/', transform = transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor()
    ]))


fed_dataset = imagefolder_dataset.federate((bob, alice)) # Raises exception
```

**Expected behavior**
`fed_dataset` should be created without raising any exception

**Actual behavior**
An exception ""Could not find inputs in dataset"" is raised:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-21c009d642db> in <module>
      7 
----> 8 fed_dataset = imagefolder_dataset.federate((bob, alice))
      9 

c:\...\syft\frameworks\torch\federated\dataset.py in dataset_federate(dataset, workers)
    148             dataset.data = dataset.test_data
    149         else:
--> 150             raise AttributeError(""Could not find inputs in dataset"")
    151     if not hasattr(dataset, ""targets""):
    152         if hasattr(dataset, ""train_labels""):

AttributeError: Could not find inputs in dataset
```

**Desktop (please complete the following information):**
 - OS: Windows 10

**Additional context**
 - torchvision: 0.3.0
 - pytorch: 1.1.0
 - pysyft: 0.1.22a1

**Workaround**
Before calling `.federate()` you can create the following dummy fields to prevent the exception:
`imagefolder_dataset.data = imagefolder_dataset.targets = True`  
Created PR to fix this: https://github.com/OpenMined/PySyft/pull/2555

There is harmful defensive code (that I removed) on `dataset_federate` function. It was checking for the data/train_data/test_data/targets/train_labels/test_labels fields in the dataset in a mandatory way. Which is not needed, and it's causing an exception that shouldn't exist.
What matters is that on each iteration of the dataset, it has to return a tuple in the form (data, target), which ImageFolder complies.
With the fix, `ImageFolder` and other datasets with the same problem now can be federated with `.federate()`

@iamtrask can you please review?@edgarinvillegas are you still working on the PR?Hi,
Is this issue sorted because I'm facing the same on the PyPi version
ThanksHello,
I have a class that inherits the Dataset class, but I can't apply the .federate() method on an instance of this class. Can someone explain why?
Thank you.

class UCI_HAR(Dataset):
    def __init__(self, samples, labels):
        self.samples = samples
        self.labels = labels
        
    def __getitem__(self, index):
        sample, target = self.samples[index], self.labels[index]
        return sample, target

    def __len__(self):
        return len(self.samples)

 Hello @ChedidJM , thank you for reporting this bug,

Could you please provide:
1. full script to reproduce the bug.
2. stack tracke/logging if you have any.
3. OS and syft version.

Thank you!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",6,2019-08-26 00:05:38,2020-07-06 00:08:36,2020-07-06 00:08:36
https://github.com/OpenMined/PySyft/issues/2546,[],Call fix_precision() on a remote model,"Call fix_precision() on a remote model**Describe the bug**
Call fix_precision() on a remote model fails due to a weird gradient initialization procedure for model parameters (see stacktrace)

**To Reproduce**
```
model = nn.Linear(2, 1)
model.fix_precision()
model.send(charlie)
model.share(alice, charlie, crypto_provider=crypto_provider, requires_grad=True)
model.get()

assert isinstance(model.weight.child, sy.AutogradTensor)
```

**Stack trace context**
```python
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-12-9b6b1f2f50de> in <module>
     25 model = nn.Linear(2, 1)
     26 model.fix_precision()
---> 27 model.send(charlie)
     28 model.share(alice, charlie, crypto_provider=crypto_provider, requires_grad=True)
     29 model.get()

~/code/PySyft/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, force_send, *dest, **kwargs)
    996 
    997             if module_is_missing_grad(nn_self):
--> 998                 create_grad_objects(nn_self)
    999 
   1000             for p in nn_self.parameters():

~/code/PySyft/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    989             for p in model.parameters():
    990                 o = p.sum()
--> 991                 o.backward()
    992                 p.grad -= p.grad
    993 

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    691                 # Send the new command to the appropriate class and get the response
    692                 method = getattr(new_self, method_name)
--> 693                 response = method(*new_args, **new_kwargs)
    694 
    695                 # For inplace methods, just directly return self

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_syft_method(self, *args, **kwargs)
    638 
    639             # Send it to the appropriate class and get the response
--> 640             response = getattr(new_self, attr)(*new_args, **new_kwargs)
    641 
    642             # Put back SyftTensor on the tensors found in the response

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    677                 except BaseException as e:
    678                     # we can make some errors more descriptive with this method
--> 679                     raise route_method_exception(e, self, args, kwargs)
    680 
    681             else:  # means that there is a wrapper to remove

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    674 
    675                 try:
--> 676                     response = method(*args, **kwargs)
    677                 except BaseException as e:
    678                     # we can make some errors more descriptive with this method

~/code/env/pysyft/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    105                 products. Defaults to ``False``.
    106         """"""
--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    108 
    109     def register_hook(self, hook):

~/code/env/pysyft/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---> 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```
Solved by #2590",1,2019-08-22 17:53:29,2019-09-10 08:18:53,2019-09-10 08:18:53
https://github.com/OpenMined/PySyft/issues/2527,"['bug ', 'good first issue :mortar_board:']",Calling .size() on a PointerTensor always returns a size of 0,"Calling .size() on a PointerTensor always returns a size of 0**Describe the bug**
Not sure if this was reported before. Couldn't find any issue about it. It seems like `.size()` method is not implemented for PointerTensors, making the Wrapper return `torch.Size([0])`

**To Reproduce**
Here's a script demonstrating the issue
```python
import torch
import syft

hook = syft.TorchHook(torch)

alice = syft.VirtualWorker(id=""alice"", hook=hook)

x = torch.Tensor([[1,2,3]])
print(x.size()) #=> torch.Size([1, 3]) 

# send x to alice and call size
x = x.send(alice)
print(x.size()) #=> torch.Size([0])
```

**Expected behavior**
`.size()` should return the size of the tensor being pointed at.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave
 - Version 0.1.23a1
Hey,
I would recommend using .shape instead of .size()
We have trouble with .size(), as explained here: https://github.com/OpenMined/PySyft/issues/2201@LaRiffle not sure why I couldn't find that issue at the time of posting this. Since this is a duplicate, I'll close this issue.",2,2019-08-18 17:32:02,2019-08-23 14:59:25,2019-08-23 14:59:25
https://github.com/OpenMined/PySyft/issues/2503,['bug '],URGENT: bug in encrypted autograd,"URGENT: bug in encrypted autograd**Describe the bug**
For some reason, calling loss.backward() on a pointer using normal autograd then breaks our ability to call loss.backward() on an encrypted loss variable even on two totally separate examples.

**To Reproduce**
```
import torch
import torch as th
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import syft as sy

# Set everything up
hook = sy.TorchHook(torch) 

big_hospital = sy.VirtualWorker(hook, id=""big_hospital2"")
small_hospital = sy.VirtualWorker(hook, id=""small_hospital2"")
crypto_provider = sy.VirtualWorker(hook, id=""crypto_provider2"")

# A Toy Model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 2)
        self.fc2 = nn.Linear(2, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x
    
def federated():
    # A Toy Dataset
    data = th.tensor([[0,0],[0,1],[1,0],[1,1.]])
    target = th.tensor([[0],[0],[1],[1.]])

    model = Net()

    # Training Logic
    opt = optim.SGD(params=model.parameters(),lr=0.1)

    data = data.send(big_hospital)
    target = target.send(big_hospital)

    # NEW) send model to correct worker
    model.send(data.location)

    # 1) erase previous gradients (if they exist)
    opt.zero_grad()

    # 2) make a prediction
    pred = model(data)

    # 3) calculate how much we missed
    loss = ((pred - target)**2).sum()

    # 4) figure out which weights caused us to miss
    loss.backward()
    
    print(""Done!"")
    
def encrypted():
    # A Toy Dataset
    data2 = th.tensor([[0,0],[0,1],[1,0],[1,1.]])
    target2 = th.tensor([[0],[0],[1],[1.]])

    model2 = Net()

    # We encode everything
    data2 = data2.fix_precision().share(big_hospital, small_hospital, crypto_provider=crypto_provider, requires_grad=True)
    target2 = target2.fix_precision().share(big_hospital, small_hospital, crypto_provider=crypto_provider, requires_grad=True)
    model2 = model2.fix_precision().share(big_hospital, small_hospital, crypto_provider=crypto_provider, requires_grad=True)

    opt2 = optim.SGD(params=model2.parameters(),lr=0.1).fix_precision()


    # 1) erase previous gradients (if they exist)
    opt2.zero_grad()

    # 2) make a prediction
    pred2 = model2(data2)

    # 3) calculate how much we missed
    loss2 = ((pred2 - target2)**2).sum()

    # 4) figure out which weights caused us to miss
    loss2.backward()

#     # 5) change those weights
#     opt2.step()

#     # 6) print our progress
#     print(loss2.get().float_precision())
        
    print(""Done"")
    
run_broken = True

# make sure to re-start your jupyter notebook / environment with each test.
if(run_broken):
    # Breaks
    federated()
    encrypted() # breaks here - something about loss2.backward() causes the federated() demo to break 
else:
    # Works fine
    encrypted()
    federated()
```

Throws error:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-db6dbbeffaa2> in <module>()
    100     # Breaks
    101     federated()
--> 102     encrypted() # breaks here - something about loss2.backward() causes the federated() demo to break
    103 else:
    104     # Works fine

<ipython-input-1-db6dbbeffaa2> in encrypted()
     84 
     85     # 4) figure out which weights caused us to miss
---> 86     loss2.backward()
     87 
     88 #     # 5) change those weights

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    683                 # Put back the wrappers where needed
    684                 response = syft.frameworks.torch.hook_args.hook_response(
--> 685                     method_name, response, wrap_type=type(self), new_self=self
    686                 )
    687 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in hook_response(attr, response, wrap_type, wrap_args, new_self)
    243         response_hook_function = hook_method_response_functions[attr_id]
    244         # Try running it
--> 245         new_response = response_hook_function(response)
    246 
    247     except (IndexError, KeyError, AssertionError):  # Update the function in cas of an error

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    502         f = many_fold
    503 
--> 504     return lambda x: f(lambdas, x)
    505 
    506 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    520 
    521 def two_fold(lambdas, args, **kwargs):
--> 522     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    523 
    524 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    480         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    481         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 482         else lambda i: backward_func[wrap_type](i, **wrap_args)
    483         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    484     ]

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.22a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     73 backward_func = {
     74     TorchTensor: lambda i: i.wrap(),
---> 75     torch.Tensor: lambda i: i.wrap(),
     76     torch.nn.Parameter: lambda i: torch.nn.Parameter(data=i),
     77     PointerTensor: lambda i: i,

AttributeError: 'NoneType' object has no attribute 'wrap'
```

**Additional context**
latest version of PySyft from PyPI ('0.1.22a1')
Is this the error you get? 
```
File ""PySyft/syft/frameworks/torch/hook/hook_args.py"", line 75, in <lambda>
    torch.Tensor: lambda i: i.wrap()
AttributeError: 'NoneType' object has no attribute 'wrap'
```YupI will try what happens if you force the function to not be taken from the dictionary in the hook. There might be a conflict there.You rock. Thank you @midokura-silvia ```
    # Try this
    federated()
    
    sy.frameworks.torch.hook.hook_args.hook_method_args_functions = {}
    sy.frameworks.torch.hook.hook_args.hook_method_response_functions = {}
    sy.frameworks.torch.hook.hook_args.get_tensor_type_functions = {}

    encrypted() # runs through
```",5,2019-08-14 12:55:13,2019-09-10 16:03:00,2019-09-10 16:03:00
https://github.com/OpenMined/PySyft/issues/2498,['bug '],Error in Federated Learning when Batch Normalization layer is used,"Error in Federated Learning when Batch Normalization layer is usedHi, I am trying to replicate the tutorial (Part 06 - Federated Learning on MNIST using a CNN.ipynb)  with CIFAR10 dataset and with a network model I defined myself. However, it gives an error like this when it tries to execute nn.BatchNorm2d() function:

> RuntimeError: running_mean should contain 3 elements not [32]

If I don't use batch normalization layers in my model, it works fine. If I use batch normalization layer without any federated learning approach, it also works perfectly. I need to use batch normalization layer to get a good accuracy and also I need to work this example with ResNet (also having batch normalization layer), so I am not sure how to work around this.

I am using google colab netbook with the installation example you gave (and also tested with my own computer with Python3.6 and PyTorch 1.1.0)

The example code and the related error is below:
```

from __future__ import print_function
import argparse
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
torch.__version__

from torchvision import datasets, transforms
from torch.autograd import Variable


import syft as sy  # <-- NEW: import the Pysyft library
hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob
alice = sy.VirtualWorker(hook, id=""alice"")  # <-- NEW: and alice


class Arguments():
    def __init__(self):
        self.batch_size = 64
        self.test_batch_size = 1000
        self.epochs = 10
        self.lr = 0.01
        self.momentum = 0.5
        self.no_cuda = False
        self.seed = 1
        self.log_interval = 30
        self.save_model = False

args = Arguments()

use_cuda = not args.no_cuda and torch.cuda.is_available()

torch.manual_seed(args.seed)

device = torch.device(""cuda"" if use_cuda else ""cpu"")

kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.CIFAR10('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.5,), (0.5,), (0.5,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.5,), (0.5,), (0.5,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

class Net(nn.Module):
    def __init__(self, dropout=0.0):
        super(Net, self).__init__()

        self.dropout = dropout
        self.conv_layer = nn.Sequential(

            # Conv Layer block 1
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            # Conv Layer block 2
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout2d(p=0.05),  # 0.05

            # Conv Layer block 3
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),  # 0.1
            nn.Linear(4096, 1024),
            nn.ReLU(inplace=True),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),  # 0.1
            nn.Linear(512, 10)
        )

    def forward(self, x):
        x = self.conv_layer(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)

        return x

def train(args, model, device, federated_train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
        model.send(data.location) # <-- NEW: send the model to the right location
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.cross_entropy(output, target)
        loss.backward()
        optimizer.step()
        model.get() # <-- NEW: get the model back
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # <-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
                100. * batch_idx / len(federated_train_loader), loss.item()))

def test(args, model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss
            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability 
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))


model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment

for epoch in range(1, args.epochs + 1):
    train(args, model, device, federated_train_loader, optimizer, epoch)
    test(args, model, device, test_loader)

if (args.save_model):
    torch.save(model.state_dict(), ""CIFAR10_cnn.pt"")


```
The complete output (from google colab):
 
```

WARNING: Logging before flag parsing goes to stderr.
W0813 08:46:34.190028 140520788572032 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'
W0813 08:46:34.211576 140520788572032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

0it [00:00, ?it/s]

Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz

170500096it [00:04, 40609204.86it/s]                               

---------------------------------------------------------------------------

PureTorchTensorFoundError                 Traceback (most recent call last)

/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    300             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.unwrap_args_from_function(
--> 301                 cmd, args, kwargs, return_args_type=True
    302             )

16 frames

PureTorchTensorFoundError: 


During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)

/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)
   1695     return torch.batch_norm(
   1696         input, weight, bias, running_mean, running_var,
-> 1697         training, momentum, eps, torch.backends.cudnn.enabled
   1698     )
   1699 

RuntimeError: running_mean should contain 3 elements not 32 
```


One possible workaround for this problem is to divide the net and use batch norm in client side. However, I do not want to rewrite big ResNet architectures and make the code more complex.

I hope you can help me with this issue. 

+1 

+1+1+1+10086+1+1
Is this bug solve? I have the same problem
even use the pytorch resnet (model= torchvision.models.resnet34(pretrained=False).to(device))can't train 
So the answer here is that BatchNormalization has internal statistics (means and stds, etc.) which themselves contain private information but are not parameters. 

This means that when you move a model from one machine to another (iterating through model.parameters()), those statistics probably aren't moving with it. 

Solution: extend nn.Module() with a .parameters_and_statistics() iterator which will look for this kind of information so that we can make sure that federated learning properly moves everything from machien to machine.I tried re creating this issue but it did not occur, So I dug a bit into the BatchNorm.

[here](https://github.com/pytorch/pytorch/blob/a6672f3b305c3805c691f3477e7940d146130a88/torch/nn/modules/batchnorm.py#L11) I could see these running statistics are being able to be registered as parameters or states. 
which extends to these lines if it is just a buffer
[def register_buffer(self, name, tensor):](https://github.com/pytorch/pytorch/blob/a6672f3b305c3805c691f3477e7940d146130a88/torch/nn/modules/module.py#L100)

But I suspect either way these are now taken care by syft in moving. 

So should we still look into this issue https://github.com/OpenMined/PySyft/issues/3236



@ratmcu 
I use the code  above , and still this issue happen , can you please tell what your code is ?
Because in my code and the code above both get this problem , and when i change the net  without batchnorm2d , the error is gone . So I think this issue is still here , or someone can try it?@johnnylin110 what is the pytorch version you are using? Can you check your source to see if it is the same as I mentioned? [colab](https://colab.research.google.com/drive/1rJzcKscyZleiLxMH_mj7UIrGY1DgkXlI)  notebook here has the code, It runs on pytorch `'1.4.0'` @ratmcu I think my syft version is the old one , and I udpate it to the new version which use pytorch1.4.0 . This issue is solve .  Thanks for helping !@bussfromspace @karlhigley This issue seems to be solved. Can you close it ?@ratmcu Hi again, I am looking at the code you paste, the different between is you modify the forward part into 
```
if x.location != None:
            print(x.location)
            loc = x.location
            x = x.get()
            print(x.sixe(0))
            x = x.view(x.size(0), -1)
            x = x.send(loc)
        else:
            x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
```
however , this network i try it on pysyft get 10% accuracy only , but in Pytorch version, this can achieve high accuracy , and if use the same code from above(without the part you modifiy) , the pysyft will pop out error message about ""shape [0,-1]  is invalid for input of size XXXX pytorch""
Is this still a bug here? @johnnylin110 this is a separate bug due to not being able to call .size() method remotely, batchnorm layer running remotely was the goal. so it was running in this example. @ratmcu  I know there is a bug so need to call .size() method here, but still, why the accuracy of the same approach(same network) will lead different ?
    In my Pytorch CIFAR with the net above is 65% at final , but in pysyft version it only 10% at the end(even when worker set to 1) . Why will this happen? 

Thanks for reply ! very appreciate!",17,2019-08-13 08:52:28,2020-03-31 09:12:51,2020-03-25 14:08:01
https://github.com/OpenMined/PySyft/issues/2494,[],"spdz_mul() - TypeError: can only concatenate list (not ""dict_values"") to list","spdz_mul() - TypeError: can only concatenate list (not ""dict_values"") to listError in `spdz_mul()` [Line 44](https://github.com/OpenMined/PySyft/blob/2e5af85043a29d5122243761e2e2d7cf2a5cb952/syft/frameworks/torch/crypto/spdz.py#L44) when concatenating list with dictionary values:

When the number of workers is greater than 2 I get the error:
`TypeError: can only concatenate list (not ""dict_values"") to list `

![image](https://user-images.githubusercontent.com/8993371/62837450-4ee53700-bc24-11e9-9b1d-a04fad18c5c8.png)

To me it seems like [line 44](https://github.com/OpenMined/PySyft/blob/2e5af85043a29d5122243761e2e2d7cf2a5cb952/syft/frameworks/torch/crypto/spdz.py#L44) should be:

`j = sy.MultiPointerTensor(children=[j1] + list(j0.child.values()))`


I haven't been working with PySyft for very long so please let me know if I am missing something!
Can anyone fix this to the original PySyft Repo? I'm also facing same issue, when workers are greater than 2.I started looking into this, but it looks like most or all the functions in securenn.py only allow for two workers (alice, bob to be specific). Since I am relatively new to PySyft it's starting to look a little more intense than just changing the syntax to what I suggested earlier.Apparently it has been fixed :)I am still seeing the same issue. I even tried making changes according to commit in the thread, still seeing the same error.

![image](https://user-images.githubusercontent.com/8968772/71577789-8e50e900-2b1b-11ea-993e-5d022fed38a8.png)",4,2019-08-11 17:48:21,2019-12-30 10:16:39,2019-12-09 03:28:28
https://github.com/OpenMined/PySyft/issues/2490,[],fix_precision() on sent model raises AttributeError exception,"fix_precision() on sent model raises AttributeError exception**Describe the bug**
Trying to run `fix_precision()` on sent models raises exception `AttributeError: 'numpy.ndarray' object has no attribute 'wrap'`. This is because the model's parameters are in this form: `Parameter>[PointerTensor | me:93626055963 -> alice:78685905360]`, and `fix_precision()` assumes that if there's no wrapper on the tensor, then it's a syft tensor (normal or pointer tensor). Therefore, tries to operate on the `Parameter` object.

**To Reproduce**
Working script demonstratin the issue:
```python
import torch as th
from torch import nn
import syft as sy

hook = sy.TorchHook(th)

# Create a worker
alice = sy.VirtualWorker(id=""alice"", hook=hook)

# Create a model and send it to worker
model = nn.Linear(2, 1).send(alice)

# Try to run fix_precision()
model.fix_precision() # AttributeError: 'numpy.ndarray' object has no attribute 'wrap'
```

**Expected behavior**
`fix_precision()` should work on a model even if it is on another location.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.5
 - Version 0.1.22a1

**Additional context**
This may have some relation to #2352, and some discussion about `wrap()` special cases in `float_prec()` and `fix_prec()` has been done on #2443. Also, I used to be able to do `fix_prec()` on sent models in version 0.1.19a1.
I think this has been fixed!",1,2019-08-09 16:19:27,2019-11-15 09:14:31,2019-11-15 09:14:31
https://github.com/OpenMined/PySyft/issues/2478,[],Encrypted Training on MNIST tutorial test model on training data itself,Encrypted Training on MNIST tutorial test model on training data itselfMax Zenk pointed out on slack(beginner channel) that in the tutorial: **Part 12 bis - Encrypted Training on MNIST** ```get_private_data_loaders``` functions loads the training set for training and testing.Issue Fixed :),1,2019-08-09 01:52:16,2019-08-13 01:09:31,2019-08-12 11:06:06
https://github.com/OpenMined/PySyft/issues/2461,[],Fix import issues,"Fix import issuesFix TODO https://github.com/OpenMined/PySyft/blob/06ce023225dd613d8fb14ab2046135b93ab22376/syft/frameworks/torch/hook/hook.py#L617

Fix TODO https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/autograd.py#L242

Fix TODO
https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L912

Fix TODO
https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/abstract.py#L158

Fix TODO
https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/multi_pointer.py#L195

Fix TODO https://github.com/OpenMined/PySyft/blob/1f05bd9babd552f4fc40545c71303dc624c0c132/syft/frameworks/torch/tensors/interpreters/precision.py#L613This has been fixed",1,2019-08-08 00:31:05,2019-12-09 03:30:26,2019-12-09 03:30:26
https://github.com/OpenMined/PySyft/issues/2456,"['bug ', 'status: stale :bread:']",Build gradients won't construct gradients correct if keywords arguments are present,"Build gradients won't construct gradients correct if keywords arguments are presentFix TODO https://github.com/OpenMined/PySyft/blob/51679c1941f172713cd2ba0d080b531a1693a15e/syft/frameworks/torch/tensors/interpreters/build_gradients.py#L22This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",1,2019-08-08 00:17:51,2020-05-25 00:07:44,2020-05-25 00:07:44
https://github.com/OpenMined/PySyft/issues/2447,[],Unexpected behavior with AutogradTensors in remote workers,"Unexpected behavior with AutogradTensors in remote workers**Describe the bug**
Transforming a remote tensor into an `AutogradTensor` with `.share(*workers, requires_grad=True)` creates an `AutogradTensor` that points to a `Wrapper` instead of the opposite, as it should be expected. We want this to behave correctly as our objective is to work with data in remote servers (i.e. remote tensors) and do encrypted training using MPC with this data.

**To Reproduce**
The code below:
```
t = torch.Tensor([3]).send(bob) # t is a remote tensor located at the remote worker Bob
t = t.fix_precision().share(alice, jon, crypto_provider=crypto_provider, requires_grad=True)
t.get()
```

Gives this output:
```
AutogradTensor>(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]
    -> [PointerTensor | me:48986511531 -> alice:2051851770]
    -> [PointerTensor | me:48878799575 -> jon:38113753813]
    *crypto provider: crypto_provider*
```

**Expected behavior**
When working with local tensors and sharing them for MPC with autograd we have a `Wrapper` at the top
```
t = t.fix_precision().share(alice, jon, crypto_provider=crypto_provider, requires_grad=True)
t
```
```
(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]
    -> [PointerTensor | me:78465969403 -> alice:24923297626]
    -> [PointerTensor | me:39395163768 -> jon:22928149946]
    *crypto provider: crypto_provider*
```


**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.4
 - Version `syft==0.1.22a1` Actually I can still see the issue. I'm on the latest version of `dev` branch.
![image](https://user-images.githubusercontent.com/24773652/63579510-0b43e300-c5bd-11e9-9f24-41de3c3829dc.png)",1,2019-08-07 11:07:35,2019-08-23 08:45:37,2019-08-22 19:17:33
https://github.com/OpenMined/PySyft/issues/2442,[],Tensors remain in server memory if websocketclient connection closes abruptly  ,"Tensors remain in server memory if websocketclient connection closes abruptly  **Describe the bug**
Tensors remain in websocket server memory if websocket client connection closes abruptly 

**To Reproduce**
Steps to reproduce the behavior:
1. Start the websocket server ""run_websocket_server.py --port 8777 --id alice""
2. Start a websocketclient and connect on port 8777 using id=""alice"".
3. Send a tensor to alice on the socket created in step 2. 
4. Close the client abruptly.
5. Check on the websocketserver console. The ""WebSocket connection created in step 2 gets closed""
4. Connect another websocketclient to port 8777 and use any random id say ""some_random_id""
5. Now call ""some_random_id.list_objects_remote()"" on the websocket created in step 4
6. Tensors sent to alice on the websocket in step 3 are clearly visible to this client with ""some_random_id"". 

**Expected behavior**
When socket connection gets closed all the tensors in server memory sent on that connection should be removed if any. This would ensure that if a websocket client closes abruptly due to network issues, etc its private tensors should not remain on the server which could be retrieved by any other client which connects to the server on the same port later. 

 - OS: Windows 10This is an important feature - but it requires user auth to know the difference between the same user re-connecting and another user re-connecting, which means this is more a feature for https://github.com/OpenMined/Grid

@IonesioJunior - I believe you'll be working on a user, based system. This is an important characteristic!",1,2019-08-05 08:03:25,2019-08-05 12:07:31,2019-08-05 12:07:31
https://github.com/OpenMined/PySyft/issues/2428,[],The WebSocketServer could be prone to a DoS attack,"The WebSocketServer could be prone to a DoS attack**Describe the bug**
The WebSocketServer could be prone to a DoS attack from a malicious script

**To Reproduce**
Steps to reproduce the behavior:
1. Start a websocketserver using run_websocket_server.py --port 8777 --id alice 
2. Create a client script which calls WebsocketClientWorker to connect to the websocketserver created above in a loop say 100000 times
3. Now start another client script which tries to connect to the above server using WebsocketClientWorker and tries sending a tensor to the remote worker
4. This client script in step 3 cannot perform any operations since it appears to hang due to DoS.

**Expected behavior**
This client script in step 3 should be able to perform its operations.

**Desktop (please complete the following information):**
 - OS: Windows 10Does it work after 1 time? I *think* WebSocketServer only allows one client to connect.Yes it works after 1 time. So i think it shouldn't be an issue then.
One question though, cannot see the objects of a remote socket worker using for e.g. ""bob._objects"". Is this for security reason?",2,2019-08-01 19:24:51,2019-08-02 13:54:15,2019-08-02 13:54:15
https://github.com/OpenMined/PySyft/issues/2426,[],Local worker *me* not recognized by other workers when explicitly declared as crypto provider,"Local worker *me* not recognized by other workers when explicitly declared as crypto provider**Describe the bug**
Sharing a sent tensor between workers, and explicitly declaring the crypto provider as `sy.local_worker` causes the warning `Worker [worker_id] couldn't recognize worker me`. This warning causes problems when trying to execute get() on the sent, shared tensor, throwing an exception `AttributeError: 'str' object has no attribute 'id'`. Strange enough, this doesn't happen if `sy.local_worker` is implicitly assigned as crypto provider by not providing any crypto provider while sharing the tensor.

**To Reproduce**
Working script to demonstrate the problem.
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)

# Declare workers
alice = sy.VirtualWorker(id=""alice"", hook=hook)
bob = sy.VirtualWorker(id=""bob"", hook=hook)
jack = sy.VirtualWorker(id=""jack"", hook=hook)

# create a tensor
a = th.zeros(1).long()

# send the tensor
a = a.send(alice)

# share the tensor with me as an implicit crypto provider
a = a.share(bob, jack) # No warning is shown here

# get the shared tensor
a = a.get() # AdditiveSharingTensor returned, *crypto provider: me*

# Redeclare tensor
a = th.zeros(1).long()

# send the tensor
a = a.send(alice)

# share the tensor with me as an explicit crypto provider
a = a.share(bob, jack, crypto_provider=sy.local_worker) 
# W0801 11:56:01.096644 4346246592 base.py:577] Worker alice couldn't recognize worker me

# get the shared tensor
a = a.get() # AttributeError: 'str' object has no attribute 'id'
```

**Expected behavior**
There should be no difference between implicit and explicit declaration of the local worker as crypto provider.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.5
 - Version `syft==0.1.19a1`

**Additional context**
A similar script can be seen inside `syft/frameworks/torch/crypto/securenn.py`, for example in `_shares_of_zero()` declaration:
```python
def _shares_of_zero(size, field, crypto_provider, *workers):
    """"""
    Return n in [0, max_value-1] chosen by a worker and sent to all workers,
    in the form of a MultiPointerTensor
    """"""
    u = (
        torch.zeros(size)
        .long()
        .send(workers[0])
        .share(*workers, field=field, crypto_provider=crypto_provider, **no_wrap)
        .get()
        .child
    )

    return u
```
and causes errors when trying to run functions inside `securenn.py` while using tensors without explicit declaration of a crypto provider. This assigns `crypto_provider` to the local worker, and gets explicitly assigned as crypto provider in the line `.share(*workers, field=field, crypto_provider=crypto_provider, **no_wrap)`.
Very interesting bug - I do wonder how deep this bug goes. Is the local worker listed in bob._known_workers?@iamtrask the local worker is not recognized by any of the virtual workers.
```python
print(alice._known_workers)
# => {'alice': <VirtualWorker id:alice #objects:10>, 'bob': <VirtualWorker id:bob #objects:14>, 'jack': <VirtualWorker id:jack #objects:12>}
# The results are the same for bob and jack
```@iamtrask I'm seeing two problems here:
1. VirtualWorkers are not recognizing the local worker.
2. letting the class `AdditiveSharingTensor` assign the default crypto_provider to local_worker behaves differently as explicitly assigning it to local_worker.

As of 1:
when declaring a new worker, the `_known_workers` dict is populated by copying `sy.hook.local_worker._known_workers`. If we run this script
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)
hook.local_worker._known_workers
# => {}
```
returns an empty dictionary, which means that `hook.local_worker` is not aware of itself, which explains why any other worker won't recognize it. I'm guessing this should be another issue by itself?

As of 2.
I still don't get it, if I don't assign a crypto_provider, then it gets automatically assigned as `sy.hook.local_worker`, which should behave the same as explicitly assigning it to the same value. Any ideas?PR #2431 fixes this problem. So I'm going to close this issue.",4,2019-08-01 17:03:48,2019-08-02 17:31:13,2019-08-02 17:31:12
https://github.com/OpenMined/PySyft/issues/2396,[],Openmined `client` tutorial is broken and needs fixing,"Openmined `client` tutorial is broken and needs fixing**Describe the bug**
The Colab version of the `Client` notebook needs fixing, as the code version it was based on is now deprecated. 

**To Reproduce**
Steps to reproduce the behavior:
1. Go to [https://colab.research.google.com/drive/1Je1rk7olA9uTWWaqvvt4_gXf7yX1rTBm](https://colab.research.google.com/drive/1Je1rk7olA9uTWWaqvvt4_gXf7yX1rTBm), or follow the web link on [https://www.openmined.org/](https://www.openmined.org/)
2. Check the outputs of the cells in that notebook
3. See error

**Expected behavior**
A good notebook should be as a bare minimum functional yet informative, especially in this context. 

**Desktop (please complete the following information):**
 - Google Colaboratory

**Additional context**
The code base of the websocket* workers might need to be modified to achieve the desired effect. 
I would really like to work on this issue though... which is not to be confused with #1905, which deals with the accompanying `Server` tutorial notebook hosted on Colab. I am guessing to make the tutorial run perfectly on Colab this is what we need to do: https://research.google.com/colaboratory/local-runtimes.htmlAm actively working on this issue, and will open a PR to follow up soon. @kakirastern Is this done? Can we close this issue?Yup, I have modified the file on Google Colab so it should be fine now. At least it was the last time I checked.",5,2019-07-25 17:33:09,2019-10-09 12:55:37,2019-10-09 12:55:37
https://github.com/OpenMined/PySyft/issues/2392,[],One-worker Bug,"One-worker Bug**Describe the bug**
When we set **only one client/work** in federated learning task, the corresponding _FederatedDataLoader_ does not work:

""....\syft\frameworks\torch\federated\dataloader.py"", line 245, in __next__
    iterator = self.iterators[0]
IndexError: list index out of range

I checked the code of **dataloader.py** and found the probable problem here:
```       
        if iter_per_worker:
            self.num_iterators = len(self.workers)
        else:
            # You can't have more iterators than n - 1 workers, because you always
            # need a worker idle in the worker switch process made by iterators
            self.num_iterators = min(num_iterators, len(self.workers) - 1)
```
where the num_iterators is set to 1, making the last statement of the codes above yields 0 (because min(1, 1-1) = 0) when len(self.workers) = 1. Consequently, no iterators available and thus the dataloader fails to work.

I wanted to test one-work FL for some reason and this bug appeared.I'll look into this @wentaiwu92 you can use ```iter_per_worker=True``` while calling FederatedDataLoader. That will allow you to have one iterator for one worker.
I hope that will help if not let me know I would be happy to help :)Close this issue :) ?Thanks ShivamSRS and kamathhrishi, **PySyft** is really helpful for FL.",4,2019-07-25 09:49:47,2019-08-02 15:53:02,2019-08-02 15:53:02
https://github.com/OpenMined/PySyft/issues/2390,[],error in federated learning with websockets ,"error in federated learning with websockets errors while trying to make websocket client workers in
Federated learning with websockets and federated averaging notebook in websockets-example-MNIST advanced tutorials
while executing this line 
after launching websocket servers on different terminals using 
python run_websocket_server.py --id alice --port 8887 
python run_websocket_server.py --id bob--port 8889 
python run_websocket_server.py --id charlie--port 8890

```
hook = sy.TorchHook(torch)

kwargs_websocket = {""host"": ""localhost"", ""hook"": hook, ""verbose"": args.verbose}
alice = WebsocketClientWorker(id=""alice"", port=8887, **kwargs_websocket)
bob = WebsocketClientWorker(id=""bob"", port=8889, **kwargs_websocket)
charlie = WebsocketClientWorker(id=""charlie"", port=8890, **kwargs_websocket)

workers = [alice, bob, charlie]
print(workers)
```
.

> AttributeError                            Traceback (most recent call last)
> <ipython-input-10-dfd3f30b67a3> in <module>
>       2 
>       3 kwargs_websocket = {""host"": ""localhost"", ""hook"": hook, ""verbose"": args.verbose}
> ----> 4 alice = WebsocketClientWorker(id=""alice"", port=8887, **kwargs_websocket)
>       5 bob = WebsocketClientWorker(id=""bob"", port=8889, **kwargs_websocket)
>       6 charlie = WebsocketClientWorker(id=""charlie"", port=8890, **kwargs_websocket)
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\syft\workers\websocket_client.py in __init__(self, hook, host, port, secure, id, is_client_worker, log_msgs, verbose, data)
>      49         self.secure = secure
>      50         self.ws = None
> ---> 51         self.connect()
>      52 
>      53     @property
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\syft\workers\websocket_client.py in connect(self)
>      61             args[""sslopt""] = {""cert_reqs"": ssl.CERT_NONE}
>      62 
> ---> 63         self.ws = websocket.create_connection(**args)
>      64 
>      65     def close(self):
> 
> AttributeError: module 'websocket' has no attribute 'create_connection'

and after I changed
`import websocket`
with
`import websocket._core as websocket`
in syft/workers/websocket-client.py
after executing same notebook line 
in am getting

> OverflowError                             Traceback (most recent call last)
> <ipython-input-5-3a01ed8c63d6> in <module>
>       2 
>       3 kwargs_websocket = {""host"": ""localhost"", ""hook"": hook, ""verbose"": args.verbose}
> ----> 4 alice = WebsocketClientWorker(id=""alice"", port=8887, **kwargs_websocket)
>       5 bob = WebsocketClientWorker(id=""bob"", port=8889, **kwargs_websocket)
>       6 charlie = WebsocketClientWorker(id=""charlie"", port=8890, **kwargs_websocket)
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\syft\workers\websocket_client.py in __init__(self, hook, host, port, secure, id, is_client_worker, log_msgs, verbose, data)
>      49         self.secure = secure
>      50         self.ws = None
> ---> 51         self.connect()
>      52 
>      53     @property
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\syft\workers\websocket_client.py in connect(self)
>      61             args[""sslopt""] = {""cert_reqs"": ssl.CERT_NONE}
>      62 
> ---> 63         self.ws = websocket.create_connection(**args)
>      64 
>      65     def close(self):
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\websocket\_core.py in create_connection(url, timeout, class_, **options)
>     512                      skip_utf8_validation=skip_utf8_validation, **options)
>     513     websock.settimeout(timeout if timeout is not None else getdefaulttimeout())
> --> 514     websock.connect(url, **options)
>     515     return websock
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\websocket\_core.py in connect(self, url, **options)
>     221         self.sock_opt.timeout = options.get('timeout', self.sock_opt.timeout)
>     222         self.sock, addrs = connect(url, self.sock_opt, proxy_info(**options),
> --> 223                                    options.pop('socket', None))
>     224 
>     225         try:
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\websocket\_http.py in connect(url, options, proxy, socket)
>     118     sock = None
>     119     try:
> --> 120         sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
>     121         if need_tunnel:
>     122             sock = _tunnel(sock, hostname, port, auth)
> 
> h:\softwares\anaconda\envs\dlpytorch\lib\site-packages\websocket\_http.py in _open_socket(addrinfo_list, sockopt, timeout)
>     160         family, socktype, proto = addrinfo[:3]
>     161         sock = socket.socket(family, socktype, proto)
> --> 162         sock.settimeout(timeout)
>     163         for opts in DEFAULT_SOCKET_OPTION:
>     164             sock.setsockopt(*opts)
> 
> OverflowError: timeout doesn't fit into C timeval

OS version windows 10 64bit
python version 3.6.8
Cuda 10

Installed python libraries
 Name                    Version                   Build  Channel
absl-py                   0.7.1                    pypi_0    pypi
astor                     0.8.0                    pypi_0    pypi
attrs                     19.1.0                   pypi_0    pypi
backcall                  0.1.0                    pypi_0    pypi
bleach                    3.1.0                    pypi_0    pypi
certifi                   2019.3.9                 py36_0
cffi                      1.12.3                   pypi_0    pypi
click                     7.0                      pypi_0    pypi
colorama                  0.4.1                    pypi_0    pypi
cycler                    0.10.0                   pypi_0    pypi
decorator                 4.4.0                    pypi_0    pypi
defusedxml                0.6.0                    pypi_0    pypi
dill                      0.3.0                    pypi_0    pypi
entrypoints               0.3                      pypi_0    pypi
enum34                    1.1.6                    pypi_0    pypi
flask                     1.1.1                    pypi_0    pypi
flask-socketio            4.1.0                    pypi_0    pypi
gast                      0.2.2                    pypi_0    pypi
gevent                    1.4.0                    pypi_0    pypi
google-pasta              0.1.7                    pypi_0    pypi
greenlet                  0.4.15                   pypi_0    pypi
grpcio                    1.22.0                   pypi_0    pypi
h5py                      2.9.0                    pypi_0    pypi
ipykernel                 5.1.1                    pypi_0    pypi
ipython                   7.6.1                    pypi_0    pypi
ipython-genutils          0.2.0                    pypi_0    pypi
itsdangerous              1.1.0                    pypi_0    pypi
jedi                      0.14.1                   pypi_0    pypi
jinja2                    2.10.1                   pypi_0    pypi
joblib                    0.13.2                   pypi_0    pypi
json5                     0.8.5                    pypi_0    pypi
jsonschema                3.0.1                    pypi_0    pypi
jupyter-client            5.3.1                    pypi_0    pypi
jupyter-core              4.5.0                    pypi_0    pypi
jupyter-http-over-ws      0.0.6                    pypi_0    pypi
jupyterlab                1.0.2                    pypi_0    pypi
jupyterlab-server         1.0.0                    pypi_0    pypi
keras-applications        1.0.8                    pypi_0    pypi
keras-preprocessing       1.1.0                    pypi_0    pypi
kiwisolver                1.1.0                    pypi_0    pypi
lz4                       2.1.10                   pypi_0    pypi
markdown                  3.1.1                    pypi_0    pypi
markupsafe                1.1.1                    pypi_0    pypi
matplotlib                3.1.1                    pypi_0    pypi
mistune                   0.8.4                    pypi_0    pypi
msgpack                   0.6.1                    pypi_0    pypi
nbconvert                 5.5.0                    pypi_0    pypi
nbformat                  4.4.0                    pypi_0    pypi
notebook                  5.7.8                    pypi_0    pypi
numpy                     1.16.4                   pypi_0    pypi
pandocfilters             1.4.2                    pypi_0    pypi
parso                     0.5.1                    pypi_0    pypi
pickleshare               0.7.5                    pypi_0    pypi
pillow                    6.0.0                    pypi_0    pypi
pip                       19.1.1                   py36_0
prometheus-client         0.7.1                    pypi_0    pypi
prompt-toolkit            2.0.9                    pypi_0    pypi
protobuf                  3.8.0                    pypi_0    pypi
pycparser                 2.19                     pypi_0    pypi
pygments                  2.4.2                    pypi_0    pypi
pyparsing                 2.4.0                    pypi_0    pypi
pyrsistent                0.15.3                   pypi_0    pypi
python                    3.6.8                h9f7ef89_7
python-dateutil           2.8.0                    pypi_0    pypi
python-engineio           3.8.2.post1              pypi_0    pypi
python-socketio           4.2.0                    pypi_0    pypi
pywinpty                  0.5.5                    pypi_0    pypi
pyyaml                    5.1.1                    pypi_0    pypi
pyzmq                     18.0.2                   pypi_0    pypi
scikit-learn              0.21.2                   pypi_0    pypi
scipy                     1.3.0                    pypi_0    pypi
send2trash                1.5.0                    pypi_0    pypi
setuptools                41.0.1                   py36_0
six                       1.12.0                   pypi_0    pypi
sqlite                    3.28.0               he774522_0
syft                      0.1.21a1                 pypi_0    pypi
tblib                     1.4.0                    pypi_0    pypi
tensorboard               1.14.0                   pypi_0    pypi
tensorflow                1.14.0                   pypi_0    pypi
tensorflow-estimator      1.14.0                   pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
terminado                 0.8.2                    pypi_0    pypi
testpath                  0.4.2                    pypi_0    pypi
tf-encrypted              0.5.4                    pypi_0    pypi
torch                     1.1.0                    pypi_0    pypi
torchsummary              1.5.1                    pypi_0    pypi
torchvision               0.3.0                    pypi_0    pypi
tornado                   6.0.3                    pypi_0    pypi
traitlets                 4.3.2                    pypi_0    pypi
vc                        14.1                 h0510ff6_4
vs2015_runtime            14.15.26706          h3a45250_4
wcwidth                   0.1.7                    pypi_0    pypi
webencodings              0.5.1                    pypi_0    pypi
websocket                 0.2.1                    pypi_0    pypi
websocket-client          0.56.0                   pypi_0    pypi
websockets                8.0.1                    pypi_0    pypi
werkzeug                  0.15.4                   pypi_0    pypi
wheel                     0.33.4                   py36_0
wincertstore              0.2              py36h7fe50ca_0
wrapt                     1.11.2                   pypi_0    pypi
zstd                      1.4.1.0                  pypi_0    pypi


I tried substituting for the L63:  `self.ws = websocket.create_connection(**args)` with the following and it seemed to have worked to some degree: 

```
self.ws = websockets.connect(uri=url, **args)
```

But it also seems like in this module to accompany the `import websockets` you will probably also need to do `import asyncio`, which is currently missing in it. I am working on the Websocket Workers tutorials too so I encountered some similar issues. Hope that they will get resolved really soon. @1000ping this issue has been addressed by PR https://github.com/OpenMined/PySyft/pull/2395@amit-rastogi I will check it and close this if no issue arrives I haven't tried it yet",3,2019-07-24 21:46:30,2019-07-27 20:33:32,2019-07-27 20:33:32
https://github.com/OpenMined/PySyft/issues/2378,[],about error in websocket mnist example ,"about error in websocket mnist example **Describe the bug**
KeyError: (wrapper)>[PointerTensor | me:some series of numbers -> alice:some series of number]

**To Reproduce**
Add the code in run_websocket_client.py:
```
kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}
alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
workers = [alice]
```
I run the lines:
python3 run_websocket_server.py --host 127.0.0.1 --port 8777 --id alice
python3 run_websocket_client.py

It shows the bug.

**Desktop (please complete the following information):**
RedHat Linux 7.2, python3.6.8, pysyft==0.1.13a1, torch==1.0.1, torchvision==0.2.2
nvidia-driver==410.48, cuda==10.0, cudnn==7.5

**Additional context**
I change to: pysyft==0.1.19a1, torch==1.1.0, torchvision==0.3.0
or I use the VirtualHook.
The bug still have.I also see this error! But when i use 2 workers it works fine.",1,2019-07-22 00:20:07,2020-01-30 13:35:18,2019-07-22 01:49:39
https://github.com/OpenMined/PySyft/issues/2370,[],error in websockets-example-MNIST tutorials,"error in websockets-example-MNIST tutorialsTo Reproduce error:
1. In terminal Activate pytorch Environment 
2. cd to PySyft-dev\examples\tutorials\advanced\websockets-example-MNIST
3. run command `python run_websocket_server.py --port 8887 --id alice`

WARNING: Logging before flag parsing goes to stderr.
W0720 07:04:28.831149  5416 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'H:\Softwares\anaconda\envs\dlpytorch\lib\s
ite-packages\tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'
W0720 07:04:28.846143  5416 deprecation_wrapper.py:119] From H:\Softwares\anaconda\envs\dlpytorch\lib\site-packages\tf_encrypted\session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

Traceback (most recent call last):
  File ""run_websocket_server.py"", line 53, in <module>
    server = start_proc(WebsocketServerWorker, kwargs)
  File ""run_websocket_server.py"", line 23, in start_proc
    p.start()
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\context.py"", line 322, in _Popen
    return Popen(process_obj)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\popen_spawn_win32.py"", line 65, in __init__
    reduction.dump(process_obj, to_child)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\reduction.py"", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
AttributeError: Can't pickle local object 'start_proc.<locals>.target'

(dlpytorch) C:\Users\wajah\PycharmProjects\pytorch_help\PySyft-dev\examples\tutorials\advanced\websockets-example-MNIST>WARNING: Logging before flag parsing goes to stderr.
W0720 07:04:31.624255 15556 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'H:\Softwares\anaconda\envs\dlpytorch\lib\s
ite-packages\tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'
W0720 07:04:31.639249 15556 deprecation_wrapper.py:119] From H:\Softwares\anaconda\envs\dlpytorch\lib\site-packages\tf_encrypted\session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 114, in _main
    prepare(preparation_data)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 277, in _fixup_main_from_path
    run_name=""__mp_main__"")
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\wajah\PycharmProjects\pytorch_help\PySyft-dev\examples\tutorials\advanced\websockets-example-MNIST\run_websocket_server.py"", line 53, in <module>
    server = start_proc(WebsocketServerWorker, kwargs)
  File ""C:\Users\wajah\PycharmProjects\pytorch_help\PySyft-dev\examples\tutorials\advanced\websockets-example-MNIST\run_websocket_server.py"", line 23, in start_proc
    p.start()
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\context.py"", line 322, in _Popen
    return Popen(process_obj)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\popen_spawn_win32.py"", line 33, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 143, in get_preparation_data
    _check_not_importing_main()
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError:
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The ""freeze_support()"" line can be omitted if the program
        is not going to be frozen to produce an executable.

4. After replacing 
`server = start_proc(WebsocketServerWorker, kwargs)`

in run_websocket_server.py with 

```
if __name__ == '__main__':
    freeze_support()
    server = start_proc(WebsocketServerWorker, kwargs)
```

and running command
 
`python run_websocket_server.py --port 8887 --id alice`

 again


Traceback (most recent call last):
  File ""run_websocket_server.py"", line 53, in <module>
    server = start_proc(WebsocketServerWorker, kwargs)
  File ""run_websocket_server.py"", line 23, in start_proc
    p.start()
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\context.py"", line 322, in _Popen
    return Popen(process_obj)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\popen_spawn_win32.py"", line 65, in __init__
    reduction.dump(process_obj, to_child)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\reduction.py"", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
AttributeError: Can't pickle local object 'start_proc.<locals>.target'

(dlpytorch) C:\Users\wajah\PycharmProjects\pytorch_help\PySyft-dev\examples\tutorials\advanced\websockets-example-MNIST>WARNING: Logging before flag parsing goes to stderr.
W0721 19:48:18.066954 13356 secure_random.py:22] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.14.0). Fix this by compi
ling custom ops.
W0721 19:48:18.099944 13356 deprecation_wrapper.py:119] From H:\Softwares\anaconda\envs\dlpytorch\lib\site-packages\tf_encrypted\session.py:28: The name tf.Session is deprecated. Please use tf.compat.
v1.Session instead.

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""H:\Softwares\anaconda\envs\dlpytorch\lib\multiprocessing\spawn.py"", line 115, in _main
    self = reduction.pickle.load(from_parent)
EOFError: Ran out of input

Expected behavior
I expected them to launch WebSocket servers on my machine 

I am getting same errors when running `python websocket_servers.py`
OS version windows 10 64bit
python version 3.6.8
Cuda 10

Installed python libraries

absl-py                   0.7.1                     <pip>
astor                     0.8.0                     <pip>
attrs                     19.1.0                    <pip>
backcall                  0.1.0                     <pip>
bleach                    3.1.0                     <pip>
certifi                   2019.3.9                 py36_0
cffi                      1.12.3                    <pip>
Click                     7.0                       <pip>
colorama                  0.4.1                     <pip>
cycler                    0.10.0                    <pip>
decorator                 4.4.0                     <pip>
defusedxml                0.6.0                     <pip>
dill                      0.3.0                     <pip>
entrypoints               0.3                       <pip>
enum34                    1.1.6                     <pip>
Flask                     1.1.1                     <pip>
Flask-SocketIO            4.1.0                     <pip>
gast                      0.2.2                     <pip>
gevent                    1.4.0                     <pip>
google-pasta              0.1.7                     <pip>
greenlet                  0.4.15                    <pip>
grpcio                    1.22.0                    <pip>
h5py                      2.9.0                     <pip>
ipykernel                 5.1.1                     <pip>
ipython                   7.6.1                     <pip>
ipython-genutils          0.2.0                     <pip>
itsdangerous              1.1.0                     <pip>
jedi                      0.14.1                    <pip>
Jinja2                    2.10.1                    <pip>
joblib                    0.13.2                    <pip>
json5                     0.8.5                     <pip>
jsonschema                3.0.1                     <pip>
jupyter-client            5.3.1                     <pip>
jupyter-core              4.5.0                     <pip>
jupyter-http-over-ws      0.0.6                     <pip>
jupyterlab                1.0.2                     <pip>
jupyterlab-server         1.0.0                     <pip>
Keras-Applications        1.0.8                     <pip>
Keras-Preprocessing       1.1.0                     <pip>
kiwisolver                1.1.0                     <pip>
lz4                       2.1.10                    <pip>
Markdown                  3.1.1                     <pip>
MarkupSafe                1.1.1                     <pip>
matplotlib                3.1.1                     <pip>
mistune                   0.8.4                     <pip>
msgpack                   0.6.1                     <pip>
nbconvert                 5.5.0                     <pip>
nbformat                  4.4.0                     <pip>
notebook                  5.7.8                     <pip>
numpy                     1.16.4                    <pip>
pandocfilters             1.4.2                     <pip>
parso                     0.5.1                     <pip>
pickleshare               0.7.5                     <pip>
Pillow                    6.1.0                     <pip>
Pillow                    6.0.0                     <pip>
pip                       19.1.1                   py36_0
prometheus-client         0.7.1                     <pip>
prompt-toolkit            2.0.9                     <pip>
protobuf                  3.8.0                     <pip>
pycparser                 2.19                      <pip>
Pygments                  2.4.2                     <pip>
pyparsing                 2.4.0                     <pip>
pyrsistent                0.15.3                    <pip>
python                    3.6.8                h9f7ef89_7
python-dateutil           2.8.0                     <pip>
python-engineio           3.8.2.post1               <pip>
python-socketio           4.2.0                     <pip>
pywinpty                  0.5.5                     <pip>
PyYAML                    5.1.1                     <pip>
pyzmq                     18.0.2                    <pip>
scikit-learn              0.21.2                    <pip>
scipy                     1.3.0                     <pip>
Send2Trash                1.5.0                     <pip>
setuptools                41.0.1                   py36_0
six                       1.12.0                    <pip>
sqlite                    3.28.0               he774522_0
syft                      0.1.21a1                  <pip>
tblib                     1.4.0                     <pip>
tensorboard               1.14.0                    <pip>
tensorflow                1.14.0                    <pip>
tensorflow-estimator      1.14.0                    <pip>
termcolor                 1.1.0                     <pip>
terminado                 0.8.2                     <pip>
testpath                  0.4.2                     <pip>
tf-encrypted              0.5.4                     <pip>
torch                     1.1.0                     <pip>
torchvision               0.3.0                     <pip>
tornado                   6.0.3                     <pip>
traitlets                 4.3.2                     <pip>
vc                        14.1                 h0510ff6_4
vs2015_runtime            14.15.26706          h3a45250_4
wcwidth                   0.1.7                     <pip>
webencodings              0.5.1                     <pip>
websocket                 0.2.1                     <pip>
websocket-client          0.56.0                    <pip>
websockets                8.0.1                     <pip>
Werkzeug                  0.15.4                    <pip>
wheel                     0.33.4                   py36_0
wincertstore              0.2              py36h7fe50ca_0
wrapt                     1.11.2                    <pip>
zstd                      1.4.1.0                   <pip>

Hi, could you please follow the template for writing an Issue, so that more people can help solve your problem? Knowing the details about the kind of installation of PySyft and your Operating System would surely help.@DanyEle Thank you for pointing that out I have edited it now.@1000ping instead of spawning a separate process on Windows during which pickling error is encountered you can create the WebSocketServer within the current process context itself. I have created a PR with this change. https://github.com/OpenMined/PySyft/pull/2389",3,2019-07-19 15:27:50,2019-07-24 21:03:38,2019-07-24 21:03:38
https://github.com/OpenMined/PySyft/issues/2365,[],"When sharing a model where bias equals true, not all parameters get shared","When sharing a model where bias equals true, not all parameters get shared

**To Reproduce**
Steps to reproduce the behavior:
Run attached notebook until you get an error. When you look at the args of the call to addmm, one of the args is a torch tensor when all should be ast. This implies that either the weights or the bias is not being shared (Im pretty sure)
[reproduce_error.ipynb.zip](https://github.com/OpenMined/PySyft/files/3403467/reproduce_error.ipynb.zip)
@shivramsrsThe pb is that the data is not shared correctly here:

The model can be shared in-place but data can't be:
```python
model.share(...) # Is OK
model = model.share(...) # Is OK

data.share(...) # IS *NOT* OK
data = data.share(...) # Is OK
```
Additionally, all the parameters of the model get shared by default: we loop on model.parameters()",3,2019-07-17 19:19:58,2019-07-18 14:41:20,2019-07-18 14:41:20
https://github.com/OpenMined/PySyft/issues/2361,[],Gradient updates not generated in remote backpropagation with custom GRU/RNN,"Gradient updates not generated in remote backpropagation with custom GRU/RNN**Describe the bug**

No gradient is produced following the remote backpropagation step neither in the model's parameters nor in the worker's parameters.
**To Reproduce**

Steps to reproduce the behavior:
1. Extract all the files in the `minimal_GRU_2.0.zip` archive to a folder of your choice. The files' download link is at the bottom of this Issue
2. Navigate to the folder where the files have been extracted
3.  Run the following command:
`python3 minimal_gru_init.py`
4. See the [0,0,...0] tensors being generated as model's gradient parameters, meaning that the gradients did not get updated. 
5. Inspect the code. The issue lies in file `minimal_gru_init.py` in the function `train_remote_model_one_epoch` at line: `loss.backward()`.

To inspect the gradient, just check the lines:

```python
 for param_remote in remote_model.parameters():
            #produces a matrix containing just zeroes
            print(param_remote.grad.copy().get())
```




**Expected behavior**

I would expect that the parameter's gradient updates are actually generated. In a local version of the same code, where backpropagation is performed locally, the gradient update is indeed generated for all parameters.

**Screenshots**

LOCAL gradient (first parameter of the model) - Correct behaviour 

![local_gradient](https://user-images.githubusercontent.com/4907418/61353477-37f33500-a870-11e9-92d1-3ce1f1b9f8e4.png)

REMOTE gradient (first parameter of the model): - Erroneous behaviour

![image](https://user-images.githubusercontent.com/4907418/61353820-f6af5500-a870-11e9-8f3e-53adf230eabe.png)


**Desktop **
 - OS: Ubuntu 
 - Version 18.04 LTS

**Additional context**
I've been stuck on this issue for a weeks now and it's extremely important for the work I'm conducting with PySyft to have it fixed. Any help would be greatly appreciated. I tried to experiment with AutogradTensor to see if there was any difference in terms of gradient produced, but the gradient updates still were not produced. 

Also note that you're going to need the .size() method to test RNNs-GRUs. You may clone the repository of this PR to get its implementation: https://github.com/OpenMined/PySyft/pull/2343

Minimal code example and dataset: [minimal_GRU_2.0.zip](https://github.com/OpenMined/PySyft/files/3400495/minimal_GRU_2.0.zip)
@LaRiffle @robert-wagner @iamtrask @mari-linhares  Thoughts? . Any ideas or help would be greatly appreciated.Hey @DanyEle What happens if you don't call `.copy` before `.get`You can't .get() on a data attribute (syft.exceptions.CannotRequestObjectAttribute)Rip okay. What is the result of copy locally?If you want to inspect in a preserving manner you can directly access the remote object:
```
worker = sy.hook.local_worker.get_worker(param_remote.location)
print(worker._objects[param_remote.id_at_location].grad)
```You get 8 param grad, the 6 first are only zeros but not the two last one:
zeros: encoder.weight, rnn.weight_ih, rnn.weight_hh, rnn.bias_ih, rnn.bias_hh
non-zeros: decoder.weight & decoder.biasTry this for your forward pass: (check carefully the differences with the send/get stufff to understand better what was not working)
```python
    def forward(self, input, hidden, worker=None):
        print(input)
        emb = self.drop(self.encoder(input))

        output = []
        if self.rnn_type in ['GRU', 'GRUCell']:
            hx = hidden
            for i in range(emb.shape[0]): #Daniele: was emb.size(0)

                hx = self.rnn(emb[i, :], hx)
                output.append(hx.unsqueeze(0))

            output = torch.cat(output, dim=0)
        else:
            # else do smthg to instantiate output
            raise ValueError
                
        output = self.drop(output)
        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))
        return (decoded.view(output.size(0), output.size(1), decoded.size(1)), hx)
```

And to print the grad safely do:
```python
#BACKPROPAGATION - ISSUES OCCUR HERE! Gradients are [0,0,...,0]
        for k, param_remote in remote_model.named_parameters():
            print(k)
            worker = sy.hook.local_worker.get_worker(param_remote.location)
            print(worker._objects[param_remote.id_at_location].grad)
            #print(param_remote.grad.get())
```
It works on my side I get non-zero gradientsThe `minimal_gru_init.py` does not run completely as we said because the hook on size() can't work: just replace the occurence of size() with .shape in your implem, remove the hook of size() and this error should disappearYes, it's indeed working!! Also the quantization example, after removing calls to clone() on the input , but operating in place on the variables, is working!!!! :)",9,2019-07-17 06:58:11,2019-07-17 17:52:37,2019-07-17 17:22:49
https://github.com/OpenMined/PySyft/issues/2359,[],Error when call fix_precision() in PySyft/examples/tutorials/Part 10 - Federated Learning with Secure Aggregation.ipynb,"Error when call fix_precision() in PySyft/examples/tutorials/Part 10 - Federated Learning with Secure Aggregation.ipynb**Describe the bug**
when it call the function of fix_precision(),
on the line _â€œfixed_precision_param = copy_of_parameter.fix_precision()â€_
and the line: _spdz_params.append(params[remote_index][param_i].copy().fix_precision().share(bob, alice, crypto_provider=james).get())_,
it will occur:
`AttributeError: 'numpy.ndarray' object has no attribute 'owner'`

entire error log:
```
KeyError                                  Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    656         # Load the utility function to register the response and transform tensors with pointers
--> 657         register_response_function = register_response_functions[attr_id]
    658         # Try running it

KeyError: 'numpy'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
15 frames
<ipython-input-17-8762fe587994> in <module>()
     11         # to use Integers to store decimal information. In other words,
     12         # we need to use ""Fixed Precision"" encoding.
---> 13         fixed_precision_param = copy_of_parameter.fix_precision()
     14 
     15         # now we encrypt it on the remote machine. Note that

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, *args, **kwargs)
    645         prec_fractional = kwargs.get(""precision_fractional"", 3)
    646         max_precision = _get_maximum_precision()
--> 647         if self._requires_large_precision(max_precision, base, prec_fractional):
    648             return (
    649                 syft.LargePrecisionTensor(*args, **kwargs)

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in _requires_large_precision(self, max_precision, base, precision_fractional)
    670         # We need to use NumPy here as log2 is not yet implemented for LongTensor PyTorch objects
    671         return np.any(
--> 672             np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision
    673         )
    674 

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    675                 # Send the new command to the appropriate class and get the response
    676                 method = getattr(new_self, method_name)
--> 677                 response = method(*new_args, **new_kwargs)
    678 
    679                 # For inplace methods, just directly return self

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    511             command = (attr, self, args, kwargs)
    512 
--> 513             response = owner.send_command(location, command)
    514 
    515             return response

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    425 
    426         try:
--> 427             ret_val = self.send_msg(codes.MSGTYPE.CMD, message, location=recipient)
    428         except ResponseSignatureError as e:
    429             ret_val = None

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_msg(self, msg_type, message, location)
    221 
    222         # Step 2: send the message and wait for a response
--> 223         bin_response = self._send_msg(bin_message, location)
    224 
    225         # Step 3: deserialize the response

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      8 class VirtualWorker(BaseWorker, FederatedClient):
      9     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
---> 10         return location._recv_msg(message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _recv_msg(self, message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:
---> 13         return self.recv_msg(message)
     14 
     15     @staticmethod

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in recv_msg(self, bin_message)
    252             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    253         # Step 1: route message to appropriate function
--> 254         response = self._message_router[msg_type](contents)
    255 
    256         # Step 2: Serialize the message to simple python objects

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in execute_command(self, message)
    391             try:
    392                 response = sy.frameworks.torch.hook_args.register_response(
--> 393                     command_name, response, list(return_ids), self
    394                 )
    395                 return response

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    664         register_response_functions[attr_id] = register_response_function
    665         # Run it
--> 666         new_response = register_response_function(response, response_ids=response_ids, owner=owner)
    667 
    668     # Remove the artificial tuple

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(x, **kwargs)
    757         f = many_fold
    758 
--> 759     return lambda x, **kwargs: f(lambdas, x, **kwargs)

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    514 
    515 def two_fold(lambdas, args, **kwargs):
--> 516     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    517 
    518 

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i, **kwargs)
    735         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    736         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 737         else lambda i, **kwargs: register_tensor(i, **kwargs)
    738         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    739     ]

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    706             and each id is pop out when needed.
    707     """"""
--> 708     tensor.owner = owner
    709     try:
    710         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```

**To Reproduce**
Steps to reproduce the behavior:
1.just pip isntall syft on google colab
and run this tutorials ipynb


**Desktop (please complete the following information):**
 - OS: [Google Colab & Ubuntu 16.04 ]

**Additional context**
I have debugged, it occur when call .fix_precision()
@LaRiffle Hey @bluerxing,

I believe this was fixed in this PR #2353. You should be able to have the correct behavior by using the dev version of this repo or using pip in the next few days (when the new version of pysyft is submitted).

I'll close this issue, but feel free to leave comments here if you face any issues.

@mari-linhares Have the new version of pysyft is submitted already?",3,2019-07-15 09:40:27,2019-08-04 03:39:29,2019-07-15 20:25:36
https://github.com/OpenMined/PySyft/issues/2352,"['bug ', 'priority: 2 - high :cold_sweat:']",Fix precision on pointers Error,"Fix precision on pointers Error**Describe the bug**
Fix_precision on pointer tensor fails because of change in fix_prec method which make use of numpy ops.

**To Reproduce**
```python
#[classic imports]
x = torch.tensor([1.])
x_ptr = x.send(alice)
x_fp = x_ptr.fix_prec()
``` 

Or run Tutorial Part 10.

![image](https://user-images.githubusercontent.com/8157164/61076178-8a1cfc00-a413-11e9-8dc3-dfba2ae73261.png)



**Error**
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    656         # Load the utility function to register the response and transform tensors with pointers
--> 657         register_response_function = register_response_functions[attr_id]
    658         # Try running it

KeyError: 'numpy'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-1-95fc1ed4192b> in <module>
     13 x = torch.tensor([1.])
     14 x_ptr = x.send(alice)
---> 15 x_fp = x_ptr.fix_prec()

~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in fix_prec(self, *args, **kwargs)
    666         prec_fractional = kwargs.get(""precision_fractional"", 3)
    667         max_precision = _get_maximum_precision()
--> 668         if self._requires_large_precision(max_precision, base, prec_fractional):
    669             return (
    670                 syft.LargePrecisionTensor(*args, **kwargs)

~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in _requires_large_precision(self, max_precision, base, precision_fractional)
    691         # We need to use NumPy here as log2 is not yet implemented for LongTensor PyTorch objects
    692         return np.any(
--> 693             np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision
    694         )
    695 

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    675                 # Send the new command to the appropriate class and get the response
    676                 method = getattr(new_self, method_name)
--> 677                 response = method(*new_args, **new_kwargs)
    678 
    679                 # For inplace methods, just directly return self

~/code/PySyft/syft/frameworks/torch/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    511             command = (attr, self, args, kwargs)
    512 
--> 513             response = owner.send_command(location, command)
    514 
    515             return response

~/code/PySyft/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    425 
    426         try:
--> 427             ret_val = self.send_msg(codes.MSGTYPE.CMD, message, location=recipient)
    428         except ResponseSignatureError as e:
    429             ret_val = None

~/code/PySyft/syft/workers/base.py in send_msg(self, msg_type, message, location)
    221 
    222         # Step 2: send the message and wait for a response
--> 223         bin_response = self._send_msg(bin_message, location)
    224 
    225         # Step 3: deserialize the response

~/code/PySyft/syft/workers/virtual.py in _send_msg(self, message, location)
      8 class VirtualWorker(BaseWorker, FederatedClient):
      9     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
---> 10         return location._recv_msg(message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:

~/code/PySyft/syft/workers/virtual.py in _recv_msg(self, message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:
---> 13         return self.recv_msg(message)
     14 
     15     @staticmethod

~/code/PySyft/syft/workers/base.py in recv_msg(self, bin_message)
    252             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    253         # Step 1: route message to appropriate function
--> 254         response = self._message_router[msg_type](contents)
    255 
    256         # Step 2: Serialize the message to simple python objects

~/code/PySyft/syft/workers/base.py in execute_command(self, message)
    391             try:
    392                 response = sy.frameworks.torch.hook_args.register_response(
--> 393                     command_name, response, list(return_ids), self
    394                 )
    395                 return response

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in register_response(attr, response, response_ids, owner)
    664         register_response_functions[attr_id] = register_response_function
    665         # Run it
--> 666         new_response = register_response_function(response, response_ids=response_ids, owner=owner)
    667 
    668     # Remove the artificial tuple

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in <lambda>(x, **kwargs)
    757         f = many_fold
    758 
--> 759     return lambda x, **kwargs: f(lambdas, x, **kwargs)

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in two_fold(lambdas, args, **kwargs)
    514 
    515 def two_fold(lambdas, args, **kwargs):
--> 516     return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
    517 
    518 

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in <lambda>(i, **kwargs)
    735         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    736         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 737         else lambda i, **kwargs: register_tensor(i, **kwargs)
    738         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    739     ]

~/code/PySyft/syft/frameworks/torch/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    706             and each id is pop out when needed.
    707     """"""
--> 708     tensor.owner = owner
    709     try:
    710         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```AttributeError: 'numpy.ndarray' object has no attribute 'owner'

Is this issue resolved? 

Infile : syft/frameworks/torch/tensors/interpreters/native.py
Having this line: np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision 
is causing issue.",1,2019-07-11 11:05:00,2020-02-21 17:13:23,2019-07-12 18:30:48
https://github.com/OpenMined/PySyft/issues/2341,"['bug ', 'status: stale :bread:']",SecureNN with n_workers >= 3,"SecureNN with n_workers >= 3**Describe the bug**
When used with n>=3 workers with SecureNN

```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
crypto_prov = sy.VirtualWorker(hook, id=""crypto_prov"")
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks, crypto_provider=crypto_prov)
t = t * 2
t = t.get()
t = t.float_prec()
print(t)
```

This doesn't work correctly:
```
tensor([[-1.0000e-03,  0.0000e+00,  1.0000e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.0000e-03,  1.0000e-03,  1.8447e+13]])
```In this particular case where we multiply by a scalar, I think we do something useless:
we first multiply the multiplier by `base ** precision_fractional` and then truncate. When I remove this, the results are ok.
But I agree that there are still some problems when multiplying 2 ASTs shared between more than 2 workersEDIT **not enough**
> Use a crypto provider and that should be sufficientHmm @LaRiffle, this doesn't seem sufficient to fix the problem of >2 workers:

```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
crypto_prov = sy.VirtualWorker(hook, id=""crypto_prov"")
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks, crypto_provider=crypto_prov)
t = t * 2
t = t.get()
t = t.float_prec()
print(t)

tensor([[-1.8447e+13,  1.8447e+13,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.0000e-03, -1.8447e+13,  1.8447e+13]])
```@LaRiffle, a quick fix using the in-place operation somehow works:
```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks)
t *= 2
t = t.get()
t.float_prec()
```
For the very specific problem of multiplying by an integer, I submitted a pull request and it passed all tests.Here's another example - calculating avg of multiple zero tensors shared to multiple workers.
Works fine with `num = 2`.

```
num = 10
wks = [ sy.VirtualWorker(hook, id=""wk#%d"" % i) for i in range(num) ]
tensors = [ torch.zeros(5, 5).fix_prec(precision_fractional=16).share(*wks) for _ in range(num) ]
avg = tensors[0]
for i in range(num-1):
  avg += tensors[i+1]
avg /= len(tensors)
avg = avg.get().float_prec()
print(avg)

tensor([[ 1.0000e-16, -1.8447e+02, -1.8447e+02, -1.8447e+02, -1.8447e+02],
        [ 1.8447e+02,  9.2234e+01,  1.8447e+02, -1.8447e+02,  9.2234e+01],
        [ 1.8447e+02,  1.8447e+02,  0.0000e+00, -1.8447e+02,  1.8447e+02],
        [ 1.0000e-16, -1.8447e+02, -1.8447e+02,  1.8447e+02, -1.0000e-16],
        [ 1.8447e+02,  1.0000e-16,  0.0000e+00,  1.8447e+02, -1.8447e+02]])
```

Expected is tensor of zeros.
@vvmnnnkv, Division in FixedPrecisionTensor is not even implemented. @Jasopaum, maybe division by integer is a nice feature to be implemented soon.@Jasopaum A big problem with operations between more than 2 ast's is that when recombining each of them there is a greater likelyhood in losing precision in the least significant bit. An intuitive way to think about this problem is to think of the last digit as a float which adds up to 1 but is rounded. For the n=2 case, unless you split the number such that both are exactly equal to 0.5, one of the numbers will round to 1 and the other to 0. However, when n>2, it is likely that all will round to 0 leading to a loss in precisionWe actually used to have test for this which was super flakey due to the above instability@joseilberto, I think we left out the division for FixedPrecisionTensor on purpose, to avoid a loss of precision when division isn't exact... But I'm not sure why we couldn't have something like a floor division, you're right. Maybe @LaRiffle knows a bit more about FixedPrecisionTensors?@joseilberto we'd love to have division with fixed_precision! We haven't had a use case yet where division by a FixedPrecision divisor was needed, we only needed integer division, that's why you don't see an implementation so far.

One thing to notice, is that for example if you don't see a method (like `__truediv__`) in precision.py it doesn't mean it's not implemented, it means that the basic PyTorch behaviour will be used. For integer division for example you don't need to specify a specific behaviour different from PyTorch.
@LaRiffle, I do understand that what it does is exactly use whatever comes from the inheritance (that is why I suggested using the in-place multiplication operator and it works properly). In the division by integer case, we are constrained by the precision_fractional we have set and it performs poorly if we need more precision just as pointed by @vvmnnnkv. Hey yes you're right, but this is linked to the additive sharing part not the fixed_precision: take the same example  from @vvmnnnkv and remove .share() and .get() it will work

So as a **recap**  we have issues with additive shared tensor with mul or div with integers with n>2 workersIs there any update on this issue? Multiplying and dividing tensors by integers is a pretty common operation, and it took me a while to understand why `torch.mean` returned an absurd value when working with n>=3 workers.We just had a great PR merged (#2982) which will help for this issue which is still open!
https://github.com/OpenMined/PySyft/pull/3148 also adresses secure comparison for more workers, but @artix41 if yoy're willing to do the checks for multiplication & addition I'd be very graeful!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",16,2019-07-08 10:22:26,2020-07-02 00:08:35,2020-07-02 00:08:35
https://github.com/OpenMined/PySyft/issues/2333,['bug '],Multiple workers with same id issues,"Multiple workers with same id issues**Describe the bug**
When multiple workers with the same id are declared, we observe some weird behaviour.
Could be just raise an Error when this happen? Alternatively, handle this in a consistent way.

**To Reproduce**
```python
import torch
import syft as sy
hook = sy.TorchHook(torch)

worker = sy.VirtualWorker(hook, id=""worker"")
worker.clear_objects()
ptr = torch.tensor([1,2,3]).send(worker)
print(worker._objects) # >>> Has 1 object!

worker = sy.VirtualWorker(hook, id=""worker"")
worker.clear_objects()
ptr = torch.tensor([1,2,3]).send(worker)
print(worker._objects) # >>> Empty!
```@LaRiffle I would like to take this up.Sure!",2,2019-07-04 07:32:27,2019-07-09 19:48:18,2019-07-09 19:48:18
https://github.com/OpenMined/PySyft/issues/2332,[],classification error,"classification error![image](https://user-images.githubusercontent.com/11493656/60638150-cff42600-9e4f-11e9-8a31-7b34084f636a.png)

The execution in part13 is OK, but the classification results are wrong. How can I fix it? Thank you very much.Hey @keenlykeenly,

I don't think this is an issue since the model is randomly initialized it's possible that it could classify the first images wrong. Having said that I'll close the issue for now.

But maybe is not a coincidence that it classified all images as zeros, have you trained the model? Can you check how your model classifies other images from the test set?

Thanks!",1,2019-07-04 03:37:39,2019-07-04 16:08:25,2019-07-04 16:08:25
https://github.com/OpenMined/PySyft/issues/2313,"['bug ', 'status: stale :bread:']",Transform ToTensor() on BaseDataset automatically executes get(),"Transform ToTensor() on BaseDataset automatically executes get()**Describe the bug**
Iterating with `FederatedDataLoader` on a federated dataset with `transforms.ToTensor()` will return the raw data tensor instead of a pointer to the tensor.

**To Reproduce**
Steps to reproduce the behavior:

This is a working script that demonstrates the issue.
```python
import torch as th
import syft as sy
import torchvision
from torchvision import transforms

hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

# DECLARE A TOY DATASET AS IMAGE DATA
data = th.tensor([[[1,1],[0,1],[1,0],[0,0]],[[1,1],[0,1],[1,0],[0,0]],[[1,1],[0,1],[1,0],[0,0]],[[1,1],[0,1],[1,0],[0,0]]]).type(th.uint8)
target = th.tensor([[1],[1], [0], [0]])

# DECLARE TRANSFORM WITH TOTENSOR
transform = transforms.ToTensor()

# SPLIT THE DATASET AND SEND TO WORKERS
bob_dataset = sy.BaseDataset(data[:2], target[:2], transform=transform).send(bob)
alice_dataset = sy.BaseDataset(data[2:], target[2:], transform=transform).send(alice)

# DECLARE THE FEDERATED DATASET AND DATALOADER
f_dataset = sy.FederatedDataset([bob_dataset, alice_dataset])
f_dataloader = sy.FederatedDataLoader(f_dataset, shuffle=True, batch_size=2)

# GET A BATCH FORM THE DATALOADER
data, label = next(iter(f_dataloader))  # This batch should be returned as pointers to the tensors


print(data) # UNEXPECTED: returns the raw data without using get()
print(label) # EXPECTED: returns the pointer to the tensor

```

**Expected behavior**
transforms should be run remotely and `FederatedDataLoader` should return the pointer to the remote data.

Specifically:
`data` should be a pointer tensor and not the data tensor itself.

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.1
 - Version `syft==0.1.19a1`

I think as of now, Transforms cannot be applied to Pointer, Fixed Precision or Float Precision tensors. @mari-linhares, If you guys are planning to extend the Transforms to Pointer, Fixed Precision or Float Precision, I would like to get involved.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",2,2019-06-26 17:56:45,2020-05-25 00:08:28,2020-05-25 00:08:28
https://github.com/OpenMined/PySyft/issues/2310,[],Travis build error: setuptools>=41.0.0 is required by {'tensorboard'},"Travis build error: setuptools>=41.0.0 is required by {'tensorboard'}There is a very frequent error while building Travis. We need to restart the build, which is time consuming and also impossible when not granted the appropriate rights.

```
...
$ python setup.py install >> build.log
zip_safe flag not set; analyzing archive contents...
error: setuptools 38.2.4 is installed but setuptools>=41.0.0 is required by {'tensorboard'}
The command ""python setup.py install >> build.log"" failed and exited with 1 during .
Your build has been stopped.
```

We need to relaunch the build several times to have it working, how can we fix this issue related to tensorboard?I fixed it putting a requirement setuptool>=41.0.0 in requirements_dev.txt
Code contained in PR on tf_encrypted dependency removalAwesome!Code merged into dev",3,2019-06-25 12:33:19,2019-06-25 19:24:43,2019-06-25 19:24:43
https://github.com/OpenMined/PySyft/issues/2282,[],Import syft on Azure databricks for secure model serving with Syft Keras,"Import syft on Azure databricks for secure model serving with Syft Keras**Describe the bug**
Dear all,
I'm working on Azure Databricks want to try out install syft and encounter error log like bellow
`Collecting pip
  Using cached https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl
Installing collected packages: pip
  Found existing installation: pip 10.0.1
    Uninstalling pip-10.0.1:
      Successfully uninstalled pip-10.0.1
Successfully installed pip-19.1.1
DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.
Collecting syft
  Downloading https://files.pythonhosted.org/packages/56/ba/12753b3ef01a4b4cd6bba6326001b1ac9d372155828f935c198dbb092c1a/syft-0.1.18.tar.gz (136kB)
    ERROR: Complete output from command python setup.py egg_info:
    ERROR: Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/tmp/pip-install-b0P0kB/syft/setup.py"", line 15, in <module>
        requirements = read(""requirements.txt"").split()
      File ""/tmp/pip-install-b0P0kB/syft/setup.py"", line 12, in read
        return open(os.path.join(os.path.dirname(__file__), fname)).read()
    IOError: [Errno 2] No such file or directory: '/tmp/pip-install-b0P0kB/syft/requirements.txt'
    ----------------------------------------
ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-install-b0P0kB/syft/`
**Expected behavior**
Hope I can import syft and secure model serving with Syft Keras
successfully on Azure Databricks

**Screenshots**
If applicable, add screenshots to help explain your problem.
![87](https://user-images.githubusercontent.com/8589224/59495146-493bd100-8ec1-11e9-9430-8c2a976211c3.png)


**Azure Databricks (please complete the following information):**
![2](https://user-images.githubusercontent.com/8589224/59495195-5e186480-8ec1-11e9-950e-fad11894e071.png)
PYSPARK_PYTHON=/databricks/python3/bin/python3
@Polarbeargo You are trying to install syft on python 2. Syft only supports python 3Thank you @robert-wagner ðŸ‘ !",2,2019-06-14 08:41:41,2019-07-01 06:18:56,2019-06-24 21:52:45
https://github.com/OpenMined/PySyft/issues/2281,"['bug ', 'help wanted :wave:', 'status: stale :bread:']",All tests calling start_proc fail on windows,"All tests calling start_proc fail on windows**Describe the bug**
Start proc does not succeed on windows causing 9 tests to fail
**To Reproduce**
Call make test on windows

**Expected behavior**
Tests should work on all operating systems
**Desktop (please complete the following information):**
 - OS: windows
 - Version: all

**Additional context**

[-.txt](https://github.com/OpenMined/PySyft/files/3286916/-.txt)

I would like to take this up if this is still available.On Windows the web socket client also fails to connect giving the error below. 

OverflowError: timeout doesn't fit into C timeval

Appears to be due to the timeout interval (TIMEOUT_INTERVAL = 9_999_999) specified in websocket_client.py.I saw the PR ""[WIP] Implement start_remote_worker #2345"" where its mentioned that start_proc would get replaced with start_remote_worker. Hence, wanted to check if this issue is still valid and needs to be worked upon?Hey @amit-rastogi,

The new function actually uses `start_proc`, so yes, this issue is still valid.The web socket client overflow error on windows has been addressed by https://github.com/OpenMined/PySyft/pull/2395 This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",6,2019-06-13 15:24:31,2020-05-25 00:08:32,2020-05-25 00:08:32
https://github.com/OpenMined/PySyft/issues/2279,"['bug ', 'help wanted :wave:', 'good first issue :mortar_board:', 'testing ', 'status: stale :bread:']",3 Tests fail when local worker is verbose,"3 Tests fail when local worker is verbose**Describe the bug**
When hook.local_worker is set to verbose the following errors occur

```
FAILED test/torch/test_hook.py::test_RNN_grad_set_backpropagation - RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 57 and 128 in dimension 1 at ../aten/src/TH/generic/THTensor.cpp:711
FAILED test/torch/tensors/test_additive_shared.py::test_max - RuntimeError: Error, Please consider calling "".get"" method instead of "".item"" method, so you can be safely getting the item you need.
FAILED test/torch/tensors/test_additive_shared.py::test_argmax - RuntimeError: Error, Please consider calling "".get"" method instead of "".item"" method, so you can be safely getting the item you need.
```

**To Reproduce**
In test/conftest.py 
put the line `hook.local_worker.verbose=True` in the hook function

**Expected behavior**
Tests should pass regardless of if they are printing output

@robert-wagner I've had a discussion about this with @IonesioJunior some time ago, we think this is due to the fact that garbage collector ""gets stuck"" since every time you're printing something you're creating a new reference to it, that tries to be deleted but then is printed again, ... and so onHaving said that, if our intuition is right I'm not sure how easy is to get this fixedHello, please is anyone working on this. 
I will like to give it a try. ThanksI don't think so, you're very much welcome!@LaRiffle Is anyone working on this? Can I start working on this?This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",7,2019-06-12 19:37:02,2020-05-25 00:08:33,2020-05-25 00:08:33
https://github.com/OpenMined/PySyft/issues/2275,[],Error in Introduction-to-TrainConfig tutorial,"Error in Introduction-to-TrainConfig tutorial**Describe the bug**
I am trying to run the tutorial [Introduction to TrainConfig](https://github.com/OpenMined/PySyft/blob/train-config-rebase/examples/tutorials/advanced/Federated%20Learning%20with%20TrainConfig/Introduction%20to%20TrainConfig.ipynb), but I am getting an error in the following tep :
Step --> **Send TrainConfig to worker**

**Actual Error** --> `TypeError: Cannot serialize <torch._C.Function object at 0x133459af0>
`
```python
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-11-dbfb7bd00645> in <module>
      1 # Send train config
----> 2 train_config.send(alice)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/federated/train_config.py in send(self, location)
    117 
    118         # Send loss function
--> 119         self.loss_fn_ptr, self._loss_fn_id = self._wrap_and_send_obj(self.loss_fn, location)
    120 
    121         # Send train configuration itself

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/federated/train_config.py in _wrap_and_send_obj(self, obj, location)
     94         """"""Wrappers object and send it to location.""""""
     95         obj_with_id = pointers.ObjectWrapper(id=sy.ID_PROVIDER.pop(), obj=obj)
---> 96         obj_ptr = self.owner.send(obj_with_id, location)
     97         obj_id = obj_ptr.id_at_location
     98         return obj_ptr, obj_id

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/workers/base.py in send(self, obj, workers, ptr_id, local_autograd, preinitialize_grad)
    333             pointer = obj
    334         # Send the object
--> 335         self.send_obj(obj, worker)
    336 
    337         return pointer

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/workers/base.py in send_obj(self, obj, location)
    504                 receive the object.
    505         """"""
--> 506         return self.send_msg(codes.MSGTYPE.OBJ, obj, location)
    507 
    508     def request_obj(self, obj_id: Union[str, int], location: ""BaseWorker"") -> object:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/workers/base.py in send_msg(self, msg_type, message, location)
    218 
    219         # Step 1: serialize the message to simple python objects
--> 220         bin_message = sy.serde.serialize(message)
    221 
    222         # Step 2: send the message and wait for a response

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/serde.py in serialize(obj, simplified, force_no_compression, force_no_serialization, force_full_simplification)
    131         return simple_objects
    132     else:
--> 133         binary = msgpack.dumps(simple_objects)
    134 
    135     # 3) Compress

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
     44     See :class:`Packer` for options.
     45     """"""
---> 46     return Packer(**kwargs).pack(o)
     47 
     48 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/fallback.py in pack(self, obj)
    898     def pack(self, obj):
    899         try:
--> 900             self._pack(obj)
    901         except:
    902             self._buffer = StringIO()  # force reset

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/fallback.py in _pack(self, obj, nest_limit, check, check_type_strict)
    885                 self._pack_array_header(n)
    886                 for i in xrange(n):
--> 887                     self._pack(obj[i], nest_limit - 1)
    888                 return
    889             if check(obj, dict):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/fallback.py in _pack(self, obj, nest_limit, check, check_type_strict)
    885                 self._pack_array_header(n)
    886                 for i in xrange(n):
--> 887                     self._pack(obj[i], nest_limit - 1)
    888                 return
    889             if check(obj, dict):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/fallback.py in _pack(self, obj, nest_limit, check, check_type_strict)
    885                 self._pack_array_header(n)
    886                 for i in xrange(n):
--> 887                     self._pack(obj[i], nest_limit - 1)
    888                 return
    889             if check(obj, dict):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/fallback.py in _pack(self, obj, nest_limit, check, check_type_strict)
    885                 self._pack_array_header(n)
    886                 for i in xrange(n):
--> 887                     self._pack(obj[i], nest_limit - 1)
    888                 return
    889             if check(obj, dict):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/fallback.py in _pack(self, obj, nest_limit, check, check_type_strict)
    894                 default_used = 1
    895                 continue
--> 896             raise TypeError(""Cannot serialize %r"" % (obj, ))
    897 
    898     def pack(self, obj):

TypeError: Cannot serialize <torch._C.Function object at 0x133459af0>
```


**To Reproduce**
Follow the steps in the tutorial sequentially.

**Reference Screenshots**

![screencapture-localhost-8888-notebooks-Introduction-to-TrainConfig-ipynb-2019-06-12-17_23_58 (1)](https://user-images.githubusercontent.com/22014979/59364385-0fd75a00-8d37-11e9-9588-e62b35950efe.png)



**Desktop (please complete the following information):**

     System Version:	macOS 10.14.4 (18E226)
     Kernel Version:	Darwin 18.5.0
     Boot Volume:	Coyote_HD
     Boot Mode:	Normal
     torch                1.1.0   
     torchvision          0.3.0
     syft                0.1.18
     python           Python 3.7.3 (default, Mar 27 2019, 16:54:48) 


Thank you !Hey @akaanirban,

There is an error in torch 1.1 (check https://github.com/pytorch/pytorch/issues/20017 for details), if you downgrade torch to 1.0.1 should work as expected :blush: .I can confirm this works with torch 1.0.1. Thanks a lot for the reply. 

But any new installation of pysyft 0.1.18 has dependency of torch>=1.1.0. Anybody trying this with fresh installation might have issues. :smiley:@mari-linhares , the vanilla tutorial worked flawlessly. However, I tried modifying the script for training MNIST model where the remote device contains the dataset, instead of sending/federating data to workers from the central scheduler. 

I am in Torch 1.0.1, the vanilla TrainConfig tutorial works. But when I try to use a CNN model , I get the following error : 

![screencapture-localhost-8888-notebooks-TrainConfigMnist-ipynb-2019-06-13-18_06_43](https://user-images.githubusercontent.com/22014979/59449066-ae7ebc00-8e06-11e9-83ec-ee834a840fd7.jpg)

Any idea why this is happening?

Thanks in advance.Hey @akaanirban from this part of the notebook I'm not sure what can be wrong, can you send the file so I can try to execute it?

Also, maybe @midokura-silvia can help, she's the author of this PR that uses MNIST with train config for async federated training https://app.reviewnb.com/OpenMined/PySyft/pull/2217/files/@mari-linhares  and @midokura-silvia I saw the PR. I am so excited about it. That was exactly what I was trying to do (though not the async part). 

Now, @midokura-silvia's branch has torch>=1.1.0 and torchvision>=0.3.0. I tried with both combinations of (torch1.1.0+torchvision0.3) and (torch1.0.1 +torchvision0.2.2 , because of the bug mentioned in this tracker). I get error in both. Results of the following two cases:

**1. Torch 1.1.0, torchvision 0.3 ==>** I am getting the error mentioned in this bug. `TypeError: Cannot serialize <torch._C.Function object at 0x134a7c2b0>`, and also while converting the loss function to jit trace, I get the error 
```python
# Loss function 
@torch.jit.script
def loss_fn(output, target):
    return F.nll_loss(output, target)
type(loss_fn)
---------------------------------------------------------------------------
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/annotations.py in parse_type_line(type_line)
     94     try:
---> 95         arg_ann = eval(arg_ann_str, _eval_env)
     96     except (NameError, SyntaxError) as e:

<string> in <module>

NameError: name 'Optional' is not defined

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-14-9fce5d7056f9> in <module>
      1 # Loss function
----> 2 @torch.jit.script
      3 def loss_fn(output, target):
      4     return F.nll_loss(output, target)
      5 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py in script(obj, optimize, _frames_up, _rcb)
    822     else:
    823         ast = get_jit_def(obj)
--> 824         fn = torch._C._jit_script_compile(ast, _rcb, get_default_args(obj))
    825         # Forward docstrings
    826         fn.__doc__ = obj.__doc__

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/annotations.py in get_signature(fn)
     53         return None
     54 
---> 55     return parse_type_line(type_line)
     56 
     57 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/annotations.py in parse_type_line(type_line)
     95         arg_ann = eval(arg_ann_str, _eval_env)
     96     except (NameError, SyntaxError) as e:
---> 97         raise RuntimeError(""Failed to parse the argument list of a type annotation: {}"".format(str(e)))
     98 
     99     if not isinstance(arg_ann, tuple):

RuntimeError: Failed to parse the argument list of a type annotation: name 'Optional' is not defined
```
The following is the file related to this version. [Jupyter Notebook LINK](https://colab.research.google.com/drive/1HAFPxIJQ6uVttVdyYRq6lonBqJ5i7nCT) I have put it on google colab with the results. The results in the notebook are from running it on my laptop. 

**2. Torch 1.0.1, torchvision 0.2.2 ==>** To address the problem described in the original bug for this issue, I downgraded to 1.0.1,  but then the vanilla tutorial works. But a MNIST related CNN throws the following error : 
```python
traced_model = torch.jit.trace(model, data)
---------------------------------------------------------------------------
---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    157         # Run it
--> 158         new_args = args_hook_function(args)
    159 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in three_fold(lambdas, args, **kwargs)
    511     return (
--> 512         lambdas[0](args[0], **kwargs),
    513         lambdas[1](args[1], **kwargs),

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-10-1e5257ea3eb4> in <module>
      1 # Create the trace jit version
----> 2 traced_model = torch.jit.trace(model, data)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py in trace(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace)
    634     var_lookup_fn = _create_interpreter_name_lookup_fn(0)
    635     module._create_method_from_trace('forward', func, example_inputs,
--> 636                                      var_lookup_fn, _force_outplace)
    637 
    638     # Check the trace against new traces created from user-specified inputs

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    485             hook(self, input)
    486         if torch._C._get_tracing_state():
--> 487             result = self._slow_forward(*input, **kwargs)
    488         else:
    489             result = self.forward(*input, **kwargs)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)
    475         tracing_state._traced_module_stack.append(self)
    476         try:
--> 477             result = self.forward(*input, **kwargs)
    478         finally:
    479             tracing_state.pop_scope()

<ipython-input-7-ca434fff0989> in forward(self, x)
     10     def forward(self, x):
     11         x = F.relu(self.conv1(x))
---> 12         x = F.max_pool2d(x, 2, 2)
     13         x = F.relu(self.conv2(x))
     14         x = F.max_pool2d(x, 2, 2)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    703             cmd_name = f""{attr.__module__}.{attr.__name__}""
    704             command = (cmd_name, None, args, kwargs)
--> 705             response = TorchTensor.handle_func_command(command)
    706             return response
    707 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in <module>

AttributeError: module 'torch._jit_internal' has no attribute 'native_fn'
```
The following is the file related to this version. [Jupyter Notebook LINK](https://colab.research.google.com/drive/1h_hRMxSz9L1k7FkgzVAcMfzi24YIl7xA).

@midokura-silvia since you submitted the PR, it would be very helpful if you could please let me know what configuration should work (like torch version/torchvision/syft version combination) . I tried both and getting these error. 

For relevance, this is my system information:
```
System Version:	macOS 10.14.4 (18E226)
 Kernel Version:	Darwin 18.5.0
 Boot Volume:	Coyote_HD
 Boot Mode:	Normal
 syft                0.1.18
 python           Python 3.7.3 (default, Mar 27 2019, 16:54:48) 
```

Thanks a lot. You folks are doing an excellent job here ðŸ˜ƒ Please let me know if we can take this offline. It makes no sense to continue this chain on a closed issue tracker. Also I apologise if these errors are due to some stupid mistake I am making somewhere you can spot.I am using torch==1.0.1 and torchvision==0.2.2.post3. torch=1.1.0 will not work. Will take a look at your issue later, latest Monday.
@midokura-silvia @mari-linhares  It is working now. I installed pysyft from the pull request commit in midokura's fork. Seems like, there were several other changes in the pull request which were not in the dev version, but were needed in order for the example to run. This is probably why it was not working. 

It'll be great when it is merged with the master branch. Thanks a lot for your help.Should this issue be reopened? I still get `TypeError: can not serialize 'torch._C.Function' object` with Torch 1.1. 
Or TrainConfig still only works with Torch 1.0.1? @midokura-silvia @mari-linhares 

Thanks!",8,2019-06-12 15:25:59,2019-10-30 19:19:34,2019-06-12 18:14:14
https://github.com/OpenMined/PySyft/issues/2273,['bug '],AttributeError: 'int' object has no attribute 'is_wrapper',"AttributeError: 'int' object has no attribute 'is_wrapper'**Describe the bug**
Execute Part 11 - Secure Deep Learning Classification.ipynb ecounter ""AttributeError: 'int' object has no attribute 'is_wrapper'""

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'examples/tutorials/Part 11 - Secure Deep Learning Classification.ipynb'
2. Click on 'run all'
3. Scroll down to 'cell 17 test(args, model, private_test_loader)'
4. See error 

**Expected behavior**
No error here:).
**Screenshots**
![1](https://user-images.githubusercontent.com/8589224/59334626-7fe0e280-8d2d-11e9-9c9b-e556e3c1d099.png)
**Desktop (please complete the following information):**
 On Google colaboratory
Hey, indeed there is a bug in our last release 0.1.18 when operating with constant values, I'm working on a fix right now.@LaRiffle Thank you:)! I appreciate your help.#2274 should solve
It will be merged very soon so if you can build the code from source in your colab you should benefit from it quickly, otherwise the 1.19 release will arrive in a few days. :)Thank you @LaRiffle!For information, this is my config to build and run the latest code from PySyft on Colab:
```
!pip install tf-encrypted

! URL=""https://github.com/openmined/PySyft.git"" && FOLDER=""PySyft"" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;

!cd PySyft; python setup.py install  > /dev/null

import os
import sys
module_path = os.path.abspath(os.path.join('./PySyft'))
if module_path not in sys.path:
    sys.path.append(module_path)

!pip install --upgrade --force-reinstall lz4
!pip install --upgrade --force-reinstall websocket
!pip install --upgrade --force-reinstall websockets
!pip install --upgrade --force-reinstall zstd
```

I'm sure this is sub optimal, but it works ;)",5,2019-06-12 08:20:14,2019-06-12 12:15:35,2019-06-12 12:15:35
https://github.com/OpenMined/PySyft/issues/2267,[],Bug in Federated Learning on MNIST using a CNN Example,"Bug in Federated Learning on MNIST using a CNN Example**Describe the bug**
Error on FederatedDataLoader step while running [Federated Learning on MNIST using a CNN](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%206%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb)

**To Reproduce**
![image](https://user-images.githubusercontent.com/17871166/59260179-ca445f80-8c58-11e9-81b6-9fd32f866a51.png)



**Error**
---------------------------------------------------------------------------
```
KeyError                                  Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    144         # TODO rename registry or use another one than for methods
--> 145         hook_args = hook_method_args_functions[attr]
    146         get_tensor_type_function = get_tensor_type_functions[attr]

KeyError: 'torch.as_tensor'

During handling of the above exception, another exception occurred:

IndexError                                Traceback (most recent call last)
<ipython-input-5-4085cd6569bc> in <module>
      5                        transforms.Normalize((0.1307,), (0.3081,))
      6                    ]))
----> 7     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
      8     batch_size=args.batch_size, shuffle=True, **kwargs)
      9 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/federated/dataset.py in dataset_federate(dataset, workers)
    159     datasets = []
    160     data_loader = torch.utils.data.DataLoader(dataset, batch_size=data_size)
--> 161     for dataset_idx, (data, targets) in enumerate(data_loader):
    162         worker = workers[dataset_idx % len(workers)]
    163         logger.debug(""Sending data to worker %s"", worker.id)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    558         if self.num_workers == 0:  # same-process loading
    559             indices = next(self.sample_iter)  # may raise StopIteration
--> 560             batch = self.collate_fn([self.dataset[i] for i in indices])
    561             if self.pin_memory:
    562                 batch = _utils.pin_memory.pin_memory_batch(batch)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/utils/data/dataloader.py in <listcomp>(.0)
    558         if self.num_workers == 0:  # same-process loading
    559             indices = next(self.sample_iter)  # may raise StopIteration
--> 560             batch = self.collate_fn([self.dataset[i] for i in indices])
    561             if self.pin_memory:
    562                 batch = _utils.pin_memory.pin_memory_batch(batch)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/datasets/mnist.py in __getitem__(self, index)
     93 
     94         if self.transform is not None:
---> 95             img = self.transform(img)
     96 
     97         if self.target_transform is not None:

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, img)
     59     def __call__(self, img):
     60         for t in self.transforms:
---> 61             img = t(img)
     62         return img
     63 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, tensor)
    162             Tensor: Normalized Tensor image.
    163         """"""
--> 164         return F.normalize(tensor, self.mean, self.std, self.inplace)
    165 
    166     def __repr__(self):

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torchvision/transforms/functional.py in normalize(tensor, mean, std, inplace)
    204         tensor = tensor.clone()
    205 
--> 206     mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)
    207     std = torch.as_tensor(std, dtype=torch.float32, device=tensor.device)
    208     tensor.sub_(mean[:, None, None]).div_(std[:, None, None])

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    197             # Note that we return also args_type which helps handling case 3 in the docstring
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )
    201             # This handles case 3: it redirects the command to the appropriate class depending

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    150     except (IndexError, KeyError, AssertionError):  # Update the function in case of an error
    151         args_hook_function, get_tensor_type_function = build_hook_args_function(
--> 152             args, return_tuple=True
    153         )
    154         # Store the utility functions in registries

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in build_hook_args_function(args, return_tuple)
    180     # Build a function with this rule to efficiently the child type of the
    181     # tensor found in the args
--> 182     get_tensor_type_function = build_get_tensor_type(rule)
    183     return args_hook_function, get_tensor_type_function
    184 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in build_get_tensor_type(rules, layer)
    409 
    410     if first_layer:
--> 411         return lambdas[0]
    412     else:
    413         return lambdas

IndexError: list index out of range
```



**Desktop:**
 - OS: Ubuntu 16.04
 - Python: 3.7.3
 - torch : 1.1.0
 - torchvision: 0.3.0 
 - syft: 0.1.16a1
 - No GPU or Cuda
Issue is solved by moving to `torch==1.0.1` and `torchvision==0.2.2`Will be solved in syft>=0.1.18 (coming soon)Thanks",3,2019-06-11 09:28:58,2019-06-11 11:37:56,2019-06-11 11:37:56
https://github.com/OpenMined/PySyft/issues/2265,"['bug ', 'status: stale :bread:']",AttributeError: 'Conv2D' object has no attribute '_batch_input_shape',"AttributeError: 'Conv2D' object has no attribute '_batch_input_shape'**Describe the bug**
AttributeError: 'Conv2D' object has no attribute '_batch_input_shape'

**To Reproduce**
In Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving, I encounter the next problem when execeute ""model.share(alice, bob, carol)"":

**Screenshots**
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-7-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    116     for keras_layer in keras_model.layers:
    117         tfe_layer = _instantiate_tfe_layer(keras_layer, stored_keras_weights)
--> 118         tfe_model.add(tfe_layer)
    119 
    120         if hasattr(tfe_layer, ""_batch_input_shape""):

d:\programdata\anaconda3\tf-encrypted\tf_encrypted\keras\models\sequential.py in add(self, layer)
     42                          ""tfe.keras.Sequential model."")
     43 
---> 44       batch_shape = layer._batch_input_shape  # pylint: disable=protected-access
     45 
     46       # Instantiate an input layer.

AttributeError: 'Conv2D' object has no attribute '_batch_input_shape'


**Desktop (please complete the following information):**
 - OS: [Windows 7 64 bits]
In anaconda3, python 3.6.4
 - Version [In anaconda3, python 3.6.4]

**Additional context**
I have updated the tf-encrypted to version 0.5.5 from source and reinstalled pysyft from pip.
Hi @keenlykeenly, unfortunately I was unable to reproduce your bug with the information provided -- when I try the notebook it works smoothly on both the pip package and the dev branch.  Did you change any code in the notebook?

It looks like your version of PySyft is slightly out of date though, you're using syft-0.1.15a1, while the current version from pip should be syft-0.1.17.  I recommend reinstalling with `pip install -U syft` in your environment and retrying this notebook.  Hope that helps!I update the syft as you suggest using pip install -U syft==0.1.17. 
And the version information is as follows .

Requirement already up-to-date: syft==0.1.17 in d:\programdata\anaconda3\lib\site-packages (0.1.17)
Requirement already satisfied, skipping upgrade: torchvision in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (0.2.2)
Requirement already satisfied, skipping upgrade: sklearn in d:\programdata\anaconda3\lib\site-packages\sklearn-0.0-py3.6.egg (from syft==0.1.17) (0.0)
Requirement already satisfied, skipping upgrade: zstd in d:\programdata\anaconda3\lib\site-packages\zstd-1.4.0.0-py3.6-win-amd64.egg (from syft==0.1.17) (1.4.0.0)
Requirement already satisfied, skipping upgrade: lz4 in d:\programdata\anaconda3\lib\site-packages\lz4-2.1.6-py3.6-win-amd64.egg (from syft==0.1.17) (2.1.6)
Requirement already satisfied, skipping upgrade: tf-encrypted>=0.5.4 in d:\programdata\anaconda3\tf-encrypted (from syft==0.1.17) (0.5.5)
Requirement already satisfied, skipping upgrade: websockets>=7.0 in d:\programdata\anaconda3\lib\site-packages\websockets-7.0-py3.6-win-amd64.egg (from syft==0.1.17) (7.0)
Requirement already satisfied, skipping upgrade: torch>=1.0.1 in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (1.0.1)
Requirement already satisfied, skipping upgrade: flask-socketio in d:\programdata\anaconda3\lib\site-packages\flask_socketio-4.0.0-py3.6.egg (from syft==0.1.17) (4.0.0)
Requirement already satisfied, skipping upgrade: tblib in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (1.4.0)
Requirement already satisfied, skipping upgrade: msgpack in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (0.6.1)
Requirement already satisfied, skipping upgrade: websocket-client in d:\programdata\anaconda3\lib\site-packages\websocket_client-0.56.0-py3.6.egg (from syft==0.1.17) (0.56.0)
Requirement already satisfied, skipping upgrade: Flask in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (1.0.3)
Requirement already satisfied, skipping upgrade: numpy in d:\programdata\anaconda3\lib\site-packages (from torchvision->syft==0.1.17) (1.16.4)
Requirement already satisfied, skipping upgrade: six in c:\users\administrator\appdata\roaming\python\python36\site-packages (from torchvision->syft==0.1.17) (1.11.0)
Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in d:\programdata\anaconda3\lib\site-packages (from torchvision->syft==0.1.17) (6.0.0)
Requirement already satisfied, skipping upgrade: scikit-learn in d:\programdata\anaconda3\lib\site-packages (from sklearn->syft==0.1.17) (0.19.1)
Requirement already satisfied, skipping upgrade: tensorflow<2,>=1.12.0 in d:\programdata\anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg (from tf-encrypted>=0.5.4->syft==0.1.17) (1.14.0rc0)
Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in d:\programdata\anaconda3\lib\site-packages (from tf-encrypted>=0.5.4->syft==0.1.17) (5.1)
Requirement already satisfied, skipping upgrade: python-socketio>=2.1.0 in d:\programdata\anaconda3\lib\site-packages\python_socketio-4.0.3-py3.6.egg (from flask-socketio->syft==0.1.17) (4.0.3)
Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (1.1.0)
Requirement already satisfied, skipping upgrade: Werkzeug>=0.14 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (0.15.4)
Requirement already satisfied, skipping upgrade: click>=5.1 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (7.0)
Requirement already satisfied, skipping upgrade: Jinja2>=2.10 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (2.10.1)
Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in d:\programdata\anaconda3\lib\site-packages\absl_py-0.7.1-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.7.1)
Requirement already satisfied, skipping upgrade: astor>=0.6.0 in d:\programdata\anaconda3\lib\site-packages\astor-0.8.0-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.8.0)
Requirement already satisfied, skipping upgrade: gast>=0.2.0 in d:\programdata\anaconda3\lib\site-packages\gast-0.2.2-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.2.2)
Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in d:\programdata\anaconda3\lib\site-packages\google_pasta-0.1.7-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.1.7)
Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in d:\programdata\anaconda3\lib\site-packages\grpcio-1.21.1-py3.6-win-amd64.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.21.1)
Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in d:\programdata\anaconda3\lib\site-packages\keras_applications-1.0.8-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.0.8)
Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in d:\programdata\anaconda3\lib\site-packages\keras_preprocessing-1.0.9-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.0.9)
Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in d:\programdata\anaconda3\lib\site-packages\protobuf-3.8.0-py3.6-win-amd64.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (3.8.0)
Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in d:\programdata\anaconda3\lib\site-packages\tensorboard-1.13.1-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.13.1)
Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in d:\programdata\anaconda3\lib\site-packages\termcolor-1.1.0-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.1.0)
Requirement already satisfied, skipping upgrade: tf-estimator-nightly<1.14.0.dev2019042302,>=1.14.0.dev2019042301 in d:\programdata\anaconda3\lib\site-packages\tf_estimator_nightly-1.14.0.dev2019042301-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.14.0.dev2019042301)
Requirement already satisfied, skipping upgrade: wheel>=0.26 in d:\programdata\anaconda3\lib\site-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.33.4)
Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in d:\programdata\anaconda3\lib\site-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.11.1)
Requirement already satisfied, skipping upgrade: python-engineio>=3.2.0 in d:\programdata\anaconda3\lib\site-packages\python_engineio-3.7.0-py3.6.egg (from python-socketio>=2.1.0->flask-socketio->syft==0.1.17) (3.7.0)
Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in d:\programdata\anaconda3\lib\site-packages (from Jinja2>=2.10->Flask->syft==0.1.17) (1.1.1)
Requirement already satisfied, skipping upgrade: h5py in d:\programdata\anaconda3\lib\site-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (2.9.0)
Requirement already satisfied, skipping upgrade: setuptools in d:\programdata\anaconda3\lib\site-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (41.0.1)
Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in d:\programdata\anaconda3\lib\site-packages\markdown-3.1.1-py3.6.egg (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (3.1.1)


But I still get the error:
AttributeError                            Traceback (most recent call last)
<ipython-input-8-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    115     for keras_layer in keras_model.layers:
    116         tfe_layer = _instantiate_tfe_layer(keras_layer, stored_keras_weights)
--> 117         tfe_model.add(tfe_layer)
    118 
    119         if hasattr(tfe_layer, ""_batch_input_shape""):

d:\programdata\anaconda3\tf-encrypted\tf_encrypted\keras\models\sequential.py in add(self, layer)
     42                          ""tfe.keras.Sequential model."")
     43 
---> 44       batch_shape = layer._batch_input_shape  # pylint: disable=protected-access
     45 
     46       # Instantiate an input layer.

AttributeError: 'Conv2D' object has no attribute '_batch_input_shape'

The only change I made is: 
config_filename = ""/tmp/tfe.config""
 in C:\Users\Administrator\Desktop\covert security\codes\PySyft-dev\PySyft-dev\syft\workers\tfe.py 
to 
config_filename = ""D:\ProgramData\Anaconda3\lib\site-packages\syft\workers\tfe.config"",
because in the windows OS the directory /tmp does not exist.

I am sorry to confuse you, maybe there are some version probloms in my notebook environment. I will check it carefully. And thank you very much for your help.Hi. I download the Pysyft you released yesterday from github and that error disappears!
But it seems abnormal and this instruction remains running for a long long time but does not move on:
![æ•èŽ·](https://user-images.githubusercontent.com/11493656/59321232-dafddf80-8d03-11e9-964a-01618c685098.PNG)


![notebook](https://user-images.githubusercontent.com/11493656/59321100-50b57b80-8d03-11e9-822f-1789241c0db8.PNG)

This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2019-06-11 02:29:56,2020-05-25 00:08:35,2020-05-25 00:08:35
https://github.com/OpenMined/PySyft/issues/2259,[],pip install syft - ZSTD errors,"pip install syft - ZSTD errorsReceived lots of ZSTD errors on OSX Mac Sierra when installing 'pip install syft' within Anaconda.  Tried the various workarounds in documentation and also tried installing from source - still had the same errors.  

Running 'conda install gcc' fixed the issue for me.  Which changed GCC in my conda environment from:

gcc --version
Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 9.0.0 (clang-900.0.39.2)
Target: x86_64-apple-darwin16.7.0
Thread model: posix

To:
gcc --version
gcc (GCC) 4.8.5

Perhaps add this work-around to documentation if it will help others.


Thanks for the indication!
Thank you.  I did see/try the 'pip install --upgrade --force-reinstall zstd' command, but it failed with similar ZSTD errors which led me to another work-around.  Just wanted to mention incase others benefit from it.  I just bumped into a lot of error with zstd on an Ubuntu 16.04 machine a few hours ago. They were solved by running:

`sudo apt-get install python3.6-dev`I share also here the install procedure I use on Google colab, which is not very clean but works for people wanting to use the last updates from `dev` branch (and their amazing bugs!)

```
!pip install tf-encrypted

! URL=""https://github.com/openmined/PySyft.git"" && FOLDER=""PySyft"" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;

!cd PySyft; python setup.py install  > /dev/null

import os
import sys
module_path = os.path.abspath(os.path.join('./PySyft'))
if module_path not in sys.path:
    sys.path.append(module_path)

!pip install --upgrade --force-reinstall lz4
!pip install --upgrade --force-reinstall websocket
!pip install --upgrade --force-reinstall websockets
!pip install --upgrade --force-reinstall zstd
```Hi I tried to install pysyft on OSX Mac Mojave and have an installation error regarding zstd

```
Requirement already satisfied: syft in ./anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.19a1-py3.7.egg (0.1.19a1)
Requirement already satisfied: Flask>=1.0.2 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.0.3)
Requirement already satisfied: flask_socketio>=3.3.2 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (4.0.0)
Requirement already satisfied: lz4>=2.1.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (2.1.6)
Requirement already satisfied: msgpack>=0.6.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.6.1)
Requirement already satisfied: numpy>=1.14.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.16.4)
Requirement already satisfied: scikit-learn>=0.21.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.21.2)
Requirement already satisfied: tblib>=1.4.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.4.0)
Requirement already satisfied: tf_encrypted>=0.5.4 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.5.4)
Requirement already satisfied: torch>=1.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.1.0)
Requirement already satisfied: torchvision>=0.3.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.3.0)
Requirement already satisfied: websocket_client>=0.56.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.56.0)
Requirement already satisfied: websockets>=7.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (7.0)
Collecting zstd>=1.4.0.0 (from syft)
  Using cached https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz
Requirement already satisfied: itsdangerous>=0.24 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (1.1.0)
Requirement already satisfied: click>=5.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (7.0)
Requirement already satisfied: Jinja2>=2.10 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (2.10.1)
Requirement already satisfied: Werkzeug>=0.14 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (0.15.4)
Requirement already satisfied: python-socketio>=2.1.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from flask_socketio>=3.3.2->syft) (4.0.3)
Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from scikit-learn>=0.21.0->syft) (0.13.2)
Requirement already satisfied: scipy>=0.17.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from scikit-learn>=0.21.0->syft) (1.3.0)
Requirement already satisfied: tensorflow<2,>=1.12.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tf_encrypted>=0.5.4->syft) (1.13.1)
Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tf_encrypted>=0.5.4->syft) (5.1)
Requirement already satisfied: six in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from torchvision>=0.3.0->syft) (1.12.0)
Requirement already satisfied: pillow>=4.1.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from torchvision>=0.3.0->syft) (6.0.0)
Requirement already satisfied: MarkupSafe>=0.23 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)
Requirement already satisfied: python-engineio>=3.2.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from python-socketio>=2.1.0->flask_socketio>=3.3.2->syft) (3.7.0)
Requirement already satisfied: gast>=0.2.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.2.2)
Requirement already satisfied: astor>=0.6.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.8.0)
Requirement already satisfied: wheel>=0.26 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.33.4)
Requirement already satisfied: grpcio>=1.8.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.21.1)
Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)
Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.13.0)
Requirement already satisfied: absl-py>=0.1.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.7.1)
Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.13.1)
Requirement already satisfied: keras-preprocessing>=1.0.5 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)
Requirement already satisfied: keras-applications>=1.0.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.0.8)
Requirement already satisfied: protobuf>=3.6.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.8.0)
Requirement already satisfied: mock>=2.0.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.0.5)
Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.1.1)
Requirement already satisfied: h5py in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (2.9.0)
Requirement already satisfied: setuptools in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (41.0.1)
Building wheels for collected packages: zstd
  Building wheel for zstd (setup.py) ... error
  ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-wheel-uan2sja0 --python-tag cp37:
  ERROR: running bdist_wheel
  running build
  running build_ext
  building 'zstd' extension
  creating build
  creating build/temp.macosx-10.7-x86_64-3.7
  creating build/temp.macosx-10.7-x86_64-3.7/zstd
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
  creating build/temp.macosx-10.7-x86_64-3.7/src
  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
  In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                   from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                   from zstd/lib/compress/zstd_compress.c:14:
  /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
   #include_next <limits.h>  /* recurse down to the real one */
                                                               ^
  compilation terminated.
  error: command 'gcc' failed with exit status 1
  ----------------------------------------
  ERROR: Failed building wheel for zstd
  Running setup.py clean for zstd
Failed to build zstd
Installing collected packages: zstd
  Running setup.py install for zstd ... error
    ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-abluqg99/install-record.txt --single-version-externally-managed --compile:
    ERROR: running install
    running build
    running build_ext
    building 'zstd' extension
    creating build
    creating build/temp.macosx-10.7-x86_64-3.7
    creating build/temp.macosx-10.7-x86_64-3.7/zstd
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
    creating build/temp.macosx-10.7-x86_64-3.7/src
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
    In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                     from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                     from zstd/lib/compress/zstd_compress.c:14:
    /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
     #include_next <limits.h>  /* recurse down to the real one */
                                                                 ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command ""/Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-abluqg99/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/
```

I also  tried `pip install --upgrade --force-reinstall zstd` command, but I have the following error.

```
 Collecting zstd
  Using cached https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz
Building wheels for collected packages: zstd
  Building wheel for zstd (setup.py) ... error
  ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-wheel-tl7z0e0e --python-tag cp37:
  ERROR: running bdist_wheel
  running build
  running build_ext
  building 'zstd' extension
  creating build
  creating build/temp.macosx-10.7-x86_64-3.7
  creating build/temp.macosx-10.7-x86_64-3.7/zstd
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
  creating build/temp.macosx-10.7-x86_64-3.7/src
  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
  In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                   from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                   from zstd/lib/compress/zstd_compress.c:14:
  /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
   #include_next <limits.h>  /* recurse down to the real one */
                                                               ^
  compilation terminated.
  error: command 'gcc' failed with exit status 1
  ----------------------------------------
  ERROR: Failed building wheel for zstd
  Running setup.py clean for zstd
Failed to build zstd
Installing collected packages: zstd
  Running setup.py install for zstd ... error
    ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-wk6c1yyz/install-record.txt --single-version-externally-managed --compile:
    ERROR: running install
    running build
    running build_ext
    building 'zstd' extension
    creating build
    creating build/temp.macosx-10.7-x86_64-3.7
    creating build/temp.macosx-10.7-x86_64-3.7/zstd
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
    creating build/temp.macosx-10.7-x86_64-3.7/src
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
    In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                     from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                     from zstd/lib/compress/zstd_compress.c:14:
    /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
     #include_next <limits.h>  /* recurse down to the real one */
                                                                 ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command ""/Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-wk6c1yyz/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/
```
The solution that worked for me on MacOS Mojave 10.14.5:

`conda create -n py3_6_3 python=3.6.3 anaconda`
`conda activate py3_6_3`
`conda install pytorch torchvision -c pytorch`
`pip install --upgrade --force-reinstall zstd`
`pip install syft`Hey @dvu4 

I'm facing the exactly similar issue on MacOS Mojave Ver 10.14.5. Were you able to find a solution to this issue?

Conda Version: `4.6.14`
Python Version in Conda environment: `python 3.7.3`

Can anyone else with a similar configuration please help me with the installation?
> I just bumped into a lot of error with zstd on an Ubuntu 16.04 machine a few hours ago. They were solved by running:
> 
> `sudo apt-get install python3.6-dev`
@DanyEle How can you do that successfully? I am on the Ubuntu16.04 too and I get the error that the zstd cannot be imported. And when I do as your guide I get the following error:

(pysyft) daisy@ubuntu:~/PySyft$ sudo apt-get install python3.6-dev
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package python3.6-dev
E: Couldn't find any package by glob 'python3.6-dev'
E: Couldn't find any package by regex 'python3.6-dev'

![image](https://user-images.githubusercontent.com/11493656/63084676-4c654300-bf7e-11e9-959a-bcc2616790f7.png)
I solved this issue by following the instructions on this page: https://discourse.mc-stan.org/t/compilation-error-in-pystan-macos-mojave/6383/3 . 
I installed the package using: 
`sudo installer -pkg  /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg -target /`. 
This was also solved by changing the gcc version to a more recent one using:
`export CC=/usr/local/Cellar/gcc/9.2.0/bin/gcc-9`
`export CFLAGS=""-Wa,-q""`
and then running:
`pip install --upgrade --force-reinstall zstd`This issue happened again on macOS Catalina and all the solutions above cannot fix it. 
Same error message as above. 
`
error: command 'gcc' failed with exit status 1
`Could you add more elements about the stacktrace? Haven't you find any useful information on stackaoverflow?@LaRiffle I fixed the issue by installing the full Xcode and reinstalling the command line tools. The command `pip install syft` works well now. Please close this issue, thanks. I had similar problems on my linux system. The problem is conda's gcc and ld conflict with the system's ones. Using a plain python virtualenvironment instead of conda solves the problem. 

I created a PR #2662 to extend the readme on this issue.Well, it seems like conda has already some zstd header files in its include directory. 
```
~/anaconda3/envs/pysyft/include/zstd.h
~/anaconda3/envs/pysyft/include/zstd_errors.h
```
When installing zstd, conda will add its include directory to gcc's search path. So when compiling zstd source file, gcc will use `zstd.h` in conda instead of its own.
The solution is simple, just move the headers somewhere else, install pysyft, and move them back.I upgraded my gcc version to 4.8.5 and also tried installing zstd using pip install --upgrade --force-reinstall zstd and also within a virtual environment. But it keeps failing with the error: command 'gcc' failed with exit status 1 error.
I'm using MacOS Mojave.
Here's the full stack trace:
gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/judytraj/anaconda3/include -arch x86_64 -I/Users/judytraj/anaconda3/include -arch x86_64 -I/Users/judytraj/env/include -I/Users/judytraj/anaconda3/include/python3.6m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.6/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.4.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
    In file included from /Users/judytraj/anaconda3/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                     from /Users/judytraj/anaconda3/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                     from zstd/lib/compress/zstd_compress.c:14:
    /Users/judytraj/anaconda3/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
     #include_next <limits.h>  /* recurse down to the real one */
                                                                 ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    
    ----------------------------------------
Command ""/Users/judytraj/env/bin/python3 -u -c ""import setuptools, tokenize;__file__='/private/var/folders/gl/nvvrj70x0jl8c_sjl8byd0580000gn/T/pip-install-53a8mopu/zstd/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /private/var/folders/gl/nvvrj70x0jl8c_sjl8byd0580000gn/T/pip-record-61j83b2i/install-record.txt --single-version-externally-managed --compile --install-headers /Users/judytraj/env/include/site/python3.6/zstd"" failed with error code 1 in /private/var/folders/gl/nvvrj70x0jl8c_sjl8byd0580000gn/T/pip-install-53a8mopu/zstd/
In order to get rid of this **_zstd_** error on **Windows**, you'll need to install a small package of Microsoft Visual C++ from [here](https://download.microsoft.com/download/5/f/7/5f7acaeb-8363-451f-9425-68a90f98b238/visualcppbuildtools_full.exe) 
After that try installing the package using `pip install syft`With conda environment on Mac, I found this to be useful for installing zstd, and ultimately using PySyft.

https://github.com/sergey-dryabzhinsky/python-zstd/issues/33#issuecomment-527252753

1. Change the gcc-version to a recent one:
`export CC=/usr/local/Cellar/gcc/9.2.XX/bin/gcc-9` (Check your gcc-version in this location before using the command)
`export CFLAGS=""-Wa,-q""`

2. Install zstd using pip. 
**Note:** If you are using a conda environment, double-check that pip is installed in that environment. :)
`pip install zstd`For information, #3150 removes zstd so starting from the next release there won't be these kinds of problems ðŸŽ‰I have installed gcc using conda and updated it to 4.8 but things did work on MacOS Mojave 10.14.6.

The solution mentioned by in  [#python-zstd](https://github.com/sergey-dryabzhinsky/python-zstd/issues/33#issuecomment-527252753) and @guptakhil12 works for me with a little modification. You just need to install the gcc using brew (if not installed) before exporting the new path. 
Following are the steps that should do the trick.

1.  Install gcc using brew 
   `brew install gcc`

2. Change the gcc-version to a recent the one installed by brew:
    `export CC=/usr/local/Cellar/gcc/9.3.0/bin/gcc-9` (**Note:** Check your gcc-version in this location before using the command)
    `export CFLAGS=""-Wa,-q""`

3. Install zstd using pip.
   `pip install zstd` (This should work now)

4. Install pysyft.
   `pip install syft[udacity]`
zstd is no longer used from release v0.2.4. I think we can close this issue for good now.",21,2019-06-10 01:32:45,2020-03-26 23:18:27,2020-03-26 23:18:27
https://github.com/OpenMined/PySyft/issues/2258,[],websockets-example-MNIST ,"websockets-example-MNIST Error while running websockets example on my macbook pro

```
=======
python ./run_websocket_server.py

=======
python ./run_websocket_client.py
Traceback (most recent call last):
  File ""./run_websocket_client.py"", line 273, in <module>
    main()
  File ""./run_websocket_client.py"", line 211, in main
    alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_client.py"", line 57, in __init__
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_core.py"", line 514, in create_connection
    websock.connect(url, **options)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_http.py"", line 120, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_http.py"", line 197, in _open_socket
    raise err
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_http.py"", line 172, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [Errno 61] Connection refused
```


```

Software:

    System Software Overview:

      System Version: macOS 10.14.5 (18F132)
      Kernel Version: Darwin 18.6.0
      Boot Volume: Macintosh HD
      Boot Mode: Normal

Python 3.7.3 (default, Jun  8 2019, 16:41:03)

In [2]: torch.__version__
Out[2]: '1.1.0'

pysyfy commit 9685467662d21bbf534af746640e19926b27c23f (HEAD -> dev, origin/dev, origin/HEAD)
````    alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket)
`
This cannot work. You need to specify a valid host for websockets. Supposing you're running this example with local workers, you may want to use:

```
kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}

alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
```

Alternatively, if you want to make use of virtual workers - which are not actually web sockets - the following would work:

`    alice = sy.VirtualWorker(hook, id=""alice"")    `
`Hello DanyEle, thanks for your answer but I am still confused. 

I am running the examples as they are provided in 

`https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/websockets-example-MNIST/README.md
`

How am I supposed to run the python commands while running both server and client on the same machine?

I have tried (in two distinct bash shells):

`>> python run_websocket_server.py --host 127.0.0.1`

and

`>> python run_websocket_client.py`

and I get 

`ConnectionRefusedError: [Errno 61] Connection refused`

What am I doing wrong?You still need to specify the port and ID of the worker. For example for Alice:

  python3 run_websocket_server.py --host 127.0.0.1 --port 8777 --id aliceOK, I think I go that part now. 
But I am now getting a different error though when running the client, which also crashes the servers:

**Error on the client side**

```
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 145, in hook_function_args
KeyError: 'torch.as_tensor'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""run_websocket_client.py"", line 273, in <module>
    main()
  File ""run_websocket_client.py"", line 233, in main
    ).federate(tuple(workers)),
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/federated/dataset.py"", line 161, in dataset_federate
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 560, in __next__
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 560, in <listcomp>
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/datasets/mnist.py"", line 95, in __getitem__
    img = self.transform(img)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/transforms/transforms.py"", line 61, in __call__
    img = t(img)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/transforms/transforms.py"", line 164, in __call__
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/transforms/functional.py"", line 206, in normalize
    mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook.py"", line 708, in overloaded_func
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py"", line 199, in handle_func_command
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 152, in hook_function_args
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 182, in build_hook_args_function
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 411, in build_get_tensor_type
IndexError: list index out of range
```

**Error on the Server side**

```
python start_websocket_servers.py
Starting server for Alice
Starting server for Bob
Starting server for Charlie
 acortis@Jeeg î‚° ï¼ ~/my_codes/testbed/PySyft/examples/tutorials/advanced/websockets-example-MNIST î‚° ï„“  ï„¦ dev ïª ï™ î‚° ERROR:asyncio:Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._consumer_handler() done, defined at /Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py:74> exception=ConnectionClosed('WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason')>
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 674, in transfer_data
    message = yield from self.read_message()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 742, in read_message
    frame = yield from self.read_data_frame(max_size=self.max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 815, in read_data_frame
    frame = yield from self.read_frame(max_size)
  File ""/Users/acortis/myERROR:asyncio:Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._consumer_handler() done, defined at /Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py:74> exception=ConnectionClosed('WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason')>
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 674, in transfer_data
    message = yield from self.read_message()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 742, in read_message
    frame = yield from self.read_data_frame(max_size=self.max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 815, in read_data_frame
    frame = yield from self.read_frame(max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
ERROR:asyncio:Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._consumer_handler() done, defined at /Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py:74> exception=ConnectionClosed('WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason')>
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 674, in transfer_data
    message = yield from self.read_message()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 742, in read_message
    frame = yield from self.read_data_frame(max_size=self.max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 815, in read_data_frame
    frame = yield from self.read_frame(max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
>....
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
zsh: parse error near `)'
```I noticed two more weird things in your configuration:

- You are using Python 3.7.3 --> Try using Python3.6 instead. I always run PySyft on Python 3.6.7. 
- You are using Pytorch 1.1.0 --> Try using Pytorch 1.0.1 instead. I don't think PySyft supports PyTorch 1.1, yet, although there are plans to port it to that version. A couple of remarks: the [readme file](https://github.com/OpenMined/PySyft) clearly states 

> PySyft supports Python >= 3.6 and PyTorch 1.1.0

Anyways, I went ahead and tried what you suggest, that is python 3.6.7, torch=1.0.1, and torchvision=0.2.2, and still does not work. 

Any further suggestions are very much appreciated. ThanksHi, thanks for reporting this error,
I believe the error was first in the client side to due `mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)`.
This a bug due to upgrading to torchvision 0.3, which was fixed in the dev branch yesterday. If you use directly the source code I'd recommend pulling and retrying you shouldn't have this error anymore (at least not this one). Alternatively check that you have indeed downgraded to torchvision to 0.2.2 (in which the line `mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)` doesn't exist).
So if you can manage to do one of these changes and report how it goes, I'd love to help further!

One last thing, indeed PySyft supports PyTorch 1.1.0 even if there are some bugs like this one that we try to solve as quickly as possible.
This should be now fixed with #2266 ENV: linux, python3.6.8, pysyft==0.1.13a1, torch==1.0.1, torchvision==0.2.2

Add the code in run_websocket_client.py:
```
kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}
alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
workers = [alice]
```

I run the lines:
python3 run_websocket_server.py --host 127.0.0.1 --port 8777 --id alice
python3 run_websocket_client.py

It shows the bug:
KeyError: (wrapper)>[PointerTensor | me:some series of numbers -> alice:some series of number]

And I change to: pysyft==0.1.19a1, torch==1.1.0, torchvision==0.3.0
It still have.

@LaRiffle @DanyEle change ""host"" to your local address like ""192.168.x.x"" (not 127.0.0.1), it works on my machine.",11,2019-06-09 21:28:31,2020-01-05 12:57:11,2019-06-12 12:19:43
https://github.com/OpenMined/PySyft/issues/2255,['bug '],AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name',"AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name'**Describe the bug**
AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name'.

**To Reproduce**
In Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving, I encounter the next problem when execeute ""model.share(alice, bob, carol)"":

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-6-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    112     """"""
    113 
--> 114     tfe_model = tfe.keras.Sequential()
    115 
    116     for keras_layer in keras_model.layers:

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\sequential.py in __init__(self, layers, name)
     10   """"""
     11   def __init__(self, layers=None, name=None):
---> 12     super(Sequential, self).__init__(name=name)
     13 
     14     self._layers = []

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in __init__(self, trainable, name, **kwargs)
     51 
     52     self.trainable = trainable
---> 53     self._init_set_name(name)
     54     self.built = False
     55 

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in _init_set_name(self, name, zero_based)
    108   def _init_set_name(self, name, zero_based=True):
    109     if not name:
--> 110       self._name = base_layer_utils.unique_layer_name(
    111           generic_utils.to_snake_case(self.__class__.__name__),
    112           zero_based=zero_based)

AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name'

**Desktop (please complete the following information):**
 - OS: [Windows 7 64 bits]
 - In anaconda3, python 3.6.4


@AndyClouder has similar issues in #2234 The best way to solve this at the moment would be to install your tf-encrypted dependency from source. We will do a release of tf-encrypted on Monday that fixes this issue in the pip package.Instructions can be found [here](https://github.com/tf-encrypted/tf-encrypted/blob/master/README.md#installation)> Instructions can be found [here](https://github.com/tf-encrypted/tf-encrypted/blob/master/README.md#installation)

I install the tf-encrypted dependency from source as you suggest and get the following error:
FileNotFoundError                         Traceback (most recent call last)
<ipython-input-6-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     55     # Tell the TFE workers to launch TF servers
     56     for player_name, worker in player_to_worker_mapping.items():
---> 57         worker.start(player_name, *workers)
     58 
     59     # Push and initialize shared model on servers

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\workers\tfe.py in start(self, player_name, *workers)
     23 
     24         config, _ = self.config_from_workers(workers)
---> 25         config.save(config_filename)
     26 
     27         if self._auto_managed:

c:\users\administrator\tf-encrypted\tf_encrypted\config.py in save(self, filename)
    232     :param str filename: Name of file to save to.
    233     """"""
--> 234     with open(filename, 'w') as f:
    235       json.dump(self.hostmap, f)
    236 

FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'> Instructions can be found [here](https://github.com/tf-encrypted/tf-encrypted/blob/master/README.md#installation)

And I try changing the **config_filename = ""/tmp/tfe.config""** in C:\Users\Administrator\Desktop\covert security\codes\PySyft-dev\PySyft-dev\syft\workers\tfe.py to **config_filename = ""/tfe.config""**, and get the following error:

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-19-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     31 
     32     # Handle input combinations to configure TFE
---> 33     player_to_worker_mapping = _configure_tfe(workers)
     34 
     35     if target_graph is None:

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _configure_tfe(workers)
     99         config.get_player(""server0""), config.get_player(""server1""), config.get_player(""server2"")
    100     )
--> 101     tfe.set_protocol(prot)
    102 
    103     return player_to_worker_mapping

c:\users\administrator\tf-encrypted\tf_encrypted\__init__.py in set_protocol(prot)
     40   # add global names according to new protocol
     41   if prot is not None:
---> 42     methods = inspect.getmembers(prot, predicate=inspect.ismethod)
     43     public_methods = [
     44         method for method in methods if not method[0].startswith('_')]

D:\ProgramData\Anaconda3\lib\inspect.py in getmembers(object, predicate)
    340         # looking in the __dict__.
    341         try:
--> 342             value = getattr(object, key)
    343             # handle the duplicate key
    344             if key in processed:

c:\users\administrator\tf-encrypted\tf_encrypted\protocol\pond\pond.py in initializer(self)
    599   @property
    600   def initializer(self) -> tf.Operation:
--> 601     return tf.group(*_initializers)
    602 
    603   def clear_initializers(self) -> None:

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\ops\control_flow_ops.py in group(*inputs, **kwargs)
   3621   if kwargs:
   3622     raise ValueError(""Unknown keyword arguments: "" + "", "".join(kwargs.keys()))
-> 3623   with ops.name_scope(name, ""group_deps"", inputs) as name:
   3624     # Grouping no inputs means do nothing
   3625     if not inputs:

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\framework\ops.py in __enter__(self)
   6506       if self._values is None:
   6507         self._values = []
-> 6508       g = _get_graph_from_inputs(self._values)
   6509       self._g_manager = g.as_default()
   6510       self._g_manager.__enter__()

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\framework\ops.py in _get_graph_from_inputs(op_input_list, graph)
   6133         graph = graph_element.graph
   6134       elif original_graph_element is not None:
-> 6135         _assert_same_graph(original_graph_element, graph_element)
   6136       elif graph_element.graph is not graph:
   6137         raise ValueError(""%s is not from the passed-in graph."" % graph_element)

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\framework\ops.py in _assert_same_graph(original_item, item)
   6069   if original_item.graph is not item.graph:
   6070     raise ValueError(""%s must be from the same graph as %s."" %
-> 6071                      (item, original_item))
   6072 
   6073 

ValueError: name: ""group_deps""
op: ""NoOp""
input: ""^group_deps/NoOp""
input: ""^group_deps/NoOp_1""
 must be from the same graph as name: ""group_deps""
op: ""NoOp""
input: ""^group_deps/NoOp""
input: ""^group_deps/NoOp_1""
.
>We will do a release of tf-encrypted on Monday that fixes this issue in the pip package.

I just pushed tf-encrypted version 0.5.5 to PyPI, and the original AttributeError bug in this issue is fixed when using TF 1.14.0-rc0.  For anyone reading this, please ensure you've either upgraded tf-encrypted to 0.5.5 or downgraded your version of TensorFlow to 1.13.1.

> FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'

This one should be fixed by #2254, which is now in `dev`.  Please open up a new bug report if this continues to be a problem there.

>ValueError: name: ""group_deps"" ...

This one is more interesting -- @mortendahl any idea what could be going on here?  If this is more than a quick fix, I suggest moving that discussion to a new issue since this one should be resolved now.> > We will do a release of tf-encrypted on Monday that fixes this issue in the pip package.
> 
> I just pushed tf-encrypted version 0.5.5 to PyPI, and the original AttributeError bug in this issue is fixed when using TF 1.14.0-rc0. For anyone reading this, please ensure you've either upgraded tf-encrypted to 0.5.5 or downgraded your version of TensorFlow to 1.13.1.
> 
> > FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'
> 
> This one should be fixed by #2254, which is now in `dev`. Please open up a new bug report if this continues to be a problem there.
> 
> > ValueError: name: ""group_deps"" ...
> 
> This one is more interesting -- @mortendahl any idea what could be going on here? If this is more than a quick fix, I suggest moving that discussion to a new issue since this one should be resolved now.

Thank you very much. When I reinstall the tf-encrypted to version 0.5.5 and reinstall pysft, the error disappear. But there exist another problem. And I start a  new issue to discuss it. 

Thank you again for your quick reply.@jvmancuso is this fixed now?Yup!",9,2019-06-08 05:39:32,2019-06-13 18:01:07,2019-06-13 18:01:07
https://github.com/OpenMined/PySyft/issues/2243,[],.federate() error in the MNIST dataset,".federate() error in the MNIST datasetI tried to run the example of pysyft tutorial
link: https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%206%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb
But I have error in the .federate().
Somehow it can't convert torchvision.datasets to FederatedDataset.
 I think that the error is somewhere in the for loop in the def dataset_federate (path:syft/frameworks/torch/federated/dataset.py).

[error_federate.pdf](https://github.com/OpenMined/PySyft/files/3262832/error_federate.pdf)

Thank you!

### Syft Version: 0.1.16a1
### Python Version: latest
### OS: Mac OS Sierra 10.12.6
@LaRiffle Do you know why for build tensor type first_layer would be true but the length of lambdas would be <1Hey @geochri are you running the tutorial ""as is"" or have you made any modifications?
Also, do you have gpus or cuda?@LaRiffle I don't have gpu. I didn't make any modifications!Today I tried this approach and it works for the conversion. 
```python
train_dataset = datasets.MNIST('.', train=True, download=True,
                   transform=transform)

train_base = sy.BaseDataset(data=train_dataset.data, targets=train_dataset.targets)
train_base_federated = train_base.federate((bob, alice))
federated_trainloader = sy.FederatedDataLoader(train_base_federated, 
                                                batch_size=64, 
                                                shuffle=True)
```
But it's strange... because now other error appears.
```python
---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    147         # Try running it
--> 148         new_args = hook_args(args)
    149 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in seven_fold(lambdas, args, **kwargs)
    543     return (
--> 544         lambdas[0](args[0], **kwargs),
    545         lambdas[1](args[1], **kwargs),

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-18-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-17-ceb0955942ca> in forward(self, x)
      8 
      9     def forward(self, x):
---> 10         x = F.relu(self.conv1(x))
     11         x = F.max_pool2d(x, 2, 2)
     12         x = F.relu(self.conv2(x))

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py in forward(self, input)
    336                             _pair(0), self.dilation, self.groups)
    337         return F.conv2d(input, self.weight, self.bias, self.stride,
--> 338                         self.padding, self.dilation, self.groups)
    339 
    340 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    207             new_command = (cmd, None, new_args, new_kwargs)
    208             # Send it to the appropriate class and get the response
--> 209             response = new_type.handle_func_command(new_command)
    210             # Put back the wrappers where needed
    211             response = syft.frameworks.torch.hook_args.hook_response(

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/pointers/object_pointer.py in handle_func_command(cls, command)
     86 
     87         # Send the command
---> 88         response = owner.send_command(location, command)
     89 
     90         return response

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    421 
    422         try:
--> 423             ret_val = self.send_msg(MSGTYPE.CMD, message, location=recipient)
    424         except ResponseSignatureError as e:
    425             ret_val = None

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, msg_type, message, location)
    219 
    220         # Step 2: send the message and wait for a response
--> 221         bin_response = self._send_msg(bin_message, location)
    222 
    223         # Step 3: deserialize the response

~/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      4 class VirtualWorker(BaseWorker):
      5     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 6         return location._recv_msg(message)
      7 
      8     def _recv_msg(self, message: bin) -> bin:

~/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py in _recv_msg(self, message)
      7 
      8     def _recv_msg(self, message: bin) -> bin:
----> 9         return self.recv_msg(message)

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in recv_msg(self, bin_message)
    250             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    251         # Step 1: route message to appropriate function
--> 252         response = self._message_router[msg_type](contents)
    253 
    254         # Step 2: Serialize the message to simple python objects

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in execute_command(self, message)
    379                 command = getattr(command, path)
    380 
--> 381             response = command(*args, **kwargs)
    382 
    383         # some functions don't return anything (such as .backward())

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

RuntimeError: Expected 4-dimensional input for 4-dimensional weight 20 1 5, but got 3-dimensional input of size [5, 28, 28] instead
```This is a bit mysterious to me :/
One thing, why have you changed the path of data `../data` to `.`?

Second thing, can you try replacing the cell
```
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)
```
with
```
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True)
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)
```
What happens now?I had moved the data to a different path, but this isn't the problem.
I restored the path on the data, to be exactly the same as the repo path, but I had the same error.
I replaced the cell with your suggestions and here is the new error occurred.

```python
    ---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-4-7a53acbaa3ff> in <module>
      1 federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
      2     datasets.MNIST('../data', train=True, download=True)
----> 3     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
      4     batch_size=args.batch_size, shuffle=True, **kwargs)
      5 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/federated/dataset.py in dataset_federate(dataset, workers)
    159     datasets = []
    160     data_loader = torch.utils.data.DataLoader(dataset, batch_size=data_size)
--> 161     for dataset_idx, (data, targets) in enumerate(data_loader):
    162         worker = workers[dataset_idx % len(workers)]
    163         logger.debug(""Sending data to worker %s"", worker.id)

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    558         if self.num_workers == 0:  # same-process loading
    559             indices = next(self.sample_iter)  # may raise StopIteration
--> 560             batch = self.collate_fn([self.dataset[i] for i in indices])
    561             if self.pin_memory:
    562                 batch = _utils.pin_memory.pin_memory_batch(batch)

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)
     66     elif isinstance(batch[0], container_abcs.Sequence):
     67         transposed = zip(*batch)
---> 68         return [default_collate(samples) for samples in transposed]
     69 
     70     raise TypeError((error_msg_fmt.format(type(batch[0]))))

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in <listcomp>(.0)
     66     elif isinstance(batch[0], container_abcs.Sequence):
     67         transposed = zip(*batch)
---> 68         return [default_collate(samples) for samples in transposed]
     69 
     70     raise TypeError((error_msg_fmt.format(type(batch[0]))))

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)
     68         return [default_collate(samples) for samples in transposed]
     69 
---> 70     raise TypeError((error_msg_fmt.format(type(batch[0]))))

TypeError: batch must contain tensors, numbers, dicts or lists; found <class 'PIL.Image.Image'>
```This is now fixed in dev
Ans will be in master very soon,
The issue was torchvision update from 0.2.2 to 0.3Thank you!",8,2019-06-06 17:47:51,2019-06-10 21:43:46,2019-06-10 21:11:50
https://github.com/OpenMined/PySyft/issues/2234,[],AttributeError: 'FixedPrecisionTensor' object has no attribute 'attr',"AttributeError: 'FixedPrecisionTensor' object has no attribute 'attr'**Describe the bug**

When I run the demo of Part 11 - Secure Deep Learning Classification from the example.
In cell [12]  `model.fix_precision().share(alice, bob, crypto_provider=crypto_provider)`
I met an error as below:

![ERROR](https://user-images.githubusercontent.com/16660974/58936093-86a5ad80-87a1-11e9-85fe-f0d134bfd777.PNG)

Is that a bug ?

My env details:
python 3.6.8
pytorch 1.0.1
syft 1.12.a1
os WIN10
Let's start by updating PySyft. The latest version is 0.1.17.a1 which is 5 versions after the one you have.@AndyClouder did updating PySyft fix your issue?AttributeError                            Traceback (most recent call last)
<ipython-input-7-5b486064ddb2> in <module>()
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    112     """"""
    113 
--> 114     tfe_model = tfe.keras.Sequential()
    115 
    116     for keras_layer in keras_model.layers:

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\sequential.py in __init__(self, layers, name)
     10   """"""
     11   def __init__(self, layers=None, name=None):
---> 12     super(Sequential, self).__init__(name=name)
     13 
     14     self._layers = []

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in __init__(self, trainable, name, **kwargs)
     51 
     52     self.trainable = trainable
---> 53     self._init_set_name(name)
     54     self.built = False
     55 

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in _init_set_name(self, name, zero_based)
    108   def _init_set_name(self, name, zero_based=True):
    109     if not name:
--> 110       self._name = base_layer_utils.unique_layer_name(
    111           generic_utils.to_snake_case(self.__class__.__name__),
    112           zero_based=zero_based)

AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name'

How can I solve this problem? Thanks.Hi, this error is now related to #2255 
I will therefore close this one, and add you in the other one.",4,2019-06-05 06:52:43,2019-06-09 15:38:16,2019-06-09 15:38:16
https://github.com/OpenMined/PySyft/issues/2221,['bug '],"Could not find a version that satisfies the requirement torch>=1.0.1 (from syft) (from versions: 0.1.2, 0.1.2.p","Could not find a version that satisfies the requirement torch>=1.0.1 (from syft) (from versions: 0.1.2, 0.1.2.p I am using a windows machine, with anaconda navigator I installed as per the instructions given in the readme.md 
1. created an enviornment named pysyft and activated it
2. initialized pip install syft
3. The error mentioned above is displayed

I am  Udacity Student for Secure and Private AI

![image](https://user-images.githubusercontent.com/39687652/58757245-8e0d5280-8526-11e9-962f-7d231cec825e.png)
Looks you haven't installed the appropriate version of torch or don't have torch installed in your conda environment. So activate your conda environment and install pytorch. Conda environments are a good way to keep separate dependencies. So if you have had a different version of torch in your system which you usually use. You can still use a specific version of torch separately using virtual environments such as conda.  Did you execute the following command in your pysyft environment? If not, then please run this command and check.

conda install pytorch torchvision -c pytorchYou should update conda and pip. If it doesn't have torch 1.x it's likely very old.I have already tried all the mentioned commands I even tried using it within the enviornment in which I had pytorch Installed and I got back the same error my current conda version is 4.5x and the torch version is 1.x @iamtrask  
I've the exact same issue seems to me that torch 1.2 (latest) isn't compatible with syft ?.
Any suggestions",5,2019-06-02 05:37:33,2019-08-28 13:13:48,2019-06-04 22:00:40
https://github.com/OpenMined/PySyft/issues/2218,['bug '],Federated Recurrent Neural Network Tutorial Issue with Predict Method (Using Two Raspberry Pi's),"Federated Recurrent Neural Network Tutorial Issue with Predict Method (Using Two Raspberry Pi's)**Describe the bug**
I was following the [great tutorial](https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/) put out by @DanyEle and ran into an issue on the very last step of the [Jupyter notebook tutorial](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/Federated%20Recurrent%20Neural%20Network.ipynb) with the predict comparison.

I am getting the following error after it prints the line ""Qing"":

`RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn`

I am trying to understand what the above error is but I can't figure it out. I have a suspicion that this error is occurring due to some error in communication with my two Raspberry Pi's that I have set up for the federated training. I am double checking all my installed packages to make sure everything is the same between the Pi's and control (my laptop). 

I am going to try training again and make sure my packages are up to date. Will add error message if the issue persists. 

UPDATE: Error is still persisting - I have added my error log below.

Thanks!

**To Reproduce**
Steps to reproduce the behavior:
1. Follow directions from [great tutorial](https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/) and set up the two Pi's
2. Follow the directions in the [Jupyter notebook tutorial](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/Federated%20Recurrent%20Neural%20Network.ipynb) 
3. Check output of cell 24

**Expected behavior**
Should output something such as:

> Qing
(-0.18) Chinese
(-2.85) German
(-3.16) Italian

> Qing
(-0.73) Vietnamese
(-1.23) Korean
(-2.90) Arabic

> Daniele
(-1.32) Japanese
(-1.47) German
(-1.69) Greek

> Daniele
(-1.95) French
(-2.04) Scottish
(-2.13) Irish

**Screenshots**
None

**Desktop (please complete the following information):**
 - OS: Ubuntu 
 - Version 16.04

**Additional context**

Error traceback 

```
> Qing
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-23-6650cbe85de0> in <module>
      1 
----> 2 predict(model_pointers[""alice""], ""Qing"", alice)
      3 predict(model_pointers[""bob""], ""Qing"", bob)
      4 
      5 predict(model_pointers[""alice""], ""Daniele"", alice)

<ipython-input-22-3a84bf13c0eb> in predict(model, input_line, worker, n_predictions)
      3     print('\n> %s' % input_line)
      4     with torch.no_grad():
----> 5         model_remote = model.send(worker)
      6         line_tensor = lineToTensor(input_line)
      7         line_remote = line_tensor.copy().send(worker)

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, dest)
    950 
    951             if module_is_missing_grad(nn_self):
--> 952                 create_grad_objects(nn_self)
    953 
    954             for p in nn_self.parameters():

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    943             for p in model.parameters():
    944                 o = p.sum()
--> 945                 o.backward()
    946                 p.grad -= p.grad
    947 

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    651                 except BaseException as e:
    652                     # we can make some errors more descriptive with this method
--> 653                     raise route_method_exception(e, self, args, kwargs)
    654 
    655             else:  # means that there is a wrapper to remove

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    645                 try:
    646                     if isinstance(args, tuple):
--> 647                         response = method(*args, **kwargs)
    648                     else:
    649                         response = method(args, **kwargs)

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    105                 products. Defaults to ``False``.
    106         """"""
--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    108 
    109     def register_hook(self, hook):

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---> 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```Hi, I'm glad to know you're actually trying my code for Raspberry Pis and that it all seems to be running up to the last point. I have two questions:

1. Which version of PySyft are you using on the Raspberry PIs and on  your laptop?  How did you install it?

2. Did you try using the model locally by getting it with model.copy().get() at all places where it is used in the predict phase? It may be an issue with the remote execution, so running it locally with native PyTorch would solve it.Hey @DanyEle in response to your questions: 

1a. Which version of PySyft are you using on the Raspberry Pi's? How did you install it?
  - PySyft on Raspberry Pi: `syft==0.1.14a1`
      - Installed following your directions in the article you wrote using the commands:

```
git clone https://github.com/OpenMined/PySyft.git
cd PySyft
pip3 install -r requirements.txt
python3 setup.py build
sudo -E python3 setup.py install
```
1b. Which version of PySyft are you using on your laptop? How did you install it?
  - PySyft on laptop running Ubuntu 16.04: `syft==0.1.14a1`
      - Installed via running `pip install syft==0.1.14a1` in a conda python environment (the specific versioning was to match the Raspberry Pi's version of PySyft).


2. Did you try using the model locally by getting it with model.copy().get() at all places where it is used in the predict phase? It may be an issue with the remote execution, so running it locally with native PyTorch would solve it.
   - Trying this now - will update soon. Hey @DanyEle - tried your suggestions on part two but still the same error as before; here is the predict function that I was trying to use per your suggestion:

```
def predict(model, input_line, worker, n_predictions=3):
    model = model.copy().get()
    print('\n> %s' % input_line)
    with torch.no_grad():
        model_remote = model.send(worker).copy().get()
        line_tensor = lineToTensor(input_line)
        line_remote = line_tensor.copy().send(worker)
        #line_tensor = lineToTensor(input_line)
        #output = evaluate(model, line_remote)
        # Get top N categories
        hidden = model_remote.initHidden()
        hidden_remote = hidden.copy().send(worker)

        for i in range(line_remote.shape[0]):
            output, hidden_remote = model_remote(line_remote[i], hidden_remote)
        
        topv, topi = output.copy().get().topk(n_predictions, 1, True)
        predictions = []

        for i in range(n_predictions):
            value = topv[0][i].item()
            category_index = topi[0][i].item()
            print('(%.2f) %s' % (value, all_categories[category_index]))
            predictions.append([value, all_categories[category_index]])


```

P.S. For reference, here is the error log:

```


> Qing
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-23-6650cbe85de0> in <module>
      1 
----> 2 predict(model_pointers[""alice""], ""Qing"", alice)
      3 predict(model_pointers[""bob""], ""Qing"", bob)
      4 
      5 predict(model_pointers[""alice""], ""Daniele"", alice)

<ipython-input-22-7031e812578d> in predict(model, input_line, worker, n_predictions)
      3     print('\n> %s' % input_line)
      4     with torch.no_grad():
----> 5         model_remote = model.send(worker).copy().get()
      6         line_tensor = lineToTensor(input_line)
      7         line_remote = line_tensor.copy().send(worker)

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, dest)
    950 
    951             if module_is_missing_grad(nn_self):
--> 952                 create_grad_objects(nn_self)
    953 
    954             for p in nn_self.parameters():

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    943             for p in model.parameters():
    944                 o = p.sum()
--> 945                 o.backward()
    946                 p.grad -= p.grad
    947 

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    651                 except BaseException as e:
    652                     # we can make some errors more descriptive with this method
--> 653                     raise route_method_exception(e, self, args, kwargs)
    654 
    655             else:  # means that there is a wrapper to remove

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    645                 try:
    646                     if isinstance(args, tuple):
--> 647                         response = method(*args, **kwargs)
    648                     else:
    649                         response = method(args, **kwargs)

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    105                 products. Defaults to ``False``.
    106         """"""
--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    108 
    109     def register_hook(self, hook):

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---> 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

```Alright, I looked into it and it was because of the misplaced line ` with torch.no_grad():`, which was referring to a larger block. Here is the fixed code for the predict method

```
def predict(model, input_line, worker, n_predictions=3):
    model = model.copy().get()
    print('\n> %s' % input_line)
    model_remote = model.send(worker)
    line_tensor = lineToTensor(input_line)
    line_remote = line_tensor.copy().send(worker)
    #line_tensor = lineToTensor(input_line)
    #output = evaluate(model, line_remote)
    # Get top N categories
    hidden = model_remote.initHidden()
    hidden_remote = hidden.copy().send(worker)
        
    with torch.no_grad():
        for i in range(line_remote.shape[0]):
            output, hidden_remote = model_remote(line_remote[i], hidden_remote)
        
    topv, topi = output.copy().get().topk(n_predictions, 1, True)
    predictions = []

    for i in range(n_predictions):
        value = topv[0][i].item()
        category_index = topi[0][i].item()
        print('(%.2f) %s' % (value, all_categories[category_index]))
        predictions.append([value, all_categories[category_index]])
```

Hey @DanyEle and @iamtrask 

# Can confirm, this bug is now fixed! :tada: :tada: :tada: 

## Also, @DanyEle since I have your attention here, I wanted to also make you aware of some errors and thoughts I encountered while following your [article](https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/). Here they are: 

- When you are trying to install PyTorch on the RPi, you must first have installed `pyyaml==5.1`
- I had to run `sudo apt-get update && sudo reboot` after installing PyTorch on the RPi as I had some issues moving forward with installs
- In the `requirements.txt` for PySyft (when you are trying to build and install it on the RPi) you need to remove the following packages for it to compile/build correctly:
    - torch
- On Part 2 in Section 1 of ""Start the worker servers on the Raspberry PIs"" - I was going crazy until I figured out there was an error in the command you specified - it should be as follows:
    - **Raspberry Pi 1:** `python run_websocket_server.py --host 10.42.0.55 --port 8777 --id alice`
    - **Raspberry Pi 2:** `python run_websocket_server.py --host 10.42.0.56 --port 8778 --id bob`
- It is worth making a note in the instructions that training on the RPi using the federated method often takes a very long time - for me, it took about 2 hours for my RPi 3B+'s 
- I found the instructions about using screen confusing so you may want to clear that up just a little bit or include pictures about how to use this with respect to connecting to a raspberry pi
- I found setting the alias `alias python=python3.6` while following your instructions so I would suggest adding that as a way of setting your default RPi Python to Python3.6

I also think it may be useful to have actually demonstrated how to assign a static IP to the Raspberry Pi's; I stubbed out the basic outline of how to do that here (these steps are to be followed on the RPi's): 

- Run `netstat -nr`
    - Write down the Gateway Address associated with Destination 0.0.0.0

- Run `sudo nano /etc/dhcpcd.conf` and at the top of the file write, 
  - `ip_address=[Write in the Gateway address but with the last numbers specified to a number you want]/24` (example: if my gateway address is 10.42.0.1, then I would write in something like: `ip_address=10.42.0.77/24`)
  - `static routers=[Write down the Gateway address]`
  - `static domain_name_servers=[Write down the Gateway address from earlier]`

- Reboot the RPi and SSH into the RPi using the ip_address you just specified earlier. 

## I hope this was helpful - thanks for the help with setting this up properly; this was awesome! Keep up the great work and good luck with grad school @DanyEle! Thank you very much @TheCedarPrince for the useful fixes to the tutorial I wrote and good job in setting it all up on the two Raspberry PIs! I hope the tutorial helped you with some guidance on how to go through the whole procedure to setup PySyft and Pytorch, at least. :) 

I'm surely going to apply your fixes to my tutorial, but a static IP address, even if suggested to carry out experiments multiple times, is not actually a necessary condition to run the RNN example. Well since everything is fixed here, I am going to close the issue! 

This was more than helpful - it is was an amazing piece of work and I am looking forward to looking at other work on PySyft and PyTorch. : )",7,2019-06-01 02:52:43,2019-06-03 19:03:04,2019-06-03 19:03:04
https://github.com/OpenMined/PySyft/issues/2211,['bug '],Test share for keras does not work on macos in a virtual env,"Test share for keras does not work on macos in a virtual env**Describe the bug**
Due to firewall issues, it is not possible to run test share on macos in a venv. This can be remedied by replacing network calls with mock.
**To Reproduce**
run make_test on a fresh macos install


**Additional context**
contact @robert-wagner to replicate as it is still broken on his system
Mind taking a look at the linked PR @robert-wagner?",1,2019-05-31 13:25:56,2019-06-03 16:30:55,2019-06-03 16:30:55
https://github.com/OpenMined/PySyft/issues/2207,[],Model.copy() is not working properly,"Model.copy() is not working properly**windows 10
python 3.7.3
pytorch=1.0.1
pysyft=0.1.13**
```
#Train Bob's and Alice's Models (in parallel) 

client_copy=[0]*2;
for epoch in range(1, 2):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset
        if batch_idx==0:
            bobmodel=model.copy().send(data.location) # <-- NEW: send the model to the rig
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = bobmodel(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step() 
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # <-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
                100. * batch_idx / len(federated_train_loader), loss.data))
```

Give output:-
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.305134
Train Epoch: 1 [1920/60032 (3%)]	Loss: 2.306227
Train Epoch: 1 [3840/60032 (6%)]	Loss: 2.314577
Train Epoch: 1 [5760/60032 (10%)]	Loss: 2.301752
Train Epoch: 1 [7680/60032 (13%)]	Loss: 2.304796
Train Epoch: 1 [9600/60032 (16%)]	Loss: 2.305816
Train Epoch: 1 [11520/60032 (19%)]	Loss: 2.307251
Train Epoch: 1 [13440/60032 (22%)]	Loss: 2.305082
Train Epoch: 1 [15360/60032 (26%)]	Loss: 2.309973
Train Epoch: 1 [17280/60032 (29%)]	Loss: 2.296431
Train Epoch: 1 [19200/60032 (32%)]	Loss: 2.309648
Train Epoch: 1 [21120/60032 (35%)]	Loss: 2.313736
Train Epoch: 1 [23040/60032 (38%)]	Loss: 2.303707
Train Epoch: 1 [24960/60032 (42%)]	Loss: 2.308319
Train Epoch: 1 [26880/60032 (45%)]	Loss: 2.306007
Train Epoch: 1 [28800/60032 (48%)]	Loss: 2.307840
```

While without making copy of model:-
 `bobmodel=model.send(data.location)`
give output 
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.305134
Train Epoch: 1 [1920/60032 (3%)]	Loss: 2.156802
Train Epoch: 1 [3840/60032 (6%)]	Loss: 1.896611
Train Epoch: 1 [5760/60032 (10%)]	Loss: 1.440396
Train Epoch: 1 [7680/60032 (13%)]	Loss: 0.867146
Train Epoch: 1 [9600/60032 (16%)]	Loss: 0.654510
Train Epoch: 1 [11520/60032 (19%)]	Loss: 0.593326
Train Epoch: 1 [13440/60032 (22%)]	Loss: 0.455695
Train Epoch: 1 [15360/60032 (26%)]	Loss: 0.370735
Train Epoch: 1 [17280/60032 (29%)]	Loss: 0.303775
Train Epoch: 1 [19200/60032 (32%)]	Loss: 0.312882
Train Epoch: 1 [21120/60032 (35%)]	Loss: 0.369826
Train Epoch: 1 [23040/60032 (38%)]	Loss: 0.237517
Train Epoch: 1 [24960/60032 (42%)]	Loss: 0.187326
Train Epoch: 1 [26880/60032 (45%)]	Loss: 0.522530
Train Epoch: 1 [28800/60032 (48%)]	Loss: 0.225577
 ```

Model.copy() is not working properly. As loss is not decreasing in same input with model.copy while it is decreasing without copy in starting even before federated averaging.   



Hey, if you have the whole code I'd love to see it to better understand our use case. Should I infer that all the data is owned by bob, as you only the model once per epoch and to bob?

Also, you should update `pytorch=1.0.1 -> pytorch=1.1` and `pysyft=0.1.13 -> pysyft=0.1.15a1`; many changes are happening currently :)[`Link`](https://drive.google.com/file/d/1CnvBwgLMd4W1jtXlT2PBRuGjWQBmHpV0/view?usp=sharing)
If you change this line ""bobmodel=model.send(data.location)"" to ""bobmodel=model.copy().send(data.location)"" then loss is not decreasing.Run the whole code by replacing ""bobmodel=model.send(data.location)"" with ""bobmodel=model.copy().send(data.location)"" you see that loss is not decreasing for latter case.Oh yes of course!
You have given to your optimizer the parameters of the original model, not of the copy, thats why the copy of the model doesn't improve.
Another thing is that during an epoch, you only send once the model to the first worker, so when you will have data batches owned by the other worker, it will fail.

I believe this Issue is solved, if you have other issues related to your use case, please let us know!",4,2019-05-31 12:30:01,2019-06-01 15:36:20,2019-06-01 15:36:19
https://github.com/OpenMined/PySyft/issues/2202,['bug '],Error: Tuple of tensors being returned from websockets ,"Error: Tuple of tensors being returned from websockets **Describe the bug**
When invoking a method returning a tuple of tensors on a remote tensor that is stored on a remote **_websocket_**, an error occurs.

**To Reproduce**
Steps to reproduce the error:

1. Startup a remote websocket on the local machine

```
cd 
cd PySyft/examples/tutorials/advanced/websockets-example-MNIST
python3 run_websocket_server.py --id alice --host 127.0.0.1 --port 8777
```


2. In a new terminal, initialize syft and hook the remote websocket
```

import torch
import syft as sy
from syft.workers import WebsocketClientWorker
 
hook = sy.TorchHook(torch)

kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}
alice= WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
```

2. Initialize a tensor and send it to the remote worker:

```
random_tensor = torch.randn(5,3)
remote_tensor = random_tensor.send(alice)
positions, sorted_values = torch.sort(remote_tensor)
```

It seems to be somehow related to the way PySyft returns tuples of tensors. Notice that this issues does not occur on virtual sockets, but just on remote web socket!

Error in the remote console:

![image](https://user-images.githubusercontent.com/4907418/58690123-1d7cff00-8389-11e9-9b04-cf9550c39e95.png)
The reason of this error is that with virtualworkers, a `syft.exceptions.ResponseSignatureError` is sent back from servers workers to the client, which is not supported by socketworkers.
Maybe we would like to handle Exception forwarding through some serialization process.This issue #2214 is related
And #2219 attempts to give fix.HI @DanyEle - should we close?@iamtrask  If it's fixed in #2219, then sure!@DanyEle It is now merged!",5,2019-05-31 07:45:18,2019-06-04 17:10:33,2019-06-04 17:10:33
https://github.com/OpenMined/PySyft/issues/2198,[],Unable to run unit tests.,"Unable to run unit tests.Unable to run unit tests even after installing everything properly ( tried both pip install and the installation guide for Linux )
* Installation is proper
![Screenshot from 2019-05-31 06-38-28](https://user-images.githubusercontent.com/43285614/58674758-de41b480-836e-11e9-86c8-1c7620649978.png) 

*Breaks after cd-ing into test dir
![Screenshot from 2019-05-31 06-39-17](https://user-images.githubusercontent.com/43285614/58674760-deda4b00-836e-11e9-8852-084b7d36d3cc.png)
What am I missing?
@jidroid404  you can run unit tests using pytest. E.g from inside test folder run the command 
pytest test_serde.py@jidroid404  as @amit-rastogi pointed you should run the file using pytest. Also if you want to run all the unit tests you can cd to the PySyft folder and run: `pytest test/*`Then throwing off this import error, while running all of the unit tests
![Screenshot from 2019-06-02 18-16-19](https://user-images.githubusercontent.com/43285614/58761590-b6677200-8563-11e9-8ea3-7b4d86c01684.png)

@jidroid404 try to run as I described on my previous comment. conftest.py is not a valid unit test, so probably that's why you see the error.

Go to Desktop/PysSyft/ and run pytest test/*

This should execute without errors.
Nope,it doesn't.
![issue](https://user-images.githubusercontent.com/43285614/58761906-c92f7600-8566-11e9-960d-e1c9a5534ff6.png)
right... weird...  can you check if you have all the dependencies installed?

run:

```
pip install -r requirements.txt
pip install -r requirements_dev.txt
```All the dependencies are intact.From the error details your python version appears to be 2.7. Could you check with python 3.x? Had the same suspicion, it's Python 3.6 only.Oh indeed @amit-rastogi, nice catch!Not really @jidroid404 from the previous print-screen error you sent your pytest is running python2.7Okay lesson learned. :) Thanks peeps.
python3 -m pytest test/test_serde.py",12,2019-05-31 01:11:08,2019-06-02 13:47:51,2019-06-02 12:11:08
https://github.com/OpenMined/PySyft/issues/2185,[],Cannot import syft,"Cannot import syft**Describe the bug**
I just installed the new version of syft and now when i try to import it I get the following error.

```---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
ImportError: numpy.core.multiarray failed to import

The above exception was the direct cause of the following exception:

SystemError                               Traceback (most recent call last)
/Users/atrask/anaconda/lib/python3.6/importlib/_bootstrap.py in _find_and_load(name, import_)

SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
ImportError: numpy.core._multiarray_umath failed to import
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
ImportError: numpy.core.umath failed to import```


**To Reproduce**
run ```import syft```
he following information):**
 - OS: macOS High Sierra 
 - Version 10.13.6
I fixed this by running

```
pip uninstall numpy
```

and then from Syft's home directory I ran

```python setup.py install```

and then I could import syft again.",1,2019-05-29 20:57:50,2019-05-29 20:58:30,2019-05-29 20:58:29
https://github.com/OpenMined/PySyft/issues/2179,[],Error in Tutorial Part 4 Step 6,"Error in Tutorial Part 4 Step 6Hi, 

I am runing the sample code in the tutorial Part 4 Federated Learning with Model Averaging. The code is in Step 6 Rinse and Repeat  and the error message is as following. Any idea on the reason behind this? thanks!


---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    195             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 196                 cmd, args, kwargs, return_args_type=True
    197             )

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    146         # Try running it
--> 147         new_args = hook_args(args)
    148 

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook_args.py in <lambda>(x)
    340 
--> 341     return lambda x: f(lambdas, x)
    342 

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook_args.py in three_fold(lambdas, args, **kwargs)
    504     return (
--> 505         lambdas[0](args[0], **kwargs),
    506         lambdas[1](args[1], **kwargs),

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook_args.py in <lambda>(i)
    318         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 319         else lambda i: forward_func[type(i)](i)
    320         for a, r in zip(args, rules)  # And do this for all the args / rules provided

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook_args.py in <lambda>(i)
     53     if hasattr(i, ""child"")
---> 54     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     55     LoggingTensor: lambda i: i.child,

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook_args.py in <genexpr>(.0)
     53     if hasattr(i, ""child"")
---> 54     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     55     LoggingTensor: lambda i: i.child,

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

IndexError                                Traceback (most recent call last)
<ipython-input-9-3b113eb239f0> in <module>
     14         # Train Bob's Model
     15         bobs_opt.zero_grad()
---> 16         bobs_pred = bobs_model(bobs_data)
     17         bobs_loss = ((bobs_pred - bobs_target)**2).sum()
     18         bobs_loss.backward()

c:\users\rs\documents\projectworkspace\pysyft\.venv\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

c:\users\rs\documents\projectworkspace\pysyft\.venv\lib\site-packages\torch\nn\modules\linear.py in forward(self, input)
     90     @weak_script_method
     91     def forward(self, input):
---> 92         return F.linear(input, self.weight, self.bias)
     93 
     94     def extra_repr(self):

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    204             new_command = (cmd, None, new_args, new_kwargs)
    205             # Send it to the appropriate class and get the response
--> 206             response = new_type.handle_func_command(new_command)
    207             # Put back the wrappers where needed
    208             response = syft.frameworks.torch.hook_args.hook_response(

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\tensors\interpreters\pointer.py in handle_func_command(cls, command)
    102 
    103         # Send the command
--> 104         response = owner.send_command(location, command)
    105 
    106         return response

~\Documents\ProjectWorkspace\PySyft\syft\workers\base.py in send_command(self, recipient, message, return_ids)
    416 
    417         try:
--> 418             _ = self.send_msg(MSGTYPE.CMD, message, location=recipient)
    419         except ResponseSignatureError as e:
    420             return_ids = e.ids_generated

~\Documents\ProjectWorkspace\PySyft\syft\workers\base.py in send_msg(self, msg_type, message, location)
    216 
    217         # Step 2: send the message and wait for a response
--> 218         bin_response = self._send_msg(bin_message, location)
    219 
    220         # Step 3: deserialize the response

~\Documents\ProjectWorkspace\PySyft\syft\workers\virtual.py in _send_msg(self, message, location)
      4 class VirtualWorker(BaseWorker):
      5     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 6         return location._recv_msg(message)
      7 
      8     def _recv_msg(self, message: bin) -> bin:

~\Documents\ProjectWorkspace\PySyft\syft\workers\virtual.py in _recv_msg(self, message)
      7 
      8     def _recv_msg(self, message: bin) -> bin:
----> 9         return self.recv_msg(message)

~\Documents\ProjectWorkspace\PySyft\syft\workers\base.py in recv_msg(self, bin_message)
    247             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    248         # Step 1: route message to appropriate function
--> 249         response = self._message_router[msg_type](contents)
    250 
    251         # Step 2: Serialize the message to simple python objects

~\Documents\ProjectWorkspace\PySyft\syft\workers\base.py in execute_command(self, message)
    374                 command = getattr(command, path)
    375 
--> 376             response = command(*args, **kwargs)
    377 
    378         # some functions don't return anything (such as .backward())

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    221             # in the execute_command function
    222             if isinstance(args, tuple):
--> 223                 response = eval(cmd)(*args, **kwargs)
    224             else:
    225                 response = eval(cmd)(args, **kwargs)

c:\users\rs\documents\projectworkspace\pysyft\.venv\lib\site-packages\torch\nn\functional.py in linear(input, weight, bias)
   1404     if input.dim() == 2 and bias is not None:
   1405         # fused op is marginally faster
-> 1406         ret = torch.addmm(bias, input, weight.t())
   1407     else:
   1408         output = input.matmul(weight.t())

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\hook\hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~\Documents\ProjectWorkspace\PySyft\syft\frameworks\torch\tensors\interpreters\native.py in handle_func_command(cls, command)
    221             # in the execute_command function
    222             if isinstance(args, tuple):
--> 223                 response = eval(cmd)(*args, **kwargs)
    224             else:
    225                 response = eval(cmd)(args, **kwargs)

IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)Hey @RunshanHu ,

I've just executed it with pysyft most updated version (dev branch) and pytorch 1.1 and 1.0.1 with no errors.

Can you check if you have all the correct/updated dependencies installed?

Feel free to ping me on slack if you continue to have problems, closing it for now.",1,2019-05-29 14:49:59,2019-05-30 00:23:53,2019-05-30 00:23:32
https://github.com/OpenMined/PySyft/issues/2177,['bug '],Fix ambiguous_functions in hook_args,"Fix ambiguous_functions in hook_argsin hook_args if you want to add function to `ambiguous_functions` like stack you need to add `torch.stack` and `stack` while only should be needed `torch.stack`
This is due to an error in overload_torch.py where we don't retrieve the module of functions correctly@LaRiffle could you clarify where the module of functions should be be retrieved in this file? There does not appear to be anything which explicitly checks to see if they are in the exclude_functions listAt l.50 we do
```
# Replace all syft tensor with their child attribute
            new_args, new_kwargs, new_type = syft.frameworks.torch.hook_args.hook_function_args(
                attr.__name__, args, kwargs
            )
```
But ideally we should be replace `attr.__name__` with smthg like `attr.__module__+'.'+attr.__name__`

However hooked functions have a module which is changed and we would like to keep the original module. Note the hooked functions are in hook.py and with @overload.module and @overload.function decorator in tensor definition files.

I'd like to underline that this is not a trivial issue",2,2019-05-29 10:47:52,2019-11-15 09:17:53,2019-11-15 09:17:53
https://github.com/OpenMined/PySyft/issues/2168,['bug '],Error: matmul operation with websocket workers,"Error: matmul operation with websocket workersI'm trying to run a [simple code snippet](https://hastebin.com/uhafamejey.py) that applies the matmul method on two SMPC tensors.

But I'm having problems when applying spdz multiplication (more precisely when trying to **reconstruct** the delta and epsilon tensors). 
https://github.com/OpenMined/PySyft/blob/734742554358f5fc8ef6942a4aca042746aafc89/syft/frameworks/torch/crypto/spdz.py#L31-L32

When creating a pp tensor by **sending** the SMPC tensor to the **first worker**.
https://github.com/OpenMined/PySyft/blob/734742554358f5fc8ef6942a4aca042746aafc89/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L178

 I get the following warnings on server side:
`
WARNING:root:Worker remote_worker0 couldn't recognize worker (crypto_provider)
` 
`
WARNING:root:Worker me couldn't recognize worker (remote_worker2)
`
`WARNING:root:Worker me couldn't recognize worker (remote_worker3)`
 

After that, when calling the function **remote_get ()** to get the value of pointer stored on previous worker, my websocket servers throw exceptions. 
https://github.com/OpenMined/PySyft/blob/734742554358f5fc8ef6942a4aca042746aafc89/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L179


If it is a bug, I would like to work on it. But I need someone to help me understand the behavior behind the tensors and workers.

**syft version: 0.1.14a1**I'm on it.Solving this might be moree of a Grid project than a PySyft one - primarily because it will require two people to be able to connect to the same worker and interact with the same tensors on that worker. This requires things like user roles and permission and managing multiple connections.I agree with @iamtrask, I'll close this issue for now and re-open it at [Grid](https://github.com/OpenMined/Grid/)",3,2019-05-24 20:25:25,2019-05-31 23:10:45,2019-05-31 23:10:44
https://github.com/OpenMined/PySyft/issues/2156,[],RuntimeError: set_storage is not allowed on Tensor created from .data or .detach(),"RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()In the Part 2: Intro to Federated Learningï¼Œhave a code running errorï¼šRuntimeError: set_storage is not allowed on Tensor created from .data or .detach().
![image](https://user-images.githubusercontent.com/46445562/58070014-03456300-7bca-11e9-9830-bdb9edff42f4.png)
Hey @songchuangyuan,

I've just executed the notebook using PySyft most current version (dev branch) and it works.

Can you check if you're using an updated version of PySyft and re-run the notebook? Thanks!",1,2019-05-21 05:12:04,2019-06-04 22:00:09,2019-06-04 22:00:09
https://github.com/OpenMined/PySyft/issues/2135,[],Demo Part 2 Failed,"Demo Part 2 FailedHi,
I just tried the part 2 example here, and it didn't work when calling the second train() and the error message is:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 5, in train
  File ""~/anaconda3/lib/python3.6/site-packages/syft-0.1.14a1-py3.6.egg/syft/frameworks/torch/hook.py"", line 929, in module_send_
  File ""~/anaconda3/lib/python3.6/site-packages/syft-0.1.14a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py"", line 330, in send_
  File ""~/anaconda3/lib/python3.6/site-packages/syft-0.1.14a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py"", line 279, in send
RuntimeError: set_storage is not allowed on Tensor created from .data or .detach()

System info:
OS: Ubuntu 18.04.1 LTS
python version:  3.6.5 :: Anaconda, Inc.
pytorch version: 1.1.0Ok, downgrading pytorch back to version 1.0.0 works....",1,2019-05-10 22:15:56,2019-05-11 00:22:45,2019-05-11 00:22:45
https://github.com/OpenMined/PySyft/issues/2132,['bug '],Batchnorm Layer incompatible,"Batchnorm Layer incompatibleI am using trying to the notebook Part 8 - Federated Learning on MNIST using a CNN.ipynb but with a modified model. I have added a batchnorm layer as follows.
'
 class Net(nn.Module):
     def __init__(self):
         super(Net, self).__init__()
         self.conv1 = nn.Conv2d(1, 20, 5, 1)
         self.conv2 = nn.Conv2d(20, 50, 5, 1)
         self.fc1 = nn.Linear(4*4*50, 500)
         self.fc2 = nn.Linear(500, 10)
         self.bn1 = nn.BatchNorm2d(20)
        
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.bn1(x)
        x = F.max_pool2d(x, 2, 2)
        x = F.relu((self.conv2(x)))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)`

I get the following error :
`RuntimeError                              Traceback (most recent call last)
<ipython-input-8-9375ae22719e> in <module>()
      4 optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment
      5 for epoch in range(1, args.epochs + 1):
----> 6     train(args, model, device, federated_train_loader, optimizer, epoch)
      7     test(args, model, device, test_loader)
      8 

7 frames
<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

<ipython-input-5-090f8e67fd65> in forward(self, x)
     11     def forward(self, x):
     12         x = F.relu(self.conv1(x))
---> 13         x = self.bn1(x)
     14         x = F.max_pool2d(x, 2, 2)
     15         x = F.relu((self.conv2(x)))

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)
     58     @weak_script_method
     59     def forward(self, input):
---> 60         self._check_input_dim(input)
     61 
     62         exponential_average_factor = 0.0

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py in _check_input_dim(self, input)
    239     @weak_script_method
    240     def _check_input_dim(self, input):
--> 241         if input.dim() != 4:
    242             raise ValueError('expected 4D input (got {}D input)'
    243                              .format(input.dim()))

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    636                 except BaseException as e:
    637                     # we can make some errors more descriptive with this method
--> 638                     raise route_method_exception(e, self, args, kwargs)
    639 
    640             else:  # means that there is a wrapper to remove

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    630                 try:
    631                     if isinstance(args, tuple):
--> 632                         response = method(*args, **kwargs)
    633                     else:
    634                         response = method(args, **kwargs)

RuntimeError: bool value of Tensor with no values is ambiguous`

This error is I believe related to another issue. #2049 

Any help is greatly appreciated!@SohamMazumder We haven't hooked BatchNorm yet. So you will have to stick to Linear and CNN layers till then :/ I think the .dim() method has been fixed since this issue is open but I have now another error when trying to use Batchnorm with the same modification as above:

---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    157         # Run it
--> 158         new_args = args_hook_function(args)
    159 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in eight_fold(lambdas, args, **kwargs)
    556         lambdas[0](args[0], **kwargs),
--> 557         lambdas[1](args[1], **kwargs),
    558         lambdas[2](args[2], **kwargs),

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

<ipython-input-5-7560ae2ae6d3> in forward(self, x)
     10     def forward(self, x):
     11         x = F.relu(self.conv1(x))
---> 12         x = self.bn1(x)
     13         x = F.max_pool2d(x, 2, 2)
     14         x = F.relu(self.conv2(x))

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/batchnorm.py in forward(self, input)
     74             input, self.running_mean, self.running_var, self.weight, self.bias,
     75             self.training or not self.track_running_stats,
---> 76             exponential_average_factor, self.eps)
     77 
     78     def extra_repr(self):

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    706             cmd_name = f""{attr.__module__}.{attr.__name__}""
    707             command = (cmd_name, None, args, kwargs)
--> 708             response = TorchTensor.handle_func_command(command)
    709             return response
    710 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)
   1621     return torch.batch_norm(
   1622         input, weight, bias, running_mean, running_var,
-> 1623         training, momentum, eps, torch.backends.cudnn.enabled
   1624     )
   1625 

RuntimeError: running_mean should contain 11333 elements not 20
---------------------------------------------------------------------------

Where the 11333 seems to be a bit random (I tried several times and the error does not give the same number each time). Maybe it is now due to the .size() method (#2201)?I think this is the same as #2175, if not feel free to re-open.",3,2019-05-09 08:48:17,2019-06-15 18:50:02,2019-06-15 18:50:02
https://github.com/OpenMined/PySyft/issues/2130,[],"python3 setup.py test  fails with ""test_plan_built_on_method Illegal instruction""","python3 setup.py test  fails with ""test_plan_built_on_method Illegal instruction""I've followed https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md and https://pytorch.org/get-started/locally/ to install torch-1.0.1.post2.

The install goes fine, but the test errors out with theses last two lines of output...
.....
test/federated/test_plan.py::test_plan_built_remotely PASSED                                                                                                                                                                           [ 28%]
test/federated/test_plan.py::test_plan_built_on_method Illegal instruction

There are no conflicted packages in my pip3 environment : 
...
torch                    1.0.1.post2  
torchvision           0.2.2.post3
syft                      0.1.14a1 

platform linux -- Python 3.6.7, pytest-4.4.1, py-1.8.0, pluggy-0.11.0 -- /usr/bin/python3


_I'm quite happy to check this out if someone gives me some pointers as to where to look._
  ======================================================================
I've tried a local install and I'm getting ..
ERROR: syft 0.1.14a1 has requirement torch==1.0.1, but you'll have torch 1.0.1.post2 which is incompatible.
torch               1.0.1.post2


Then I did the torchvision install and got...
torch                1.1.0      
torchvision         0.2.2.post3
ERROR: syft 0.1.14a1 has requirement torch==1.0.1, but you'll have torch 1.1.0 which is incompatible.

no syft !
@pkc-harry can you install torch 1.0.1 instead of torch 1.0.1.post2 and try it out?Sure.
I cleared out all other installs and tried it with

torch (1.0.1)
torchvision (0.2.2.post3)
syft (0.1.13a1)

same error resulting. [test/federated/test_plan.py::test_plan_built_on_method Illegal instruction]Thanks, I'll try to reproduce it.I've done a near identical build from scratch.

test/workers/test_worker.py::test_get_unknown_worker PASSED                                                                                                     [ 99%]
test/workers/test_worker.py::test_search PASSED                                                                                                                   [100%]
=============================================================== 236 passed, 12 warnings in 59.35 seconds ================================================================
Well it gets me moving, but doesn't identify the original  problem.  On a web search, I've noticed a few  'illegal instruction' errors logged with python modules. 
@mari-linhares : I'll carry on checking this out, but I don't expect a solution soon. Ta !

Modules as above, but syft (0.1.14a1). numpy (1.16.3)

Thanks for trying @pkc-harry!

Probably it was the syft version... I don't think it was numpy.",6,2019-05-08 21:54:23,2019-05-21 15:40:44,2019-05-21 15:40:44
https://github.com/OpenMined/PySyft/issues/2122,[],Backpropagation not producing gradients,"Backpropagation not producing gradientsI'm currently working on the implementation of the federated training of a Recurrent Neural Network, and I stumbled upon the following issue: when operating on the remote pointer of the loss function initialized with Negative Log Likelihood, the grad_fn function is not set and it will still say ""requires_grad=True"" despite the loss function being set in the code:

![requires_grad_True](https://user-images.githubusercontent.com/4907418/57189502-f826dd80-6f0f-11e9-9787-f2f8b39be1ae.png)

Instead, in the sequential version or when the input arguments of the loss function are "".get()"", the grad_fn is actually set in the loss function:

![requires_grad_fn](https://user-images.githubusercontent.com/4907418/57189535-40460000-6f10-11e9-8b8d-38f8442a703f.png)


Because of this issue, the backpropagation does not successfully generate all the model's gradient parameters (i.e.: only two parameters are generated in the remote version vs four parameters in the local version), hence preventing the model from converging in the remote version. I looked up if other people are having the same issue, and these pages seem to suggest that the graph is broken (?):  https://discuss.pytorch.org/t/list-model-parameters-0-grad-doubt-in-weight-updates/8422

To reproduce:

```
import torch.nn as nn
import torch
import syft as sy
import numpy as np

hook = sy.TorchHook(torch)  
dani = sy.VirtualWorker(hook, id=""dani"")  
ele = sy.VirtualWorker(hook, id=""ele"") 
workers_virtual = [dani, ele]

criterion = nn.NLLLoss()
output = torch.from_numpy(np.ones((1, 18)))
output.requires_grad_()
output_sent = output.send(dani)

category_single = torch.from_numpy(np.array([2]))
category_sent = category_single.send(dani)
#Non-working version, with requires_grad=True
loss = criterion(output_sent, category_sent) 
print(loss.copy().get()) #Requires_grad=True

#Working version, with grad_fn properly set.
loss_working = criterion(output_sent.copy().get(), category_sent.copy().get()) 
print(loss_working) #grad_fn = NllLossBackward

loss.backward()
```

#model just has 2 parameters with grad != None following the backpropagation. Consequently, during the training process, the model weights are not updated. 

for param in model_ptr.parameters():

Returns an error, as parameters at position [0] is not present.
I've tried to run the snippet above, and I got the following error:

```python
File ""original_syft_bug.py"", line 12, in <module>
    output = np.ones(1, 18)
  File ""/home/marianne/anaconda3/envs/syft/lib/python3.6/site-packages/numpy/core/numeric.py"", line 203, in ones
    a = empty(shape, dtype, order)
TypeError: data type not understood
```

I've changed line 12 to: `output = torch.from_numpy(np.ones((1, 18)))`

And the script doesn't break, it gives me the following output:

```python
tensor(-1., dtype=torch.float64, requires_grad=True)
tensor(-1., dtype=torch.float64, grad_fn=<NllLossBackward>)
```

I'm using syft from dev branch.Thank you for running my example!!
Yes, that's exactly the same output I got too. Isn't the pointed loss supposed to have grad_fn=<NllLossBackward> too? (the first tensor you're showing) . However, the issue is not in the loss per se,  but later on. In fact, after the backpropagation phase, not all the gradients are present as model's parameters in the federated version. (just 2 gradients are present among the model's parameters, whereas in the sequential version there are 4 gradients among the model parameters). So, it actually breaks here. This seems to be the same issue reported at: https://discuss.pytorch.org/t/list-model-parameters-0-grad-doubt-in-weight-updates/8422

```
  for param in model_ptr.parameters():
        #if(param.grad is not None):
        #Daniele: code breaks here, as not all gradient parameters are there
        param.data.add_(-args.learning_rate, param.grad.data)
```

I've attached a full example about my federated code for RNNs (kinda messy though). Bear in mind to change the following line before running it:

`os.chdir(""/home/daniele/py_thesis/RNN_Example"")`


I tried replicating my issue with the hidden layer, the model, the output and the input arguments obtained via the `""copy().get()""` function and the backpropagation seems to be successfully working in that case, with all gradients being present in the model's parameters.

This is the current non-working version:
![image](https://user-images.githubusercontent.com/4907418/57276202-20921180-70a1-11e9-9238-9fa10f6e9201.png)

Working version, with all variables extracted via the .get() function:

![image](https://user-images.githubusercontent.com/4907418/57276561-4bc93080-70a2-11e9-9cc4-b673a307bf07.png)


I presume there could be some issues the PySyft backpropagation function when operating on the remote pointers for such case?I believe the issue is related to the fact that the .grad and .data attributes are still not supported by PySyft, but there seems to be some code about it in syft/frameworks/torch about it. This comment seems to suggest that the .grad and .grad.data tensors are not supported yet?

            # TODO: add .data and .grad to syft tensors

However, it turns out that by de-commenting the following lines in syft/frameworks/torch/hook.py (which were previously commented), the gradients are properly computed following the backpropagation phase.

![image](https://user-images.githubusercontent.com/4907418/57285656-f6961a80-70b3-11e9-8fab-c5bc4cb2ed10.png)



Fixed by #2127, great job @DanyEle!",5,2019-05-05 06:59:52,2019-05-08 20:19:47,2019-05-08 20:19:47
https://github.com/OpenMined/PySyft/issues/2083,"['bug ', 'status: stale :bread:']",Error Creating Tensor of Tensors,"Error Creating Tensor of TensorsYou get an error stating TypeError: Not a Sequence when you create a tensor of tensors. This does not occur when test functions are called manually locally but occurs when Travis is run. I am guessing we haven't hooked the function that is used to create a tensor using tensors. 

`torch.tensor([torch.tensor(1),torch.tensor(2),torch.tensor(3)])`

I get this error too, when creating a tensor of tensors in a custom class. Does anyone have a work around for the moment?I did this 

```
def tensors_to_literals(tensor_list):
    """"""Converts list of torch tensors to list of integers/floats. Fix for not having the functionality which converts list of tensors to tensors
       Args:
           tensor_list[List]: List of torch tensors
        
       Returns:
           literal_list[List]: List of floats/integers
    """"""

    literal_list = []

    for tensor in tensor_list:
        literal_list.append(tensor.item())

    return literal_list
```

Also try using torch.cat to convert list of tensors into a single tensor. Thanks!This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2019-04-20 11:56:45,2020-05-25 00:08:56,2020-05-25 00:08:56
https://github.com/OpenMined/PySyft/issues/2081,[],Problem at encrypted evaluation with remote workers,"Problem at encrypted evaluation with remote workers When I try to implement an encrypted evaluation application using remote workers, I am experiencing the following problems: 

> --- Logging error ---
Traceback (most recent call last):
  File ""/usr/lib/python3.6/logging/__init__.py"", line 994, in emit
    msg = self.format(record)
  File ""/usr/lib/python3.6/logging/__init__.py"", line 840, in format
    return fmt.format(record)
  File ""/usr/lib/python3.6/logging/__init__.py"", line 577, in format
    record.message = record.getMessage()
  File ""/usr/lib/python3.6/logging/__init__.py"", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File ""run_websocket_server.py"", line 48, in <module>
    server = start_proc(WebsocketServerWorker, kwargs)
  File ""run_websocket_server.py"", line 20, in start_proc
    p.start()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 277, in _Popen
    return Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 73, in _launch
    code = process_obj._bootstrap()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""run_websocket_server.py"", line 17, in target
    server.start()
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/websocket_server.py"", line 125, in start
    asyncio.get_event_loop().run_forever()
  File ""/usr/lib/python3.6/asyncio/base_events.py"", line 427, in run_forever
    self._run_once()
  File ""/usr/lib/python3.6/asyncio/base_events.py"", line 1440, in _run_once
    handle._run()
  File ""/usr/lib/python3.6/asyncio/events.py"", line 145, in _run
    self._callback(*self._args)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/websocket_server.py"", line 92, in _producer_handler
    response = self.recv_msg(message)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/base.py"", line 228, in recv_msg
    (msg_type, contents) = sy.serde.deserialize(bin_message, worker=self)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 151, in deserialize
    return _detail(worker, simple_objects)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1227, in _detail
    return detailers[obj[0]](worker, obj[1])
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 612, in _detail_collection_tuple
    pieces.append(_detail(worker, part))
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1227, in _detail
    return detailers[obj[0]](worker, obj[1])
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 426, in _detail_torch_tensor
    chain = _detail(worker, chain)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1227, in _detail
    return detailers[obj[0]](worker, obj[1])
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/serde.py"", line 1014, in _detail_additive_shared_tensor
    owner=worker, id=tensor_id, field=field, crypto_provider=worker.get_worker(crypto_provider)
  File ""/home/ionesio/workspace/tcc/venv/lib/python3.6/site-packages/syft-0.1.12a1-py3.6.egg/syft/workers/base.py"", line 594, in get_worker
    logging.warning(""Worker"", self.id, ""couldn't recognize worker"", id_or_worker)
Message: 'Worker'
Arguments: ('alice', ""couldn't recognize worker"", 'crypto_provider')

Apparently, workers are failing to communicate / recognize.

When I replace remote workers with virtual workers, the application works perfectly.

Workers Manager application: https://hastebin.com/ruxuqejabi.py
Start remote workers app: https://hastebin.com/koxukoqoxa.makefile
Web socket server: https://hastebin.com/eciviwijib.pyHey @IonesioJunior, 

I'll have a look at this!@IonesioJunior, I've just tried using the `dev` branch and it works. Can you try again with the most updated version of `dev`?My current settings:
syft == 0.1.12a1
Python == 3.6.7
torch == 1.0.1.post2

The error still persists with these settings, but discarding the possibility of a bug has lessened my effort to find the problem. I believe it's something related to the multiple versions of python / libraries that I use on my machine. I'll dig deeper.
Thank you anyway  :smiley:.",3,2019-04-18 17:05:08,2019-04-19 20:53:02,2019-04-19 20:53:02
https://github.com/OpenMined/PySyft/issues/2080,[],Net has no attribute 'share',"Net has no attribute 'share'I faced the same error pointed out in the comment section of your blog post Encrypted Deep Learning Classification with PyTorch & PySyft in my project  https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py.

AttributeError: 'Simple_CNN' object has no attribute 'share'

https://blog.openmined.org/encrypted-deep-learning-classification-with-pysyft/
+1It is defined here: https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/hook.py#L981

Can you share a code sample failing please?```
import torch
import torch.nn as nn
import torch.nn.functional as F
import syft as sy


class Simple_CNN(nn.Module):
    def __init__(self):
        super(Simple_CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 20, 3, 3)
        self.conv2 = nn.Conv2d(20, 50, 3, 3)

        self.fc1 = nn.Linear(50, 500)
        self.fc2 = nn.Linear(500, 2)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def reproduce_error():
    model = Simple_CNN()

    hook = sy.TorchHook(torch)
    client = sy.VirtualWorker(hook, id=""client"")
    bob = sy.VirtualWorker(hook, id=""bob"")
    alice = sy.VirtualWorker(hook, id=""alice"")
    crypto_provider = sy.VirtualWorker(hook, id=""crypto_provider"")

    model.fix_precision().share(alice, bob, crypto_provider=crypto_provider)


if __name__ == ""__main__"":
    reproduce_error()
```@2fasc just tried this code snippet with the most current version (dev branch) and it runs. Can you try again?@mari-linhares thank you! It works :+1:  

`pip install https://github.com/OpenMined/PySyft/archive/dev.zip`@2fasc (or @LaRiffle) can you close this issue?",6,2019-04-18 14:41:03,2019-04-23 12:58:54,2019-04-23 12:58:54
https://github.com/OpenMined/PySyft/issues/2079,[],Create interface for objects able to send and catch tensor operations,"Create interface for objects able to send and catch tensor operationsAs discussed at #2068:

>  *The reason why it (Plan) was a worker is that we needed to use the functionality to catch function and method calls on torch tensors, just the way it is done by workers sending commands between each other*

In the future is possible that this functionality could be useful for other non-worker objects. I suggest that we create an interface that implements this and a worker implements this interface.



@LaRiffle any idea about how to make this work? I've tried for a bit, but I'm having a hard time.

I think the problem is the ways plans are built ([more specifically line 146](https://github.com/OpenMined/PySyft/blob/cd4d6e985c03b9cf57b784c4f49eed47e116bbda/syft/workers/plan.py#L146)). Any ideas or suggestions?So maybe what we could do is, instead of recreating a worker of each plan, to use the plan owner. 
Example:
you have a plan f and some data x, which you all send to bob. F is unbuild. When you do f(x) the first time, you tell bob ""Hey, the next commands you'll get should be stored in the my plan f"", you run the commands in f, and then ""Ok bob, now build the plan with those commands and run it"", and you and him set the plan to ""built"". The second time (or the first time if you sent your plan f already built), when you do f(x2), actually you say to bob ""Hey, remember f? Give him my x2 and run it"".

This way you relie on Bob ability to catch calls, and plan appear more like what they should be: benign objects, which can be stored by workers and can have Pointers referencing them (in line with #2096)Right now, I feel like we can treat each specific case differently like was done in #2098.",3,2019-04-18 13:25:36,2019-04-25 02:04:03,2019-04-25 02:04:03
https://github.com/OpenMined/PySyft/issues/2076,['bug '],Search remote data will cause the data being deleted,"Search remote data will cause the data being deletedI've experimented on getting PySyft to work with remote worker with its own dataset.
During these, I found out the `search` from local will cause the data deleted on the remote.

Relevant files in [this gist](https://gist.github.com/feigaoxyz/99dffd2f4336417f83f0cf4e1c80d8fd).

To trigger the error, 
1. First run `python remote.py` in one terminal window
2. Then run `python local.py` from another terminal window

You will see the results:

```sh
$ python remote.py
Objects: {94139650912: tensor([-1.,  2.])
	Tags: x
	Shape: torch.Size([2])}
worker <WebsocketServerWorker id:0 #tensors:1> received SEARCH (b'x',)
worker <WebsocketServerWorker id:0 #tensors:1> received OBJ_DEL 94139650912
Objects: {}
```

```sh
$ python local.py
Local objects before search {}
Search result: [(Wrapper)>[PointerTensor | me:68744693343 -> 0:13527568418]]
Local objects after search {}
```

As the first one showed: the remote worker actually received two actions `SEARCH` and `OBJ_DEL` in correspondence with the search command on Line 20 of local.py.

---

This error can also be reproduced by slightly modifying the `test/test_websocket_woker.py` by searching same term twice, see [L57 of updated test](https://gist.github.com/feigaoxyz/99dffd2f4336417f83f0cf4e1c80d8fd#file-test_websocket_woker-py).This is usually because a function (in this case search()) is returning pointers with self.garbage_collect_data==True. This means that when the pointers are deleted (garbage collected) that it sends a delete command to the remote machine.Have you gotten https://github.com/OpenMined/PySyft/tree/dev/examples/experimental/Federated%20Learning%20Experiment to work on your local setup?Yes, I can get this example working. 

(A side note, perhaps it would be better to have some detail instructions in files to help others running.)@feigaoxyz can you open a new issue (or issues) pointing to parts of the documentation that are not clear? 

Thank you!Hi @iamtrask 

Are you able to reproduce this error from your side?
The simplest way is to replicate the search and asserts again after the first round in [this standard test file for websocket worker](https://github.com/OpenMined/PySyft/blob/4251f728bdff186328b7c24603dedf09e3037230/test/workers/test_websocket_worker.py#L51-L55).
Hi @mari-linhares 

Some of my thoughts on the ""FL experiment"" example as its current state:
1. add a readme to guide user to run the server with either
  - `FLASK_APP=server.py flask run`; or
  - add `app.run()` in `server.py` and run `python server.py`
2. a clean-up on `ipynb`.

I might put a PR when I got some time.",6,2019-04-17 11:40:04,2019-05-17 10:25:10,2019-05-09 17:57:36
https://github.com/OpenMined/PySyft/issues/2071,"['bug ', 'status: stale :bread:']",Federating datasets doesn't work with subsets,"Federating datasets doesn't work with subsetsI don't know if this is an issue of general interest but PySyft would be more versatile if it were more agnostic in the way it handles datasets in dataset.federate((...))

I wrote a little tool to convert Subsets (also of ImageFolder datasets) to regular Datasets as a fix but it ain't a pretty solution:

```
class DatasetFromSubset(Dataset):
    def __init__(self, subset):
        data, targets = self.subset_to_dataset(subset)
        self.data = data
        self.targets = targets

    def __len__(self):
        return len(self.targets)

    def __getitem__(self, index):
        return self.data[index, :], self.targets[index]

    @staticmethod
    def subset_to_dataset(subset):
        indices = subset.indices
        targets = subset.dataset.targets

        targets_subset = torch.tensor(
            [targets[ii] for ii in list(indices.data.numpy())]
        )

        # Empty definition
        concat_tensor = None

        dataloader = torch.utils.data.DataLoader(subset, batch_size=2000, shuffle=False)

        for ii, (data, target) in enumerate(dataloader):
            print(ii)

            if ii == 0:
                concat_tensor = data
            else:
                concat_tensor = torch.cat((concat_tensor, data), 0)

return concat_tensor, targets_subset
```Very interesting feature! What kind of subset are you interested in selecting?@iamtrask I assume it is linked to this example: https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py>  What kind of subset are you interested in selecting?
 
I'm using `torch.utils.data.random_split(dataset, size_set)` to split datasets into train, test and validation sets. This basically creates a new class that contains the original dataset and adds a list of indices assigned to each split. 


> I assume it is linked to this example: https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py

Exactly. I'm curious how imbalanced label distributions affect federated / distributed training. 
@2fasc thanks for posting your code. How do I use it to convert an imagefolder dataset to a dataset that I can federate? This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",5,2019-04-15 08:59:34,2020-05-25 00:08:57,2020-05-25 00:08:57
https://github.com/OpenMined/PySyft/issues/2070,['bug '],Adam causes errors in training loop ,"Adam causes errors in training loop [Related to #1909]

I tracked down the error to 
 'optimizer = optim.Adam(model.parameters(), lr=1e-3)' in my code,  'optimizer = optim.SGD(model.parameters(), lr=1e-3)' works.

My guess is that this is related to me using PyTorch 1.0 .

The code can be found in https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py

```
Traceback (most recent call last):
  File ""/home/fasc/Documents/Distributed_Malaria/src/federated_training.py"", line 143, in <module>
    simple_federated_model()
  File ""/home/fasc/Documents/Distributed_Malaria/src/federated_training.py"", line 66, in simple_federated_model
    federated=True,
  File ""/home/fasc/Documents/Distributed_Malaria/src/auxiliaries.py"", line 111, in train
    optimizer.step()
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/torch/optim/adam.py"", line 94, in step
    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 650, in overloaded_native_method
    response = method(*new_args, **new_kwargs)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 486, in overloaded_pointer_method
    response = owner.send_command(location, command)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 364, in send_command
    _ = self.send_msg(MSGTYPE.CMD, message, location=recipient)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 198, in send_msg
    bin_response = self._send_msg(bin_message, location)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/virtual.py"", line 6, in _send_msg
    return location._recv_msg(message)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/virtual.py"", line 9, in _recv_msg
    return self.recv_msg(message)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 229, in recv_msg
    response = self._message_router[msg_type](contents)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/workers/base.py"", line 316, in execute_command
    getattr(_self, command_name)(*args, **kwargs)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 636, in overloaded_native_method
    raise route_method_exception(e, self, args, kwargs)
  File ""/home/fasc/miniconda3/envs/malaria/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 630, in overloaded_native_method
    response = method(*args, **kwargs)
TypeError: addcmul_() takes 2 positional arguments but 3 were given
```Hmm - it's not totally clear to me why this would be the case. Will require a deeper look. I don't think we have any unit tests around Adam so this might just require new functionality to get working.I'm looking at it right now
First observation: Adam optim works in the setting of https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb if you replace the SGD optim with Adam.Oh actually it fails, but after a certain number of batch iterations
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.303720
Train Epoch: 1 [1920/60032 (3%)]	Loss: 3.148396
Train Epoch: 1 [3840/60032 (6%)]	Loss: 4.953410
Train Epoch: 1 [5760/60032 (10%)]	Loss: 6.552952
Train Epoch: 1 [7680/60032 (13%)]	Loss: 8.274794
Train Epoch: 1 [9600/60032 (16%)]	Loss: 9.585523
Train Epoch: 1 [11520/60032 (19%)]	Loss: 11.709550
Train Epoch: 1 [13440/60032 (22%)]	Loss: 14.805451
Train Epoch: 1 [15360/60032 (26%)]	Loss: 14.508088
Train Epoch: 1 [17280/60032 (29%)]	Loss: 18.298759
Train Epoch: 1 [19200/60032 (32%)]	Loss: 16.543806
Train Epoch: 1 [21120/60032 (35%)]	Loss: 19.365683
Train Epoch: 1 [23040/60032 (38%)]	Loss: 23.546900
Train Epoch: 1 [24960/60032 (42%)]	Loss: 26.782951
Train Epoch: 1 [26880/60032 (45%)]	Loss: 28.923700
Train Epoch: 1 [28800/60032 (48%)]	Loss: 28.413818
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()
---> 10         optimizer.step()
     11         model.get() # <-- NEW: get the model back
     12         if batch_idx % args.log_interval == 0:

~/code/env/pysyft/lib/python3.7/site-packages/torch/optim/adam.py in step(self, closure)
     92                 # Decay the first and second moment running average coefficient
     93                 exp_avg.mul_(beta1).add_(1 - beta1, grad)
---> 94                 exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
     95                 if amsgrad:
     96                     # Maintains the maximum of all 2nd moment running avg. till now

~/code/PySyft/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    650                 # Send the new command to the appropriate class and get the response
    651                 method = getattr(new_self, method_name)
```I suspect there is a bug in the hooking as the loss is increasingOk here is the trouble: Adam uses momentum (actually: second moments of the gradients), which means it stores the gradients in a list and for each batch produces a correction of the current gradient based on the old ones. When changing of batch owner (so in Part 8 of tutorial at the middle of the epoch), you have now gradients from alice which you want to correct with moments of old gradients owned by bob: this is not possible as the data needs to be at the same location and it raises an error, which is here a bit tricky to find.
This is also why momentum is not supported so far on SGD.

The fix for this would probably imply to rewrite the optimizers. This is an important project and maybe could be correlated to the notions of aggregator needed for Federated or Secure Averaging.

Thank you for reporting the error!Is there a way for us to perhaps clear out the momentum as needed? (reset to None)Hey @2fasc - seems like the solution here is to have different optimizers for different machines (one for bob, another for alice, etc.) Eventually we'll write custom Federated optimizers but for now this is the solution :)Fastest way to do this is probably to have a dict of optimizers, the key being the data.location, this would keep the code simpleJust wondering, is this related to #1909 ?@mari-linhares exactly!Yes, according @iamtrask , you can write a optimizer list like Part4 or Par10, then you can use Adam, Adadelta or other optimizer with momentum. @2fasc @LaRiffle I've experienced the increasing loss issues with my Adam as well.

But, since it wasn't raising errors, I tried to see where things went numerically wrong.

Somehow, in Adam's `step()` method, changing this line
```
exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
```
to this line
```
exp_avg_sq.mul_(beta2).add_(grad.pow(2).mul_(1 - beta2))
```

and this line
```
p.data.addcdiv_(-step_size, exp_avg, denom)
```
to this line
```
p.data.add_(exp_avg.div(denom).mul_(-step_size))
```

made it work and the loss decreased with no problem.

So, it seems like `addcmul_()` and `addcdiv_()` functions have issues working with PySyft, but doing what those functions do step by step somehow fixes them.> @LaRiffle I've experienced the increasing loss issues with my Adam as well.
> 
> But, since it wasn't raising errors, I tried to see where things went numerically wrong.
> 
> Somehow, in Adam's `step()` method, changing this line
> 
> ```
> exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
> ```
> 
> to this line
> 
> ```
> exp_avg_sq.mul_(beta2).add_(grad.pow(2).mul_(1 - beta2))
> ```
> 
> and this line
> 
> ```
> p.data.addcdiv_(-step_size, exp_avg, denom)
> ```
> 
> to this line
> 
> ```
> p.data.add_(exp_avg.div(denom).mul_(-step_size))
> ```
> 
> made it work and the loss decreased with no problem.
> 
> So, it seems like `addcmul_()` and `addcdiv_()` functions have issues working with PySyft, but doing what those functions do step by step somehow fixes them.

coolWhen this is fixed remember to remove the TODO at https://github.com/OpenMined/PySyft/blob/319d59c9aa3ab9b8dfda95c42f7dd5978b3bc48a/examples/tutorials/advanced/websockets-example-MNIST/run_websocket_client.py#L55

https://github.com/OpenMined/PySyft/blob/ac3d6172c268e26bf0a7100c6ee0a7f4cc4d8890/examples/tutorials/advanced/Federated%20CIFAR10.ipynb#L465

https://github.com/OpenMined/PySyft/blob/2776cffc619dacf9486584f6e455104d80901928/examples/tutorials/Part%2006%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb#L378Just a small report, I'm running into a similar error, but it appears a few lines earlier:
```
exp_avg.mul_(beta1).add_(1 - beta1, grad)
```

The following error appears:
```
TypeError: add_() takes 1 positional argument but 2 were given
```

So it's to be a more general problem than only specific functions like `addcmul_()` and `addcdiv_()`> Just a small report, I'm running into a similar error, but it appears a few lines earlier:
> 
> ```
> exp_avg.mul_(beta1).add_(1 - beta1, grad)
> ```
> 
> The following error appears:
> 
> ```
> TypeError: add_() takes 1 positional argument but 2 were given
> ```
> 
> So it's to be a more general problem than only specific functions like `addcmul_()` and `addcdiv_()`

I encountered an error in the same line, but it raises 

> syft.exceptions.PureFrameworkTensorFoundError

Syft 0.1.26a1
Torch 1.1.0Any solutions yet?Yes - the solution was the FL Optimizer project. We can close this issue.

On Tue, Mar 17, 2020 at 12:49 PM Aditya Malte <notifications@github.com>
wrote:

> Any solutions yet?
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2070#issuecomment-600052348>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEQSAB62MQJMRJT2MQTRH5WW5ANCNFSM4HF52S2Q>
> .
>
Could you give a link please?@aditya-malte 
https://github.com/OpenMined/PySyft/issues/3141
https://github.com/OpenMined/PySyft/pull/3179/files> 
> Yes - the solution was the FL Optimizer project. We can close this issue.
> [â€¦](#)
> On Tue, Mar 17, 2020 at 12:49 PM Aditya Malte ***@***.***> wrote: Any solutions yet? â€” You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#2070 (comment)](https://github.com/OpenMined/PySyft/issues/2070#issuecomment-600052348)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ABBAZEQSAB62MQJMRJT2MQTRH5WW5ANCNFSM4HF52S2Q> .

Alright, I'll close the issue then",21,2019-04-15 08:53:42,2020-03-24 13:34:02,2020-03-24 13:34:02
https://github.com/OpenMined/PySyft/issues/2049,['bug '],Custom Neural Network in Federated Learning,"Custom Neural Network in Federated LearningHi,
I've experienced a problem while replacing the simple Neural Network of the ""Federated CIFAR 10 Example"" with more complex ones - eg. those untrained models in torchvision.models. 

I've replaced `model = Net().to(device)` by 
`import torchvision.models as models; model = models.resnet18()` and left everything else untouched, but at `output = model(data)` I'm always receiving a ""RuntimeError: bool value of Tensor with no values is ambiguous"". 

It seems that the model tries to make a prediction on an empy tensor - however, the tensor should be there, as it's working with the simple model in the tutorial.

Do you have any suggestions? 
Thank you@flo257 Thank you for raising this issue.We haven't particularly thought of developing support for pretrained models from torch vision , but in the near future we will ensure the support for it is taken care of :) Hi @flo257 - it sounds like there's an issue with the way the model is deserialized. In particular, we have to wrap all of our custom tensor types (wrapped by empty tensors). There's no reason why your operation shouldn't work - but it's hard for me to debug without seeing the code. Can you upload what you've got here? How can I reproduce?Sure - I've used the ""Federated CIFAR 10 Example"" here on GitHub from `/examples/tutorials/advanced/`and only changed the line `model = Net().to(device)` into `import torchvision.models as models; model = models.resnet18().to(device)` while leaving everything else untouched. 

You can reproduce this by simply changing this line on the tutorial in the jupyter notebook and start the training process. I think this is related to #2175, I'm closing this for now. Feel free to re-open if after #2175 is fixed this is still a problem.",4,2019-04-09 07:25:00,2019-06-15 18:55:12,2019-06-15 18:55:12
https://github.com/OpenMined/PySyft/issues/2047,[],Key error in hook_args when calling torch.randn(),"Key error in hook_args when calling torch.randn()```
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import syft as sy  # <-- NEW: import the Pysyft library
hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning

a=torch.randn_like(torch.ones(1,2))
print(a)
a=torch.randn(1,2)
print(a)
```

`a=torch.randn_like(torch.ones(1,2))`
works properly but error occurres when executing torch.randn()
```
Traceback (most recent call last):
  File ""/home/crd/.local/lib/python3.6/site-packages/syft/frameworks/torch/hook_args.py"", line 134, in hook_function_args
    hook_args = hook_method_args_functions[attr]
KeyError: 'torch.randn'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 11, in <module>
    a=torch.randn(1,2)
  File ""/home/crd/.local/lib/python3.6/site-packages/syft/frameworks/torch/hook.py"", line 690, in overloaded_func
    response = TorchTensor.handle_func_command(command)
  File ""/home/crd/.local/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 191, in handle_func_command
    cmd, args, kwargs, return_args_type=True
  File ""/home/crd/.local/lib/python3.6/site-packages/syft/frameworks/torch/hook_args.py"", line 141, in hook_function_args
    args, return_tuple=True
  File ""/home/crd/.local/lib/python3.6/site-packages/syft/frameworks/torch/hook_args.py"", line 171, in build_hook_args_function
```The thing is that we haven't hooked torch.randn yet. Check issue https://github.com/OpenMined/PySyft/issues/2046 we should hopefully get it ready soon. For now what you could do is create a random array in numpy and convert it to a torch tensor. Thanks @peter9711 for reporting this issue, don't hesitate tu put the full stacktrace next time, the real message was in the part you cut. I'm issuing a fix in a few minutes!#2048",3,2019-04-08 13:45:23,2019-04-08 15:36:19,2019-04-08 15:36:19
https://github.com/OpenMined/PySyft/issues/2036,[],Custom Federated Data Loader Tutorial ,"Custom Federated Data Loader Tutorial Create a tutorial explaining how the users could create custom Federated Data Loaders to load their data. Ideally an example of image and text dataset. Example of how this was done with text dataset is given in the <a href=""https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Advanced/Federated%20Word%20Vectors.ipynb"">Federated Word Vectors Tutorial</a> . Is there any major difference in the creation of a federated data loader to a regular pytorch data loader?@mari-linhares There are some minor differences which is why it helps to have a separate tutorial on it. 
For, instance unlike Torch data loader you can't load text inside the training loop and then convert them to torch tensors, you need to convert them beforehand so that they could be sent to the desired workers and there are some attributes that need to be created such as data and target. 
Although they aren't significant it helps to have the user informed about such intricacies and have code reference that works :) Cool, makes sense. Thanks for the great explanation!",3,2019-04-02 15:25:40,2019-05-02 06:03:48,2019-05-02 06:03:48
https://github.com/OpenMined/PySyft/issues/2011,[],Federated learning not working on multi-layer fully connected model,"Federated learning not working on multi-layer fully connected modelI am trying to build a federated model with 2 virtual workers bob and alice. I am following code from examples folder to build my model. The model seems to perfectly it is a single fully connected layer but doesn't learning when I increase the layers and change loss function to CrossEntropy. 
**Single Layer:**
**Model -** 
`model = nn.Linear(8,2)
loss= torch.nn.MSELoss()`
**Output -** 
<img width=""833"" alt=""Screenshot 2019-03-25 at 6 56 35 PM"" src=""https://user-images.githubusercontent.com/11030979/54959572-e5dc7b80-4f2f-11e9-8563-161ba374879a.png"">

**Multi Layer :**
**Model -**
 `
class my_network(torch.nn.Module):

     def __init__(self):
        super(my_network, self).__init__()
        self.fc1=nn.Linear(data_width,200)
        self.fc2=nn.Linear(200,100)
        self.fc3=nn.Linear(100,2)
    
    def forward(self,input_):
        a1=F.relu(self.fc1(input_))
        a1=F.relu(self.fc2(a1))
        y=self.fc3(a1)
        return F.softmax(y,dim=1)

     loss= torch.nn.CrossEntropyLoss()
`

 
**Output -** 
<img width=""757"" alt=""Screenshot 2019-03-25 at 7 01 49 PM"" src=""https://user-images.githubusercontent.com/11030979/54959742-7450fd00-4f30-11e9-80e0-de55728d5b51.png"">

This might be a trivial issue but I am new to PyTorch and PySyft and I've been trying to solve this problem for a week without any success. Hey @mshubhankar, I'm having a look at this. I'll let you know if I find anything. Can you share the notebook you're using (a [gist](https://gist.github.com/) link would be great)? Thanks!Thank you for looking into the matter @mari-linhares . The link to the gist code is [here](https://gist.github.com/mshubhankar/94bb81d13290ed29f687fdeafefee5d9) .Hi @mshubhankar, I've modified your code to use a fake dataset and I was able to train a model using multi-layers and crossentropy ([here](https://gist.github.com/mari-linhares/c6c76ed8933b6cfed785d6c95b34e5fe)).

The only big difference from my example to yours is that you're using AdamOptimizer, try to use SGD instead. I think momentum is not yet supported so that's why you may be seeing a strange behavior.

Oh thank you so much @mari-linhares !!!! I have been banging my head for this for such a long time now for this!",4,2019-03-25 23:17:22,2019-03-31 20:43:58,2019-03-31 20:43:57
https://github.com/OpenMined/PySyft/issues/2009,[],Configuration of the system,"Configuration of the systemWhile working on `seder` I found out that more and more having a configuration would help when adding workers.
In the case of external workers (Android, web sockets) they do not have direct access to the configuration used when starting the federated setup. Though part of this information can be inserted in the stream sent and received by the workers other is only part of a set of assumptions

Having a configuration when a worker starts would have some benefits as:
* Knowing which serialisation is in use
* Homogenisation of the compression schemes. If a worker cannot use the compression scheme used by other, it could discard itself from the federation
* Check compatibility of backends

The configuration could be sent to a worker when it's first instantiated or when it first connects to a socket server or aggregation server

@mccorby is this still open (in discussion)?
There has not been much of a discussion about it. I still think it will be necessary if we intend to expand PySyft to other systems but we can reopen this if we need to
Or maybe I can come back with a plan :)",2,2019-03-25 11:25:55,2019-05-05 07:51:28,2019-05-05 07:51:28
https://github.com/OpenMined/PySyft/issues/1992,['bug '],Urgent: fail gracefully when initializing two VirtualWorker objects with the same id/name,"Urgent: fail gracefully when initializing two VirtualWorker objects with the same id/nameWhen people are introduced to PySyft, they often fall into the mistake (particularly in Jupyter Notebbooks) of initializing a VirtualWorker with the same ID twice. This causes really strange errors because both workers end up co-existing together. We need to modify the VirtualWorker (or perhaps the BaseWorker) API to make it so that this fails gracefully (aka... that the new worker actually becomes the old worker or all intensive purposes)

Aka - we want this code to function normally

bob = sy.VirtualWorker(hook, ""bob"")

x = th.tensor([1,2,3,4,5]).send(bob)

bob = sy.VirtualWorker(hook, ""bob"")

y = th.tensor([1,2,3,4,5]).send(bob)

z = x + y

z.get() # returns [2,4,6,8,10]


We should accomplish this by having both the new ""bob"" and the old ""bob"" point to the same underlying _objects dictionary.
At any moment, you can check all the virtual workers present on your process by retrieving syft.hook.local_worker.(known_workers) as they get automatically added to this list on __init__. Just making a search and returning the already existing one if any should fix the pb@LaRiffle Tried this out. Trying to naively return the known worker with the same id, causes over half of the tests to fail. I am of the impression it might be best to make this simply throw a verbose error for the moment. #2000 for reference to my changes @robert-wagner just tried your solution (#2000) with a small modification and it seems to work, can you check if it makes sense? I've just made the PR #2022. Thanks!",3,2019-03-13 19:02:05,2019-03-29 14:09:43,2019-03-29 14:09:43
https://github.com/OpenMined/PySyft/issues/1981,[],bug in Federated learning on MNIST using CNN while loading federated dataset !,"bug in Federated learning on MNIST using CNN while loading federated dataset !Hi,
In the FederatedDataLoader function
on the execution of this  statement
federated_train_loader = sy.FederatedDataLoader( datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])) .federate((bob, alice)), batch_size=args.batch_size, shuffle=True, **kwargs)

It gives this as an ERROR :-

'MNIST' object has no attribute 'federate'

 any suggestion or procedure can help!
Thank you.
Would you mind sharing the complete snippet of code you used?
Thanks!*THIS IS  THE CODE SNIPPET :- *
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

*THIS IS THE ERROR :- *

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-4085cd6569bc> in <module>
      3                    transform=transforms.Compose([
      4                        transforms.ToTensor(),
----> 5                        transforms.Normalize((0.1307,), (0.3081,))
      6                    ]))
      7     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset

AttributeError: 'MNIST' object has no attribute 'federate'
> Would you mind sharing the complete snippet of code you used?
> Thanks!

https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb

 I tried to run exact code from this link but it showed that error.Oh this is strange, and you didn't make any changes in the code or imports ?Hey @Adarshsng, are you still getting errors with the most updated version of syft and torch?Would be cool to see applications of CNN's in the field of construction and project management, nothing to do with bug fixes in code - but a life-saving idea nonetheless. I know most devs focus on merchandise and e-commerce when applying a convolutional, yet there exists a vast library of architecture and blueprints from companies in mech engineerin' (Caterpillar, John Deere, Toyota) that remain in the dark  Hopefully if you manage to debug the FederatedDataLoader you could find time to explore new datasets

Gears Churnin'> > Would you mind sharing the complete snippet of code you used?
> > Thanks!
> 
> https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb
> 
> I tried to run exact code from this link but it showed that error.

link broken.This error appears when you haven't hooked PySyft:
`hook = sy.TorchHook(torch) `
`bob = sy.VirtualWorker(hook, id=""bob"") `

Can you review you did that?",8,2019-03-08 07:47:39,2019-09-23 14:29:47,2019-09-23 14:29:47
https://github.com/OpenMined/PySyft/issues/1978,[], Bug in Federated Learning on MNIST using a CNN,"Bug in Federated Learning on MNIST using a CNNHi, 
In the FederatedDataLoader function, `**kwargs` is passed as a parameter. 
> kwargs = {'num_workers': 1, 'pin_memory': True}

However, the DataLoader function implementation in Pysyft doesn't take `num_workers` and `pin_memory` as arguments as in pytorch. 

> **Hence running this below snippet results in an error:**

> `federated_train_loader = sy.FederatedDataLoader( 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), 
    batch_size=args.batch_size, shuffle=True, **kwargs)`

Shouldn't this argument be removed from this function?Hi, this has been fixed in #1982
The change should be already in dev branch, and next week in master
You can now use this code and it should work!Okay, thanks!",2,2019-03-06 19:14:44,2019-03-09 13:51:19,2019-03-09 13:45:38
https://github.com/OpenMined/PySyft/issues/1975,"['bug ', 'help wanted :wave:']",Get .max() working on PointerTensor; multiple ptrs in response,"Get .max() working on PointerTensor; multiple ptrs in responseWe can't return tuples of tensors when calling remote executions. This means that functions like .max() fail on PointerTensor objects.```
import torch 
import syft as sy
hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")
x = torch.tensor([1,2,3,4,5])
x_ptr = x.send(bob)
print(x_ptr.max())
```

Currently, `x_ptr.max()` returns  `(Wrapper)>[PointerTensor | me:73509977871 -> bob:73509977871]`
and instead, should return `5` right?
@iamtrask I was wondering, if we should build an interface to directly enable all torch tensor functionalities to pointer tensor? Is that something useful? Do we require all torch functionality for pointer tensor? Why do we specifically need max?max is one between others (torch.split, etc.), basically all functions that can return more than one tensors with fail if they are run remotely as we explicitely always make the assumption the response is a unique tensor.",3,2019-03-05 15:21:51,2019-03-12 15:17:46,2019-03-12 15:17:46
https://github.com/OpenMined/PySyft/issues/1945,[],Looking for a runnable demo,"Looking for a runnable demoThe tutorial is almost broken, and unfinished.
I'd like to find pieces of example code on federated learning with SMC and DP.
Is there any of them?The tutorials on Federated Learning are very much working :) 

https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials for Torch1 version of PySyft. Currently, Torch 1 supports only federated learning and DP is under experimental which you could review if you would like to. 

 We did have SMPC on our previous version supported for torch 0.3.1 version only.

https://github.com/OpenMined/PySyft/tree/torch_031/examples/tutorials
Thanks a lot.
I'll try on torch_031 branch.",2,2019-02-25 07:33:38,2019-02-26 06:43:42,2019-02-26 06:43:42
https://github.com/OpenMined/PySyft/issues/1919,[],.get() operation failed,".get() operation failedMy version is
PySyft-dev
Python 3.6.5
Pytorch '1.0.0'
I did the Tutorial Section 1.1 on page https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%201%20-%20The%20Basic%20Tools%20of%20Private%20Deep%20Learning.ipynb

The same code.

import syft as sy
from syft.frameworks.torch.tensors.interpreters import PointerTensor
from syft.frameworks.torch.tensors.decorators import LoggingTensor
import sys
import torch
hook = sy.TorchHook(torch)
from torch.nn import Parameter
import torch.nn as nn
import torch.nn.functional as F

bob = sy.VirtualWorker(hook, id=""bob"")
x=torch.tensor([1,2,3,4,5])
y=torch.tensor([1,1,1,1,1])
x_ptr=x.send(bob)
y_ptr=y.send(bob)
print(bob._objects)
z=x_ptr+x_ptr
print(z)
print(bob._objects)
print(x_ptr)
x_ptr.get()
print(y_ptr)
y_ptr.get()
z.get()
print(bob._objects)

When I do 'z.get()', errors shows below while bob._objects still has tensor z with the same number.

Error log:

Traceback (most recent call last):

  File ""<ipython-input-4-11b60d6ede25>"", line 1, in <module>
    runfile('D:/my_program/python/syft/start_test/test_start.py', wdir='D:/my_program/python/syft/start_test')

  File ""C:\Program_Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 705, in runfile
    execfile(filename, namespace)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""D:/my_program/python/syft/start_test/test_start.py"", line 52, in <module>
    z.get()

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\frameworks\torch\tensors\interpreters\native.py"", line 419, in get
    tensor = self.child.get(*args, **kwargs)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\frameworks\torch\tensors\interpreters\pointer.py"", line 209, in get
    tensor = self.owner.request_obj(self.id_at_location, self.location)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 455, in request_obj
    obj = self.send_msg(MSGTYPE.OBJ_REQ, obj_id, location)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 148, in send_msg
    bin_response = self._send_msg(bin_message, location)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\virtual.py"", line 6, in _send_msg
    return location._recv_msg(message)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\virtual.py"", line 9, in _recv_msg
    return self.recv_msg(message)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 179, in recv_msg
    response = self._message_router[msg_type](contents)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 381, in respond_to_obj_req
    obj = self.get_obj(obj_id)

  File ""C:\Program_Files\Anaconda3\lib\site-packages\syft\workers\base.py"", line 362, in get_obj
    raise KeyError(msg)

KeyError: 'Tensor ""16217007849"" not found on worker ""bob""!!! You just tried to interact with an object ID:16217007849 on worker bob which does not exist!!! Use .send() and .get() on all your tensors to make sure they\'reon the same machines. If you think this tensor does exist, check the ._objects dictionaryon the worker and see for yourself!!! The most common reason this error happens is because someone calls.get() on the object\'s pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven\'t already called .get() on this pointer!!!'
Does the code run when it is in the notebook?This is almost certainly because the VirtualWorker was created twice.> This is almost certainly because the VirtualWorker was created twice.

Can you tell me more? I just create bob once by 'bob = sy.VirtualWorker(hook, id=""bob"")'. Where is the other one? Do you mean that one 'hook = sy.TorchHook(torch)'? In the tutorial, you say that create 'me' (<VirtualWorker id:me #tensors:0>) automatically. But does it affact 'bob'? I saw 'z' belongs to 'bob' by the command 'print(z)' and can't get back.
Or can you tell me the right case?
Thank you!> Does the code run when it is in the notebook?

I run it in my spyder.I saw what happened. This happened just because I runed it twice on my spyder. Maybe this was what iamtrask said 'the VirtualWorker was created twice'.
This program can only run once on your python or restart it!!
Thank you all for help!",5,2019-02-19 07:30:21,2019-02-20 07:55:53,2019-02-20 07:55:53
https://github.com/OpenMined/PySyft/issues/1910,['bug '],Moving the result of an operation fails,"Moving the result of an operation failsI am using syft 0.1.0a1
                   torch 1.0.0
                   python 3.7
In IPython (spyder):

This minimal example fails:
```
from __future__ import print_function
import torch
import syft as sy


hook = sy.TorchHook(torch)
ss=sy.VirtualWorker(hook, id=""secure-server"")
w=sy.VirtualWorker(hook, id=""worker"")

#local data
t1=torch.tensor([1,1,1,1])
t2=torch.tensor([2,2,2,2])
z=torch.tensor([0.,0.,0.,0.])



#all necessary inputs are sent to w
t1=t1.send(w)
t2=t2.send(w)
z_w=z.send(w)

#sending z also to the secure server
z_ss=z.send(ss)

#Performing operations locally on worker w
t3=t1+t2
print(w._objects)

#This runs
t1.move(ss)
print(w._objects)
t2.move(ss)
print(w._objects)
z_w.move(ss)
print(w._objects)


#This never runs
t3.move(ss)
```

The error message I get is:
```
  File ""<ipython-input-1-2a2f4c66bf55>"", line 42, in <module>
    t3.move(ss)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 390, in move
    self.owner.send_command(message=(""mid_get"", ptr, ()), recipient=location)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 316, in send_command
    response = self.send_msg(MSGTYPE.CMD, message, location=recipient)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 144, in send_msg
    bin_response = self._send_msg(bin_message, location)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py"", line 6, in _send_msg
    return location._recv_msg(message)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py"", line 9, in _recv_msg
    return self.recv_msg(message)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 174, in recv_msg
    response = self._message_router[msg_type](contents)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/workers/base.py"", line 266, in execute_command
    tensor = getattr(_self, command)(*args, **kwargs)

  File ""/Users/me/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 353, in mid_get
    del self.owner._objects[tensor.id]

KeyError: 39375020161
```
But the referred key is exactly the address that appears by doing t3.id_at_location. Is it intended behavior ?I've just executed the script with no error, probably this was naturally fixed by time. @LaRiffle, @robert-wagner Closing this, since I believe it's fixed in syft 0.1.13a1.",2,2019-02-14 14:43:02,2019-05-05 03:49:04,2019-05-05 03:48:00
https://github.com/OpenMined/PySyft/issues/1909,"['bug ', 'status: stale :bread:']",Optimizer and momentum for remote tensors,"Optimizer and momentum for remote tensorsAs you know, optim with momentum keeps old gradients in a buffer.
However, when gradients are pointers, it becomes really tricky if you move the parameters from a worker to another, which is exactly what we do in tutorial Part 8. Let's say you move from bob to alice, then you will try to update parameters at alice using a buffer containing pointers to bob, and you get in real trouble.

So, how should we handle this? Drop the buffer by hand? Having different optimizers and different models? Or another solution?Any updates for this?I think this was solved by #3179, where each worker now maintains it's own optimizer. However I'm pretty new here so I may be missing something.I'm not sure that #3179 was intended to add full support for momentum-based optimizers. It certainly seems like a step in the right direction, but it's not clear that momentum-based optimizers are fully compatible with the rest of PySyft.This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",4,2019-02-14 10:51:34,2020-05-25 00:09:17,2020-05-25 00:09:17
https://github.com/OpenMined/PySyft/issues/1906,[],Where should I hook? Choosing the right level.,"Where should I hook? Choosing the right level.I'm currently working with fixed precision tensors (see PR #1897).
In this PR, I had to unhook nn.Linear because it contains the operation `a*x + b`. Indeed, multiplication should be controlled at the fixed precision level (for truncation after multiplication) which you can't do if you hook Linear. Because if you do, then `a*x + b` happens on the LongTensors which are below the precision tensor and the aggregation result is unusable.

Example:
 a = 2.0, x = 3.0, b = 1.0, precision_fractional = 3
 - without hook on Linear:
    a*x + b = [(2000 * 3000) / 10e3 + 1000 ] / 10e3 = 7.0
 - with hook on Linear
    a*x + b = [(2000 * 3000)  + 1000 ] / 10e3 = 6001.0

So there are some tensors like MPC or precision which can't handle ""high level"" functions, but they can deal with the native implementation of these functions (typically nn.Linear). So I'm incline to think that we could have a double level of hooking: a high level hook (typically you want pointer to handle nn.Linear and not to send the details operations of it; so hook every thing you can) and low-level hook (typically you want the precision tensor to understand what is the recipe for doing nn.Linear with low-level operations [and you definitely don't want to rewrite the recipe which is already in torch.nn.functional]; so hook nothing but low-level ops that you can handle specifically).TODO: make this string comparison more efficient

https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/tensors/interpreters/precision.py#L190solved by #2005",2,2019-02-13 10:56:10,2019-03-28 08:11:21,2019-03-28 08:11:20
https://github.com/OpenMined/PySyft/issues/1905,"['bug ', 'help wanted :wave:']",OpenMined.org Demo Broken,"OpenMined.org Demo BrokenOn our homepage - we link to colabs which implement a simple SocketWorker demo - as the new version of PySyft has no SocketWorker - the demo fails to work.

https://colab.research.google.com/drive/1-Jb_E_nDuBGHIJ_psI95k-ukh-P_aly-Hi @iamtrask I would like to help out on this issue if no one has been assigned to it or has volunteered to take on the task yet. And, I have just checked the PySyft repo with a keyword search and it returns no results for `SocketWorker`. Yes any help is welcome is the issue is still there :)
Check that you have the latest version of pysystf and then check out `syft/workers/websocket*` to find the workers.Thanks for the prompt response and the tip to start! Sure, will work on it as soon as possible. Working on the issue here: https://github.com/kakirastern/PySyft/tree/fix-broken-demo
Will submit a PR when more certain about the edited tutorials. Currently fixed the `server` tutorial, but not the `client` one yet, which is more difficult as it turned out. Ok excellent, let us know if you're stuck somewhere :)Thanks @LaRiffle... Incidentally when I was checking the code in Google Colab I found the `syft`-native variable `id` to be problematic, whereas the same issue does not crop up when I was testing locally.

The code I used prior to such an error is:
```
! rm -rf ./PySyft
! git clone https://github.com/OpenMined/PySyft.git
# http://pytorch.org/
from os import path
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())

accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'

!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl
!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl
import torch

!cd PySyft; pip3 install -r requirements.txt; pip3 install -r requirements_dev.txt; python3 setup.py install
import os
import sys

module_path = os.path.abspath(os.path.join('./PySyft'))
if module_path not in sys.path:
    sys.path.append(module_path)
```
Following this then I did:
```
import syft as sy
from syft.workers.websocket_server import WebsocketServerWorker

hook = sy.TorchHook(torch)

local_worker = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182,
                            log_msgs=True,
                            verbose=True)

local_worker.start()  # Might need to Interupt with `control-C`

hook = sy.TorchHook(torch, local_worker=local_worker)
``` 

So the following is the error output:
```
  File ""/content/PySyft/syft/frameworks/torch/tensors/interpreters/abstract.py"", line 19
    id: int = None,
      ^
SyntaxError: invalid syntax
```
Any idea why and how to approach it? Is it just some simple syntax stuff as the error seems to suggest, or does it have to do with `id()` being a Python built-in function? Or if Google Colab proves to be problematic... Would be also be worthwhile to explore alternatives say using Binder for an interactive Jupyter notebook on the Internet?: https://mybinder.readthedocs.io/en/latest/introduction.htmlI think I was able to fix the error, seems like if I do `sys.path.remove('/usr/local/lib/python3.6/dist-packages/syft-0.1.21a1-py3.6.egg')` and also `sys.path.append('./PySyft')` I would then be able to patch or mask it. As for the `id` issue previously, that turned out to be specific to the `Client` notebook only, which for some reason is using Python 2.7 instead of Python 3.x... I will look more into it and make changes where appropriate for the notebooks to work on Colab. What is the latest implementation of `listen()` (if any) for the `WebsocketServerWorker`? I am investigating whether the following code would work well for `WebsocketServerWorker`:
```
def listen(self, backlog=5):
        self.socket.listen(backlog)
        logging.info(""Listening on %s"" % self.port)
        self.running = True
        self.cls = WebsocketServerWorker
        while self.running:
            rList, wList, xList = select(self.listeners, [], self.listeners, 1)
            for ready in rList:
                if ready == self.socket:
                    logging.debug(""New client connection."")
                    client, address = self.socket.accept()
                    filenum = client.filenum()
                    self.listeners.append(filenum)
                    self.connections[filenum] = self.cls(client, self)
                else:
                    logging.debug(""Client ready for reading %s."" % ready)
                    client = self.connections[ready].client
                    data = client.recv(1024)
                    filenum = client.filenum()
                    if data:
                        self.connections[filenum].feed(data)
                    else:
                        logging.debug(""Closing client %s."" % ready)
                        self.connections[filenum].close()
                        del self.connections[filenum]
                        self.listeners.remove(ready)
            for failed in xList:
                if failed == self.socket:
                    logging.error(""Socket is broken."")
                    for filenum, con in self.connections:
                        con.close()
                    self.running = False
```
where we have in `__init__():`
```
self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.listeners = [self.socket]
self.connections = {}
```
Any feedback for suggestions would be much appreciated. Or should I separate out new classes `WebSocket` and `WebSocketServer` from `WebSocketServerWorker`? Would that approach work?",11,2019-02-12 22:28:41,2019-08-01 17:32:43,2019-08-01 17:32:43
https://github.com/OpenMined/PySyft/issues/1893,"['bug ', 'good first issue :mortar_board:', 'priority: 2 - high :cold_sweat:']",Moving a module to cuda throws errors,"Moving a module to cuda throws errors```
import numpy as np                                                                                                                                         
import torch                                                                                                                                               
import torch.utils.data as data                                                                                                                            
import torch.nn as nn                                                                                                                                      
import torch.nn.functional as F                                                                                                                            
import torch.optim as optim                                                                                                                                
from torchvision import datasets, transforms                                                                                                               
                                                                                                                                                           
import torch                                                                                                                                               
from torch import nn                                                                                                                                       
from torch import optim                                                                                                                                    
from torchvision.datasets.mnist import MNIST                                                                                                               
import pdb                                                                                                                                                 
                                                                                                                                                           
import syft as sy                                                                                                                                          
class Net(nn.Module):                                                                                                                                      
    def __init__(self):                                                                                                                                    
        super(Net, self).__init__()                                                                                                                        
        self.conv1 = nn.Conv2d(1, 20, 5, 1)                                                                                                                
        self.conv2 = nn.Conv2d(20, 50, 5, 1)                                                                                                               
        self.fc1 = nn.Linear(4*4*50, 500)                                                                                                                  
        self.fc2 = nn.Linear(500, 10)                                                                                                                      
                                                                                                                                                           
    def forward(self, x):                                                                                                                                  
        x = F.relu(self.conv1(x))                                                                                                                          
        x = F.max_pool2d(x, 2, 2)                                                                                                                          
        x = F.relu(self.conv2(x))                                                                                                                          
        x = F.max_pool2d(x, 2, 2)                                                                                                                          
        x = x.view(-1, 4*4*50)                                                                                                                             
        x = F.relu(self.fc1(x))                                                                                                                            
        x = self.fc2(x)                                                                                                                                    
        return F.log_softmax(x, dim=1)                                                                                                                     
                                                                                                                                                           
                                                                                                                                                           
hook = sy.TorchHook(torch)                                                                                                                                 
device = torch.device(""cuda"")                                                                                                                              
model = Net().to(device)                                                                                                                                   
print(model) ```
Can you add the stacktrace?
One **good-first-issue** would be in the case you have only cpu, and try to call .to(device), to fix the error which is only due to us not serializing devices. This could be easily handled.
_The part with the gpu and cuda is not part of the good-first-issue._```
Traceback (most recent call last):
  File ""test.py"", line 37, in <module>
    model = Net().to(device)                                                                                                                                   
  File ""/network/home/maloneyj/.local/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 381, in to
    return self._apply(convert)
  File ""/network/home/maloneyj/.local/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 187, in _apply
    module._apply(fn)
  File ""/network/home/maloneyj/.local/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 193, in _apply
    param.data = fn(param.data)
  File ""/network/home/maloneyj/PySyft/syft/frameworks/torch/hook.py"", line 339, in data
    self.native_param_data.set_(new_data)  # .wrap()
RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 'source'
```in data(): `new_data` is cuda whereas native_param_data is `cpu`
fix should be moving new_data to cpu while setting native_param_data
Please correct me if I'm wrongFYI, for the code snippet above I'm able to fix the error adding this line after importing torch:

`torch.set_default_tensor_type(torch.cuda.FloatTensor)`

Not sure if this is ideal for every case...
> FYI, for the code snippet above I'm able to fix the error adding this line after importing torch:
> 
> `torch.set_default_tensor_type(torch.cuda.FloatTensor)`
> 
> Not sure if this is ideal for every case...

@mari-linhares nice finding. This is changing default tensor type and should be considered as a work around for now. What we are truely looking for is to to data transfer over cuda@bhushan23 do you know why changing the tensor to FloatTensor works? I'm not using my work computer right now, but I assume since there's no error that the data is transferred over to cuda. I'll check when I get home.@mari-linhares 
try changing `torch.set_default_tensor_type(torch.cuda.FloatTensor)` with `torch.set_default_tensor_type(torch.FloatTensor)` you will be able to reproduce original error.

`set_default_tensor_type` creates tensors of specified type and I think, setting to cuda float tensor is leading to ensuring hook is also using cuda.floattensor and hence no error as both `new_data` and `native_param_data` are on cuda

Ref: https://pytorch.org/docs/stable/torch.html#torch.set_default_tensor_typeThis issue is breaking [tutorial 8](examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb) at the moment when used with CUDA.

[Python 3.7, PySyft from master branch]

I've tried to apply @mari-linhares 's [workaround](https://github.com/OpenMined/PySyft/issues/1893#issuecomment-478717757) to no success so far:
  - when set after distributing the dataset, the instruction crashes with `IndexError: list index out of range`

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    135         # TODO rename registry or use another one than for methods
--> 136         hook_args = hook_method_args_functions[attr]
    137         get_tensor_type_function = get_tensor_type_functions[attr]

KeyError: 'torch.set_default_tensor_type'

During handling of the above exception, another exception occurred:

IndexError                                Traceback (most recent call last)
<ipython-input-6-fb50db14b868> in <module>
      3 if device.type == ""cuda"":
      4   os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""
----> 5   torch.set_default_tensor_type(torch.cuda.FloatTensor)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    691             cmd_name = f""{attr.__module__}.{attr.__name__}""
    692             command = (cmd_name, None, args, kwargs)
--> 693             response = TorchTensor.handle_func_command(command)
    694             return response
    695 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    191             # Note that we return also args_type which helps handling case 3 in the docstring
    192             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 193                 cmd, args, kwargs, return_args_type=True
    194             )
    195             # This handles case 3: it redirects the command to the appropriate class depending

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    141     except (IndexError, KeyError, AssertionError):  # Update the function in case of an error
    142         args_hook_function, get_tensor_type_function = build_hook_args_function(
--> 143             args, return_tuple=True
    144         )
    145         # Store the utility functions in registries

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in build_hook_args_function(args, return_tuple)
    171     # Build a function with this rule to efficiently the child type of the
    172     # tensor found in the args
--> 173     get_tensor_type_function = build_get_tensor_type(rule)
    174     return args_hook_function, get_tensor_type_function
    175 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in build_get_tensor_type(rules, layer)
    392 
    393     if first_layer:
--> 394         return lambdas[0]
    395     else:
    396         return lambdas

IndexError: list index out of range
```

  - when set right after `import torch`, data distribution fails with `RuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor`

```
RuntimeError                              Traceback (most recent call last)
<ipython-input-8-4085cd6569bc> in <module>
      5                        transforms.Normalize((0.1307,), (0.3081,))
      6                    ]))
----> 7     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
      8     batch_size=args.batch_size, shuffle=True, **kwargs)
      9 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/federated/dataset.py in dataset_federate(dataset, workers)
     89     datasets = []
     90     data_loader = torch.utils.data.DataLoader(dataset, batch_size=data_size)
---> 91     for dataset_idx, (data, targets) in enumerate(data_loader):
     92         worker = workers[dataset_idx % len(workers)]
     93         logger.debug(""Sending data to worker %s"", worker.id)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    613         if self.num_workers == 0:  # same-process loading
    614             indices = next(self.sample_iter)  # may raise StopIteration
--> 615             batch = self.collate_fn([self.dataset[i] for i in indices])
    616             if self.pin_memory:
    617                 batch = pin_memory_batch(batch)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py in <listcomp>(.0)
    613         if self.num_workers == 0:  # same-process loading
    614             indices = next(self.sample_iter)  # may raise StopIteration
--> 615             batch = self.collate_fn([self.dataset[i] for i in indices])
    616             if self.pin_memory:
    617                 batch = pin_memory_batch(batch)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/datasets/mnist.py in __getitem__(self, index)
     93 
     94         if self.transform is not None:
---> 95             img = self.transform(img)
     96 
     97         if self.target_transform is not None:

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, img)
     58     def __call__(self, img):
     59         for t in self.transforms:
---> 60             img = t(img)
     61         return img
     62 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, tensor)
    161             Tensor: Normalized Tensor image.
    162         """"""
--> 163         return F.normalize(tensor, self.mean, self.std, self.inplace)
    164 
    165     def __repr__(self):

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/transforms/functional.py in normalize(tensor, mean, std, inplace)
    206     mean = torch.tensor(mean, dtype=torch.float32)
    207     std = torch.tensor(std, dtype=torch.float32)
--> 208     tensor.sub_(mean[:, None, None]).div_(std[:, None, None])
    209     return tensor
    210 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    637                 except BaseException as e:
    638                     # we can make some errors more descriptive with this method
--> 639                     raise route_method_exception(e, self, args, kwargs)
    640 
    641             else:  # means that there is a wrapper to remove

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    631                 try:
    632                     if isinstance(args, tuple):
--> 633                         response = method(*args, **kwargs)
    634                     else:
    635                         response = method(args, **kwargs)

RuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor
```

This might also break other tutorials when using GPUs, have not tried yet._Disclaimer: I needed this running (asap) to train a large-ish dataset on GPU, so it's more like a hacky workaround than an actual solution, but I'll be happy if it helps anyone with the same problem. Or can be used to build up a proper fix._ 

So I was experiencing the same problem as @jopasserat . I think the problem was that the function that handles function commands in hooks.py needed to convert a _non-tensor_ to a _torch.tensor_ , but this exception was not contemplated. So basically I am catching the `IndexError` that happens in those cases. 

Apart from that I'm using `torch.set_default_tensor_type(torch.cuda.FloatTensor)`. I tried to convert the non-cuda tensors to cuda but for some reason in the wrapped tensors `.to()` method doesn't seem to work for me. So unless I set it to default I get the problem @bhushan23 was mentioning. Plus, I need to set the `num_workers=0` (I think the method has been overwritten so it does not run anymore) and `pin_memory=False` (as that will only work with dense CPU tensors).> FYI, for the code snippet above I'm able to fix the error adding this line after importing torch:
> 
> `torch.set_default_tensor_type(torch.cuda.FloatTensor)`
> 
> Not sure if this is ideal for every case...

I am so glad to see this, it  really solved my problem of worrying all afternoonI found a workaround that worked for my needs. The trick is to hook pysyft **after** you move your model to cuda.> I found a workaround that worked for my needs. The trick is to hook pysyft **after** you move your model to cuda.

what do you meanï¼Ÿ Hook the workerï¼ŸBut if you hook after these, how can you make federated dataset? For example,in the tutorial example>advanced>CIFAR10. Can you post your code",12,2019-02-10 03:01:10,2019-10-28 09:24:08,2019-10-28 09:24:08
https://github.com/OpenMined/PySyft/issues/1884,[],Spelling mistake in the README,"Spelling mistake in the READMEHi,
I was going through the README and found a minor spelling error in Siraj Raval's name. It says Rav**e**l, but should be Rav**a**l. 

Cheers,
PranavHi @pranav-ap,  Just make a PR with corrected spelling.Yeah, its done.",2,2019-02-07 15:24:05,2019-02-08 02:41:23,2019-02-08 02:35:00
https://github.com/OpenMined/PySyft/issues/1880,[],More Verbose Documentation for PureTorchTensorFoundError and RemoteTensorFoundError,More Verbose Documentation for PureTorchTensorFoundError and RemoteTensorFoundErrorHey @LaRiffle could you clarifiy what you meant in the documentation of these errors. The documentation does not detail their purposeYes you're right I will do this :)Done! in #1892,2,2019-02-06 03:15:14,2019-02-08 22:10:43,2019-02-08 22:10:42
https://github.com/OpenMined/PySyft/issues/1850,[],AttributeError: 'Parameter' object has no attribute 'child'`,"AttributeError: 'Parameter' object has no attribute 'child'````---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/tensors/native.py in handle_func_command(cls, command)
     64             # Replace all torch tensor with their child attribute
---> 65             new_args, new_type = syft.frameworks.torch.hook_args.hook_function_args(cmd, args)
     66             # build the new command

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in hook_function_args(attr, args)
     96         # Try running it
---> 97         new_args = hook_args(args)
     98         new_type = get_tensor_type(new_args)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <lambda>(x)
    234     f = folds[len(lambdas)]
--> 235     return lambda x: f(lambdas, x)
    236 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in three_fold(lambdas, args)
    374 def three_fold(lambdas, args):
--> 375     return lambdas[0](args[0]), lambdas[1](args[1]), lambdas[2](args[2])
    376 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <lambda>(i)
    226         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 227         else lambda i: forward_func[type(i)](i)
    228         for a, r in zip(args, rules)  # And do this for all the args / rules provided

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <lambda>(i)
     28     if hasattr(i, ""child"")
---> 29     else (_ for _ in ()).throw(PureTorchTensorFoundError(i)),
     30     torch.nn.Parameter: lambda i: i.child,

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <genexpr>(.0)
     28     if hasattr(i, ""child"")
---> 29     else (_ for _ in ()).throw(PureTorchTensorFoundError(i)),
     30     torch.nn.Parameter: lambda i: i.child,

PureTorchTensorFoundError: tensor([[0, 0],
        [0, 1]])

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in hook_function_args(attr, args)
     93         # TODO rename registry or use another one than for methods
---> 94         hook_args = hook_method_args_functions[attr]
     95         get_tensor_type = get_tensor_type_functions[attr]

KeyError: 'torch.addmm'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-5-f2549e52dc21> in <module>()
      3     # Train Bob's Model
      4     bobs_opt.zero_grad()
----> 5     bobs_pred = bobs_model(bobs_data)
      6     bobs_loss = ((bobs_pred - bobs_target)**2).sum()
      7     bobs_loss.backward()

/Users/atrask/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

/Users/atrask/anaconda/lib/python3.6/site-packages/torch/nn/modules/linear.py in forward(self, input)
     65     @weak_script_method
     66     def forward(self, input):
---> 67         return F.linear(input, self.weight, self.bias)
     68 
     69     def extra_repr(self):

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in overloaded_attr(*args, **kwargs)
    459             cmd_name = f""{attr.__module__}.{attr.__name__}""
    460             command = (cmd_name, None, args)  # TODO add kwargs
--> 461             response = TorchTensor.handle_func_command(command)
    462             return response
    463 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/tensors/native.py in handle_func_command(cls, command)
     67             new_command = (cmd, None, new_args)
     68             # Send it to the appropriate class and get the response
---> 69             response = new_type.handle_func_command(new_command)
     70             # Put back the wrappers where needed
     71             response = syft.frameworks.torch.hook_args.hook_response(cmd, response, wrap_type=cls)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/tensors/pointer.py in handle_func_command(cls, command)
    101 
    102         # Send the command
--> 103         response = owner.send_command(location, command)
    104 
    105         return response

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in send_command(self, recipient, message)
    307         """"""
    308 
--> 309         response = self.send_msg(MSGTYPE.CMD, message, location=recipient)
    310         return response
    311 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in send_msg(self, msg_type, message, location)
    142 
    143         # Step 2: send the message and wait for a response
--> 144         bin_response = self._send_msg(bin_message, location)
    145 
    146         # Step 3: deserialize the response

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/virtual.py in _send_msg(self, message, location)
      4 class VirtualWorker(BaseWorker):
      5     def _send_msg(self, message, location):
----> 6         return location._recv_msg(message)
      7 
      8     def _recv_msg(self, message):

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/virtual.py in _recv_msg(self, message)
      7 
      8     def _recv_msg(self, message):
----> 9         return self.recv_msg(message)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in recv_msg(self, bin_message)
    172 
    173         # Step 1: route message to appropriate function
--> 174         response = self._message_router[msg_type](contents)
    175 
    176         # # Step 2: If response in none, set default

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in execute_command(self, message)
    277                 command = getattr(command, path)
    278 
--> 279             tensor = command(*args, **kwargs)
    280 
    281         # some functions don't return anything (such as .backward())

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in overloaded_attr(*args, **kwargs)
    459             cmd_name = f""{attr.__module__}.{attr.__name__}""
    460             command = (cmd_name, None, args)  # TODO add kwargs
--> 461             response = TorchTensor.handle_func_command(command)
    462             return response
    463 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/tensors/native.py in handle_func_command(cls, command)
     82             # in the execute_command function
     83             if isinstance(args, tuple):
---> 84                 response = eval(cmd)(*args)
     85             else:
     86                 response = eval(cmd)(args)

/Users/atrask/anaconda/lib/python3.6/site-packages/torch/nn/functional.py in linear(input, weight, bias)
   1350     if input.dim() == 2 and bias is not None:
   1351         # fused op is marginally faster
-> 1352         ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())
   1353     else:
   1354         output = input.matmul(weight.t())

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in overloaded_attr(*args, **kwargs)
    459             cmd_name = f""{attr.__module__}.{attr.__name__}""
    460             command = (cmd_name, None, args)  # TODO add kwargs
--> 461             response = TorchTensor.handle_func_command(command)
    462             return response
    463 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/tensors/native.py in handle_func_command(cls, command)
     63         try:  # will work if tensors are wrappers
     64             # Replace all torch tensor with their child attribute
---> 65             new_args, new_type = syft.frameworks.torch.hook_args.hook_function_args(cmd, args)
     66             # build the new command
     67             new_command = (cmd, None, new_args)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in hook_function_args(attr, args)
    106         get_tensor_type_functions[attr] = get_tensor_type_function
    107         # Run it
--> 108         new_args = args_hook_function(args)
    109         new_type = get_tensor_type_function(new_args)
    110 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <lambda>(x)
    233     folds = {0: zero_fold, 1: one_fold(return_tuple), 2: two_fold, 3: three_fold, 4: four_fold}
    234     f = folds[len(lambdas)]
--> 235     return lambda x: f(lambdas, x)
    236 
    237 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in three_fold(lambdas, args)
    373 
    374 def three_fold(lambdas, args):
--> 375     return lambdas[0](args[0]), lambdas[1](args[1]), lambdas[2](args[2])
    376 
    377 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <lambda>(i)
    225         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    226         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 227         else lambda i: forward_func[type(i)](i)
    228         for a, r in zip(args, rules)  # And do this for all the args / rules provided
    229     ]

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook_args.py in <lambda>(i)
     28     if hasattr(i, ""child"")
     29     else (_ for _ in ()).throw(PureTorchTensorFoundError(i)),
---> 30     torch.nn.Parameter: lambda i: i.child,
     31     LoggingTensor: lambda i: i.child,
     32     ""my_syft_tensor_type"": lambda i: i.child,

AttributeError: 'Parameter' object has no attribute 'child'```I just wanted to mention that if you see this in the Torch 1.0 branch it probably means that we hooked a torch attribute (something in torch.*) that we shouldn't have. The solution is to figure out what this thing is and add it to self.exclude in torch_attributes.py.What is the general reason for this error?In the current version of syft we create a chain of tensors - and a wrapper around them. Basically, if you have something like an ```AdditiveSharingTensor``` you will have:
```
shared_tensor = torch.tensor([1,2,3], dtype=torch.long).share(alice, bob, crypto_provider=charlie, protocol=""securenn"")
print(shared_tensor)
> (Wrapper)>AST[list of shares]
```
(this^ is written from memory, but you should have something like this :D)
in this case --> ```shared_tensor.child``` represents the ```AST```",3,2019-02-02 10:44:48,2020-09-01 08:28:30,2019-02-02 10:45:48
https://github.com/OpenMined/PySyft/issues/1817,['bug '],Constructor of torch.Tensor is broken in the torch_1 branch,"Constructor of torch.Tensor is broken in the torch_1 branchCurrently in the torch_1 branch we are unable to construct tensors which require gradients (formerly known as variables). The proper way to do this is ` torch.Tensor(<list>, requires_grad=True)` On the current version this returns the error of
```
TypeError                                 Traceback (most recent call last)
<ipython-input-28-35439c5a0d54> in <module>
----> 1 x = torch.Tensor([1,2,3,4,5], requires_grad=True).send(bob)
      2 y = torch.Tensor([1,1,1,1,1], requires_grad=True).send(bob)

TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of:
 * (torch.device device)
 * (torch.Storage storage)
 * (Tensor other)
 * (tuple of ints size, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
 * (object data, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
```@LaRiffle @iamtrask if you had any insight on this issue that would be appreciatedtrask [3:30 PM]
x = torch.tensor([1.,2,3,45], requires_grad=True)

ThÃ©o Ryffel [3:30 PM]
`x = torch.tensor([1.,2,3,4,5], requires_grad=True)``

trask [3:30 PM]
:point_up: that works
x = torch.Tensor([1.,2,3,45], requires_grad=True)I am reopening this because we are unable to call send on torch.tensor which means either we need to hook torch.tensor or get pytorch to fix this issue upstream (ideally both) cc @iamtrask Note that hooking `torch.tensor` is not trivial since you can't add any attributes, if you try you get:
`AttributeError: 'builtin_function_or_method' object has no attribute 'my_attr'`
One work around for `owners` could be adding owner as a property:

```
@property
        def owner(self):
            if not hasattr(self, ""_owner""):
                self._owner = hook_self.local_worker
            return self._owner

        @owner.setter
        def owner(self, new_owner):
            self._owner = new_owner
            return self

        tensor_type.owner = owner
```Got this to work by just doing initialization normally then adding the attributes after",6,2019-01-14 22:23:09,2019-02-05 14:41:31,2019-02-05 14:41:31
https://github.com/OpenMined/PySyft/issues/1816,[],Issues about Tutorial Part-7,"Issues about Tutorial Part-7When trying to follow the tutorial part 7--Encrypting / Decentralizing the ledger, I found tensors after operation('+' or '-') will lose their dimension, is it the expected behavior, or a bug?
![ledge1](https://user-images.githubusercontent.com/33448800/51094287-974f8a00-17e6-11e9-9a97-19c334472b52.png)
![ledge2](https://user-images.githubusercontent.com/33448800/51094311-b6e6b280-17e6-11e9-9282-b60f9ff5e380.png)
This example is now part of a deprecated branch.",1,2019-01-14 02:27:04,2019-02-05 15:07:27,2019-02-05 15:07:27
https://github.com/OpenMined/PySyft/issues/1815,[],cannot import name '_set_worker_signal_handlers',"cannot import name '_set_worker_signal_handlers'Unable to get a Hook in Remote PyTorch using Virtual Worker.ipynb(colab notebook)



![screenshot 96](https://user-images.githubusercontent.com/43285614/51068968-ef9e5480-164b-11e9-8eed-251c781788d9.png)
![screenshot 97](https://user-images.githubusercontent.com/43285614/51068969-ef9e5480-164b-11e9-985d-18fa36b37c34.png)
It seems problem related to the torch GPU torch version 0.3.0 vs  0.3.1 just comment the following lines in first shell of colab notebook.

```
#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'
#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}linux_x86_64.whl torchvision
#import torch
```

It will work just fine or you can check for torch GPU v0.3.1
here the working colab notebook of me : 
https://colab.research.google.com/drive/1OWl-iud3gSM7ZYyEkK2EVr0q8zNIe0C9",1,2019-01-12 03:56:17,2019-01-16 10:00:07,2019-01-16 10:00:07
https://github.com/OpenMined/PySyft/issues/1813,[],Boston Housing server-client demo under /examples/torch,"Boston Housing server-client demo under /examples/torchHi, I mat some problems when trying these two demos:

https://github.com/OpenMined/PySyft/blob/master/examples/torch/Boston_Housing_Federated_Training%20with%20Diff%20Privacy%20SERVER.ipynb

https://github.com/OpenMined/PySyft/blob/master/examples/torch/Boston_Housing_Federated_Training%20with%20Diff%20Privacy%20CLIENT.ipynb

On client side, when coming to this line, error shows like this:
![client-side1](https://user-images.githubusercontent.com/33448800/50941363-91446b00-14bf-11e9-90e8-bae686205247.png)

Then when re-running this line, error changes into this:
![client-side2](https://user-images.githubusercontent.com/33448800/50941385-ac16df80-14bf-11e9-8aaa-b68ca71b334f.png)

When re-runing this line again( the 3rd time), error will disappear:
![client-side3](https://user-images.githubusercontent.com/33448800/50941447-e3858c00-14bf-11e9-9354-18f5b29f7f54.png)

Now, on server side, an error appears:
![server-side](https://user-images.githubusercontent.com/33448800/50941489-09ab2c00-14c0-11e9-9c6e-552d04d44819.JPG)

I run server side and client side on two different machines.This notebook has been deprecated on the master branch.",1,2019-01-10 02:12:37,2019-02-05 15:14:46,2019-02-05 15:14:46
https://github.com/OpenMined/PySyft/issues/1811,[],Worker Queueing of Async Commands,"Worker Queueing of Async CommandsThis is a sub-ticket of Epic #1659.

This ticket is blocked by #1809.

In the previous issue (#1809), we created functionality which allowed for .send commands be sent asynchronously, returning a promise. However, promises cannot be used until the .wait() function guarantees that they are fulfilled. Trying to use a promise without calling .wait() throws an error.

In this ticket, we want to build on this functionality by eliminating the need for explicitly calling .wait() on promises. Instead, we want:

- [ ] 1) each ASYNC command also sends an ID (or several) which the resulting tensors should have.
- [ ] 2) each ASYNC command automatically returns pointers to the (yet to be created) results, using the IDs from (1)
- [ ] 3) If a pointer (on the client) is used before the object it points to has been created, the worker should put the operation into a queue, which waits until the tensor is created/available before executing.I think your solution is elegant by making async tasks a chain,  however, have you ever checked this paper? http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf   I just had a glance,  it might be more practical for large scale , though you may say it's not real asyn...

>  To apply SGD to large data sets, we introduce Downpour SGD, a variant of asynchronous stochastic gradient descent that uses multiple replicas of a single DistBelief model. The basic approach is as follows: We divide the training data into a number of subsets and run a copy of the model on each of these subsets. The models communicate updates through a centralized parameter server, which keeps the current state of all parameters for the model, sharded across many machines (e.g., if we have 10 parameter server shards, each shard is responsible for storing and applying updates to 1/10th of the model parameters) (Figure 2). This approach is asynchronous in two distinct aspects: the model replicas run independently of each other, and the parameter server shards also run independently of one another.irrelevant given new promise architecture",2,2019-01-08 15:56:33,2019-08-15 14:03:18,2019-08-15 14:03:18
https://github.com/OpenMined/PySyft/issues/1809,[],Make send operations async,"Make send operations asyncThis a sub ticket of #1659. All work is happening in the torch_1 branch.

## Description

Make send operations async and by default raise an error if an on-going operation result is accessed. For this step in the implementation `c` will be a wrapper object (similar to a promise). But at the final implementation `c` will be an object that has an `id` so it can be used for the following operations.

## Async python
Threading is clean and easily readable. But the operational systems control when it's executed not us, and can be especially difficult to deal with shared data structures (structure would need to be locked).

Asyncio looks like a better option: async / await are builtin since python 3.5 and asyncio is an std library.

## Full working example

```
import syft as sy
import torch
hook = sy.TorchHook(torch)

me = sy.torch.hook.local_worker
alice = sy.VirtualWorker()

a = torch.Tensor([1, 2, 3])
b = torch.Tensor([1, 4, 5])

ptr_a = me.send(a, alice)
ptr_b = b.create_pointer(location=alice)
ptr_c = ptr_a + ptr_b  # running async
ptr_y = ptr_c + ptr_b  # raises an exception if previous operation is not done
```
@LaRiffle I've just made the description more clear, let me know if there's anything unclear to you. Thanks for the feedback!i'll be replacing this with a new issue soon which I believe to be stronger.",2,2019-01-08 15:53:59,2019-08-15 14:02:52,2019-08-15 14:02:52
https://github.com/OpenMined/PySyft/issues/1786,[],Increase Test coverage to fail under 100,"Increase Test coverage to fail under 100Currently test coverage is set to fail under 95 percent. We should try to have tests for everything and manually exclude (using #pragma: no cover) functions or sections of functions which we do not want tested. This gives intentionality to what we are and are not testing.@LaRiffle @Nivek92 @Ogofo @iamtrask Would appreciate your feedback on thisI've been working on having a very high coverage, however at some point you end make a stupid test just to cover a single line which really doesn't gives you much. I'm a bit cautious about using quotes #pragma because it makes the code less readable
I think you can go up to 97% but I would prefer that we spend time doing tests that are really relevant and writing code :)",2,2018-12-21 16:17:13,2019-02-01 13:39:48,2019-02-01 13:39:48
https://github.com/OpenMined/PySyft/issues/1781,[],Out of memory during MNIST model training.,"Out of memory during MNIST model training.I am training MNIST model with 2 virtual workers, my machine has 128 GB of memory, 97% of which is consumed by the python code (attached below). After 16th epoch, the process is killed by the OS. Has anyone faced similar issue before?

```
import copy
import torch
from torch import nn, optim
from torchvision import datasets, transforms
import torch.nn.functional as F
import argparse

# Training settings
parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                    help='input batch size for training (default: 64)')
parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                    help='input batch size for testing (default: 1000)')
parser.add_argument('--epochs', type=int, default=10, metavar='N',
                    help='number of epochs to train (default: 10)')
parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
                    help='learning rate (default: 0.01)')
parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
                    help='SGD momentum (default: 0.5)')
parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
parser.add_argument('--seed', type=int, default=1, metavar='S',
                    help='random seed (default: 1)')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                    help='how many batches to wait before logging training status')
args = parser.parse_args()
args.cuda = not args.no_cuda and torch.cuda.is_available()

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

model = Net()
kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

dataset_train = datasets.MNIST('../data/', train=True, download=True,
                       transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                ]))


import syft as sy
hook = sy.TorchHook()
me = hook.local_worker
me.is_client_worker = False

# create a couple of socket workers and a virtual worker to aggregate parameters.
#alice = sy.SocketWorker(id=""alice"", hostname=""52.71.29.35"", port=2006, hook=hook, is_pointer=True, is_client_worker=False)
#bob   = sy.SocketWorker(id=""bob"", hostname=""54.209.142.85"", port=2005, hook=hook, is_pointer=True, is_client_worker=False)
bob = sy.VirtualWorker(id=""bob"")
alice = sy.VirtualWorker(id=""alice"")
secure_worker = sy.VirtualWorker(id=""secure_worker"")

bob.add_workers([alice, secure_worker])
alice.add_workers([bob, secure_worker])
secure_worker.add_workers([alice, bob])

compute_nodes = [bob, alice]
train_distributed_dataset  = []
for batch_idx, (data,target) in enumerate(train_loader):
    #if batch_idx > 4: break
    data = sy.Var(data)
    target = sy.Var(target.long())
    data.send(compute_nodes[batch_idx % len(compute_nodes)])
    target.send(compute_nodes[batch_idx % len(compute_nodes)])
    train_distributed_dataset.append((data, target))

bobs_model = model.copy().send(bob)
alices_model = model.copy().send(alice)

bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)
alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)

opt_nodes   = [bobs_opt, alices_opt]
model_nodes = [bobs_model, alices_model]

def train(epoch):
    #TODO train Bob and Alice in parallel.
    bobs_model = model.copy().send(bob)
    alices_model = model.copy().send(alice)
    for batch_idx, (data,target) in enumerate(train_distributed_dataset):

        bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)
        alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)

        opt_nodes[batch_idx % len(compute_nodes)].zero_grad()
        pred = model_nodes[batch_idx % len(compute_nodes)](data)
        loss = F.nll_loss(pred, target)
        loss.backward()

        opt_nodes[batch_idx % len(compute_nodes)].step()
        loss = loss.get().data[0]
        #print(loss)

    alices_model.move(secure_worker)
    bobs_model.move(secure_worker)

    model.conv1.weight.data.set_(((alices_model.conv1.weight.data + bobs_model.conv1.weight.data) / 2).get())
    model.conv1.bias.data.set_(((alices_model.conv1.bias.data + bobs_model.conv1.bias.data) / 2).get())
    model.conv2.weight.data.set_(((alices_model.conv2.weight.data + bobs_model.conv2.weight.data) / 2).get())
    model.conv2.bias.data.set_(((alices_model.conv2.bias.data + bobs_model.conv2.bias.data) / 2).get())
    model.fc1.weight.data.set_(((alices_model.fc1.weight.data + bobs_model.fc1.weight.data) / 2).get())
    model.fc1.bias.data.set_(((alices_model.fc1.bias.data + bobs_model.fc1.bias.data) / 2).get())
    model.fc2.weight.data.set_(((alices_model.fc2.weight.data + bobs_model.fc2.weight.data) / 2).get())
    model.fc2.bias.data.set_(((alices_model.fc2.bias.data + bobs_model.fc2.bias.data) / 2).get())

    len_train_loader = len(train_loader.dataset)
    if batch_idx % args.log_interval == 0:
       print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
             epoch, batch_idx *  args.batch_size, len_train_loader * args.batch_size,
             100. * batch_idx / len_train_loader, loss))

def test():
    #model.eval()
    test_loss = 0
    correct = 0
    for data, target in test_loader:
        data, target = sy.Var(data), sy.Var(target)
        output = model(data)
        #print(""output "", output)
        #print(""loss "", F.nll_loss(output, target, size_average=False))
        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss
        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability
        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()

    len_test_loader = len(test_loader.dataset)
    test_loss /= len_test_loader
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len_test_loader,
        100. * correct / len_test_loader))

for epoch in range(1, args.epochs + 1):
    print(epoch)
    train(epoch)
    test()
```Hi @bigdata2,
There are known issues with remote memory management (remote value is not destroyed when the pointer to it disappears), which are being addressed in the new PySyft version (compatible with PyTorch 1.0) which should be released in February.Thanks for the update. I was also wondering if the version with PyTorch 1.0 will have a feature to let workers load training data separately? Specifically, the case where the entire training data is not read by the client first, but workers can read the training data independently from a local storage. Also, it would be nice to have a feature when workers can join a client asynchronously, i.e. a worker can indicate that it is now ready to join the federated learning pool of other workers and then take part in the model transmission and reception of averaged model parameters.  Hi @bigdata2 can you see if you're experiencing these issues on the new master branch? 

Thanks!In the new master branch based on torch 1.0 - we have automatic garbage collection - which should mitigate this.Hi, torch 1.0 does not work for me, I get the following exception;

> Process Process-1:
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 104, in hook_function_args
>     hook_args = hook_method_args_functions[attr]
> KeyError: 'torch._C.set_num_threads'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
>     self.run()
>   File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
>     self._target(*self._args, **self._kwargs)
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 111, in _worker_loop
>     torch.set_num_threads(1)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py"", line 489, in overloaded_attr
>     response = TorchTensor.handle_func_command(command)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 158, in handle_func_command
>     new_args, new_type = syft.frameworks.torch.hook_args.hook_function_args(cmd, args)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 112, in hook_function_args
>     args, return_tuple=True
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 134, in build_hook_args_function
>     get_tensor_type_function = build_get_tensor_type(rule)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 327, in build_get_tensor_type
>     return lambdas[0]
> IndexError: list index out of range
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 104, in hook_function_args
>     hook_args = hook_method_args_functions[attr]
> KeyError: 'torch.randperm'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""test1.py"", line 83, in <module>
>     for batch_idx, (data,target) in enumerate(train_loader):
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 819, in __iter__
>     return _DataLoaderIter(self)
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 584, in __init__
>     self._put_indices()
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 646, in _put_indices
>     indices = next(self.sample_iter, None)
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py"", line 160, in __iter__
>     for idx in self.sampler:
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py"", line 73, in __iter__
>     return iter(torch.randperm(n).tolist())
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py"", line 489, in overloaded_attr
>     response = TorchTensor.handle_func_command(command)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 158, in handle_func_command
>     new_args, new_type = syft.frameworks.torch.hook_args.hook_function_args(cmd, args)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 112, in hook_function_args
>     args, return_tuple=True
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 134, in build_hook_args_function
>     get_tensor_type_function = build_get_tensor_type(rule)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 327, in build_get_tensor_type
>     return lambdas[0]
> IndexError: list index out of rangeHey @bigdata2 Could you send the code which throws that error?Hi @robert-wagner here is the code.
```
import syft as sy
import copy
import torch
from torch import nn, optim
from torchvision import datasets, transforms
import torch.nn.functional as F
import argparse

# Training settings
parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                    help='input batch size for training (default: 64)')
parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                    help='input batch size for testing (default: 1000)')
parser.add_argument('--epochs', type=int, default=10, metavar='N',
                    help='number of epochs to train (default: 10)')
parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
                    help='learning rate (default: 0.01)')
parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
                    help='SGD momentum (default: 0.5)')
parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
parser.add_argument('--seed', type=int, default=1, metavar='S',
                    help='random seed (default: 1)')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                    help='how many batches to wait before logging training status')
args = parser.parse_args([])
args.cuda = not args.no_cuda and torch.cuda.is_available()

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

model = Net()

kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

dataset_train = datasets.MNIST('../data/', train=True, download=True,
                       transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                ]))

hook = sy.TorchHook(torch)
# create a couple workers
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
secure_worker = sy.VirtualWorker(hook, id=""secure_worker"")

bob.add_workers([alice, secure_worker])
alice.add_workers([bob, secure_worker])
secure_worker.add_workers([alice, bob])

train_distributed_dataset  = []
for batch_idx, (data,target) in enumerate(train_loader):
    if batch_idx > 4: break
    data = sy.Var(data)
    target = sy.Var(target.long())
    data.send(bob)
    target.send(bob)
    train_distributed_dataset.append((data, target))

bobs_model = Net()
bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)
bobs_model = bobs_model.send(bob)

for batch_idx, (data,target) in enumerate(train_distributed_dataset):

    print(data)
    bobs_model.send(data.location)
    # Train Bob's Model
    bobs_opt.zero_grad() 
    bobs_pred = bobs_model(data)
    bobs_loss = F.nll_loss(bobs_pred, target)
    bobs_loss.backward()
    bobs_opt.step()
    bobs_loss = bobs_loss.get().data[0]
```@robert-wagner I think this is related to `randperm`. Is it possible we're not hooking it correctly? Hi @bigdata2 
This is now solved! We have made a notebook tutorial for this case: https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb
I am still getting the same error messages and exceptions as reported originally. 
EDIT: I installed the latest syft-0.1.1a2 version using pip for my test. I used both your notebook and the MNIST example copied to this issue. 
EDIt: Tried with syft-0.1.2a1 still the same error and now it hangs after printing errors/exceptions.
@LaRiffle can you open this issue and leave it open until it is resolved?",10,2018-12-21 01:20:27,2019-02-18 04:40:39,2019-02-13 16:59:27
https://github.com/OpenMined/PySyft/issues/1777,[],Wrong behavior in comparison operator,"Wrong behavior in comparison operatorPls confirm the behavior below. The behavior seems wrong.

```
import syft as sy

hook = sy.TorchHook(verbose=False)
me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
workers = [bob, alice]

y = sy.FloatTensor([1.]).fix_precision().share(*workers)
x = sy.FloatTensor([-1.]).fix_precision().share(*workers)

print(any(y<0), all(y<0))
print(any(x<0), all(x<0))
# False True
# False True
```Hi @0shimax,

**TL;DR**: I think this is the current expected behaviour, not sure if intended or not, but it seems to be the way that ""wrapper"" tensors are implemented.

To be clear I'm definetly not the best person to say if this is expected behaviour or not, but I would say that if we consider that  `fix_precision` creates a [`FixedPrecisionTensor_`](https://github.com/OpenMined/PySyft/blob/5403658ec2d9a9ea2043c4b3bf09fa23e957735d/syft/core/frameworks/torch/tensor.py#L1223) parent to the FloatTensor which is basically a wrapper to the sy.FloatTensor, it is expected behavior.

The wrapper doesn't behave as a tensor. What I mean with this is that if you compare the tensor values to any number it will not have direct access to the values on the tensor, it will just return a Fixed precision tensor:

```
>>> sy.FloatTensor([-1.0, 1.0, 11]).fix_precision() < 0
[Fixed precision tensor]
```

In other words, if you try to iterate on this tensor it's empty.
```
>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11])]
[-1.0, 1.0, 11.0]

>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11]).fix_precision()]
[]
```

On the other hand if you run the same operation with a Float tensor you'll see:

```
>>> sy.FloatTensor([-1.0, 1.0, 11]) < 0
 1
 0
 0
[syft.core.frameworks.torch.tensor.ByteTensor of size 3]
```
This ""wrapper behaviour"" can be seen in other situations, per instance, if you send a tensor to another virtual worker:

```
>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11]).send(bob)]
[]

>>> sy.FloatTensor([-1.0, 1.0, 11]).send(bob) < 0
FloatTensor[_PointerTensor - id:4734155120 owner:me loc:bob id@loc:23451730700]
```

So the wrapper tensor just return a tensor object, which is basically an empty iterator. If we check the documentation for any and all, we'll see that the default behaviour of the any function is to return False if the iterator is empty, and for the all function to return True.

```
Help on built-in function any in module builtins:

any(iterable, /)
    Return True if bool(x) is True for any x in the iterable.    
    If the iterable is empty, return False.

Help on built-in function all in module builtins:

all(iterable, /)
    Return True if bool(x) is True for all values x in the iterable.    
    If the iterable is empty, return True.
```

To have the expected output in the code snippet you just sent, a option would be to use the child tensors (I'm not sure if this is good practice, but probably not):

```
import syft as sy

hook = sy.TorchHook(verbose=False)
me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
workers = [bob, alice]

y = sy.FloatTensor([1., 2.0]).fix_precision().share(*workers)
x = sy.FloatTensor([-1., -2.0]).fix_precision().share(*workers)

def any_less_than_zero(wrapper_tensor):
    for element in wrapper_tensor.child.child:
        if element <= 0:
            return True
    return False
def all_less_than_zero(wrapper_tensor):
    for element in wrapper_tensor.child.child:
        if element >= 0:
            return False
    return True

print(any_less_than_zero(y), all_less_than_zero(y)) 
print(any_less_than_zero(x), all_less_than_zero(x))
# False False
# True True
```
Hi @mari-linhares,

Thank you for explaining in detail. 
Understand about the behavior. I need to call ""child"" of chain.

Thank you again for describing in detail :)@robert-wagner, @Ogofo any thoughts on this? Maybe close this issue if you think this is intended behaviour?

Thank you! Cheers!In the original comment x and y are both mpc shared variables. We currently do not have the functions any and all implemented for mpc tensors as it leaks information most of the time. This behavior should return an error rather than a result that doesn't make sense @robert-wagner 
Thank you for your kind reply. I got it.",5,2018-12-15 08:35:37,2018-12-18 22:46:17,2018-12-18 22:46:17
https://github.com/OpenMined/PySyft/issues/1772,[],Ser / deser attributes id and owner of tensors,"Ser / deser attributes id and owner of tensorsThe attributes id and owner are not kept in the builtin methods on torch tensor used to serialize / deser.

Can we:
1. Overload theses methods to handle this
2. transfer them aside and add them together as attributes
3. Do we really need them?
I'm addressing your questions from bot to top. 

Regarding point 3. I'm not entirely sure. I think it will depend on the workflow:

1. Sending a Tensor to a remote worker
Regarding the discussion in #1697 I don't think we need either variable as they are newly set by the remote worker anyways. 

2. Saving a Tensor to disk
This depends if we want to be able to save a complete syft-instance to disk with all the workers and tensors staying connected. If we don't care about the worker <-> Tensor relation we could simply save the tensors and assign them a new worker once we loaded them. This probably depends on whether the syft worker will hold a state at a later point, but one could build a workaround to save a worker and assign the loaded worker to all tensors.

3. Future/other syft-variables
I'm not sure what else we are going to add in the future and If this might be a necessity so send syft variables attached to a tensor to the remote worker. 

---
Regarding your second point: this is totally possible. I'm not sure how ""big"" the variables might get that we want to transfer, but we should be able to build a deserialization for this. 

--- 
Regarding your first point: Currently, a Tensor is saved via `torch.save()`. We would have to hook into https://github.com/pytorch/pytorch/blob/master/torch/serialization.py which I would not like to do if possible. I do agree with you, I think we could avoid these tensors attribute because:
1. owner is trivial
2. id is not: we expect a ptr = x.send()  then x2 = ptr.get() to return an x2 with the same id than x. But if the id is transmitted to the PointerTensor and given back this would work.@LaRiffle any final decisions? From the discussion above I would say it will be implemented in a way similar to what you described as `2.` in your fist comment?I *think* this issue was addressed in https://github.com/OpenMined/PySyft/pull/1791. 

At the moment, I elected to NOT serialize .owner because it can always be inferred by whoever is doing the deserialization (.owner is just supposed to reflect who is currently managing it, and we DO need it but only for when we're using VirtualWorker). 

However, ID is now serialized/deserialized with both Tensor and PointerTensorOk this is the behavior with currently have in serde.py",5,2018-12-11 19:03:34,2019-01-25 10:55:58,2019-01-25 10:55:58
https://github.com/OpenMined/PySyft/issues/1756,['bug '],Tests not Working ,"Tests not Working Tests were working all fine  until recently when I ran `make test` locally. 

I get these errors. Any idea on how I could resolve it?

```
test -e venv/bin/activate || python -m venv venv
Error: Command '['/Users/hrishikesh/Hrishikesh/Projects/PySyft/venv/bin/python', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.
make: *** [venv/bin/activate] Error 1
``` Hmm - I'm really not sure. Maybe try rebuilding your virtual environment?@iamtrask  That did the trick!",2,2018-12-08 09:35:57,2018-12-31 10:00:51,2018-12-31 10:00:51
https://github.com/OpenMined/PySyft/issues/1738,['bug '],No local packages or working download links found for tensorflow error: Could not find suitable distribution for Requirement.parse('tensorflow'),"No local packages or working download links found for tensorflow error: Could not find suitable distribution for Requirement.parse('tensorflow')Help! I am new here, when I follow tutorial, run `scripts/run_dockers.sh`;  there are errors:
```
Reading https://pypi.org/simple/tensorflow/
No local packages or working download links found for tensorflow
error: Could not find suitable distribution for Requirement.parse('tensorflow')
The command '/bin/sh -c python setup.py install     && jupyter notebook --generate-config     && jupyter nbextension enable --py --sys-prefix widgetsnbextension     && python -m ipykernel.kernelspec     && mkdir /notebooks     && rm -rf /var/cache/apk/*' returned a non-zero code: 1
Build done!
Running PySyft container with name My_PySyft...
Unable to find image 'pysyft:latest' locally
docker: Error response from daemon: pull access denied for pysyft, repository does not exist or may require 'docker login'.
See 'docker run --help'.
Something went wrong.
```Yeah, the Dockerfile is broken atm, I have some working ones but the images are rather big, I'm going to see if I can shrink them but Tensorflow + Torch + PySyft + Jupyter probably approaches 1GB anyway.This should be resolved at this point. Please open a new issue if you're still having trouble.",2,2018-12-03 15:21:30,2019-02-05 15:10:24,2019-02-05 15:10:23
https://github.com/OpenMined/PySyft/issues/1733,[],SocketWorker with Data Tensors on remote machine problem,"SocketWorker with Data Tensors on remote machine problemI'm trying to implement a SocketWorker Server/Client application with data on remote server, taking the inspiration from here->
https://github.com/OpenMined/PySyft/blob/master/examples/torch/toy/SocketWorker%20Server.ipynb
https://github.com/OpenMined/PySyft/blob/master/examples/torch/toy/SocketWorker%20Client.ipynb

But in the above example I face the below error with pointer to the data from the client side->
After this line->

```
pointers = remote_client.search(""#boston_housing"")
pointers
```
Error->
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~\Anaconda3\lib\site-packages\IPython\core\formatters.py in __call__(self, obj)
    700                 type_pprinters=self.type_printers,
    701                 deferred_pprinters=self.deferred_printers)
--> 702             printer.pretty(obj)
    703             printer.flush()
    704             return stream.getvalue()

~\Anaconda3\lib\site-packages\IPython\lib\pretty.py in pretty(self, obj)
    383                 if cls in self.type_pprinters:
    384                     # printer registered in self.type_pprinters
--> 385                     return self.type_pprinters[cls](obj, self, cycle)
    386                 else:
    387                     # deferred printer

~\Anaconda3\lib\site-packages\IPython\lib\pretty.py in inner(obj, p, cycle)
    561                 p.text(',')
    562                 p.breakable()
--> 563             p.pretty(x)
    564         if len(obj) == 1 and type(obj) is tuple:
    565             # Special case for 1-item tuples.

~\Anaconda3\lib\site-packages\IPython\lib\pretty.py in pretty(self, obj)
    400                         if cls is not object \
    401                                 and callable(cls.__dict__.get('__repr__')):
--> 402                             return _repr_pprint(obj, self, cycle)
    403 
    404             return _default_pprint(obj, self, cycle)

~\Anaconda3\lib\site-packages\IPython\lib\pretty.py in _repr_pprint(obj, p, cycle)
    695     """"""A pprint that just redirects to the normal repr function.""""""
    696     # Find newlines and replace them with p.break_()
--> 697     output = repr(obj)
    698     for idx,output_line in enumerate(output.splitlines()):
    699         if idx:

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\tensor.py in __repr__(self)
   2491             return ""[Head of chain]\n"" + x_.native___repr__()
   2492 
-> 2493         return self.native___repr__()
   2494 
   2495     def create_pointer(self, register=False, location=None, ptr_id=None):

~\Anaconda3\lib\site-packages\torch\autograd\variable.py in __repr__(self)
    117 
    118     def __repr__(self):
--> 119         return 'Variable containing:' + self.data.__repr__()
    120 
    121     def __bool__(self):

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\tensor.py in __repr__(self)
   2491             return ""[Head of chain]\n"" + x_.native___repr__()
   2492 
-> 2493         return self.native___repr__()
   2494 
   2495     def create_pointer(self, register=False, location=None, ptr_id=None):

~\Anaconda3\lib\site-packages\torch\tensor.py in __repr__(self)
    142 
    143     def __repr__(self):
--> 144         return str(self)
    145 
    146     def __str__(self):

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\tensor.py in __str__(self)
   2531         elif isinstance(self.child, _LocalTensor) and torch_utils.is_tensor_empty(self):
   2532             if hasattr(self.child, ""child""):
-> 2533                 return self.child.child.native___str__()
   2534             else:
   2535                 return ""Empty Wrapper:\n"" + self.native___str__()

AttributeError: 'NoneType' object has no attribute 'native___str__'
```
And if I try to do a calculation with this pointer it raises this->

`y = x+x`

Error->
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-6-546c5468b2b2> in <module>
----> 1 y = x+x

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\hook.py in _execute_method_call(self, *args, **kwargs)
    527             worker = hook_self.local_worker
    528             try:
--> 529                 return worker._execute_call(attr, self, *args, **kwargs)
    530 
    531             except NotImplementedError:

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\workers\base.py in _execute_call(self, attr, self_, *args, **kwargs)
   1046         # performing the operation
   1047 
-> 1048         result = child_type.handle_call(syft_command, owner=self)
   1049 
   1050         if is_torch_command:

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\tensor.py in handle_call(cls, syft_command, owner)
   1024         """"""_PointerTensor has an overloaded handle_call function because it
   1025         converts the command to torch tensors and send it over the network.""""""
-> 1026         tensor_command = torch_utils.wrap_command_pre_ser(syft_command)
   1027 
   1028         attr = tensor_command[""command""]

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\utils.py in wrap_command_pre_ser(obj)
    303     # Dict
    304     elif isinstance(obj, dict):
--> 305         return {k: wrap_command_pre_ser(o) for k, o in obj.items()}
    306     # sy._SyftTensor
    307     elif is_syft_tensor(obj):

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\utils.py in <dictcomp>(.0)
    303     # Dict
    304     elif isinstance(obj, dict):
--> 305         return {k: wrap_command_pre_ser(o) for k, o in obj.items()}
    306     # sy._SyftTensor
    307     elif is_syft_tensor(obj):

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\utils.py in wrap_command_pre_ser(obj)
    313     # List or iterables which could contain tensors
    314     elif isinstance(obj, (list, tuple, set, bytearray, range)):
--> 315         return type(obj)([wrap_command_pre_ser(o) for o in obj])
    316     # Torch tensor or variable
    317     elif is_tensor(obj) or is_variable(obj):

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\utils.py in <listcomp>(.0)
    313     # List or iterables which could contain tensors
    314     elif isinstance(obj, (list, tuple, set, bytearray, range)):
--> 315         return type(obj)([wrap_command_pre_ser(o) for o in obj])
    316     # Torch tensor or variable
    317     elif is_tensor(obj) or is_variable(obj):

~\Anaconda3\lib\site-packages\syft-0.1.0-py3.6.egg\syft\core\frameworks\torch\utils.py in wrap_command_pre_ser(obj)
    309             wrapper = sy.FloatTensor.ser_wrap(obj.torch_type, obj)
    310         else:
--> 311             wrapper = sy.Variable.ser_wrap(obj.torch_type, obj, obj.data, obj.grad)
    312         return wrapper
    313     # List or iterables which could contain tensors

AttributeError: '_PointerTensor' object has no attribute 'grad'
```

The Pointer object pointing to the variable on the server side seems to give the issue. Please can anyone provide me a clue on how to resolve this?

Thanks!Hi @miranthajayatilake thanks for reporting this. Are you still having trouble with `PointerTensor` on our master branch? We've just refactored for torch 1Hey - not sure the status of this but i think this bug was on 0.3.1 which is now deprecated. We'd like to instead build this on torch 1.0 branch (master/dev)",2,2018-11-28 13:20:18,2019-02-26 15:21:56,2019-02-26 15:21:55
https://github.com/OpenMined/PySyft/issues/1725,[],train() function in 'Intro to Federated Learning.ipynb' example code,"train() function in 'Intro to Federated Learning.ipynb' example codeHi,
First of all, great work Trask! Loving your work. 
I'm following the tutorials and in the Federated Learning notebook example, when passing each worker's dataset to the sent model, shouldn't we pass `data_bob` as a parameter to the function?

I'm talking about the function here :-

```
def train():
    # Training Logic
    opt = optim.SGD(params=model.parameters(),lr=0.1)
    for iter in range(20):
        
        # NEW) iterate through each worker's dataset
        for data,target in datasets:
            
            # NEW) send model to correct worker
            model.send(data.location)

            # 1) erase previous gradients (if they exist)
            opt.zero_grad()

            # 2) make a prediction
            pred = model(data)
```

I think that the function should have a parameter input as `def train(dataset)` in order to pass each worker's data. Am I wrong? Would love to clarify.

Thanks!Hi @miranthajayatilake!!! This function would be greatly improved if the ""model"" and ""datasets"" variables were passed in as a parameter! PR Welcome!Thank you very much for the response! I will look into it.",2,2018-11-23 04:18:31,2018-11-28 05:12:52,2018-11-28 05:12:52
https://github.com/OpenMined/PySyft/issues/1705,[],Make tests pass,"Make tests passSome tests are failing. 

Fix the appropriate code to make the tests pass.Looks like all tests are passing here

https://github.com/OpenMined/PySyft/pull/1714",1,2018-11-18 06:36:31,2018-11-20 15:38:45,2018-11-20 15:38:45
https://github.com/OpenMined/PySyft/issues/1703,[],Get 100% test coverage,"Get 100% test coverageThe travis build still fails as we have not reached 100% test coverage yet.

Goal of this issue is to add the necessary tests.


Current state
```

Name                                           Stmts   Miss  Cover
------------------------------------------------------------------
setup.py                                          12      3    75%
syft/__init__.py                                   4      0   100%
syft/frameworks/__init__.py                        2      0   100%
syft/frameworks/torch/__init__.py                  0      0   100%
syft/frameworks/torch/hook.py                      0      0   100%
syft/frameworks/torch/mpc/__init__.py              0      0   100%
syft/frameworks/torch/mpc/snn.py                   0      0   100%
syft/frameworks/torch/mpc/spdz.py                  0      0   100%
syft/frameworks/torch/tensors/__init__.py          0      0   100%
syft/frameworks/torch/tensors/plusisminus.py       0      0   100%
syft/frameworks/torch/tensors/pointer.py           0      0   100%
syft/frameworks/torch/tensors/precision.py         0      0   100%
syft/frameworks/torch/tensors/snn.py               0      0   100%
syft/frameworks/torch/tensors/spdz.py              0      0   100%
syft/objects.py                                    3      0   100%
syft/serde.py                                     91     14    85%
syft/workers/__init__.py                           3      0   100%
syft/workers/base.py                              37     21    43%
syft/workers/virtual.py                            6      2    67%
test/__init__.py                                   0      0   100%
test/test_objects.py                               0      0   100%
test/test_serde.py                                83      0   100%
------------------------------------------------------------------
TOTAL                                            241     40    83%
```Test coverage should be 100% but there are some errors that prevent all tests from running through.

Will fix these after that we should have 100%@iamtrask could you close that issue for me please",2,2018-11-17 11:18:08,2018-11-23 12:34:37,2018-11-23 12:34:37
https://github.com/OpenMined/PySyft/issues/1699,[],Add register_obj() to worker,"Add register_obj() to workerThis is a sub issue of #1697 

Objects given as args should be registered by the worker, meaning they should be included in the worker registry `self._objects`


That's already solved by `bob.send_obj(obj, alice)`I'm not sure, send_obj or receive object does not register any object at the moment. Have a look at the register_object method of worker in `master` to see the former registration process.What's missing in comparison to the original register_object method is the creation of a pointer and changing the owner of the obj. 

Other than that it will add the object to the _object dictionary using the id of the obj.

But do we need a seperate method than or wouldn't it be better to adjust one of the existing methods? e.g. the set_obj or recv_msgSometimes you want to register tensors that are included in a rather complex response, like tuples, dictionary which include tensors.
In this case I think a separate  method is useful to handle registration gracefully
But it could also be included in the deserialize logic since we already iterate in the response",4,2018-11-16 16:08:02,2019-01-09 21:50:27,2019-01-09 21:50:27
https://github.com/OpenMined/PySyft/issues/1690,[],Failing tests on Mac OS,"Failing tests on Mac OSWhen running the PySyft tests (`python ./setup.py test`) I get a few failures as shown in the attached log file. Running them on macOS High Sierra 10.13.6, python 3.6.3, installed with Anaconda, pytorch 0.3.1
As suggested on slack by @iamtrask filing an issue here.

[pysyft_failing_tests_log.txt](https://github.com/OpenMined/PySyft/files/2589056/pysyft_failing_tests_log.txt)
With the current master (commit 33e23644b026815d76c9e5d6594e3d0b8fe6830b) all tests pass on Mac OS (112 tests in total). So, closing the issue as resolved.",1,2018-11-16 11:20:51,2018-12-24 08:32:55,2018-12-24 08:32:55
https://github.com/OpenMined/PySyft/issues/1689,[],Investigate if pickle for numpy arrays is secure,"Investigate if pickle for numpy arrays is secure@iamtrask is wondering whether pickle is a secure way to serialize numpy arrays.
By default pickle allows for arbitrary code injection so we don't want to use it for normal python objects. We have to investigate further as to whether this concern applies to numpy.I looked into it and found

https://intoli.com/blog/dangerous-pickles/ & https://checkoway.net/musings/pickle/ which describe the problem. 

So from my understanding the whole code injection is only a problem if we unpickle user generated data which isn't the case (except they manipulate the message that is send between client and server)

Aside from that I found that pickle.dumps is slower than using .tobytes on the array so I will change it anyway so we are safe on that side either way.

This sounds solved!",2,2018-11-15 20:12:17,2019-02-05 15:21:11,2019-02-05 15:21:10
https://github.com/OpenMined/PySyft/issues/1685,[],Fix travis ci build process,"Fix travis ci build processThe is an error in the paths for the exclude commandThere is another issue within the Travis CI run, I would suggest to use this ticket to resolve the issues and get the Travis build running. 

Current issue is: 

```
$ coverage run python setup.py test
No file to run: 'python'
The command ""coverage run python setup.py test"" exited with 1.
```The previous can be resolved by changing the line to `coverage run setup.py test`.

Currently the build would still faile because:

1. The test coverage is not 100% yet. 
2. The `bash scripts/execute_notebooks.sh` will fail, because the script does not yet exist on the `torch_1` branchAssociated 

Get 100% test coverage #1703
Make tests pass #1705Woot woot!!!",4,2018-11-15 16:03:31,2018-11-20 15:41:19,2018-11-20 15:41:19
https://github.com/OpenMined/PySyft/issues/1655,['bug '],Tensor missing on worker when model contains several convolution layers,"Tensor missing on worker when model contains several convolution layersHello, 

I am getting the error `Exception: Tensor ""XX"" not found on worker ""0""!!!` when there are several convolution layers included in the model or a batch normalization layer. If I run the same model with one convolution layer, it will work. The error seems to be happening when initializing the gradients `optimizer.zero_grad()`. 

Here is an example: https://github.com/yanndupis/PySyft/blob/pate-syft/examples/torch/PATE_SYFT.ipynb

Thank you!I am experiencing the same issue. It works for a simple nn.linear model but not for a simple MNIST model with a couple of convolution layers. Here is my code and the error message:

```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

model = Net()

kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)
dataset_train = datasets.MNIST('../data/', train=True, download=True,
                       transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                ]))

# create a couple workers

bob = sy.VirtualWorker(id=""bob"")
alice = sy.VirtualWorker(id=""alice"")
secure_worker = sy.VirtualWorker(id=""secure_worker"")

bob.add_workers([alice, secure_worker])
alice.add_workers([bob, secure_worker])
secure_worker.add_workers([alice, bob])

train_distributed_dataset  = []
for batch_idx, (data,target) in enumerate(train_loader):
    if batch_idx > 4: break
    data = sy.Var(data)
    target = sy.Var(target.long())
    data.send(bob)
    target.send(bob)
    train_distributed_dataset.append((data, target))

bobs_model = model.copy().send(bob)
alices_model = model.copy().send(alice)

bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)
alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)

for batch_idx, (data,target) in enumerate(train_distributed_dataset):
    bobs_opt.zero_grad() # this is where it breaks.........
    bobs_pred = bobs_model(data)
    bobs_loss = F.nll_loss(bobs_pred, target)
    bobs_loss.backward()

    bobs_opt.step()
    bobs_loss = bobs_loss.get().data[0]
```

> Traceback (most recent call last):
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 620, in get_obj
> KeyError: 42641825531
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""test1.py"", line 102, in <module>
>     bobs_opt.zero_grad() # this is where it breaks.........
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py"", line 116, in zero_grad
>     p.grad.data.zero_()
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/hook.py"", line 531, in _execute_method_call
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 1035, in _execute_call
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py"", line 1045, in handle_call
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 1149, in send_torch_command
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 1158, in send_command
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 251, in send_msg
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/profiling.py"", line 60, in wrapper
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 256, in _profiled_send_msg
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/virtual.py"", line 113, in _send_msg
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 313, in receive_msg
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py"", line 204, in decode
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py"", line 323, in python_decode
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py"", line 297, in python_decode
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py"", line 2582, in deser
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py"", line 259, in deser_routing
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py"", line 1111, in deser
>   File ""/home/ubuntu/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py"", line 647, in get_obj
> Exception: Tensor ""42641825531"" not found on worker ""bob""!!!
> 
> You just tried to interact with an object ID:42641825531 on worker bob which does not exist!!! Use .send() and .get() on all your tensors to make sure they'reon the same machines.
> 
> If you think this tensor does exist, check the ._objects dictionaryon the worker and see for yourself!!! The most common reason this error happens is because someone calls.get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!@yanndupis  you have `me.is_client_worker = False` line commented out. Not sure why linear layer works without it and convolution does not.We're doing a massive refactor with the release of pytorch 1.0, please re-open an issue if you still have this problem, thanks! :)Sounds good :). Thank you @LaRiffle !!",4,2018-11-09 06:09:13,2019-02-05 19:25:40,2019-02-05 15:17:33
https://github.com/OpenMined/PySyft/issues/1647,[],Downloading datasets via torchvision is not working after hooking,"Downloading datasets via torchvision is not working after hookingHey, please see the attached code.

After hooking torch, the torchvision method to download the MNIST Dataset fails. I can only assume that this is an unintended behavior. After hooking the functionality of torch/torchvision methods should be guaranteed. 

I will work on this issue in the future. 

```
>>> import torchvision
>>> import syft as sy
>>> from syft.core.frameworks.torch import TorchHook
>>> from syft.core.workers import VirtualWorker, SocketWorker
>>> hook = TorchHook(local_worker=SocketWorker(id=1, port=8290, is_pointer=False, is_client_worker=False))
Starting Socket Worker...
Ready to receive commands...
>>> transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))])
>>> root = ""./data""
>>> train_set = torchvision.datasets.MNIST(root=root, transform=transform, download=True)
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Processing...
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/mnist.py"", line 45, in __init__
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/mnist.py"", line 135, in download
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 135, in save
    return _with_file_like(f, ""wb"", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 117, in _with_file_like
    return body(f)
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 135, in <lambda>
    return _with_file_like(f, ""wb"", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/serialization.py"", line 198, in _save
    pickler.dump(obj)
  File ""/Users/Philipp/anaconda3/envs/pysyft-dev/lib/python3.6/site-packages/torch/tensor.py"", line 131, in __reduce__
    args = self.__getstate__()
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/hook.py"", line 467, in _execute_method_call
    return worker._execute_call(attr, self, *args, **kwargs)
  File ""/Users/Philipp/PySyft/syft/core/workers/base.py"", line 1061, in _execute_call
    wrapper = torch_utils.wrap_command(result)
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 292, in wrap_command
    return type(obj)([wrap_command(o) for o in obj])
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 292, in <listcomp>
    return type(obj)([wrap_command(o) for o in obj])
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 273, in wrap_command
    bind_tensor_nodes(wrapper, obj)
  File ""/Users/Philipp/PySyft/syft/core/frameworks/torch/utils.py"", line 258, in bind_tensor_nodes
    wrapper.child = child_obj
AttributeError: 'tuple' object has no attribute 'child'
```Great find!",1,2018-10-29 14:05:39,2018-12-06 19:36:48,2018-12-06 19:36:48
https://github.com/OpenMined/PySyft/issues/1645,[],Variable-Tensors are not completely removed from the receiver after get(),"Variable-Tensors are not completely removed from the receiver after get()Hey, check out this quick example:

```
import syft as sy
import torch
from torch.autograd import Variable as Var
hook = sy.TorchHook(verbose=True)
me = hook.local_worker
bob = sy.VirtualWorker(id=""Bob"", hook=hook, is_client_worker=False)
x_var = Var(torch.FloatTensor([1,2,3,4]))
print(bob._objects)

>>>> {}

x_var.send(bob)
print(bob._objects)

>>>> {
           59413128941: [_LocalTensor - id:59413128941 owner:Bob], 
           54679542725: [_LocalTensor - id:54679542725 owner:Bob], 
           49424246791: [_LocalTensor - id:49424246791 owner:Bob], 
           84172249055: [_LocalTensor - id:84172249055 owner:Bob]
     }

x_var.get()
print(bob._objects)

>>>> {84172249055: [_LocalTensor - id:84172249055 owner:Bob]}
```

Registering a variable creates 4 objects in the local registry (`base.py:register(self, result)`). `get()`only triggers `de_register()` on the three of them, leaving out `self.register(variable.grad.data.child)`. I'm not sure wether the issue is in `get()` or within the `de_register()` method, but I would like to fix this issue. Close please @iamtrask.",1,2018-10-29 08:22:53,2018-11-02 11:04:36,2018-11-02 11:04:36
https://github.com/OpenMined/PySyft/issues/1642,[],WebSocketWorker example code doesn't work,"WebSocketWorker example code doesn't workThe example code from WebSocketWorker docstring breaks. The first line imports TorchHook from a no longer existing module:
```>>> from syft.core.hooks import TorchHook```
The hook is available in syft now. When this is fixed, after a few steps a nonexistent function utils.PythonJSONDecoder is called on the server side. I don't know what else needs to be updated.

There are no tests for this Worker.I'd like to fix this Worker and add a test or two.Are you making any progress on this issue and do you need help?I see a lot of broken code in workers, fixing this is not a ""fun issue"" and may take a little more time.

If you're interested, take a look at [workers_test.py](https://github.com/OpenMined/PySyft/blob/4036adcac0ea20d702d5f9eee314a188b2e297d2/test/core/workers_test.py). There's only one test. ~~Try executing example code from [VirtualWorker's docstring](https://github.com/OpenMined/PySyft/blob/4036adcac0ea20d702d5f9eee314a188b2e297d2/syft/core/workers/virtual.py#L45-L72). It brakes.~~ (I made a mistake. This one works). Adding any worker tests ~~or fixing VirtualWorker~~ would be nice. If you still want to help with workers, maybe try checking other docstring examples and adding tests, so we don't get in each other's way or spend time both doing exactly the same thing.

Or you can take a look at ""good first issues"" here: https://github.com/OpenMined/PySyft/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22

Do you have a branch that you are actively working on or a list of broken things that need to be repaired? That would help us do not get in each other's way. 

A potential issue I found is if the WebSocketWorker is initialized with `is_client_worker=True` which is the default, he will not register any received objects in either `_objects` or `_tmp_objects`. This is because  `set_obj(self, remote_key, value, force=False, tmp=False)`of BaseWorker only allows client worker to register temporary objects, but the `tmp` variable is not set to `True`. The WebSocketWorker and SocketWorker APIs are (at present) quite tricky. As an aside - very open to suggestions for how we could simplify it or have some of the configuration happen automatically. In particular, we use the same class for the Server config of each socket based worker (is_client_worker==False, and it's what actually does the computation) and the Client config (is_client_worker==True) which is just designed to send messages to a particular server.

We also don't yet have this documented in our tutorials section (https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)Yes, I got a little stuck in this issue. We're talking with Ogofo and Nivek92 on Slack. I think this weekend I'll create a pull request with what I have: a correctly failing test and some small incomplete fixes. Or maybe it will be in my repo only, because I think I have no permissions to create a PR to a new branch here and I don't want this to be a pull request to master.Should this issue be closed?Hello!
I think this issue still needs discussion and bigger rewrite. I've been a little out of touch lately and I'm not sure what's the plan exactly. Please don't close it yet.I suggest creating a ticket to implement the WebSocket worker in torch_1 branch. I don't think we should put more work than necessary into an outdated version of the repository :)",9,2018-10-23 21:27:08,2018-12-20 18:50:26,2018-12-20 18:50:26
https://github.com/OpenMined/PySyft/issues/1639,[],Unable to complete Docker build: No local packages or working download links found for tensorflow,"Unable to complete Docker build: No local packages or working download links found for tensorflowWhen running `scripts/run_docker.sh`, I get the following error:

```text
Searching for tensorflow
Reading https://pypi.org/simple/tensorflow/
No local packages or working download links found for tensorflow
error: Could not find suitable distribution for Requirement.parse('tensorflow')
Build done!
The command '/bin/sh -c python setup.py install     && jupyter notebook --generate-config     && jupyter nbextension enable --py --sys-prefix widgetsnbextension     && python -m ipykernel.kernelspec     && mkdir /notebooks     && rm -rf /var/cache/apk/*' returned a non-zero code: 1
```

When executing `pip install tensorflow` in the intermediary image before this step, I see the same issue.yes, I got same error, too. Now I still can not solve it. Do you?The current version of PySyft does not support Tensorflow. See https://arxiv.org/pdf/1902.01046.pdf for a Federated Learning implementation in Tensorflow.",2,2018-10-18 19:14:14,2019-02-05 15:16:25,2019-02-05 15:16:25
https://github.com/OpenMined/PySyft/issues/1592,[],URGENT: remove all % operators and replace with torch.fmod(),"URGENT: remove all % operators and replace with torch.fmod()@channel - BUG IN PYTORCH 0.3.1

The modulus operator doesn't always work.
https://github.com/pytorch/pytorch/issues/1164

torch.fmod() works correctly
torch.remainder() and the % sign do NOT work.

We need to swap out all uses of % for torch.fmod() prontoI think I can take this. @iamtrask Thank you @ionlights !!Note that % work fine if it's just between two python ints... it's only when it's computing on one or more torch tensors that it's an issueHey @ionlights - how's it goin?:wave: Sorry, got caught up finishing up some assignments due an hour ago. :joy:

I should be able to finish this up towards late afternoon today (Oct 08) in EST.",5,2018-10-04 21:35:47,2018-11-26 15:53:40,2018-11-26 15:53:40
https://github.com/OpenMined/PySyft/issues/1581,[],Mid-Chain Commands,"Mid-Chain CommandsRight now there's a both ambiguity and a sortof barrier to doing some API calls on the middle sections of chains. For example, if I have:

x = Pointer[bob] -> Pointer[alice] -> Pointer[james] -> LocalTensor[bill]

if would be really nice if I could call

y = x.child.get()

which would return a new chain ""y"" which equals

Pointer[bob] -> Pointer[alice] -> LocalTensor[bill]

Basically - the idea being that we should be able to dynamically point to parts of the chain we want to make calls on. This is particularly true for complex MPC protocols which often require an ""orchestrating party"" such as a crypto provider to request that tensors be moved around to which it does not have direct access.So it's almost like we want a .get() which copies the pointer locally instead of deleting the one that's also somewhere else. Then we can overload Pointer.child with that method. That way, if you go:

x.child

then you get another pointer but it doesn't get registered locally and it doesn't delete the pointer that exists on the other worker. It just copies the remote x.child object to the local machine.This has been solved in torch_1",2,2018-09-29 14:58:43,2019-02-05 15:07:27,2019-02-05 15:07:26
https://github.com/OpenMined/PySyft/issues/1562,[],Documentation link not found,"Documentation link not foundI am not sure why but the documentation link on the readme page is not working. It links to https://openmined.github.io/PySyft/_build/html/index.html which gives 404 file not found error on github page. 
![image](https://user-images.githubusercontent.com/10602903/46029145-7f24f500-c0a7-11e8-8315-2e2dba131b1c.png)
Yeah - we're having general link issues - if you pull the docs down and build them locally it works - @jeremyjordan is currently working on thisi'll pull the docs page down from the readme for now - thanks for the heads up!",2,2018-09-25 16:44:06,2018-09-25 17:37:59,2018-09-25 17:37:59
https://github.com/OpenMined/PySyft/issues/1557,[],"missing ""workers"" parameter when calling share on new spdz demo.ipynb","missing ""workers"" parameter when calling share on new spdz demo.ipynbIn notebook :
PySyft/examples/other/experimental/new spdz demo.ipynb

There's a calls to _SPDZTensor.share which are missing ""workers"" parameterI'll fix this .That demo might actually be out of date in general - would be great if it used the new APIIt seems as the notebook is missing in master branch, maybe it was renamed?It was moved to experimental -  but we really should create _new_ demos(because that one is out of date)",5,2018-09-24 17:45:26,2018-10-09 18:16:19,2018-10-09 18:15:58
https://github.com/OpenMined/PySyft/issues/1542,[],Tensors shouldn't store information about commands,"Tensors shouldn't store information about commands## Context
The _PlusIsMinusTensor has been created as a canonical example of what can be done by extending the SyftTensor.However, it does not make sense that we modify the behaviour of commands from an argument.

This underlines that the architecture is very much argument oriented, which is excellent when we send tensor or transform them in MPCTensor, but rather unefficient and complicated when we want to execute command on them.

Idea: using contexts defining workers involved and mpc. PR #1543 https://github.com/OpenMined/PySyft/pull/1543 gives extended explanation of a possible solution.

A typical example would be:
```
x = sy.FloatTensor([1.2])

#x.send(bob) #<- This is what you don't need to do

with sy.session(bob):
    # Here all the commands and ensors are sent to bob
    z = torch.add(x, x)

#z.get() or x.get() #<- This is what you don't need to do

print(z) # This is FloatTensor
```^^^^ I just added an example of what I meant by context.I assume we'll be leaving in .send() and .get() as backups? There are some cases when it will be very challenging to use the indented case (such as when you're working with tensors in multiple places at once or pointers to pointers.Exactly, .send() and .get() will be kept. Sending a tensor to bob before opening a context session with bob for example means that when the session ends, that tensor still is at bob (example: the data when doing training over epochs).
If you have two remote datasets at bob and alice as it is the case in most of our examples, you would probably iterate on each batch, and depending of whom stores it, you would open the appropriate remote session.",3,2018-09-21 20:00:46,2019-02-05 15:17:02,2019-02-05 15:17:02
https://github.com/OpenMined/PySyft/issues/1526,['bug '],Matrix Multiplication Broken,"Matrix Multiplication BrokenSome combination of the following PRs broke Matrix Multiplication 

https://github.com/OpenMined/PySyft/pull/1519
https://github.com/OpenMined/PySyft/pull/1518
https://github.com/OpenMined/PySyft/pull/1515
https://github.com/OpenMined/PySyft/pull/1514

At present, the branch ""trask2"" still has working matrix multiplication so i plan to add each of these changes to the branch and see which one broke it.To reproduce on master branch, run

```
import random
import syft as sy
from syft.core import utils
from syft.core.frameworks.torch import utils as torch_utils
from syft.core.frameworks import encode

from syft.core.frameworks.torch.tensor import _GeneralizedPointerTensor
from syft.mpc import spdz
from syft.core.frameworks.torch.tensor import _MPCTensor
import torch
import torch.nn.functional as F
from torch.autograd import Variable as Var
import json

hook = sy.TorchHook(verbose=True)

me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
james = sy.VirtualWorker(id=""james"", hook=hook, is_client_worker=False)

x = torch.LongTensor([[3,-2],[-3,-4]])
x = x.share(bob, alice)

y = torch.LongTensor([[5,6],[7,8]])
y = y.share(bob, alice)

x.mm(y).get()
```

and you'll see

```
1.7582e+09  4.9458e+08
 3.7146e+08  4.9147e+08
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```Ok, I've narrowed it down to a bug somewhere in generate_matmul_triple_communication in spdz.pyFound it!!! Tiny typo in spdz.py.

```
def generate_matmul_triple_communication(shapes, workers):
    r, s, t = generate_matmul_triple(shapes)

    n_workers = len(workers)
    r_shares = share(r, n_workers)
    s_shares = share(s, n_workers)
    t_shares = share(t, n_workers)

    # For r, s, t as a shared var, send each share to its worker
    for var_shares in [r_shares, s_shares, t_shares]:
        for var_share, worker in zip(var_shares, workers):
            var_share.send(worker)

    # Build the pointer dict for r, s, t. Note that we remove the head of the pointer (via .child)
    gp_r = sy._GeneralizedPointerTensor({
        share.location: share.child for share in r_shares
    }).on(r)
    gp_s = sy._GeneralizedPointerTensor({
        share.location: share.child for share in s_shares
    }).on(s)
    gp_t = sy._GeneralizedPointerTensor({
        share.location: share.child for share in r_shares
    }).on(t)
    triple = [gp_r, gp_s, gp_t]
    return triple
```

should be

```
def generate_matmul_triple_communication(shapes, workers):
    r, s, t = generate_matmul_triple(shapes)

    n_workers = len(workers)
    r_shares = share(r, n_workers)
    s_shares = share(s, n_workers)
    t_shares = share(t, n_workers)

    # For r, s, t as a shared var, send each share to its worker
    for var_shares in [r_shares, s_shares, t_shares]:
        for var_share, worker in zip(var_shares, workers):
            var_share.send(worker)

    # Build the pointer dict for r, s, t. Note that we remove the head of the pointer (via .child)
    gp_r = sy._GeneralizedPointerTensor({
        share.location: share.child for share in r_shares
    }).on(r)
    gp_s = sy._GeneralizedPointerTensor({
        share.location: share.child for share in s_shares
    }).on(s)
    gp_t = sy._GeneralizedPointerTensor({
        share.location: share.child for share in t_shares
    }).on(t)
    triple = [gp_r, gp_s, gp_t]
    return triple
```",3,2018-09-20 12:07:03,2018-09-20 12:32:48,2018-09-20 12:32:48
https://github.com/OpenMined/PySyft/issues/1520,[],fix unit testing for brand new forked repos,"fix unit testing for brand new forked reposThe unit tests are failing after just forking the repo even after 0 modifications to the code, i found the issue following this steps(on MacOS using Anaconda):

1. Fork Repo
2. Clone repo to your computer
3. Create conda environment and install requirements from requirements.txt
4. Fix any dependencies and version issues
5. runt tests: python3 setup.py test

Some of the errors in result:
test_tensor2unregsitered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde) ... FAIL
test_plus_is_minus_backward_local (test.torch_test.TestChainTensor) ... ERROR
test_plus_is_minus_backward_remote (test.torch_test.TestChainTensor) ... ERROR
test_plus_is_minus_tensor_local (test.torch_test.TestChainTensor) ... ok
test_plus_is_minus_tensor_remote (test.torch_test.TestChainTensor) ... ok
test_plus_is_minus_variable_local (test.torch_test.TestChainTensor) ... ERROR
test_plus_is_minus_variable_remote (test.torch_test.TestChainTensor) ... ERROR
test_gpc_add (test.torch_test.TestGPCTensor) ... ok
test_gpc_unwrapped_add (test.torch_test.TestGPCTensor) ... ok
test_mpc_mul (test.torch_test.TestMPCTensor) ... ok
test_mpc_sum (test.torch_test.TestMPCTensor) ... ok
test___repr__ (test.torch_test.TestTorchTensor) ... ok
test_add_remote_tensor (test.torch_test.TestTorchTensor) ... ok
test_chain_send_get_tensor (test.torch_test.TestTorchTensor) ... ok
test_local_tensor_binary_methods (test.torch_test.TestTorchTensor)
Unit tests for methods mentioned on issue 1385 ... ok
test_local_tensor_iterable_methods (test.torch_test.TestTorchTensor) ... ok
test_local_tensor_tertiary_methods (test.torch_test.TestTorchTensor) ... ok
test_local_tensor_unary_methods (test.torch_test.TestTorchTensor)
Unit tests for methods mentioned on issue 1385 ... ok
test_multiple_pointers_to_same_target (test.torch_test.TestTorchTensor) ... FAIL
****
ERROR: test_plus_is_minus_backward_local (test.torch_test.TestChainTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/torch_test.py"", line 172, in test_plus_is_minus_backward_local
    x = sy._PlusIsMinusTensor().on(x)
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 281, in on
    wrapper.init_grad_()
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 1346, in init_grad_
    self.grad.native_set_()
  File ""/Users/llealhernandez/anaconda/envs/dlnd/lib/python3.6/site-packages/torch/autograd/variable.py"", line 65, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Variable' object has no attribute 'native_set_'

======================================================================
ERROR: test_plus_is_minus_backward_remote (test.torch_test.TestChainTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/torch_test.py"", line 184, in test_plus_is_minus_backward_remote
    x = sy._PlusIsMinusTensor().on(x)
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 281, in on
    wrapper.init_grad_()
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 1346, in init_grad_
    self.grad.native_set_()
  File ""/Users/llealhernandez/anaconda/envs/dlnd/lib/python3.6/site-packages/torch/autograd/variable.py"", line 65, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Variable' object has no attribute 'native_set_'
**************************************
Hi @llealgt! What version of python and pytorch are you using?Interestingly - both of those errors likely mean that the test was run _before_ pytorch was hooked... as .native_set_ is a method we create. That's very strange indeed.Even more strangely - i have unit tests which are failing but when i run them separately they work fine. I think this might involve us not creating our global variables correctly - such that some tests are getting run before the global variables are initialied.Hey @llealgt - i think i fixed it... try pulling from master and see how it goesStill getting failed tests after  pulling from master ,here's some sample errors:

test_send_and_get_tensor (test.tensor_serde_test.TestTensorPointerSerde) ... FAIL
test_tensor2registered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde) ... FAIL
test_tensor2unregsitered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde) ... FAIL
setup module
WARNING:root:Torch was already hooked... skipping hooking process
test_plus_is_minus_backward_local (test.torch_test.TestChainTensor) ... ERROR
test_plus_is_minus_backward_remote (test.torch_test.TestChainTensor) ... ERROR
test_plus_is_minus_tensor_local (test.torch_test.TestChainTensor) ... ok
test_plus_is_minus_tensor_remote (test.torch_test.TestChainTensor) ... ok
test_plus_is_minus_variable_local (test.torch_test.TestChainTensor) ... ERROR
test_plus_is_minus_variable_remote (test.torch_test.TestChainTensor) ... ERROR
#############

ERROR: test_plus_is_minus_backward_local (test.torch_test.TestChainTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/torch_test.py"", line 187, in test_plus_is_minus_backward_local
    x = sy._PlusIsMinusTensor().on(x)
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 281, in on
    wrapper.init_grad_()
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 1559, in init_grad_
    self.grad.native_set_()
  File ""/Users/llealhernandez/anaconda/envs/dlnd/lib/python3.6/site-packages/torch/autograd/variable.py"", line 65, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Variable' object has no attribute 'native_set_'

======================================================================
ERROR: test_plus_is_minus_backward_remote (test.torch_test.TestChainTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/torch_test.py"", line 199, in test_plus_is_minus_backward_remote
    x = sy._PlusIsMinusTensor().on(x)
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 281, in on
    wrapper.init_grad_()
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/syft/core/frameworks/torch/tensor.py"", line 1559, in init_grad_
    self.grad.native_set_()
  File ""/Users/llealhernandez/anaconda/envs/dlnd/lib/python3.6/site-packages/torch/autograd/variable.py"", line 65, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Variable' object has no attribute 'native_set_'

**My conda env list of packages and versions**
(obtained using conda list)
alabaster                 0.7.11                    <pip>
appnope                   0.1.0                    py36_0  
aspy.yaml                 1.1.1                     <pip>
atomicwrites              1.2.1                    py36_0    anaconda
attrs                     18.2.0           py36h28b3542_0    anaconda
Babel                     2.6.0                     <pip>
blas                      1.0                         mkl    anaconda
bleach                    1.5.0                    py36_0  
bokeh                     0.12.5                   py36_0  
cached-property           1.5.1                     <pip>
certifi                   2018.8.24                py36_1    anaconda
cffi                      1.10.0                   py36_0  
cfgv                      1.1.0                     <pip>
cycler                    0.10.0                   py36_0  
decorator                 4.0.11                   py36_0  
docutils                  0.14                      <pip>
entrypoints               0.2.2                    py36_1  
freetype                  2.8                  h12048fb_1    anaconda
h5py                      2.8.0            py36h878fce3_3    anaconda
hdf5                      1.10.2               hfa1e0ec_1    anaconda
html5lib                  0.999                    py36_0  
icu                       54.1                          0  
identify                  1.1.6                     <pip>
imagesize                 1.1.0                     <pip>
intel-openmp              2019.0                      118    anaconda
ipykernel                 4.6.0                    py36_0  
ipython                   5.3.0                    py36_0  
ipython_genutils          0.2.0                    py36_0  
ipywidgets                6.0.0                    py36_0  
jbig                      2.1                           0  
jinja2                    2.9.6                    py36_0  
jpeg                      9b                            0  
jsonschema                2.5.1                    py36_0  
jupyter                   1.0.0                    py36_3  
jupyter_client            5.0.1                    py36_0  
jupyter_console           5.1.0                    py36_0  
jupyter_core              4.3.0                    py36_0  
keras                     1.0.7                    py36_0    conda-forge
kiwisolver                1.0.1            py36h792292d_0    anaconda
libcxx                    4.0.1                h579ed51_0    anaconda
libcxxabi                 4.0.1                hebd6815_0    anaconda
libgfortran               3.0.1                h93005f0_2    anaconda
libgpuarray               0.7.6                h1de35cc_0    anaconda
libpng                    1.6.34               he12f830_0    anaconda
libprotobuf               3.6.0                hd9629dc_0    anaconda
libtiff                   4.0.9                hcb84e12_2    anaconda
mako                      1.0.7                    py36_0    conda-forge
markupsafe                0.23                     py36_2  
matplotlib                2.2.2            py36ha7267d0_0    anaconda
mistune                   0.7.4                    py36_0  
mkl                       2019.0                      118    anaconda
mkl_fft                   1.0.4            py36h5d10147_1    anaconda
mkl_random                1.0.1            py36h5d10147_1    anaconda
mock                      2.0.0                    py36_0    conda-forge
more-itertools            4.3.0                    py36_0    anaconda
nbconvert                 5.1.1                    py36_0  
nbformat                  4.3.0                    py36_0  
nodeenv                   1.3.2                     <pip>
notebook                  5.0.0                    py36_0  
numpy                     1.15.1           py36h6a91979_0    anaconda
numpy-base                1.15.1           py36h8a80b8c_0    anaconda
olefile                   0.44                     py36_0  
openssl                   1.0.2k                        1  
packaging                 17.1                      <pip>
pandas                    0.23.4           py36h6440ff4_0    anaconda
pandocfilters             1.4.1                    py36_0  
path.py                   10.1                     py36_0  
pbr                       3.1.1                    py36_0    conda-forge
pexpect                   4.2.1                    py36_0  
pickleshare               0.7.4                    py36_0  
pillow                    4.2.1            py36h0263179_0    anaconda
pip                       9.0.1                    py36_1  
pluggy                    0.7.1            py36h28b3542_0    anaconda
pre-commit                1.11.0                    <pip>
prompt_toolkit            1.0.14                   py36_0  
protobuf                  3.6.0            py36h0a44026_0    anaconda
protobuf                  3.3.0                     <pip>
ptyprocess                0.5.1                    py36_0  
py                        1.6.0                    py36_0    anaconda
pycparser                 2.18                     py36_0  
pygments                  2.2.0                    py36_0  
pygpu                     0.7.6            py36h917ab60_0    anaconda
pyparsing                 2.1.4                    py36_0  
pyqt                      5.6.0                    py36_2  
pytest                    3.8.0                    py36_0    anaconda
python                    3.6.1                         0  
python-dateutil           2.6.0                    py36_0  
pytorch                   0.2.0                py36_4cu75    soumith
pytz                      2017.2                   py36_0  
pyyaml                    3.12                     py36_0  
pyzmq                     16.0.2                   py36_0  
qt                        5.6.2                         0  
qtconsole                 4.3.0                    py36_0  
readline                  6.2                           2  
requests                  2.13.0                   py36_0  
scikit-learn              0.19.1           py36hffbff8c_0    anaconda
scipy                     1.1.0            py36h28f7352_1    anaconda
setuptools                40.2.0                   py36_0    anaconda
simplegeneric             0.8.1                    py36_1  
sip                       4.18                     py36_0  
six                       1.10.0                   py36_0  
snowballstemmer           1.2.1                     <pip>
Sphinx                    1.8.0                     <pip>
sphinx-rtd-theme          0.4.1                     <pip>
sphinxcontrib-websupport  1.1.0                     <pip>
sqlite                    3.13.0                        0  
tensorflow                1.1.0                    py36_0    conda-forge
terminado                 0.6                      py36_0  
testpath                  0.3                      py36_0  
theano                    0.9.0                    py36_1    conda-forge
tk                        8.5.18                        0  
toml                      0.9.6                     <pip>
tornado                   4.4.2                    py36_0  
tqdm                      4.11.2                    <pip>
traitlets                 4.3.2                    py36_0  
virtualenv                16.0.0                    <pip>
wcwidth                   0.1.7                    py36_0  
websockets                6.0                       <pip>
Werkzeug                  0.12.1                    <pip>
werkzeug                  0.12.2                   py36_0    conda-forge
wheel                     0.29.0                   py36_0  
widgetsnbextension        2.0.0                    py36_0  
xz                        5.2.4                h1de35cc_4    anaconda
yaml                      0.1.6                         0  
zlib                      1.2.11               hf3cbc9b_2    anacondayour pytorch version is too old. You have 0.2.0 but you need 0.3.1Still getting failed tests after pytorch version update, but the number of errors decreased significantly(just 3 failures left) : 

======================================================================
FAIL: test_send_and_get_tensor (test.tensor_serde_test.TestTensorPointerSerde)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/tensor_serde_test.py"", line 228, in test_send_and_get_tensor
    assert xid in me._objects
AssertionError

======================================================================
FAIL: test_tensor2registered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/tensor_serde_test.py"", line 182, in test_tensor2registered_pointer2tensor
    assert x.id in me._objects
AssertionError

======================================================================
FAIL: test_tensor2unregsitered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/llealhernandez/Documents/Personal/Programming/PySyft/test/tensor_serde_test.py"", line 145, in test_tensor2unregsitered_pointer2tensor
    assert x.id in me._objects
AssertionError

Hmmmmm....  this is the kind of error i thought i fixed... can you pull from master again and check?Nope, i created a new conda env, installed from scratch again and still getting failures:

ERROR: test_plus_is_minus_backward_local (test.torch_test.TestChainTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/media/luis/media/PySyft/test/torch_test.py"", line 175, in test_plus_is_minus_backward_local
    z.backward()
  File ""/media/luis/media/PySyft/syft/core/frameworks/torch/hook.py"", line 423, in _execute_method_call
    return worker._execute_call(attr, self, *args, **kwargs)
  File ""/media/luis/media/PySyft/syft/core/workers/base.py"", line 891, in _execute_call
    result = child_type.handle_call(syft_command, owner=self)
  File ""/media/luis/media/PySyft/syft/core/frameworks/torch/tensor.py"", line 117, in handle_call
    result = child_type.handle_call(next_command, owner)
  File ""/media/luis/media/PySyft/syft/core/frameworks/torch/tensor.py"", line 404, in handle_call
    response = command(*args, **kwargs)
  File ""/media/luis/media/PySyft/syft/core/frameworks/torch/hook.py"", line 502, in new_backward
    self.native_native_backward(*args, **kwargs)
  File ""/home/luis/anaconda2/envs/PySyft/lib/python3.6/site-packages/torch/autograd/variable.py"", line 167, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File ""/home/luis/anaconda2/envs/PySyft/lib/python3.6/site-packages/torch/autograd/__init__.py"", line 99, in backward
    variables, grad_variables, retain_graph)
RuntimeError: std::bad_alloc

======================================================================
FAIL: test_send_and_get_tensor (test.tensor_serde_test.TestTensorPointerSerde)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/media/luis/media/PySyft/test/tensor_serde_test.py"", line 228, in test_send_and_get_tensor
    assert xid in me._objects
AssertionError

======================================================================
FAIL: test_tensor2registered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/media/luis/media/PySyft/test/tensor_serde_test.py"", line 182, in test_tensor2registered_pointer2tensor
    assert x.id in me._objects
AssertionError

======================================================================
FAIL: test_tensor2unregsitered_pointer2tensor (test.tensor_serde_test.TestTensorPointerSerde)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/media/luis/media/PySyft/test/tensor_serde_test.py"", line 145, in test_tensor2unregsitered_pointer2tensor
    assert x.id in me._objects
AssertionError

======================================================================
FAIL: test_multiple_pointers_to_same_target (test.torch_test.TestTorchTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/media/luis/media/PySyft/test/torch_test.py"", line 277, in test_multiple_pointers_to_same_target
    assert False
AssertionError

======================================================================
FAIL: test_send_get_tensor (test.torch_test.TestTorchTensor)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/media/luis/media/PySyft/test/torch_test.py"", line 235, in test_send_get_tensor
    assert x_id in me._objects
AssertionError

----------------------------------------------------------------------
I just made a pull from master and all tests are passing now",10,2018-09-20 01:24:38,2018-10-03 05:16:44,2018-10-03 05:16:44
https://github.com/OpenMined/PySyft/issues/1513,[],"Add Subtraction, Negation, and Power function to MPCTensor","Add Subtraction, Negation, and Power function to MPCTensorIn this project, I'll be adding several basic operators to MPCTensor.got sub working 

    def __sub__(self, other):
        gp_response = spdz.spdz_add(self.shares, spdz.spdz_neg(other.shares))
        response = _MPCTensor(gp_response).wrap(True)
        return response

Maybe the question of negative values is related as well:
trt this:
```
x = torch.LongTensor([3])
y = torch.LongTensor([-5])

mpc_x = x.share(alice, bob)
mpc_y = y.share(alice, bob)

mpc_z = mpc_x + mpc_y
mpc_z.get()
```
You get a negative value -2 because I did a hacky fix, but without it because of the modulo you would have <field_value> - 2I might skip pow since torch.LongTensor doesn't seem to have it either.Hit a speedbump - this seems to fail

```
x = torch.LongTensor([[1, 2], [-3, -4]])

x = x.share(bob, alice)

z = -x
assert (z.get() == torch.LongTensor([[-1, -2], [3, 4]])).all()
```z.get() returns

 2.1475e+09  2.1475e+09
 3.0000e+00  4.0000e+00
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]Curiously these work fine

```
x = torch.LongTensor([[1, 2], [3, 4]])

x = x.share(bob, alice)

z = -x
# assert (z.get() == torch.LongTensor([[-1, -2], [3, 4]])).all()

z.get()
```



AND




```
x = torch.LongTensor([[-1, -2], [-3, -4]])

x = x.share(bob, alice)

z = -x
# assert (z.get() == torch.LongTensor([[-1, -2], [3, 4]])).all()

z.get()
```@robert-wagner had some good things to say in Slack

yo - there seems to be an issue with the negation logic in spdz.py

https://github.com/OpenMined/PySyft/issues/1513

bobby [9:08 PM]
Are you decoding the value before checking what it is or just summing the result
Because if you're summing the result it will definitely be wrong for negative numbers

trask [9:10 PM]
i have no idea
lo
def __neg__(self):
       gp_response = spdz.spdz_neg(self.shares)
       response = _MPCTensor(gp_response).wrap(True)
       return response
that's what i did

bobby [9:13 PM]
How is get sum defined? Or I'll be back on laptop in 5

trask [9:13 PM]
sum?
where is sum?

bobby [9:13 PM]
Get_sum
It's on mpc tensor

trask [9:13 PM]
oh - it's defined how you defined it

bobby [9:13 PM]
Theo wrote it

trask [9:13 PM]
def get(self, deregister_ptr=False):
       # TODO: have deregister_ptr do something
       value = self.shares.child.sum_get() % spdz.field
       if (value > spdz.torch_max_value).all(): # TODO: value per value
           return value - spdz.torch_field
       else:
           return value

bobby [9:14 PM]
The comment needs to be fixed
We need to have it do that subtraction on every entry greater than the max value
I'll write up a fix in a few

trask [9:15 PM]
oh - so mask and subtract
ok i'm going to copy paste this into the github issue for referenceMerged in some improvements from Bobby - but they aren't finished yet https://github.com/OpenMined/PySyft/pull/1518

Now whenever i call .get() on an MPC tensor I get an error 
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-14-f01fae6ab1b3> in <module>()
----> 1 z.get()

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py in get(self, deregister_ptr, update_ptr_wrapper)
   1182                     and tensor is not None \
   1183                     and tensor.dim() > 0:
-> 1184                 self.native_set_(tensor)
   1185             torch_utils.fix_chain_ends(self)
   1186             torch_utils.assert_is_chain_well_formed(self)


TypeError: set_ received an invalid combination of arguments - got (torch.FloatTensor), but expected one of:
 * no arguments
 * (torch.LongTensor source)
      didn't match because some of the arguments have invalid types: (torch.FloatTensor)
 * (torch.LongStorage storage)
      didn't match because some of the arguments have invalid types: (torch.FloatTensor)
 * (torch.LongStorage sourceStorage, int storage_offset, torch.Size size)
 * (torch.LongStorage sourceStorage, int storage_offset, torch.Size size, tuple stride)
```Traced the issue to

```
def decode(field_element, precision_fractional=PRECISION_FRACTIONAL, mod=field):
    neg_values = field_element.gt(mod)
    # pos_values = field_element.le(field)
    # upscaled = field_element*(neg_valuese+pos_values)
    field_element[neg_values] = mod - field_element[neg_values]
    rational = field_element.float() / BASE ** precision_fractional
    return rational
```

the .float() casting seems to be the issue. Changing it to 

```
def decode(field_element, precision_fractional=PRECISION_FRACTIONAL, mod=field):
    neg_values = field_element.gt(mod)
    # pos_values = field_element.le(field)
    # upscaled = field_element*(neg_valuese+pos_values)
    field_element[neg_values] = mod - field_element[neg_values]
    rational = field_element / BASE ** precision_fractional
    return rational
```

gets rid of the error but then negative numbers stop working again.

```
x = torch.LongTensor([[-1,2],[3,4]])
x = x.share(bob, alice)
x.get()
```

 ```
2.1475e+09  2.0000e+00
 3.0000e+00  4.0000e+00
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```

Notice that all the numbers are correct except the negative one... makes me think something's broken in decode(). Looking into it now.Ok, made some progress by looking back at what it was before (https://github.com/OpenMined/PySyft/blob/trask2/syft/core/frameworks/torch/tensor.py)

   ```
 def get(self, deregister_ptr=False):
        # TODO: have deregister_ptr do something
        value = self.shares.child.sum_get() % spdz.field
        if (value > spdz.torch_max_value).all(): # TODO: value per value
            return value - spdz.torch_field
        else:
            return value
```

and then just focusing on implementing that TODO there... using some basic masking.

  ```
  def get(self, deregister_ptr=False):
        # TODO: have deregister_ptr do something
        value = self.shares.child.sum_get() % spdz.field

        gate = (value > spdz.torch_max_value).long()

        neg_nums = (value - spdz.torch_field) * gate
        pos_nums = value * (1 - gate)
        result = neg_nums + pos_nums

        return result
```

Seems to be working so far.

```
x = torch.LongTensor([[1,-2],[-3,-4]])
x = x.share(bob, alice)
x.get()

 1 -2
-3 -4
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```going to try testing it with the other functions nowNo dice yet - doesn't work with matrix multiplication

```
x = torch.LongTensor([[1, 2], [3, 4]])
y = torch.LongTensor([[5, 6], [7, 8]])

x = x.share(bob, alice)
y = y.share(bob, alice)

x.mm(y).get()
```

```
-8.4013e+08  3.0743e+08
 9.2008e+08 -5.7132e+08
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```Ok - this piece is kindof annoying - looks like the old version of .get() doesn't work with matrix multiplication anymore either..., something else must have changed

```
x = torch.LongTensor([[1, 2], [3, 4]])
y = torch.LongTensor([[5, 6], [7, 8]])

x = x.share(bob, alice)
y = y.share(bob, alice)

z = x.mm(y)


value = z.child.shares.child.sum_get() % spdz.field

if (value > spdz.torch_max_value).all(): # TODO: value per value
    out = value - spdz.torch_field
else:
    out = value
out
```

```
2.4780e+08  1.2492e+09
 1.0811e+09  5.7968e+08
[syft.core.frameworks.torch.tensor.LongTensor of size 2x2]
```Ok... good news is that the implementation on branch trask2 still works for matrix multiplication... so going to compare the two branches (trask and trask2) to figure out where matrix multiplication differs.Ok, i'm almost completely sure that some other PR has messed up matrix multiplication, so i'm going to check that subtraction and negation work properly and then merge thisfixed by https://github.com/OpenMined/PySyft/pull/1514",16,2018-09-19 19:37:56,2018-09-20 12:07:51,2018-09-20 12:07:34
https://github.com/OpenMined/PySyft/issues/1511,['bug '],Bugfix in Matrix Multiplication for MPC,"Bugfix in Matrix Multiplication for MPCimport random
import syft as sy
from syft.core import utils
from syft.core.frameworks.torch import utils as torch_utils
from syft.core.frameworks import encode

from syft.core.frameworks.torch.tensor import _GeneralizedPointerTensor
from syft.mpc import spdz
from syft.core.frameworks.torch.tensor import _MPCTensor
import torch
import torch.nn.functional as F
from torch.autograd import Variable as Var
import json

hook = sy.TorchHook(verbose=True)

me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
james = sy.VirtualWorker(id=""james"", hook=hook, is_client_worker=False)

x = torch.LongTensor([[1,2],[3,4]])
y = torch.LongTensor([[5,6],[7,8]])
xptr = x.share(bob, alice)
yptr = y.share(bob, alice)
z = x.mm(y)


z.child isn't an MPCTensor..., it's just a GeneralizedPointerTensor. Working on a fix.

oh wait... i'm an idiot...


i should have put down xptr.mm(yptr)AhahahThere was a small bug to fix but now it's done - although i noticed that x and y are getting inline modified to become GeneralizedPointerTensors when they probably shouldn't be.Hum yes you're right this should be avoided!",4,2018-09-19 18:59:00,2018-09-19 19:14:33,2018-09-19 19:09:15
https://github.com/OpenMined/PySyft/issues/1510,[],Fixed Precision Tensor ,"Fixed Precision Tensor We want the ability to wrap any LongTensor or IntTensor object with a Fixed Precision (decimal point) interpretation. For this, we want to implement a new FixedPrecision tensor type which allows for arbitrary precision.I'm picking this up now - I'm going to focus on something that can wrap any torch tensor (aka, LongTensor or IntTensor) with FixedPrecision features.Picking this up again - got a little distracted by some other more pressing IssuesBasic fixed precision tensor works!

```
x = torch.FloatTensor([0.1, 0.2, 0.3, -0.5]).fix_precision()
y = torch.FloatTensor([1,1,1,1]).fix_precision()
x
```
```
[Fixed precision]

 0.1000
 0.2000
 0.3000
-0.5000
[syft.core.frameworks.torch.tensor.FloatTensor of size 4]
```

```
z = x + y
z
```

```
[Fixed precision]

 1.1000
 1.2000
 1.3000
 0.5000
[syft.core.frameworks.torch.tensor.FloatTensor of size 4]
```",3,2018-09-19 18:48:20,2018-09-20 16:14:21,2018-09-20 16:14:21
https://github.com/OpenMined/PySyft/issues/1503,[],Numpy Remote Execution Bug,"Numpy Remote Execution BugIn the process of creating the Numpy Federated Learning Demo (https://github.com/OpenMined/PySyft/blob/master/examples/numpy/Federated%20Learning.ipynb), I discovered that np.dot(a,b) doesn't work for remote numpy arrays while a.dot(b) does. Similarly, I also discovered that a.T does not work with remote tensors but a.transpose() does. Closing this Issue is about getting these functions to work.

To reproduce the error, just run the Federated Learning demo above with the function np.dot() instead of the method x.dot(y) (or similarly for transpose).Ill take it ðŸ‘ Hey Ian - how's this PR going? @amit-rastogi is interested in picking it up if you've moved on from the project.Hey @amit-rastogi - Ian messaged me offline that this project is all yours! :)Thanks @iamtrask I'm picking this up.",4,2018-09-19 18:04:59,2019-02-05 15:09:11,2019-02-05 15:09:11
https://github.com/OpenMined/PySyft/issues/1502,[],MPC Based Secure Aggregation for Federated Learning,"MPC Based Secure Aggregation for Federated LearningThis issue depends on https://github.com/OpenMined/PySyft/issues/1501 being completed.

This issue requires creating a demo using MPC for the secure aggregation of gradients. Multiple different workers should create a weight update (in the usual Federated Learning fashion) but instead of sending the gradients directly to the model owner, they should use MPC to securely aggregate their gradients wherein only the aggregated update is sent to the model owner.

Issue #1501 has been completed - this issue is ready for someone to pick up. I'm dealing with some broken unit tests but i'll pick it up when i'm done if no-one else has.I'm picking this up now.",2,2018-09-19 18:01:09,2018-09-22 22:34:31,2018-09-22 22:34:31
https://github.com/OpenMined/PySyft/issues/1452,[],Tensor object located at VirtualWorker giving dimension error on being passed throughs DNN,"Tensor object located at VirtualWorker giving dimension error on being passed throughs DNNI am trying to use Federated Learning with DNNs. 
1) Split the data and sent it to Alice and Bob (2 virtual workers)
2) Made a loop which selects datasets for each worker and sends the model to them.
3) On passing the datasets to the model(), I receive a
RuntimeError: dimension specified as 0, but tensor has no dimensions

This error occurs in the forward function of my DNN, where I am trying to create Embeddings.
I do not know if PySyft is compatible with DNNs and embeddings etc. as of now. Any insight would help.

Line of code causing the error: This is inside the forward function in my DNN class.
emb = [getattr(self, 'emb_layer_'+col)(X_d[:,self.deep_column_idx[col]].long())
               for col,_,_ in self.embeddings_input]

This is basically trying to get a list of embedding columns by indexing each required column and passing it through the embedding created with proper dimensions, example, 
emb_layer_userId = nn.Embedding(a, b)  (Created in the init function in the same class)

Also, this code works without PySyft.
PyTorch version 0.3.1
Edit: Tested with test_emb = Embedding(15, 60)
and Variable containing FloatTensor of dimension 667 (Column has 15 unique values, hence used embedding input as 15)My suspicion is that it's the casting that might be broken... I'm not sure I've tried doing .long() before. Perhaps this example will be helpful to you

https://github.com/OpenMined/PySyft/blob/master/examples/SocketWorker%20Boston%20Housing%20Client.ipynbClosing due to inactivity.",3,2018-08-14 12:09:45,2019-02-05 15:18:43,2019-02-05 15:18:43
https://github.com/OpenMined/PySyft/issues/1451,[],[Pointers are Tensors] Custom made tensors' attributes disappear after conversion,"[Pointers are Tensors] Custom made tensors' attributes disappear after conversion# Issue Template
## Context
### User Story:
Custom made tensors are now easier than ever to make with [pointers are tensors](https://github.com/OpenMined/PySyft/pull/1394). In `_PlusIsMinusTensor` everything works since, we're only overriding the existing methods (in this case torch.add) but if a tensor requires a custom made method if we want to add an attribute to it, they disappear during the conversion from the custom made tensor to torch supported tensor. 

## Expected Behavior

```
import syft as sy
import torch
hook = sy.TorchHook()

x = torch.FloatTensor([2, 4, 2])
x = sy._PlusIsMinusTensor().on(x)
print(hasattr(x.abs(), 'is_plusisminustensor'))

True
```

## Current Behavior

What is the current behavior?

```
import syft as sy
import torch
hook = sy.TorchHook()

x = torch.FloatTensor([2, 4, 2])
x = sy._PlusIsMinusTensor().on(x)
print(hasattr(x.abs(), 'is_plusisminustensor'))

True
```

## Failure Information (for bugs)

Please help provide information about the failure if this is a bug. If it is not a bug, please remove the rest of this template.

### Steps to Reproduce (for bugs)
Simply add `self.is_plusisminustensor` to [this line](https://github.com/OpenMined/PySyft/blob/75402439cfc78238c4bf2bad16dc1b88810c746a/syft/core/frameworks/torch/tensor.py#L496).



### Relevant Literature or Examples (for features)
https://github.com/OpenMined/PySyft/pull/1394The current behavior seems to be the same as the expected behavior. Perhaps another description?This is an issue on a deprecated branch",2,2018-08-05 16:48:38,2019-02-05 15:17:17,2019-02-05 15:17:16
https://github.com/OpenMined/PySyft/issues/1442,[],Unable to use nn.RNN module on remote workers. No .shape parameter,"Unable to use nn.RNN module on remote workers. No .shape parameter## Context
I was experimenting with PySyft and RNN's when i got errors. I was unable to use the sent model with data on a remote worker. I did some testing with a very simple RNN. It worked on the local machine, but when it was sent over to a worker it had same error as before. The error i was getting was when the RNN was trying to get the batch size from the input tensor.



**Test Configuration**:

* PySyft Version: 3.1


## Current Behavior

Throws Error Messages


### Steps to Reproduce 

1. creating a float tensor as data
2. reshaping it for rnn input (batch_size,step,seq)
3. Creating the RNN using (torch.nn.RNN)
4. sending data to worker (data.send(worker1))
5. sending model to worker (model.send(worker1))
6. Computing with the data and model (model(data)) ERROR

[Google Colab](https://colab.research.google.com/drive/1K9N74jjsWVwOzlXe97m2_57UrEwA-mOq)
### Failure Logs
[https://gist.github.com/haruza/5a5b021fda1ed5a966ad969c59b00409](https://gist.github.com/haruza/5a5b021fda1ed5a966ad969c59b00409)

Any chance you could copy paste some code to reproduce (or even better... attach a colab?) [Here is the colab](https://colab.research.google.com/drive/1K9N74jjsWVwOzlXe97m2_57UrEwA-mOq)It is a work around by using nn.RNNCell instead of the nn.RNN Brilliant! This is perfect! Thank you so much Ozzy!No problem at all :DHi @iamtrask . I have been receiving the same error. My error occurs when the remote tensor is passed through the Embeddings variable. Is it because PySyft does not support embeddings as of now? Hmmm - honestly not sure yet. We don't support GPU yet though so that could be the problem. Are you running on the CPU or GPU?i believe .shape has been fixed",8,2018-08-02 10:29:26,2019-02-05 15:10:59,2019-02-05 15:10:59
https://github.com/OpenMined/PySyft/issues/1403,[],Automatic Documentation Rebuilding,"Automatic Documentation RebuildingWe use Sphynx for the creation of automatic documentation in the PySyft project. The [build.sh](https://github.com/OpenMined/PySyft/blob/master/scripts/build.sh) script will rebuild documentation from scratch (adding any new functionality you've added). This documentation shows up in the [docs](https://github.com/OpenMined/PySyft/tree/master/docs) folder.

The main concern here, however, is that contributors as a whole haven't been rebuilding documentation as they go in Pull Requests. Thus, whenever someone does get around to it, it creates a very challenging PR to read/review because it encapsulates documentation updates for the past several PRs (sometimes many!). 

A great project would be to help resolve this issue using automation, by writing a Github bot or script which will automatically rebuild our documentation whenever we submit or merge a PR.So, I talked to some of my dev friends. Jenkins seems to be the best way to go forward with this. I will do some more research. 
Any ideas and suggestions are welcome.

UPDATE 1. Jenkins would require us to buy a host, looking into CircleCi
https://stackoverflow.com/a/48763205/7127317So I think this portion of the ticket was solved via (https://pysyft.readthedocs.io/en/latest/) - although the documentation itself still seems to be broken.",2,2018-07-16 19:56:39,2018-10-07 11:11:32,2018-10-07 11:11:32
https://github.com/OpenMined/PySyft/issues/1396,[],N-ary methods/iterable methods do not work remotely,"N-ary methods/iterable methods do not work remotely# Issue Template
## Context
### User Story:
When iterable methods are called on remote objects, the get() method returns an empty tensor. See expected and current behavior for more info.

`torch.stack` and `torch.cat` are great examples of such methods.
[torch.stack](https://pytorch.org/docs/0.3.1/torch.html#torch.stack)
[torch.cat](https://pytorch.org/docs/0.3.1/torch.html#torch.cat)

## Expected Behavior
```
>>> x = torch.FloatTensor([1,2,3,4]).send(remote)
>>> y = torch.FloatTensor([3,4,1,2]).send(remote)
>>> z = torch.FloatTensor([5,2,1,4]).send(remote)
>>> torch.stack([x,y,z]).get()

 1  2  3  4
 3  4  1  2
 5  2  1  4
[torch.FloatTensor of size 3x4]
```

## Current Behavior
What is the current behavior?
```
>>> x = torch.FloatTensor([1,2,3,4]).send(remote)
>>> y = torch.FloatTensor([3,4,1,2]).send(remote)
>>> z = torch.FloatTensor([5,2,1,4]).send(remote)
>>> torch.stack([x,y,z]).get()
[torch.FloatTensor with no dimension]
```
## Failure Information (for bugs)
When iterable methods are called on remote objects, the get() method returns an empty tensor. 
### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)

```
>>> x = torch.FloatTensor([1,2,3,4]).send(remote)
>>> y = torch.FloatTensor([3,4,1,2]).send(remote)
>>> z = torch.FloatTensor([5,2,1,4]).send(remote)
>>> torch.stack([x,y,z]).get()
```



For such methods, arrays are not supported as an argument and a tensor of tensors should be only used.Hey @alhparsa, I'm reopening this.  Maintaining the original semantics of PyTorch is very important, and I think this should be covered when #1395 lands.  We'll close when that happens.Yes, my PR fix this, I will add a unit testdoing this works for stack and cat
torch.stack([x.get(),y.get(),z.get()])

 1  2  3
 2  3  4
 5  6  7
[torch.FloatTensor of size 3x3]

I added the unittests based on this.This also works!

```
t = torch.FloatTensor([x,y,z])
torch.stack(t).get()
```
@bartimaeus12 your code actually doesn't apply the function remotely. What it does is that it gets the tensors and then it applies the function locally on them. What we want is something like `torch.stack(some array of arrays or a tensor of tensors).get()` this way the function is applied remotely first and then by calling the `get()` method we receive the data.",5,2018-07-10 15:54:08,2018-07-14 17:30:48,2018-07-14 17:30:48
https://github.com/OpenMined/PySyft/issues/1391,[],torch.matmul does not work when the output is numeric,"torch.matmul does not work when the output is numeric# Issue Template

## Context
### User Story:
torch.matmul does not work when the output is numeric.


Please delete (for bugs) or (for features) sections that are not relevant to the Issue you are creating.

Please provide any relevant information about your setup. This is important in case the issue is not reproducible except for under certain conditions.

**Test Configuration**:
* CPU:
* GPU:
* PySyft Version:
* Unity Version:
* OpenMined Unity App Version:


## Expected Behavior

the output should be 16.0.
## Current Behavior

What is the current behavior?

`    registration, torch_type, var_data, var_grad = response
ValueError: not enough values to unpack (expected 4, got 1)`
## Failure Information (for bugs)

Please help provide information about the failure if this is a bug. If it is not a bug, please remove the rest of this template.

The `_execute_remote_call` function in `hook.py` expects a tensor as an output, but the output is just a numeric value.

### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)


```
from syft.core.hooks.torch import TorchHook
from syft.core.workers import VirtualWorker
import torch

hook = TorchHook()
local = hook.local_worker
remote = VirtualWorker(hook, 1)
local.add_worker(remote)

x = torch.FloatTensor([1, 2, 3, 4])
y = torch.FloatTensor([1, 2, 1, 2])
x.send(remote)
y.send(remote)
z = torch.matmul(x, y)
print(z.get())
```

Solved! https://github.com/OpenMined/PySyft/pull/1393",1,2018-07-07 08:26:50,2018-07-10 14:47:09,2018-07-10 14:47:08
https://github.com/OpenMined/PySyft/issues/1386,[],Remote operations don't work for fixed-precision variables,"Remote operations don't work for fixed-precision variables### User Story:
Mathematical operations are not applied properly when they're performed remotely on the variables.


## Expected Behavior

The output should be:

```
Hooking into Torch...
Overloading complete.

 2.0000e+07
 4.0000e+07
 6.0000e+07
 8.0000e+07
 1.0000e+08
[torch.LongTensor of size 5]

```
## Current Behavior

What is the current behavior?

```
Hooking into Torch...
Overloading complete.

 1.0001e+07
 2.0002e+07
 3.0003e+07
 4.0004e+07
 5.0005e+07
[torch.LongTensor of size 5]

```
## Failure Information (for bugs)

Regular torch operations are applied when variables are only available remotely and fixed-precision operations are not called. 

### Steps to Reproduce (for bugs)


```
import torch
from syft.core.hooks import TorchHook
hook = TorchHook()
from syft.core.workers import VirtualWorker

local = hook.local_worker
remote = VirtualWorker(id=1,hook=hook)
local.add_worker(remote)

hook = TorchHook(verbose=False)

x = torch.FloatTensor([1, 2, 3, 4, 5]).set_precision(3)
y = torch.FloatTensor([1, 2, 3, 4, 5]).set_precision(7)

y.send(remote)
x.send(remote)

z = x + y

z.get()

print (z)

```

### Relevant Literature or Examples (for features)
https://github.com/OpenMined/PySyft/pull/1378When the function method_router is called, line 171 should be:

`if hasattr(self, 'is_pointer') and self.is_pointer and not self.fixed_precision:
`
but then the problem is that the tensor return by line 176 does not have the owner attribute:

`return hook_self._execute_fixed_precision_call(self, _method, args, kwargs)
`

New function is needed to handle remote fixed_precision calls",1,2018-07-04 15:17:36,2019-02-05 15:10:26,2019-02-05 15:10:26
https://github.com/OpenMined/PySyft/issues/1381,[],Mnist Example Not Working For GPU,"Mnist Example Not Working For GPU## Context

The new experimental example on training MNIST dataset works fine without GPU. But, throws error messages when GPU is used.

For Working CPU version, see this : https://colab.research.google.com/drive/1cpTIxtebCMRsHEmJreI7ycyzS42OjXM8 
(Run without enabling GPU)

### Test Configuration

Colab Python 3
PyTorch - 0.3.0

### Expected Behavior

The Code should work fine with GPU as it worked with CPU.

### Current Behavior

Throws Error Messages

### Steps to Reproduce

Run the GPU colab notebook link with GPU activated.
 

For GPU version, see this: https://colab.research.google.com/drive/1U6B3mp2dK0gDW1UwlBSVWS0iKF6DNplUWe still haven't Inherited the methods required for it to work on GPU.",1,2018-07-03 12:31:05,2019-02-05 15:06:51,2019-02-05 15:06:51
https://github.com/OpenMined/PySyft/issues/1367,"['bug ', 'help wanted :wave:']",Fix up special case of overloading __repr__ to print big tensors,"Fix up special case of overloading __repr__ to print big tensorsChild of OpenMined/Grid#171 and OpenMined/Grid#190 (see those and their discussion for reference/instructions)From the stacktrace below obtained when printing which involves `new___repr__`, it seems that the problem is caused by `row[-truncate:]` which uses the `select()` method on a Tensor, (which we haven't rewritten as it is in the `self.exclude` of the hook) 

`Traceback (most recent call last):`
`  File ""<stdin>"", line 1, in <module>`
`  File ""/Users/ryffel/Documents/Code/PySyft/syft/core/hooks.py"", line 622, in new___repr__`
`    return self.old__repr__()`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/tensor.py"", line 144, in __repr__`
`    return str(self)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/tensor.py"", line 151, in __str__`
`    return _tensor_str._str(self)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py"", line 297, in _str`
`    strt = _matrix_str(self)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py"", line 246, in _matrix_str`
`    strt += __repr_row(row, indent, fmt, scale, sz, n)`
`  File ""/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py"", line 202, in __repr_row`
`    ' '.join(fmt.format(val / scale) for val in row[-truncate:]) +`
`  File ""/Users/ryffel/Documents/Code/PySyft/syft/core/hooks.py"", line 298, in send_to_workers`
`    if self.is_pointer:`
`AttributeError: 'torch.FloatTensor' object has no attribute 'is_pointer'`

Can't we just fix this by modifying the `new___rpr__` as follows ?

`def new___repr__(self):`
`      _id_in_owners = hook_self.local_worker.id in self.owners`
`      if (hook_self.local_worker in self.owners or _id_in_owners):`
          **tensor_type.is_pointer = False**
`          return self.old__repr__()`
`      else:`
`          ...`

It fixes the basic examples given in the related issues, and passes tests, but I not sure it is ok in general.",1,2018-06-25 20:23:48,2019-02-05 15:07:18,2019-02-05 15:07:18
https://github.com/OpenMined/PySyft/issues/1364,[],The send method does not work when sending a torch.autograd.Variable to a SocketWorker,"The send method does not work when sending a torch.autograd.Variable to a SocketWorker# The send method does not work when sending a torch.autograd.Variable to a SocketWorker

## Context
When trying to send a torch.autograd.Variable object to a SocketWorker server with the send() method, the program freeze and never ends.
**Test Configuration**:
A Docker container with:
Python 3.6.5
Jupyter Notebook 5.5.0
IPython 6.4.0
PyTorch 0.3.1


## Expected Behavior

The program is supposed to send the object to the server and return the location of the object.

## Current Behavior

The program just block and force me to kill it.

## Failure Information (for bugs)

Here is the StackTrace of the **Server** when I interrupt it:
```
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-1-d8091d55efea> in <module>()
      7                             port=8002,
      8                             is_pointer=False,
----> 9                             is_client_worker=False)

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in __init__(self, hook, hostname, port, max_connections, id, is_client_worker, objects, tmp_objects, known_workers, verbose, is_pointer, queue_size)
   1033             if(not is_client_worker or self.is_pointer):
   1034                 print(""Ready to receive commands..."")
-> 1035                 self._listen()
   1036             else:
   1037                 print(""Ready!"")

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _listen(self)
   1049                 while True:
   1050                     # collapse buffer of messages into a string
-> 1051                     message = self._process_buffer(connection)
   1052 
   1053                     # process message and generate response

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _process_buffer(socket, buffer_size, delimiter)
   1087         # WARNING: will hang if buffer doesn't finish with newline
   1088 
-> 1089         buffer = socket.recv(buffer_size).decode('utf-8')
   1090         buffering = True
   1091         while buffering:
```
Here is the StackTrace of the **Client** when I interrupt it:
```
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-1-821e5d0475a4> in <module>()
     16 target = Var(torch.FloatTensor([[0],[0],[1],[1]]))
     17 
---> 18 remote_data = data.send(remote_worker)
     19 remote_target = target.send(remote_worker)

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in send_(self, workers)
    964                 # TODO: sync or async? likely won't be worth doing async,
    965                 #       but should check (low priority)
--> 966                 hook_self.local_worker.send_obj(self, worker)
    967 
    968             # NEW IS_POINTER STATUS. This line changes the is_pointer flag to true.

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in send_obj(self, obj, recipient, delete_local)
    834         _obj = self.send_msg(message=self.prepare_send_object(obj, delete_local),
    835                              message_type='obj',
--> 836                              recipient=recipient)
    837 
    838         if(delete_local):

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in send_msg(self, message, message_type, recipient)
    147 
    148         self.message_queue = []
--> 149         return self._send_msg(message_wrapper_json_binary, recipient)
    150 
    151     def compile_composite_message(self):

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _send_msg(self, message_wrapper_json_binary, recipient)
   1079         recipient.clientsocket.send(message_wrapper_json_binary)
   1080 
-> 1081         response = self._process_buffer(recipient.clientsocket)
   1082 
   1083         return response

/usr/local/lib/python3.6/dist-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in _process_buffer(socket, buffer_size, delimiter)
   1094                 return line + delimiter
   1095             else:
-> 1096                 more = socket.recv(buffer_size).decode('utf-8')
   1097                 if not more:
   1098                     buffering = False

```

### Steps to Reproduce (for bugs)
The Server code: https://gist.github.com/Kerat/408322d369dc5a21f6cb1a593ba6d658#file-server-py
The Client code: https://gist.github.com/Kerat/408322d369dc5a21f6cb1a593ba6d658#file-client-py
I believe this was fixed.",1,2018-06-25 16:40:16,2018-11-14 16:48:11,2018-11-14 16:48:10
https://github.com/OpenMined/PySyft/issues/1355,[],Ensure notebooks work as part of travis testing,"Ensure notebooks work as part of travis testingJust a possible feature request. I know with my own repos functions often get changed or moved around an the notebooks get out of date, so it would be useful to have them 'tested' (initially just does nbconvert run without errors)
This would be a great feature to have!@kmader are you in the Slack (http://slack.openmined.org/)? What is your handle?",2,2018-06-22 08:03:39,2018-06-22 18:42:04,2018-06-22 18:42:04
https://github.com/OpenMined/PySyft/issues/1350,['bug '],Cannot .send_() Variable objects if .grad != None,"Cannot .send_() Variable objects if .grad != None# Issue Template

## Context

When running the following code,

```
from syft.core.hooks import TorchHook
from syft.core.workers import VirtualWorker
import torch
import torch.nn as nn
from torch.autograd import Variable as Var
import torch.optim as optim
# this is our hook
hook = TorchHook()
local = hook.local_worker
remote = VirtualWorker(id=1,hook=hook)
local.add_worker(remote)

data = Var(torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]))
target = Var(torch.FloatTensor([[0],[0],[1],[1]]))

# model = nn.Linear(2,1)
model = Var(torch.zeros(2,1),requires_grad=True)

# generates grad objects
pred = data.mm(model)
loss = ((pred - target)**2).sum()
loss.backward()

model.send_(remote)
```

## Expected Behavior

I expect that when I call model.send_(remote), that it will send the Variable to the remote VirtualWorker. 

## Current Behavior

It errors out and does not send the variable with the following stacktrace.

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-14-4207de4e45fd> in <module>()
     10 loss.backward()
     11 
---> 12 model.send_(remote)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in send_(self, workers)
    907                                                    owners=self.owners, is_pointer=True)
    908 
--> 909             return hook_self._var_to_pointer(self, hook_self)
    910 
    911         setattr(torch.autograd.variable.Variable, 'send_', send_)

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in _var_to_pointer(self, var, hook_self)
    982         print(""_var_to_pointer:"" + str(var.data.id))
    983         if var.grad is not None:
--> 984             self._var_to_pointer(var.grad, hook_self)
    985 
    986         var.data.old_set_(var.data.__class__(0))

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/hooks.py in _var_to_pointer(self, var, hook_self)
    989                                           id=var.data.id,
    990                                           owners=var.owners,
--> 991                                           is_pointer=True)
    992         return var
    993 

/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers.py in register_object(self, worker, obj, force_attach_to_worker, temporary, **kwargs)
    508             raise RuntimeError(
    509                 'Invalid registry: is_pointer is {} but owners is {} on tensor {}'.format(
--> 510                     obj.is_pointer, obj.owners, obj.id))
    511         # print(""setting object:"" + str(obj.id))
    512         self.set_obj(obj.id, obj, force=force_attach_to_worker, tmp=temporary)

RuntimeError: Invalid registry: is_pointer is True but owners is [0] on tensor 2841986768
```
## Failure Information (for bugs)

Some investigation has indicated that this only happens when attempting to send a variable that has a gradient object attached to it.

### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)

1. Run code above
2. Observe error :)
The troubleshooting for this Issue is at the end of this livestream https://www.twitch.tv/videos/275575625Can close with merged PR!",2,2018-06-20 22:07:17,2018-06-21 19:03:17,2018-06-21 19:03:17
https://github.com/OpenMined/PySyft/issues/1330,[],Caching in Travis build,"Caching in Travis buildCurrently, we're using Travis for CI.  At the moment, it's doing a fresh install of all dependencies.  We should be caching static, bulky dependencies like PyTorch, so as to improve the build time.  More information at this link: https://docs.travis-ci.com/user/caching/#Caching-directories-(Bundler%2C-dependencies)@jvmancuso I think, we are already caching everything.

> Collecting sphinx_rtd_theme (from -r requirements.txt (line 1))
>  ...
>  Using cached 

Our [.travis.yml](https://github.com/OpenMined/PySyft/blob/master/.travis.yml) file reads
```
**cache: pip**
python:
    #- 2.7
    - 3.6
```


Travis CI Logs

> Collecting sphinx_rtd_theme (from -r requirements.txt (line 1))
>   Using cached https://files.pythonhosted.org/packages/87/30/7460f7b77b6e8a080dd3688f750fe5d5666c49358f8941449c5b128fa97d/sphinx_rtd_theme-0.4.1-py2.py3-none-any.whl
> Collecting sphinx (from sphinx_rtd_theme->-r requirements.txt (line 1))
>   Using cached https://files.pythonhosted.org/packages/35/e0/e9e83b244eaa382ba21896dda6172617e47aff0be225eb72782cca105d3c/Sphinx-1.8.1-py2.py3-none-any.whl
> Requirement already satisfied: six>=1.5 in /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages (from sphinx->sphinx_rtd_theme->-r requirements.txt (line 1)) (1.11.0)
> Requirement already satisfied: Pygments>=2.0 in /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages (from sphinx->sphinx_rtd_theme->-r requirements.txt (line 1)) (2.2.0)
> Collecting imagesize (from sphinx->sphinx_rtd_theme->-r requirements.txt (line 1))
>   Using cached https://files.pythonhosted.org/packages/fc/b6/aef66b4c52a6ad6ac18cf6ebc5731ed06d8c9ae4d3b2d9951f261150be67/imagesize-1.1.0-py2.py3-none-any.whl
> Collecting snowballstemmer>=1.1 (from sphinx->sphinx_rtd_theme->-r requirements.txt (line 1))
>   Using cached https://files.pythonhosted.org/packages/d4/6c/8a935e2c7b54a37714656d753e4187ee0631988184ed50c0cf6476858566/snowballstemmer-1.2.1-py2.py3-none-any.whl


ðŸ¤·â€â™‚ï¸ 
I think you're right! Great find Rohan!@iamtrask @jvmancuso could someone close this issue as it seems to be resolved already?",3,2018-06-02 18:21:17,2018-11-14 16:46:47,2018-11-14 16:46:47
https://github.com/OpenMined/PySyft/issues/1314,['bug '],"IntTensor methods sin(), cos() are broken","IntTensor methods sin(), cos() are broken@ChatSam commented on [Wed Jan 31 2018](https://github.com/OpenMined/OpenMined/issues/409)

The IntTensor methods which return objects of type FloatTensor which are sin() and cos() are broken.

<img width=""1105"" alt=""screen shot 2018-01-31 at 12 17 58 am"" src=""https://user-images.githubusercontent.com/6478266/35606314-656cb044-061c-11e8-918a-3d7ea7345cb2.png"">


Claiming this issue #1314. Found a fixPR for the bugfix - https://github.com/OpenMined/PySyft/pull/1315
Added integration tests for the fix -PR -  https://github.com/OpenMined/OpenMined/pull/410",2,2018-01-31 05:29:41,2018-02-16 17:10:13,2018-02-16 17:10:13
https://github.com/OpenMined/PySyft/issues/721,[],Stuck in trying to initialize FloatTensor - zmq TCP issue,"Stuck in trying to initialize FloatTensor - zmq TCP issueHi,
Your library looks really great!
I'm trying to follow the basic notebooks, however when initializing a FloatTensor I get a hang --
`target = FloatTensor(data).autograd(True) # my poor code`
```
# stepping into the initialization code (tensor.py):
self.id = int(self.controller.send_json({""objectType"": ""IntTensor"",
                                                     ""functionCall"": ""create"",
                                                     ""data"": list(data.flatten()),
""shape"": self.data.shape})) # --> stuck in this call
```
and then into controller.py:
```
# send the command
        socket.send_json(
            cmd_func(name, params=params))
        # receive output from command
        res = socket.recv_string() --> stuck in this call
```

I guess this happens because I'm behind a proxy. However I set in /etc/environment NO_PROXY=""localhost, localaddress, 127.0.0.1""
(also tried to post a question on [Stack Overflow](https://stackoverflow.com/questions/47966721/python-zmq-open-tcp-socket-stuck-in-recv-string) - no comment yet :(
Much thanks!

Please delete (for bugs) or (for features) sections that are not relevant to the Issue you are creating.

Please provide any relevant information about your setup. This is important in case the issue is not reproducible except for under certain conditions.

**Test Configuration**:
* CPU: Intel Haswell
* GPU: NVidia Titan-X
* PySyft Version:
* Unity Version:
* OpenMined Unity App Version:


## Expected Behavior

Code works

## Current Behavior

Code stuck in wait (I guess)

## Failure Information (for bugs)

Please help provide information about the failure if this is a bug. If it is not a bug, please remove the rest of this template.

### Steps to Reproduce (for bugs)

Please provide detailed steps for reproducing the issue. (for bugs)

Hi,
Sorry for that. The Unity application wasn't running (failed to import Vuforia) and of course there wasn't TCP server. You can close the issue.",1,2017-12-28 09:21:30,2017-12-28 10:18:17,2017-12-28 10:18:17
https://github.com/OpenMined/PySyft/issues/695,[],Order pysyft,"Order pysyft### User Story
pysyft.py is currently hard to navigate. We should order it!

### Discussion Points
Obvious route is alphabetic, ignoring __ and __i. 
Inline functions after returning functions and __ixxx__ after __xxx__

We could also put the __xxx__ ops first. And make another exception for __init__.

Thoughts?Also, have we decided whether we want to expose the operators as functions as well?
E.g. def __add__ as well as def add@Floev Good points!
Your navigation strategy sounds good to me. I'd categorize functions according to their job first (e.g. `no_params_func` is a different type of job than `_add_` or `_mul_`), and then reorganize lexicographically as you mention. What do you think?

Also, regarding the exposure of those methods, I think we should do it, so that we are still consistent with PyTorch:
<img width=""393"" alt=""screen shot 2017-12-13 at 22 57 59"" src=""https://user-images.githubusercontent.com/4405152/33974964-8a20abea-e059-11e7-98de-44f30e048333.png"">
@floev I'd like this too. In my PR https://github.com/OpenMined/PySyft/pull/701 (closed now), I ordered lexicographical inside semantic sections. Does this make sense? EditedHow do we feel about the current layout? The file was broken into pieces and seems certainly more organized before.",5,2017-12-13 04:44:23,2018-04-07 21:11:36,2018-04-07 21:11:36
https://github.com/OpenMined/PySyft/issues/393,[],Paillier tensor multiplication throws an overflow error later during decryption,"Paillier tensor multiplication throws an overflow error later during decryption#### Description:
Paillier tensor multiplication throws an overflow error later during decryption. This happens when both numbers that have been multiplied have fractions.

#### Steps/Code to Reproduce: 

Example:
```
b = PaillierTensor(pk, np.array([10]))
boo = (b*1).decrypt(sk)  #works

b = PaillierTensor(pk, np.array([10]))
boo = (b*1.1).decrypt(sk)  #works

b = PaillierTensor(pk, np.array([10.1]))
boo = (b*1).decrypt(sk)  #works

b = PaillierTensor(pk, np.array([10.1]))
boo = (b*1.1).decrypt(sk)  #overflow
```

#### Other details:
This happen because of a bug in the fixed-point multiplication method `my__mul__` in `he/paillier/keys.py`

I believe #390 is because of the same reason (?).",1,2017-11-02 19:15:14,2017-11-03 15:53:18,2017-11-03 15:53:18
https://github.com/OpenMined/PySyft/issues/390,[],"Syft Error detected in PySonar tutorial: ""Sonar - Decentralized Model Training Simulation (local)""","Syft Error detected in PySonar tutorial: ""Sonar - Decentralized Model Training Simulation (local)""I am receiving a Decryption Overflow error in Step 3 -> Ln 14 of the tutorial. Even though it's a PySonar tutorial, this is a Syft error. I am having trouble understanding the cause of the error. See below for snapshot.

![image](https://user-images.githubusercontent.com/13172478/32207885-5a6b7c64-bdd5-11e7-95c7-ec16c24afedc.png)
I believe I have pinpointed the issue. Multiplying a Paillier Encrypted array with original elements less than 1, by a scalar less than one, produces the same error. I have reproduced the error by running the following code:

```
pubkey,prikey = KeyPair().generate(n_length=1024)

x = PaillierTensor(pubkey, np.array([ 0.43188777,
        0.93408112,
        0.72565632,
        0.92994132,
        0.63109912,
        0.68034936,
        0.53725333,
        0.89133874,
        0.89126486,
        0.31854688]))

(x*0.1).decrypt(prikey)
```I reproduced the bug on my machine. Can I take this issue?Commenting out this line:
https://github.com/OpenMined/PySyft/blob/489c3f31d0d1a68ad79632d663acd55e9b9f0136/syft/he/paillier/keys.py#L228
makes the problem go away. This issue is the same as #393.this was resolved with #394 (for the time being, but we should work a bit more on this)",4,2017-10-31 04:50:02,2017-11-04 03:12:46,2017-11-04 03:12:46
https://github.com/OpenMined/PySyft/issues/384,['bug '],Capsule Snuck into PySyft Notebooks,"Capsule Snuck into PySyft NotebooksSeveral of the PySyft notebooks are now broken because they rely on a completely separate repository (Which has changed). We need to strip out reliance on Capsule in the following notebooks.

- https://github.com/OpenMined/PySyft/blob/master/notebooks/Syft%20-%20Paillier%20Homographic%20Encrypted%20Linear%20Classification%20example%20.ipynb
- https://github.com/OpenMined/PySyft/blob/master/notebooks/Syft%20-%20Paillier%20Encrypted%20Linear%20Classification.ipynb

Acceptance Criteria:
- Remove Capsule dependencies from these notebooks and get them working
- Move these notebooks to Capsule/notebooks folder and get them working@iamtrask, I'd like to take this up.Excellent @sriranganathan that's great news!@raul-jr3 wants to as well - perhaps you guys can each pick one of those notebooks to work with?@sriranganathan @raul-jr3 has there been any progress regarding this ticket? Is there any help that is still needed?@taylorperkins any help is very much appreciated :)@raul-jr3 awesome!! Working through getting the dependencies installed now. Is there a particular branch you are working off of? If not, I can create one here locally. 
@taylorperkins nope!",7,2017-10-29 15:17:27,2017-11-03 15:53:06,2017-11-03 15:53:06
https://github.com/OpenMined/PySyft/issues/383,[],Implement Default split Functionality for Base Tensor Type.,"Implement Default split Functionality for Base Tensor Type.<!-- Please make sure that you review this: https://github.com/OpenMined/Docs/blob/master/contributing/guidelines.md  -->
<!-- If you are looking to file a bug make sure to look at the .github/BUG_ISSUE_TEMPLATE.md -->


#### User story: 
As a Data Scientist using Syft's Base Tensor type, I want to leverage a default method for computing operations on a Tensor of arbitrary type. For this ticket to be complete `split` should return a new tensor. For a reference on the operation these perform check out [PyTorch's](http://pytorch.org/docs/master/torch.html#torch.split) documentation.

<!-- Provide a detailed explaination about the proposed feature, you can draw inspiration from something like this: 
https://github.com/OpenMined/PySyft/issues/227 or https://github.com/OpenMined/PySyft/issues/12 -->

#### Acceptance Criteria: 

<!-- Provide an outline af all the things that needs to be addressed in order to close this Issue,
be as descriptive as possible -->
  - [x] If the Base Tensor type's attribute ""encrypted"" is set to True, it should return a NotImplemented error.
- [ ] corresponding unit tests demonstrating the correct operation on the Base Tensor type implemented over int and float Tensors.
 - [ ] inline documentation as described over [here](https://github.com/OpenMined/PySyft/blob/85bc68e81a2f4bfc0f0bf6c4252b88d6d7b54004/syft/math.py#L5). 


<!-- Thanks for your contributions! -->
I'll take this!",1,2017-10-29 15:08:17,2017-11-01 09:04:23,2017-11-01 09:04:23
https://github.com/OpenMined/PySyft/issues/382,[],Implement Default cross Functionality for Base Tensor Type.,"Implement Default cross Functionality for Base Tensor Type.<!-- Please make sure that you review this: https://github.com/OpenMined/Docs/blob/master/contributing/guidelines.md  -->
<!-- If you are looking to file a bug make sure to look at the .github/BUG_ISSUE_TEMPLATE.md -->


#### User story: 
As a Data Scientist using Syft's Base Tensor type, I want to leverage a default method for computing operations on a Tensor of arbitrary type. For this ticket to be complete `cross` should return a new tensor. For a reference on the operation these perform check out [PyTorch's](http://pytorch.org/docs/master/torch.html#torch.cross) documentation.

<!-- Provide a detailed explaination about the proposed feature, you can draw inspiration from something like this: 
https://github.com/OpenMined/PySyft/issues/227 or https://github.com/OpenMined/PySyft/issues/12 -->

#### Acceptance Criteria:

<!-- Provide an outline af all the things that needs to be addressed in order to close this Issue,
be as descriptive as possible -->
 - [ ] If the Base Tensor type's attribute ""encrypted"" is set to True, it should return a NotImplemented error.
 - [ ] corresponding unit tests demonstrating the correct operation on the Base Tensor type implemented over int and float Tensors.
 - [ ] inline documentation as described over [here](https://github.com/OpenMined/PySyft/blob/85bc68e81a2f4bfc0f0bf6c4252b88d6d7b54004/syft/math.py#L5). 

<!-- Thanks for your contributions! -->
@bharathgs I'd like to take this one up.can I too work on this?",2,2017-10-29 14:39:56,2017-11-03 07:02:26,2017-11-03 07:02:26
https://github.com/OpenMined/PySyft/issues/353,[],Encryption design,"Encryption designWe need to consider how we want to design the encryption functionality for Syft.

A lot of objects will have TensorBase members or even higher levels of nesting.
For such objects we want to provide ""encrypt"" and ""decrypt"" functionality, calling the corresponding functions on all its TensorBase and TensorBase-containing members.

This can lead to a lot of code duplication and boilerplate which can be avoided.
One idea would to use Mixins. The ""Encryptable"" mixin offers an ""encrypt"" method that iterates over all the members of the object and recursively calls ""encrypt"" on them, all the way down to TensorBase objects which actually get encrypted.

This is just a proposal, overall we should consider how to approach this problem.

We also need to consider, referring to issue #352, if we also want to encrypt the network hyperparameters (some might be obvious by inspecting object shapes)@MarcoROG If I undestood you correctly, this sounds like a great idea. I think we can judge its merits better when we actually start implementing those â€œhigher levelâ€ objects that use Encrypted Tensors. But it looks good from a distance :)
This is inspired by Laravel Php traits. Where you have a Serializable trait/mixin and an attribute containing the list of fields you want that trait to apply to.
I'm fairly new to python (did mostly C++) so I don't know if it's a good pattern for the language",2,2017-10-18 12:55:47,2017-11-22 23:46:30,2017-11-22 23:46:30
https://github.com/OpenMined/PySyft/issues/352,[],Neural Network design,"Neural Network designWe should discuss how the user will build a neural network in Syft and how it will be implemented internally.

Do we want each Layer (Dense, Convolution..) to be its own class containing weights and all the information? (Unlike the linear example we currently have).

Do we want a ""Model"" wrapper containing meta-information?

Overall we should discuss how we want to design this structure and carry out the development.Alright, have been waiting fro this kinda :D! In my opinion, we have to give the user/data scientist a lot of flexibility. They should be able to define their model through a simple step process by:
1. defining the input tensor
2. building the NN's hidden layers, layer after layer
3. defining activation funcs for each seperate layer independently (2+3 can be done by using a layer class for example)
4. creating an own training loop and
5. defining their backpropagation algorithm

Since we have to deal with a wide variety of NNs, I would say we start with classical ANNs and build on top of them.
Also I would consider pytorchs or tensorflows syntax since they are used widely and if we implement a similiar fasion, the learning process for the data scientist wouldn't be that steep.Also consider we have Autograd functionality planned, so that should be taken in consideration as well, the internal implementation must be ""usable"" for that as well.

What you proposed sounds a lot like Keras, am I right?
The idea is to have everything as a layer.
I would not tie layers to have an activation function, as sometimes this is not the case (there are some papers where 2 convolutions without an activation inbetween are used as a form of convolution instead of using a single, bigger filter size)Yes, what I meant was enabling Modifications for each layer (of what kind ever: convolution, activation funcs, pooling, flattening etc.) The best thing in my opinion would be a class NN, that the data scientist can inherit from, which implements GPU support and Encryption on its own and the data scientist has to implement some default methods (e.g. train_cycle() or build()) by himself and can modify the class however he would like to.This could require a lot of coding and most of the times it won't be needed.
I think we should err on the side of ""make the simple case simple and the corner case possible"".
We could provide the possibility to inherit from it but I think that would be an extra.
99% of the usage should be doable just by using the existing class as a client.
Thats what makes keras so easy to use https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py
As a reference : I think 99% of the use cases should be as simple as this Well, I think that this implementation of the Sequential() class could cover our base NN class, but since most model development simply needs more depth and tuning, I would also like to be able to inherit from this class and e.g. write my own activation funcs or convolution filters, so I can exactly fit the model to my problem and my specific needs (im really OOP friendly).
Another solution would be to fit the model to ones needs through using custom created layer classes. But there we would also need a guideline on what the data sc. needs to implement in order for them to work.

In general, I think that a simple class with base functionality is not avoidable. How we implement use case specifics and custom development we'll have to discuss, because there are a wide variety of options to consider.I would opt for custom layer classes if you Wang customization.
We could also look at pytorch implementation, which is less lego-like and more similar to what you saidYea, that's also what Im using for my models >:D, at the end it comes down to preference.
Lets get some other opinions in here :DI think since syft is inspired by PyTorch, that we should kind of mimic that interface, having enough abstractions but not that much magic behind it.Different levels of abstraction are available through PyTorch's API. That is basic/low-level functions are implemented in the `torch.nn.functional` module.  At a higher level, `torch.nn` layers make use of the methods in the `torch.nn.functional` module and inherit from `torch.nn.Module`. And at a yet higher level, you can use different containers(which also inherit from `torch.nn.Module`) to stack and wrap your `torch.nn` layers. Or you can define your own container and layers by inheriting from `torch.nn.Module`
I haven't used Keras, but looks very similar to Keras, and also grant everyones wishes, no?1. I totally agree with @siarez and @cosmadrian we should stick with pytorch-esque design. 
(Ref: [`torch.nn`](http://pytorch.org/docs/master/nn.html#) & [`torch.nn.functional`](http://pytorch.org/docs/master/nn.html#torch-nn-functional)) 
2. However, If users want something more keras-esque they can always have something similar to [aorun](https://github.com/ramon-oliveira/aorun) on top of pysyft. But we should focus on the prior.Totally agree with my three pre-commentators! Implement the Basic stuff first and then we can write a wrapper around it on top!",13,2017-10-18 12:49:48,2017-11-04 02:51:31,2017-11-04 02:51:31
https://github.com/OpenMined/PySyft/issues/350,[],Organize class methods and functions ,"Organize class methods and functions Currently there is no order of how methods appear, for example, within the TensorBase class and in math.py. There is no strict convention for organizing methods and functions but a general pattern to follow would be: 

<pre>
class SomeClass(object):
    def __magic_methods__(self):
        ""magic methods first, usually in alphabetical order""
    def _private_method(self):
        ""worker methods next, also in alphabetical order""
    def a_method(self):
        ""then normal methods, also in alphabetical order""`
Totally agree with you there! And I will implement this for my Code as well.

I also see a problem with class organization and how they interact with each other, because often the docs aren't sufficient explaining code interactions. I suggest a small diagram or a flow chart to get ppl to get our code faster and of course also easier!I've gone through all the current code and organized it in PR #351, and it might be a good thing to add also to the style guidelines for the project so we can try to stay consistent throughout.  Also totally agree with you, there should be a relatively easy to understand logic behind the class organization. We use draw.io quite frequently at my work for such things, so this could be a good tool for such a task.Sounds like a good idea, Im getting to it on my code!",3,2017-10-18 09:44:18,2017-10-28 12:02:09,2017-10-28 12:02:09
https://github.com/OpenMined/PySyft/issues/349,[],Error in tutorial notebook ,"Error in tutorial notebook  
![screenshot from 2017-10-18 01-23-35](https://user-images.githubusercontent.com/3435944/31707696-acd01606-b40a-11e7-832f-d4cc9c5d40c0.png)

1> I could not understand how to pass the ""pubkey"" variable though the function don't take any variable in the implementation 

![screenshot from 2017-10-18 13-49-42](https://user-images.githubusercontent.com/3435944/31707938-4f6a6100-b40b-11e7-97df-24cc9085997c.png)
2>I think  in ModelRepository() call  ipfs=IPFS(host='ipfs')  as previous tutorial This looks related to https://github.com/OpenMined/PySyft/pull/332. I was seeing the same thing, and noticed that there is inconsistency in the way that `encrypt()` was being used across examples in notebooks. I'm not sure exactly what the intended behavior is though, so maybe this needs to be reviewed. 

I think issue raised here is resolved and merged in #332. This issue can be closed.",2,2017-10-18 08:22:08,2017-10-25 11:35:40,2017-10-25 11:35:40
https://github.com/OpenMined/PySyft/issues/348,[],Capsule zmq_client module error when running tests,"Capsule zmq_client module error when running testsIâ€™ve installed capsule  within my openmined virtualenv and started an instance using `sh build_and_run.sh` as indicated but am still getting the ModuleNotFoundError: No module named â€˜capsule.zmq_clientâ€™.  Maybe a dumb question but is it not possible to mock the client behavior in the tests so you donâ€™t need to have a client running in order to be able to run tests?can you do a `pip freeze` in your env, and see if it has been really installed?
I just tested reinstalling capsule on my machine and  I could not reproduce your error.I got the same error. If your system has python 3 and python 2 both installed. Then go to build_and_run.sh and change all *python* instances there to *python3*. It worked for me@bharathgs checked with pip freeze and have it installed. @piyush2896, ok so when I do as you said, it indeed runs the test however now in the termainal window where I have the capsule instance running it just is dumping 'Operation cannot be accomplished in current state'  repeatedly, did you happen to see this as well?@tblazina got the same issue checked right now Nevermind, I did not have an instance of redis running.
Thanks a lot for the help!

Back to my other question though, is there no way to mock this for testing purposes? It seems a bit cumbersome to have three terminals running simply to run tests during development, no?",5,2017-10-18 08:01:19,2017-10-26 03:58:31,2017-10-26 03:58:31
https://github.com/OpenMined/PySyft/issues/298,[],`conda update -q conda` in Travis configuration asks for user input,"`conda update -q conda` in Travis configuration asks for user input[My built](https://travis-ci.org/OpenMined/PySyft/jobs/284442734) stalled after `conda update -q conda` asked for user input during CI build. 
I think in [our travis configuration](https://github.com/OpenMined/PySyft/blob/master/.travis.yml), we need to change:
`conda update -q conda`
to:
`conda update -q -y conda`

https://conda.io/docs/commands/conda-update.html

@meetvora I think that line was added with your [commit](https://github.com/OpenMined/PySyft/commit/67158f2af403a44270ca714647f45c4d14da151c).I might have missed out on that part. 
Thanks @siarez for fixing it.",1,2017-10-06 23:18:07,2017-10-07 09:32:06,2017-10-07 02:12:00
https://github.com/OpenMined/PySyft/issues/283,[],TensorBase inherit from torch.Tensor,"TensorBase inherit from torch.TensorUser Story A: As a user of PySyft, I want the ability to use PyTorch's autograd on Syft tensors. Specifically, I want the ability to create a tensor ""x"" and then wrap it in a torch.autograd.Variable() object like so (torch.autograd.Variable(x)). As such, TensorBase needs to inherit from torch.Tensor. 

Acceptance Criteria:
- TensorBase inherits from torch.Tensor
- torch.autograd.Variable(a_tensorbase_tensor) works
- demonstrate .backprop() method working on a Variable object.
- notebook demo of a simple 3 layer neural network (with a nonlinearity) working using TensorBase and Variable based backprop.

I would like to take this up@iamtrask i checked this , it seems the Variable does a type check and not an instance check on the object passed to it. So it expects a tensor object as type. If we inherit from torch.Tensor even so the autograd.Variable would be throwing runtime error on passing our TensorBase. I was thinking maybe if we could return a torch tensor using an inbuilt function of our tensorbase like Tensor.numpy() does. Why not use a converter function, that way you can abstract from the TensorBase, so it does not need to know about pytorch, or any other Tensor based library that might come from future compatibility ?

```
def convert_to_torch_tensor(base):
     return # torch.Tensor instance built using base properties
```might want to check this up 
https://gist.github.com/radicalrafi/f2cd121143f6a3967a0d24159b1e09ec

@iamtrask @siarez 
https://github.com/aradhyamathur/PySyft/commit/1c30dc078a5fabe28ad35c4d21f46a352c6d971f could look at this once if this could be the way to go or should look into something else
 your ideas are good guys but remember main focus is encrypted operations from the PoC I showed we can get something going using a conversion as long as the data types are supported by PyTorch because Variable only support the standard types so a Paillier encrypted set won't actually work .yeah exactly i too did a similar implementation in above",7,2017-10-03 11:13:22,2017-11-22 23:47:02,2017-11-22 23:47:02
https://github.com/OpenMined/PySyft/issues/274,[],Convert dense matrix to sparse matrix,"Convert dense matrix to sparse matrixThis would speed up my matrix multiplies.can you write down a use case just like @iamtrask does? that would help others understand the issue better.@Ujjwal-9 
By Conversion you mean.
**Converting**:
```
A =
    0     0   11
    22    0    0
    0    33    0
```

**to something like**
```
S =
    (1,0)   22
    (2,1)   33
    (0,2)   11
```

Am I right here?That looks right to me!@iamtrask so what do you suggest?
I think making a new class inheriting from tensorbase and having functionalities like matmul and others.

As in the current scenarios  all the functionalities are present in math.py and the only possibility that I see is either make changes in the code of math.py or make a separate class with separate functionalities.I think that's the right thing to do. This also sounds very similar to PyTorch's sparse tensor implementation as well.we can do this with [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse) and for the above specific format you can check [`scipy.sparse.csr_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) so including this as a function in the *math.py* would probably be sufficient. Also, you might be interested in [this](https://github.com/pytorch/pytorch/issues/2885) and [this](https://discuss.pytorch.org/t/how-to-convert-a-dense-matrix-to-a-sparse-one/7809) @piyush2896 @Ujjwal-9 @bharathgs the second [link](https://discuss.pytorch.org/t/how-to-convert-a-dense-matrix-to-a-sparse-one/7809) you sent displays a limitation that -> The user needs to find the non zero indices to send and make sparse matrix..


```
dense = torch.randn(3,3)
dense[[0,0,1], [1,2,0]] = 0 # make sparse
indices = torch.nonzero(dense).t()
values = dense[indices[0], indices[1]] # modify this based on dimensionality
torch.sparse.FloatTensor(indices, values, dense.size())
```


I think it is redundant. What do you say?
I mean can't just the class (in the above case FloatTensor) getting the values modify the data to a sparse representation directly?@piyush2896 as you must have seen from the first link, pytorch does not let you do this directly(yet), so you have to do something as shown in that example. I think this is a nice feature to have natively, and we could probably put it in _math.py_ .Hey guys, I'd like to join in and help if necessary.Has anyone taken the lead on this? I'd like to help too.I don't get the impression anyone has claimed the leading role for this issue. @fmhall or @ivuckovic if you're interested go ahead and open up a branch (and drop the link here so we can all see it)I created branch on my fork https://github.com/ivuckovic/PySyft/tree/dense_to_sparse_matrix but haven't had time to do any changes, hopefully I'll start in next couple of days.yeh i was also looking forward to do it. But I've been very busy lately. 
Now i am free & would love to do it.ðŸ˜„I'm having problems with tests.
I'm trying to assert.Equal two numpy arrays that should be equal. They are both array(<2x2 sparse matrix of type '<class 'numpy.int64'>' with 1 stored elements in Compressed Sparse Row format>, dtype=object).
When I run test I get following error:
""E       AssertionError: array[60 chars]stored elements in Compressed Sparse Row format>, dtype=object) != array[60 chars]stored elements in Compressed Sparse Row format>, dtype=object)""

Any ides or suggestions how to solve this?",14,2017-10-01 14:27:51,2017-11-04 02:46:09,2017-11-04 02:46:09
https://github.com/OpenMined/PySyft/issues/258,[],Well-defined Docker images and Make targets,"Well-defined Docker images and Make targetsAt present, there is a bit of confusion between the Docker image and the Makefile. In short: 
- the regular `Dockerfile` installs dev dependencies
- the `Development-Dockerfile` installs all that the regular does (note: the install commands are duplicated, we are not using the FROM command), plus Jupyter
- the `run` target in the Makefile relies on the openmined/pysyft image from DockerHub, but once the container is up, it tries to start a notebook server and fails
- the `custom` target does the exact same things as the `run`, with the difference that it accepts an image as a parameter, so that one can build his own dev image based on `Development-Dockerfile` (with Jupyter) and make it work

From my point of view (close-to-zero experience with this kind of deployments), we should have two images on DockerHub:
- **openmined/pysyft** that ships without dev dependencies (e.g. no gmp-dev and mpfr-dev) and with a working installation of PySyft, based either on a PyPi package or simply installed via `git checkout tags/working-release && python3 setup.py install` (this is to develop some application _with_ PySyft)
- **openmined/pysyft-dev** that has all the additional dependencies and uses the `src` folder as source for the PySyft modules (this is to develop PySyft itself)

Regarding the Makefile, I suggest keeping the test and install targets docker agnostic, meaning that if they are run on the local machine they use what's available locally and if they are used inside the container they use the container:
```
install: 
    python3 setup.py install

test: 
   pytest && pytest --flake8

image = openmined/pysyft
docker: 
    docker run --it $(image) ...

image-dev = openmined/pysyft-dev
docker-dev: 
    docker run --it $(image-dev) ... jupyter notebook
```

Examples:
- run tests locally: `make install && make test`
- run tests in docker `make docker-dev make test`
- build a different image and use it with docker: `docker build -f MyDockerfile -t MyImage && make docker image=MyImage`

Provided that this structure will need refinement and additional details, does it make sense in general? 
Can someone with experience suggest improvements?Thanks for explaining the problem so clearly. I agree with most of your recommendations, one nit is to have simpler commands than `make docker-dev make test` which is confusing. We can follow different terminology like we do in https://github.com/OpenMined/PyYashe/blob/master/Makefile or we can use a Makefile rule such as:

(untested)
```makefile
docker_%:
  docker run -i -t openmined/pyyashe make $(shell echo $@ | sed s/^docker_//) $(MAKEFLAGS)""
```

So that `make docker_test` becomes `make test` inside the Docker environment.
Or we could just use docker-compose to create the image? 

Basically what you want are two images:

#1 - dev - having:  RUN [""pip3"", ""install"", ""jupyter""] in the dockerfile which gets started with: docker run --rm -it -v $(PWD)/notebooks:/notebooks -w /notebooks -p 8888:8888 openmined/pysyft jupyter notebook --ip=0.0.0.0 --allow-root

and

#2 without jupyter which should be started with: docker run --rm -it -v $(PWD)/notebooks:/notebooks -w /notebooks -p 8888:8888 openmined/pysyft notebook --ip=0.0.0.0 --allow-root
I assume.

By defining differences in the docker-compose.yml and passing the parameters during build it might be easier.
Hi, thanks for suggesting Docker Compose. 

I have no experience with it so I'm not able to evaluate it. In case we only want to launch one container, what are the benefits of doing it with docker-compose instead of just running `docker run`?

Btw, in the second of your examples there still is `notebook --ip=0.0.0.0 --allow-root`, which is the list of parameters that you'd pass to the command `jupyter`. I think that the simplest command to run when not in `dev` mode is a bash shell. 

I've opened a PR yesterday, please check out #270 and tell me what you think ;)Most likely it would work without Compose as well but I would definitely use an entrypoint script to parse ENV variables.

I'll try to finish my implementation today basically it would allow all  beginners to build the image via:
**docker-compose build** << for an image without Jupyter
or
**docker-compose build --build-arg INST_JUPYTER=true** << for an image without Jupyter

To start the container all users would only have to execute:
**docker-compose up**

It's not finished yet but let's see how it turns out. My main goal it to get rid of two ""Dockerfiles"" to keep it clean.Okay it seems I got a little confused. Is there a reason why the Dockerfile doesn't have the RUN [""pip3"", ""install"", ""jupyter""] included? After looking a little deeper into the matter is seems it should be included in there as well since it is always used?.. This also explains why I was chasing an error in my code which is also in the current code:

docker: Error response from daemon: oci runtime error: container_linux.go:265: starting container process caused ""exec: \""jupyter\"": executable file not found in $PATH"".
make: *** [run] Error 127

So having that in mind I completely agree with your commits for:
_Development-Dockerfile_ --> no comments, referring to the base image makes sense

_Dockerfile_ --> Thanks for the better formatting ;) but I think Jupyter needs to be included there as well if you want to call it in the Makefile, right?Well, yes and no, I agree that now all the development is probably done through Jupyter and for this reason it's good to have an image with everything pre-installed. On the other hand, in the future, people will want to have a ""production"" version of PySyft that only contains the dependencies to make it run. 

In other words, the dev image with Jupyter, Scipy and all the rest is for people who want to develop PySyft itself, the base image is for people that want to develop *with* PySyft.

Imagine (for absurd) that you want to deploy a container with numpy to make matrix computation available through a rest api, wouldn't it be weird to have Jupyter installed too?

That's why I kept the two Dockerfiles separated (I think Scipy should also be moved to the dev version) and the Docker target in the makefile simply opens a shell, from which one can easily invoke `make notebook` if that's his goal. @baldassarreFe you've got a point there, indeed. Just in general I'd think it is a better idea to go down to one Dockerfile to keep everything clean because as you said ""... the Docker target in the makefile simply opens a shell, from which one can easily invoke make notebook if that's his goal.""

But for now I'd suggest that your pull request is committed because it is way better than what is in place now (basically a not working docker implementation).Closed with #270, please check if everything works as expected",8,2017-09-28 09:30:05,2017-10-08 17:54:12,2017-10-08 17:54:12
https://github.com/OpenMined/PySyft/issues/244,[],Input values,"Input valuesThe input data only works for values between 0 and 1, when I input values like 1.4 or greater than 1, I see error. Checked tensorbase library but could not debug @gautam1858 can you provide a code to replicate your error?",1,2017-09-21 13:13:47,2017-10-09 12:28:25,2017-10-09 12:28:25
https://github.com/OpenMined/PySyft/issues/243,[],PySift import issue,"PySift import issueI have installed PySift following the installation guidelines.
After downloading the repository I ran `sudo pip3 install -r requirements.txt` and `sudo python3 setup.py install`

Now, when I run the example (Paillier HE) I get this:
```
ImportError                               Traceback (most recent call last)
<ipython-input-5-a23a6dd7c309> in <module>()
----> 1 from syft.he.paillier import KeyPair, PaillierTensor
      2 from syft import TensorBase
      3 import numpy as np

ImportError: No module named syft

```

Whereas, if I run python3 from my terminal and execute `from syft import TensorBase` I get:
```
  File ""<stdin>"", line 1, in <module>
  File ""<frozen importlib._bootstrap>"", line 2237, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 2226, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1191, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1161, in _load_backward_compatible
  File ""/usr/local/lib/python3.4/dist-packages/syft-0.1.0-py3.4.egg/syft/__init__.py"", line 1, in <module>
  File ""<frozen importlib._bootstrap>"", line 2237, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 2226, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1191, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1161, in _load_backward_compatible
  File ""/usr/local/lib/python3.4/dist-packages/syft-0.1.0-py3.4.egg/syft/he/__init__.py"", line 1, in <module>
  File ""<frozen importlib._bootstrap>"", line 2237, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 2226, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1191, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1161, in _load_backward_compatible
  File ""/usr/local/lib/python3.4/dist-packages/syft-0.1.0-py3.4.egg/syft/he/paillier/__init__.py"", line 1, in <module>
  File ""<frozen importlib._bootstrap>"", line 2237, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 2226, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1191, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 1161, in _load_backward_compatible
  File ""/usr/local/lib/python3.4/dist-packages/syft-0.1.0-py3.4.egg/syft/he/paillier/basic.py"", line 3, in <module>
  File ""<frozen importlib._bootstrap>"", line 2237, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 2222, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 2164, in _find_spec
  File ""<frozen importlib._bootstrap>"", line 1940, in find_spec
  File ""<frozen importlib._bootstrap>"", line 1916, in _get_spec
  File ""<frozen importlib._bootstrap>"", line 1897, in _legacy_get_spec
  File ""<frozen importlib._bootstrap>"", line 863, in spec_from_loader
  File ""<frozen importlib._bootstrap>"", line 904, in spec_from_file_location
  File ""/usr/local/lib/python3.4/dist-packages/syft-0.1.0-py3.4.egg/syft/tensor.py"", line 1089
SyntaxError: can use starred expression only as assignment target
```does it work if you don't use sudo?It won't let me run the python:
running install
error: can't create or remove files in install directory

```
The following error occurred while trying to add or remove files in the
installation directory:

    [Errno 13] Permission denied: '/usr/local/lib/python3.4/dist-packages/test-easy-install-11054.write-test'

```Running pip3 freeze I can see syft is installedOk, setting PYTHONPATH environment variable tells jupyter to use python3 and fixes the first issueSolved by upgrading to Python 3.5+1
On Thu, Sep 21, 2017 at 10:11 PM, Marco Bellan <notifications@github.com>
wrote:

> Solved by upgrading to Python 3.5
>
> â€”
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/243#issuecomment-331283062>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEIMkomTkARLbX7vRkCi7YwjyU0P-C3eks5sktDogaJpZM4PfP8p>
> .
>",6,2017-09-21 12:33:50,2017-09-21 22:17:07,2017-09-21 21:11:03
https://github.com/OpenMined/PySyft/issues/241,[],Close the issues that have been already implemented and merged,"Close the issues that have been already implemented and merged@iamtrask sir there are still many issues opened which have been solved and merged. This is thus causing a problem in finding non-implemented issues to fix.@sajalsubodh22 Can you let me which issues you are talking about? I'll check them out. Sorry about that @sajalsubodh22 !dammit... keep accidentally hitting ""Close and comment""... ironic... since this ticket is about my reluctance to close the right IssuesI don't know if this has been talked outside GH but these are some currently implemented-but-not-closed issues:

* Abs (#20) fixed by #124
* Cumsum (#35) fixed by #136 
* Equal (#40) fixed by #126 
* View (#108) fixed by #193 
* Rsqrt (#90) fixed by #179

ping: @iamtrask & @siarez Right now we are discussing whether we want to conform to PyTorch's conventions. And if not, come up with conventions of our own. In either case some of these functions will most likely have to be moved around. 
Maybe we can defer closing them untill then, or we can close them now and open another issue which addresses the convention issue.Closed. We should address the convention thoughts under the new ticket.
That way we keep the conversation focused in one spot (easier to follow)

On Wed, Sep 27, 2017 at 7:06 PM, Sia Rezaei <notifications@github.com>
wrote:

> Right now we are discussing whether we want to conform to PyTorch's
> conventions. And if not come up with conventions of our own. In either case
> some of these functions will most likely have to be moved around.
> Maybe we can defer closing them untill then, or we can close them now open
> another issue which addresses the convention issue.
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/241#issuecomment-332607454>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEIMkpalrFb4djHXk_EdNheInb9juaYEks5smo6ugaJpZM4PeKqa>
> .
>",6,2017-09-20 16:49:47,2017-10-04 02:39:06,2017-10-04 02:39:06
https://github.com/OpenMined/PySyft/issues/230,[],Aono Tensor Demo,"Aono Tensor Demo# Helium : Aono Tensor Demo

<b>Background:</b> One of the most valuable contributions of the PySyft library to the Cryptography and AI communities is our Tensor level abstractions of Homomorphic Encryption algorithms. This allows users with no knowledge of Encryption to perform Encrypted Linear Algebra using a wide variety of encryption techniques. In this (and similar) tickets, we want to extend this ability to new Homomorphic Encryption schemes, such that users with no knowledge of Encryption can empirically try out various backend encryption techniques for their front end use cases with minimal effort. As such, while the backend API will differ from Tensor to Tensor, we want the front-end Linear Algebra interface to be as similar as possible, and to give intuitive explanations if the API differs such that calling functions in an Encrypted Tensor that doesn't support those operations explains WHY that specific type of Encryption cannot support the operation (i.e., Paillier can't multiply two encrypted numbers together... perhaps you should try another backend Encryption scheme).

### Part 1: User Stories

* <b>User Story A:</b> As a <b>Linear Algebra</b> user, but NOT a Cryptography expert, I want the ability to perform linear algebra on Homomorphically Encrypted data using the Aono Homomorphic Encryption scheme. If operations are unsupported as a result of the limitations of Aono, I want Error messages to explain so and recommend alternate options. Furthermore, if operations must be approximated using operations such as Taylor Series (or other Polynomial Approximations), I want the option to turn these approximations on or off, with the default functionality to be ON. If I perform an operation for which approximation is necessary (non-linear), and have the ""allow_approximations"" feature turned off, it should return an error.

* <b>User Story B:</b> As a <b>Linear Algebra</b> user, but NOT a Cryptography expert who has implemented an algorithm in one of PySyft's other Encrypted Tensor libraries, I want the ability to simply change out the tensor type and be able to run all the same operations in this tensor library, with good error messages explaining why functions may not be supported (when relevant).

### Part 2: Mockup

[This Notebook](https://github.com/OpenMined/PySyft/blob/master/notebooks/Syft%20-%20Paillier%20Homomorphic%20Encryption%20Example.ipynb) is an excellent mockup of the functionality that we want to see with this new encrypted tensor class. It should be able to do all the operations in this notebook, with the added functionality of multiplication between two encrypted tensors (since that is explicitly supported by Aono).

### Part 3: Acceptance Criteria
- a basic AonoTensor class mirroring the interface of syft.he.paillier.basic.PaillierTensor class, extending the TensorBase class.
- for encryption, it should use the OpenMined/PyAono library.
- the basic operations also listed in PaillierTensor should be included.
- unit tests should exist for all operations
- a notebook should exist demonstrating the same functionality as this one 
https://github.com/OpenMined/PySyft/blob/master/notebooks/Syft%20-%20Paillier%20Homomorphic%20Encryption%20Example.ipynb
I'd like to take this issue.I would also like to collaborate on this issue .@ivuckovic @vasu-dev  any updates on this?@bharathgs unfortunately not yet. I'm getting some errors when importing Aono into jupyter notebook so I'm working on resolving them.Just a quick note... it seems that I had problems with Pari library because I tried to install it from the source from [http://pari.math.u-bordeaux.fr/](http://pari.math.u-bordeaux.fr/) on a Ubuntu and that didn't work. There is a lot easier way, using Ubuntu package libpari-dev.
Now I'll focus on closing this issue.",5,2017-09-10 19:18:09,2017-11-22 23:47:38,2017-11-22 23:47:38
https://github.com/OpenMined/PySyft/issues/195,[],TypeError in Paillier Homomorphic Encryption Example,"TypeError in Paillier Homomorphic Encryption ExampleLine 3: `x = pubkey.encrypt(np.array([1.0,2.0,3.0,4.0,5.0]))` throws this error.
I'm not sure if it is an issue with the phe package or PySyft, but I thought I should report it here.

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-f3a92114a210> in <module>()
----> 1 x = pubkey.encrypt(np.array([1.,2.,3.,4.,5.]))

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/keys.py in encrypt(self, x, same_type)
     63                 return np.array(out).reshape(sh)
     64             else:
---> 65                 return PaillierTensor(self, np.array(out).reshape(sh))
     66         else:
     67             print(""format not recognized"")

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/basic.py in __init__(self, public_key, data, input_is_decrypted)
     10         self.public_key = public_key
     11         if(type(data) == np.ndarray and input_is_decrypted):
---> 12             self.data = public_key.encrypt(data, True)
     13         else:
     14             self.data = data

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/keys.py in encrypt(self, x, same_type)
     59             out = list()
     60             for v in x_:
---> 61                 out.append(Float(self, v))
     62             if(same_type):
     63                 return np.array(out).reshape(sh)

/Users/siavash/anaconda/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/he/paillier/basic.py in __init__(self, public_key, data)
     59         self.public_key = public_key
     60         if(data is not None):
---> 61             self.data = self.public_key.pk.encrypt(data)
     62         else:
     63             self.data = None

/Users/siavash/anaconda/lib/python3.6/site-packages/phe/paillier.py in encrypt(self, value, precision, r_value)
    169             encoding = value
    170         else:
--> 171             encoding = EncodedNumber.encode(self, value, precision)
    172 
    173         return self.encrypt_encoded(encoding, r_value)

/Users/siavash/anaconda/lib/python3.6/site-packages/phe/paillier.py in encode(cls, public_key, scalar, precision, max_exponent)
    602             else:
    603                 raise TypeError(""Don't know the precision of type %s.""
--> 604                                 % type(scalar))
    605         else:
    606             prec_exponent = math.floor(math.log(precision, cls.BASE))

TypeError: Don't know the precision of type <class 'syft.he.paillier.basic.Float'>.
```The demo notebook needs to change to use PaillierTensor instead (instead of using the public key directly on a numpy array). [PR #213](https://github.com/OpenMined/PySyft/pull/213) resolved this issue.",2,2017-08-31 00:46:38,2017-09-05 18:48:54,2017-09-05 18:48:54
https://github.com/OpenMined/PySyft/issues/194,[],Import error in â€œPaillier Homomorphic Encryption Exampleâ€,"Import error in â€œPaillier Homomorphic Encryption Exampleâ€The very first line in the file notebook is
`from syft.he.Paillier import KeyPair`
I get an import error. Changing â€œPaillierâ€ to â€œpaillierâ€ solved the problem. 
Python import has some quirks around case sensitivity on OSX which should be considered. In general â€œModules should have short, all-lowercase names. ... â€
https://www.python.org/dev/peps/pep-0008/#package-and-module-namesCan this be my first PR to get my feet wet? certainly! however, i may have accidentally just pushed the fix from syft.he.paillier import KeyPair

my error is No module named 'syft.he'.
how to solve these error?",3,2017-08-31 00:03:10,2019-04-16 05:35:35,2017-09-01 22:51:14
https://github.com/OpenMined/PySyft/issues/192,[],make test error,"make test errorwuweilindeMacBook-Pro:~ Rand$ cd pysyft
wuweilindeMacBook-Pro:pysyft Rand$ make test
pytest
make: pytest: No such file or directory
make: *** [test] Error 1


this seems to work ok for me... can you confirm it still doesnt work for you (on master)? 

Also, does running ""pip install -r requirements.txt"" help?pip install -r requirements.txt works fine.cd pysyft
is that below normal?
wuweilindeMacBook-Pro:pysyft Rand$ make run
docker run --rm -it -v /Users/Rand/pysyft/notebooks:/notebooks -w /notebooks -p 8888:8888 openmined/pysyft jupyter notebook --ip=0.0.0.0 --allow-root
[I 21:20:35.654 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
[I 21:20:35.703 NotebookApp] Serving notebooks from local directory: /notebooks
[I 21:20:35.703 NotebookApp] 0 active kernels 
[I 21:20:35.703 NotebookApp] The Jupyter Notebook is running at: http://0.0.0.0:8888/?token=2d5354b98f57aa22745080e7dd63c7fa6da59bcef526d4d6
[I 21:20:35.704 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 21:20:35.705 NotebookApp] No web browser found: could not locate runnable browser.
[C 21:20:35.705 NotebookApp] 
    
    Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://0.0.0.0:8888/?token=2d5354b98f57aa22745080e7dd63c7fa6da59bcef526d4d6
do you have a browser installed?yes,of course(just checking... you could have been running it on AWS or some other headless node)no,I just turned  docker on.btw,what is headless node?a headless node is one without a monitor... like when you rent a server on Amazon EC2 :)ah... pytest is a local dependencyyou can install it conda install -c anaconda pytest or with pip: pip install pytesti'll add it to requirements.txt and close this out.",11,2017-08-28 20:30:50,2017-09-12 16:36:20,2017-09-12 16:36:19
https://github.com/OpenMined/PySyft/issues/186,[],Update make run command,"Update make run commandFollowing PR #175 The Docker image is updated without jupyter dependency, but make run has not been updated yet, thus people who run Usage:Start: `make run` will encounter something like this:
```
docker: Error response from daemon: oci runtime error: container_linux.go:262: starting container process caused ""exec: \""jupyter\"": executable file not found in $PATH"".
make: *** [run] Error 127
```
Hey, 

I created a Dockerfile to development local. And a command : 
`make custom  docker=""nameofcontainer"" `

More details in this [Pull Request](https://github.com/OpenMined/PySyft/pull/236)Closed with #270, please check if it works as expected",3,2017-08-24 20:42:40,2017-10-08 17:49:53,2017-10-08 17:49:22
https://github.com/OpenMined/PySyft/issues/159,['bug '],serializing with pickle,"serializing with picklePickle is very powerful, and therefore very dangerous. I would strongly suggest not serializing anything remotely related to crypto with it. 

Here is a quick proof of concept to steal a secret being encrypted by altering the public key before serialization. This using the (slightly tweaked) classes from [Paillier.py](https://github.com/OpenMined/PySyft/blob/develop/syft/he/Paillier.py), full code as a [gist](https://gist.github.com/hardbyte/62181849139d22ec0e2c4d9565876d08):

```python
keypair = KeyPair()
keypair.generate()

class DeviousPhePublicKey(paillier.PaillierPublicKey):

    def encrypt(self, x):
        print(""Sending the secret {} to my webserver..."".format(x))
        return super().encrypt(x)

pk_devious = DeviousPhePublicKey(keypair.public_key.pk.n)
pk_syft = PublicKey(pk_devious)

# So far nothing scary... now we serialize and send
# our public key to someone else though...

pk_s = pk_syft.serialize()
pk_reconstructed = PublicKey(pickle.loads(pk_s))
cipher_remote = pk_reconstructed.encrypt(42)

```
Output (assumed to be on a remote machine):
> Sending the secret 42 to my webserver...

Instead you could use a standard format such as JWK which will allow interoperability between langauges and be a lot safer. 

Also have you seen our [paillier keys](http://python-paillier.readthedocs.io/en/stable/serialisation.html#jwk-serialisation) jwk serialisation docs?@iamtrask I am interested in working on this. How do I start?@souravsingh great choice! This is very important functionality!

1) Look for where ""pickle"" is being used anywhere in the project (usually in a method called ""serialize"")
2) at each place, serialize using a better datastructure of your choosing (perhaps a string?)
3) implement the corresponding deserialization function to go with your new serialization  function
4) write unit tests for each!!!
5) Party with beer and pizza!!! (mandatory)

@hardbyte care to add any color re:security and performance?I'd recommend reading the spec that defines JSON Web Keys: [RFC 7517](https://tools.ietf.org/html/rfc7517#section-4)If this is still available, I would like to give it a go.",4,2017-08-19 02:00:04,2017-11-22 23:48:09,2017-11-22 23:48:09
https://github.com/OpenMined/PySyft/issues/158,[],Adapt to README template,"Adapt to README templateUpdate the `README` to follow the new [README template](https://github.com/OpenMined/Docs/blob/develop/contributing/readme_template.md)

Currently missing
* Usage
* License
* TOCThis applies to all repositories or only PySyft?There's a similar issue for each repository. They should each be 5 minute fixes though :)Issue can be closed after @lucaslopesf commit - https://github.com/OpenMined/PySyft/commit/065a3a2e59ca3ece6acbbea3407cc3ef19584abf ?",3,2017-08-19 00:17:19,2017-08-31 20:19:03,2017-08-31 20:19:03
https://github.com/OpenMined/PySyft/issues/142,['bug '],addmm tests failing,"addmm tests failingAs of bb1e78015a51de36f58ce5beb74b8f0c120aa131 :

```
$ pytest
===================================================================== test session starts =====================================================================
platform darwin -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0
rootdir: /Users/swaroop/personal/openmined/PySyft, inifile:
collected 33 items                                                                                                                                             

tests/test_math.py .......
tests/test_tensor.py ......................FFFF

========================================================================== FAILURES ===========================================================================
______________________________________________________________________ addmm.testaddmm1d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm1d>

    def testaddmm1d(self):
        t1=TensorBase(np.array([1,2,3]))
        t2=TensorBase(np.array([2,3,4]))
        mat=TensorBase(np.array([5]))
        out=t1.addmm(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(out.data,[50]))
E       AssertionError: False is not true

tests/test_tensor.py:127: AssertionError
______________________________________________________________________ addmm.testaddmm2d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm2d>

    def testaddmm2d(self):
        t1=TensorBase(np.array([[1,2],[1,2]]))
        t2=TensorBase(np.array([[1,2],[1,2]]))
        mat=TensorBase(np.array([[2,3],[3,4]]))
        out=t1.addmm(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(out.data,[[10,18],[12,20]]))
E       AssertionError: False is not true

tests/test_tensor.py:134: AssertionError
_____________________________________________________________________ addmm.testaddmm_1d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm_1d>

    def testaddmm_1d(self):
        t1=TensorBase(np.array([1,2,3]))
        t2=TensorBase(np.array([2,3,4]))
        mat=TensorBase(np.array([5]))
        t1.addmm_(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(t1.data,[50]))
E       AssertionError: False is not true

tests/test_tensor.py:141: AssertionError
_____________________________________________________________________ addmm.testaddmm_2d ______________________________________________________________________

self = <PySyft.tests.test_tensor.addmm testMethod=testaddmm_2d>

    def testaddmm_2d(self):
        t1=TensorBase(np.array([[1,2],[1,2]]))
        t2=TensorBase(np.array([[1,2],[1,2]]))
        mat=TensorBase(np.array([[2,3],[3,4]]))
        t1.addmm_(t2,mat,beta=2,alpha=2)
>       self.assertTrue(np.array_equal(t1.data,[[10,18],[12,20]]))
E       AssertionError: False is not true

tests/test_tensor.py:148: AssertionError
============================================================= 4 failed, 29 passed in 0.24 seconds =============================================================
```The error is coming due to the new inplace implementations of +. I will make the changes with the newer implementation of addmm as disscussed with @samsontmr Done
More tests are failing after those were fixed:
![image](https://user-images.githubusercontent.com/6272414/29462390-cdb14a52-83f4-11e7-8782-f1daaa145c12.png)
okay there is a d missing in def will change it",4,2017-08-15 09:13:58,2017-08-18 16:04:47,2017-08-18 16:04:46
https://github.com/OpenMined/PySyft/issues/125,['bug '],Failed to install Syft on MacOs,"Failed to install Syft on MacOsHello,
I followed the instructions to install PySyft.
But I failed to get all the dependencies after running 
`pip install -r requirements.txt`

the Error messages are the following:
`Collecting singledispatch (from tornado>=4->notebook->jupyter->-r requirements.txt (line 5))
  Downloading singledispatch-3.4.0.3-py2.py3-none-any.whl
Requirement already satisfied: certifi in /Library/Python/2.7/site-packages (from tornado>=4->notebook->jupyter->-r requirements.txt (line 5))
Collecting backports_abc>=0.4 (from tornado>=4->notebook->jupyter->-r requirements.txt (line 5))
  Downloading backports_abc-0.5-py2.py3-none-any.whl
Requirement already satisfied: functools32; python_version == ""2.7"" in /Library/Python/2.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbconvert->jupyter->-r requirements.txt (line 5))
Collecting webencodings (from html5lib>=0.99999999->bleach->nbconvert->jupyter->-r requirements.txt (line 5))
  Downloading webencodings-0.5.1-py2.py3-none-any.whl
Installing collected packages: gmpy2, phe, decorator, ipython-genutils, traitlets, scandir, pathlib2, wcwidth, prompt-toolkit, pickleshare, appnope, IPython, line-profiler, mistune, jupyter-core, nbformat, configparser, entrypoints, pandocfilters, testpath, webencodings, html5lib, bleach, nbconvert, singledispatch, backports-abc, tornado, python-dateutil, pyzmq, jupyter-client, ipykernel, terminado, notebook, jupyter-console, widgetsnbextension, ipywidgets, qtconsole, jupyter, args, clint
  Running setup.py install for gmpy2 ... error
    Complete output from command /usr/bin/python -u -c ""import setuptools, tokenize;__file__='/private/tmp/pip-build-rPx3Nd/gmpy2/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-RaN8cm-record/install-record.txt --single-version-externally-managed --compile:
    running install
    running build
    running build_ext
    building 'gmpy2' extension
    creating build
    creating build/temp.macosx-10.11-intel-2.7
    creating build/temp.macosx-10.11-intel-2.7/src
    cc -fno-strict-aliasing -fno-common -dynamic -arch i386 -arch x86_64 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch i386 -arch x86_64 -pipe -DWITHMPFR -DWITHMPC -I/usr/local/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c src/gmpy2.c -o build/temp.macosx-10.11-intel-2.7/src/gmpy2.o
    In file included from src/gmpy2.c:426:
    src/gmpy.h:252:12: fatal error: 'mpfr.h' file not found
    #  include ""mpfr.h""
               ^
    1 error generated.
    error: command 'cc' failed with exit status 1
    
    ----------------------------------------
Command ""/usr/bin/python -u -c ""import setuptools, tokenize;__file__='/private/tmp/pip-build-rPx3Nd/gmpy2/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-RaN8cm-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/tmp/pip-build-rPx3Nd/gmpy2/`
I recommend installing the tricky packages using `conda`. You can install the rest (which are not on the anaconda cloud) using `pip`.This is maybe because you need specific OS depencies to install Syft. I resolved this issue in ubuntu by installing:

```
libgmp-dev
libmpfr-dev
libmpc-dev
```

You could probably install these with the brew macOS package manager and retry Syft installation.Try installing https://github.com/OpenMined/PySonar/blob/master/README.md#base-libraries before pip install@swaroopch's solution worked on MacOS@swaroopch should we add this to the PySyft readme under just MacOs or others more generally?@iamtrask Added https://github.com/OpenMined/PySyft/pull/203",6,2017-08-13 11:50:18,2017-09-02 19:50:07,2017-09-02 19:50:07
https://github.com/OpenMined/PySyft/issues/119,[],Set up CI for automated testing and style checks,"Set up CI for automated testing and style checksNow that our codebase is growing (hooray!), we should set up CI for automated testing and style checks (PEP8, PEP257). 

Choices include [CircleCI](https://circleci.com) and [TravisCI](https://travis-ci.org). These can be integrated into our repo such that every pull request will be checked before review. I have used Travis before and could set it up to run tests and check for any style guide violations tomorrow. Assign it to me if nobody else is already working on it.

Quick question: Should the build fail if something violates PEP8/PEP257? > Quick question: Should the build fail if something violates PEP8/PEP257?

Yes!I would recommend using https://pypi.python.org/pypi/flake8",3,2017-08-12 04:33:36,2017-08-17 22:53:56,2017-08-17 22:53:56
https://github.com/OpenMined/PySyft/issues/118,['bug '],__mul__ not correctly implemented,"__mul__ not correctly implementedIn the `PaillierFloat` implementation, multiplication with another `PaillierFloat` is also implemented, whereas in the `python-paillier` library, it is not possible to multiply two `EncodedNumber`s ([ref.](https://github.com/n1analytics/python-paillier/blob/master/phe/paillier.py#L746-L748)).

https://github.com/OpenMined/PySyft/blob/16dae46b154dd755c18e941409b4ec771f5e2ca5/syft/he/Paillier.py#L97
Great catch! Fixed. :)",1,2017-08-11 21:27:49,2017-09-05 11:04:27,2017-09-05 11:04:26
https://github.com/OpenMined/PySyft/issues/115,[],Error while building Docker image,"Error while building Docker image```
Step 8 : RUN python3 setup.py install
 ---> Running in 958a320cbc46
Download error on https://pypi.python.org/simple/pytest-runner/: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749) -- Some packages may not be found!
Couldn't find index page for 'pytest-runner' (maybe misspelled?)
Download error on https://pypi.python.org/simple/: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749) -- Some packages may not be found!
No local packages or working download links found for pytest-runner
Traceback (most recent call last):
  File ""setup.py"", line 31, in <module>
    tests_require=['pytest']
  File ""/usr/lib/python3.6/distutils/core.py"", line 108, in setup
    _setup_distribution = dist = klass(attrs)
  File ""/usr/lib/python3.6/site-packages/setuptools/dist.py"", line 315, in __init__
    self.fetch_build_eggs(attrs['setup_requires'])
  File ""/usr/lib/python3.6/site-packages/setuptools/dist.py"", line 361, in fetch_build_eggs
    replace_conflicting=True,
  File ""/usr/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 850, in resolve
    dist = best[req.key] = env.best_match(req, ws, installer)
  File ""/usr/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1122, in best_match
    return self.obtain(req, installer)
  File ""/usr/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1134, in obtain
    return installer(requirement)
  File ""/usr/lib/python3.6/site-packages/setuptools/dist.py"", line 429, in fetch_build_egg
    return cmd.easy_install(req)
  File ""/usr/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 659, in easy_install
    raise DistutilsError(msg)
distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('pytest-runner')
The command 'python3 setup.py install' returned a non-zero code: 1
```@cypherai: What's your Docker version?  And what OS?  Cause it works for me.```
Server Version: 1.12.6
Kernel Version: 4.4.0-1030-aws
Operating System: Ubuntu 16.04.2 LTS
OSType: linux
```",2,2017-08-11 10:44:58,2017-08-12 13:18:54,2017-08-12 13:18:54
https://github.com/OpenMined/PySyft/issues/74,[],Implement Default nelement Functionality for Base Tensor Type,"Implement Default nelement Functionality for Base Tensor Type**User Story A:** As a Data Scientist using Syft's Base Tensor type, I want to leverage a default method for computing operations on a Tensor of arbitrary type. For this ticket to be complete, nelement() should return a new tensor. For a reference on the operation this performs check out [PyTorch](http://pytorch.org/docs/master/tensors.html)'s documentation.

**Acceptance Criteria:**
- If the Base Tensor type's attribute ""encrypted"" is set to True, it should return a NotImplemented error.
- a unit test demonstrating the correct operation on the Base Tensor type implemented over int and float Tensors.
- inline documentation in the python code. For inspiration on inline documentation, please check out [PyTorch](http://pytorch.org/docs/master/tensors.html)'s documentation for this operator.Referencing PyTorch's documentation of [`nelement()`](http://pytorch.org/docs/master/tensors.html#torch.Tensor.nelement), it appears that the operation should be returning an integer instead of a tensor. @iamtrask can you clarify please?ahhh yes definitely follow Pytorch's convention there... my bad :)great catch!",3,2017-08-10 00:00:39,2017-10-01 05:06:04,2017-10-01 05:06:03